<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="http://manishearth.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="http://manishearth.github.io/" rel="alternate" type="text/html" /><updated>2022-08-03T06:15:40+00:00</updated><id>http://manishearth.github.io/feed.xml</id><title type="html">In Pursuit of Laziness</title><author><name>Manish Goregaokar</name></author><entry><title type="html">A Tour of Safe Tracing GC Designs in Rust</title><link href="http://manishearth.github.io/blog/2021/04/05/a-tour-of-safe-tracing-gc-designs-in-rust/" rel="alternate" type="text/html" title="A Tour of Safe Tracing GC Designs in Rust" /><published>2021-04-05T00:00:00+00:00</published><updated>2021-04-05T00:00:00+00:00</updated><id>http://manishearth.github.io/blog/2021/04/05/a-tour-of-safe-tracing-gc-designs-in-rust</id><content type="html" xml:base="http://manishearth.github.io/blog/2021/04/05/a-tour-of-safe-tracing-gc-designs-in-rust/"><![CDATA[<p>I’ve been thinking about garbage collection in Rust for a long time, ever since I started working on <a href="https://github.com/servo/servo">Servo</a>’s JS layer. I’ve <a href="https://manishearth.github.io/blog/2015/09/01/designing-a-gc-in-rust/">designed a GC library</a>, <a href="https://manishearth.github.io/blog/2016/08/18/gc-support-in-rust-api-design/">worked on GC integration ideas for Rust itself</a>, worked on Servo’s JS GC integration, and helped out with a <a href="https://github.com/asajeffrey/josephine">couple</a> <a href="https://github.com/kyren/gc-arena">other</a> GC projects in Rust.</p>

<p>As a result, I tend to get pulled into GC discussions fairly often. I enjoy talking about GCs – don’t get me wrong – but I often end up going over the same stuff. Being <a href="https://manishearth.github.io/blog/2018/08/26/why-i-enjoy-blogging/#blogging-lets-me-be-lazy">lazy</a> I’d much prefer to be able to refer people to a single place where they can get up to speed on the general space of GC design, after which it’s possible to have more in depth discussions about the specific tradeoffs necessary.</p>

<p>I’ll note that some of the GCs in this post are experiments or unmaintained. The goal of this post is to showcase these as examples of <em>design</em>, not necessarily general-purpose crates you may wish to use, though some of them are usable crates as well.</p>

<h3 id="a-note-on-terminology">A note on terminology</h3>

<p>A thing that often muddles discussions about GCs is that according to some definition of “GC”, simple reference counting <em>is</em> a GC. Typically the definition of GC used in academia broadly refers to any kind of automatic memory management. However, most programmers familiar with the term “GC” will usually liken it to “what Java, Go, Haskell, and C# do”, which can be unambiguously referred to as <em>tracing</em> garbage collection.</p>

<p>Tracing garbage collection is the kind which keeps track of which heap objects are directly reachable (“roots”), figures out the whole set of reachable heap objects (“tracing”, also, “marking”), and then cleans them up (“sweeping”).</p>

<p>Throughout this blog post I will use the term “GC” to refer to tracing garbage collection/collectors unless otherwise stated<sup id="fnref:0" role="doc-noteref"><a href="#fn:0" class="footnote" rel="footnote">1</a></sup>.</p>

<h2 id="why-write-gcs-for-rust">Why write GCs for Rust?</h2>

<p>(If you already want to write a GC in Rust and are reading this post to get ideas for <em>how</em>, you can skip this section. You already know why someone would want to write a GC for Rust)</p>

<p>Every time this topic is brought up someone will inevitably go “I thought the point of Rust was to avoid GCs” or “GCs will ruin Rust” or something. As a general rule it’s good to not give too much weight to the comments section, but I think it’s useful to explain why someone may wish for GC-like semantics in Rust.</p>

<p>There are really two distinct kinds of use cases. Firstly, sometimes you need to manage memory with cycles and <code class="language-plaintext highlighter-rouge">Rc&lt;T&gt;</code> is inadequate for the job since <code class="language-plaintext highlighter-rouge">Rc</code>-cycles get leaked. <a href="https://docs.rs/petgraph/"><code class="language-plaintext highlighter-rouge">petgraph</code></a> or an <a href="https://manishearth.github.io/blog/2021/03/15/arenas-in-rust/">arena</a> are often acceptable solutions for this kind of pattern, but not always, especially if your data is super heterogeneous. This kind of thing crops up often when dealing with concurrent datastructures; for example <a href="https://docs.rs/crossbeam/"><code class="language-plaintext highlighter-rouge">crossbeam</code></a> has <a href="https://docs.rs/crossbeam/0.8.0/crossbeam/epoch/index.html">an epoch-based memory management system</a> which, while not a full tracing GC, has a lot of characteristics in common with GCs.</p>

<p>For this use case it’s rarely necessary to design a custom GC, you can look for a reusable crate like <a href="https://docs.rs/gc/"><code class="language-plaintext highlighter-rouge">gc</code></a> <sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">2</a></sup>.</p>

<p>The second case is far more interesting in my experience, and since it cannot be solved by off-the-shelf solutions tends to crop up more often: integration with (or implementation of) programming languages that <em>do</em> use a garbage collector. <a href="https://github.com/servo/servo">Servo</a> needs to do this for integrating with the Spidermonkey JS engine and <a href="https://github.com/kyren/luster">luster</a> needed to do this for implementing the GC of its Lua VM. <a href="https://github.com/jasonwilliams/boa/">boa</a>, a pure Rust JS runtime, uses the <a href="https://docs.rs/gc/"><code class="language-plaintext highlighter-rouge">gc</code></a> crate to back its garbage collector.</p>

<p>Sometimes when integrating with a GCd language you can get away with not needing to implement a full garbage collector: JNI does this; while C++ does not have native garbage collection, JNI gets around this by simply “rooting” (we’ll cover what that means in a bit) anything that crosses over to the C++ side<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">3</a></sup>. This is often fine!</p>

<p>The downside of this is that every interaction with objects managed by the GC has to go through an API call; you can’t “embed” efficient Rust/C++ objects in the GC with ease. For example, in browsers most DOM types (e.g. <a href="https://doc.servo.org/script/dom/element/struct.Element.html"><code class="language-plaintext highlighter-rouge">Element</code></a>) are implemented in native code; and need to be able to contain references to other native GC’d types (it should be possible to inspect the <a href="https://doc.servo.org/script/dom/node/struct.Node.html#structfield.child_list">children of a <code class="language-plaintext highlighter-rouge">Node</code></a> without needing to call back into the JavaScript engine).</p>

<p>So sometimes you need to be able to integrate with a GC from a runtime; or even implement your own GC if you are writing a runtime that needs one. In both of these cases you typically want to be able to safely manipulate GC’d objects from Rust code, and even directly put Rust types on the GC heap.</p>

<h2 id="why-are-gcs-in-rust-hard">Why are GCs in Rust hard?</h2>

<p>In one word: Rooting. In a garbage collector, the objects “directly” in use on the stack are the “roots”, and you need to be able to identify them. Here, when I say “directly”, I mean “accessible without having to go through other GC’d objects”, so putting an object inside a <code class="language-plaintext highlighter-rouge">Vec&lt;T&gt;</code> does not make it stop being a root, but putting it inside some other GC’d object does.</p>

<p>Unfortunately, Rust doesn’t really have a concept of “directly on the stack”:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">struct</span> <span class="n">Foo</span> <span class="p">{</span>
    <span class="n">bar</span><span class="p">:</span> <span class="nb">Option</span><span class="o">&lt;</span><span class="nb">Gc</span><span class="o">&lt;</span><span class="n">Bar</span><span class="o">&gt;&gt;</span>
<span class="p">}</span>
<span class="c1">// this is a root</span>
<span class="k">let</span> <span class="n">bar</span> <span class="o">=</span> <span class="nn">Gc</span><span class="p">::</span><span class="nf">new</span><span class="p">(</span><span class="nn">Bar</span><span class="p">::</span><span class="nf">new</span><span class="p">());</span>
<span class="c1">// this is also a root</span>
<span class="k">let</span> <span class="n">foo</span> <span class="o">=</span> <span class="nn">Gc</span><span class="p">::</span><span class="nf">new</span><span class="p">(</span><span class="nn">Foo</span><span class="p">::</span><span class="nf">new</span><span class="p">());</span>
<span class="c1">// bar should no longer be a root (but we can't detect that!)</span>
<span class="n">foo</span><span class="py">.bar</span> <span class="o">=</span> <span class="nf">Some</span><span class="p">(</span><span class="n">bar</span><span class="p">);</span>
<span class="c1">// but foo should still be a root here since it's not inside</span>
<span class="c1">// another GC'd object</span>
<span class="k">let</span> <span class="n">v</span> <span class="o">=</span> <span class="nd">vec!</span><span class="p">[</span><span class="n">foo</span><span class="p">];</span>
</code></pre></div></div>

<p>Rust’s ownership system actually makes it easier to have fewer roots since it’s relatively easy to state that taking <code class="language-plaintext highlighter-rouge">&amp;T</code> of a GC’d object doesn’t need to create a new root, and let Rust’s ownership system sort it out, but being able to distinguish between “directly owned” and “indirectly owned” is super tricky.</p>

<p>Another aspect of this is that garbage collection is really a moment of global mutation – the garbage collector reads through the heap and then deletes some of the objects there. This is a moment of the rug being pulled out under your feet. Rust’s entire design is predicated on such rug-pulling being <em>very very bad and not to be allowed</em>, so this can be a bit problematic. This isn’t as bad as it may initially sound because after all the rug-pulling is mostly just cleaning up unreachable objects, but it does crop up a couple times when fitting things together, especially around destructors and finalizers<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote" rel="footnote">4</a></sup>. Rooting would be far easier if, for example, you were able to declare areas of code where “no GC can happen”<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" class="footnote" rel="footnote">5</a></sup> so you can tightly scope the rug-pulling and have to worry less about roots.</p>

<h3 id="destructors-and-finalizers">Destructors and finalizers</h3>

<p>It’s worth calling out destructors in particular. A huge problem with custom destructors on GCd types is that the custom destructor totally can stash itself away into a long-lived reference during garbage collection, leading to a dangling reference:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">struct</span> <span class="n">LongLived</span> <span class="p">{</span>
    <span class="n">dangle</span><span class="p">:</span> <span class="n">RefCell</span><span class="o">&lt;</span><span class="nb">Option</span><span class="o">&lt;</span><span class="nb">Gc</span><span class="o">&lt;</span><span class="n">CantKillMe</span><span class="o">&gt;&gt;&gt;</span>
<span class="p">}</span>

<span class="k">struct</span> <span class="n">CantKillMe</span> <span class="p">{</span>
    <span class="c1">// set up to point to itself during construction</span>
    <span class="n">self_ref</span><span class="p">:</span> <span class="n">RefCell</span><span class="o">&lt;</span><span class="nb">Option</span><span class="o">&lt;</span><span class="nb">Gc</span><span class="o">&lt;</span><span class="n">CantKillMe</span><span class="o">&gt;&gt;&gt;</span>
    <span class="n">long_lived</span><span class="p">:</span> <span class="nb">Gc</span><span class="o">&lt;</span><span class="n">LongLived</span><span class="o">&gt;</span>
<span class="p">}</span>

<span class="k">impl</span> <span class="nb">Drop</span> <span class="k">for</span> <span class="n">CantKillMe</span> <span class="p">{</span>
    <span class="k">fn</span> <span class="nf">drop</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">)</span> <span class="p">{</span>
        <span class="c1">// attach self to long_lived</span>
        <span class="o">*</span><span class="k">self</span><span class="py">.long_lived.dangle</span><span class="nf">.borrow_mut</span><span class="p">()</span> <span class="o">=</span> <span class="nf">Some</span><span class="p">(</span><span class="k">self</span><span class="py">.self_ref</span><span class="nf">.borrow</span><span class="p">()</span><span class="nf">.clone</span><span class="p">()</span><span class="nf">.unwrap</span><span class="p">());</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="k">let</span> <span class="n">long</span> <span class="o">=</span> <span class="nn">Gc</span><span class="p">::</span><span class="nf">new</span><span class="p">(</span><span class="nn">LongLived</span><span class="p">::</span><span class="nf">new</span><span class="p">());</span>
<span class="p">{</span>
    <span class="k">let</span> <span class="n">cant</span> <span class="o">=</span> <span class="nn">Gc</span><span class="p">::</span><span class="nf">new</span><span class="p">(</span><span class="nn">CantKillMe</span><span class="p">::</span><span class="nf">new</span><span class="p">());</span>
    <span class="o">*</span><span class="n">cant</span><span class="py">.self_ref</span><span class="nf">.borrow_mut</span><span class="p">()</span> <span class="o">=</span> <span class="nf">Some</span><span class="p">(</span><span class="n">cant</span><span class="nf">.clone</span><span class="p">());</span>
    <span class="c1">// cant goes out of scope, CantKillMe::drop is run</span>
    <span class="c1">// cant is attached to long_lived.dangle but still cleaned up</span>
<span class="p">}</span>

<span class="c1">// Dangling reference!</span>
<span class="k">let</span> <span class="n">dangling</span> <span class="o">=</span> <span class="n">long</span><span class="py">.dangle</span><span class="nf">.borrow</span><span class="p">()</span><span class="nf">.unwrap</span><span class="p">();</span>
</code></pre></div></div>

<p>The most common  solution here is to disallow destructors on types that use <code class="language-plaintext highlighter-rouge">#[derive(Trace)]</code>, which can be done by having the custom derive generate a <code class="language-plaintext highlighter-rouge">Drop</code> implementation, or have it generate something which causes a conflicting type error.</p>

<p>You can additionally provide a <code class="language-plaintext highlighter-rouge">Finalize</code> trait that has different semantics: the GC calls it while cleaning up GC objects, but it may be called multiple times or not at all. This kind of thing is typical in GCs outside of Rust as well.</p>

<h2 id="how-would-you-even-garbage-collect-without-a-runtime">How would you even garbage collect without a runtime?</h2>

<p>In most garbage collected languages, there’s a runtime that controls all execution, knows about every variable in the program, and is able to pause execution to run the GC whenever it likes.</p>

<p>Rust has a minimal runtime and can’t do anything like this, especially not in a pluggable way your library can hook in to. For thread local GCs you basically have to write it such that GC operations (things like mutating a GC field; basically some subset of the APIs exposed by your GC library) are the only things that may trigger the garbage collector.</p>

<p>Concurrent GCs can trigger the GC on a separate thread but will typically need to pause other threads whenever these threads attempt to perform a GC operation that could potentially be invalidated by the running garbage collector.</p>

<p>While this may restrict the flexibility of the garbage collector itself, this is actually pretty good for us from the side of API design: the garbage collection phase can only happen in certain well-known moments of the code, which means we only need to make things safe across <em>those</em> boundaries. Many of the designs we shall look at build off of this observation.</p>

<h2 id="commonalities">Commonalities</h2>

<p>Before getting into the actual examples of GC design, I want to point out some commonalities of design between all of them, especially around how they do tracing:</p>

<h3 id="tracing">Tracing</h3>

<p>“Tracing” is the operation of traversing the graph of GC objects, starting from your roots and perusing their children, and their children’s children, and so on.</p>

<p>In Rust, the easiest way to implement this is via a <a href="https://doc.rust-lang.org/book/ch19-06-macros.html#how-to-write-a-custom-derive-macro">custom derive</a>:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// unsafe to implement by hand since you can get it wrong</span>
<span class="k">unsafe</span> <span class="k">trait</span> <span class="n">Trace</span> <span class="p">{</span>
    <span class="k">fn</span> <span class="nf">trace</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">,</span> <span class="n">gc_context</span><span class="p">:</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="n">GcContext</span><span class="p">);</span>
<span class="p">}</span>

<span class="nd">#[derive(Trace)]</span>
<span class="k">struct</span> <span class="n">Foo</span> <span class="p">{</span>
    <span class="n">vec</span><span class="p">:</span> <span class="nb">Vec</span><span class="o">&lt;</span><span class="nb">Gc</span><span class="o">&lt;</span><span class="n">Bar</span><span class="o">&gt;&gt;</span><span class="p">,</span>
    <span class="n">extra_thing</span><span class="p">:</span> <span class="nb">Gc</span><span class="o">&lt;</span><span class="n">Baz</span><span class="o">&gt;</span><span class="p">,</span>
    <span class="n">just_a_string</span><span class="p">:</span> <span class="nb">String</span>
<span class="p">}</span>
</code></pre></div></div>

<p>The custom derive of <code class="language-plaintext highlighter-rouge">Trace</code> basically just calls <code class="language-plaintext highlighter-rouge">trace()</code> on all the fields. <code class="language-plaintext highlighter-rouge">Vec</code>’s <code class="language-plaintext highlighter-rouge">Trace</code> implementation will be written to call <code class="language-plaintext highlighter-rouge">trace()</code> on all of its fields, and <code class="language-plaintext highlighter-rouge">String</code>’s <code class="language-plaintext highlighter-rouge">Trace</code> implementation will do nothing. <code class="language-plaintext highlighter-rouge">Gc&lt;T&gt;</code> will likely have a <code class="language-plaintext highlighter-rouge">trace()</code> that marks its reachability in the <code class="language-plaintext highlighter-rouge">GcContext</code>, or something similar.</p>

<p>This is a pretty standard pattern, and while the specifics of the <code class="language-plaintext highlighter-rouge">Trace</code> trait will typically vary, the general idea is roughly the same.</p>

<p>I’m not going to get into the actual details of how mark-and-sweep algorithms work in this post; there are a lot of potential designs for them and they’re not that interesting from the point of view of designing a safe GC <em>API</em> in Rust. However, the general idea is to keep a queue of found objects initially populated by the root, trace them to find new objects and queue them up if they’ve not already been traced. Clean up any objects that were <em>not</em> found.</p>

<h3 id="immutable-by-default">Immutable-by-default</h3>

<p>Another commonality between these designs is that a <code class="language-plaintext highlighter-rouge">Gc&lt;T&gt;</code> is always potentially shared, and thus will need tight control over mutability to satisfy Rust’s ownership invariants. This is typically achieved by using interior mutability, much like how <code class="language-plaintext highlighter-rouge">Rc&lt;T&gt;</code> is almost always paired with <code class="language-plaintext highlighter-rouge">RefCell&lt;T&gt;</code> for mutation, however some approaches (like that in <a href="https://github.com/asajeffrey/josephine">josephine</a>) do allow for mutability without runtime checking.</p>

<h3 id="threading">Threading</h3>

<p>Some GCs are single-threaded, and some are multi-threaded. The single threaded ones typically have a <code class="language-plaintext highlighter-rouge">Gc&lt;T&gt;</code> type that is not <code class="language-plaintext highlighter-rouge">Send</code>, so while you can set up multiple graphs of GC types on different threads, they’re essentially independent. Garbage collection only affects the thread it is being performed for, all other threads can continue unhindered.</p>

<p>Multithreaded GCs will have a <code class="language-plaintext highlighter-rouge">Send</code> <code class="language-plaintext highlighter-rouge">Gc&lt;T&gt;</code> type. Garbage collection will typically, but not always, block any thread which attempts to access data managed by the GC during that time. In some languages there are “stop the world” garbage collectors which block all threads at “safepoints” inserted by the compiler; Rust does not have the capability to insert such safepoints and blocking threads on GCs is done at the library level.</p>

<p>Most of the examples below are single-threaded, but their API design is not hard to extend towards a hypothetical multithreaded GC.</p>

<h2 id="rust-gc">rust-gc</h2>

<p>The <a href="https://docs.rs/gc/"><code class="language-plaintext highlighter-rouge">gc</code></a> crate is one I wrote with <a href="https://twitter.com/kneecaw/">Nika Layzell</a> mostly as a fun exercise, to figure out if a safe GC API is <em>possible</em>. I’ve <a href="https://manishearth.github.io/blog/2015/09/01/designing-a-gc-in-rust/">written about the design in depth before</a>, but the essence of the design is that it does something similar to reference counting to keep track of roots, and forces all GC mutations go through special <code class="language-plaintext highlighter-rouge">GcCell</code> types so that they can update the root count. Basically, a “root count” is updated whenever something becomes a root or stops being a root:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">struct</span> <span class="n">Foo</span> <span class="p">{</span>
    <span class="n">bar</span><span class="p">:</span> <span class="n">GcCell</span><span class="o">&lt;</span><span class="nb">Option</span><span class="o">&lt;</span><span class="nb">Gc</span><span class="o">&lt;</span><span class="n">Bar</span><span class="o">&gt;&gt;&gt;</span>
<span class="p">}</span>
<span class="c1">// this is a root (root count = 1)</span>
<span class="k">let</span> <span class="n">bar</span> <span class="o">=</span> <span class="nn">Gc</span><span class="p">::</span><span class="nf">new</span><span class="p">(</span><span class="nn">Bar</span><span class="p">::</span><span class="nf">new</span><span class="p">());</span>
<span class="c1">// this is also a root (root count = 1)</span>
<span class="k">let</span> <span class="n">foo</span> <span class="o">=</span> <span class="nn">Gc</span><span class="p">::</span><span class="nf">new</span><span class="p">(</span><span class="nn">Foo</span><span class="p">::</span><span class="nf">new</span><span class="p">());</span>
<span class="c1">// .borrow_mut()'s RAII guard unroots bar (sets its root count to 0)</span>
<span class="o">*</span><span class="n">foo</span><span class="py">.bar</span><span class="nf">.borrow_mut</span><span class="p">()</span> <span class="o">=</span> <span class="nf">Some</span><span class="p">(</span><span class="n">bar</span><span class="p">);</span>
<span class="c1">// foo is still a root here, no call to .set()</span>
<span class="k">let</span> <span class="n">v</span> <span class="o">=</span> <span class="nd">vec!</span><span class="p">[</span><span class="n">foo</span><span class="p">];</span>

<span class="c1">// at destrucion time, foo's root count is set to 0</span>
</code></pre></div></div>

<p>The actual garbage collection phase will occur when certain GC operations are performed at a time when the heap is considered to have gotten reasonably large according to some heuristics.</p>

<p>While this is essentially “free” on reads, this is a fair amount of reference count traffic on any kind of write, which might not be desired; often the goal of using GCs is to <em>avoid</em> the performance characteristics of reference-counting-like patterns. Ultimately this is a hybrid approach that’s a mix of tracing and reference counting<sup id="fnref:10" role="doc-noteref"><a href="#fn:10" class="footnote" rel="footnote">6</a></sup>.</p>

<p><a href="https://docs.rs/gc/"><code class="language-plaintext highlighter-rouge">gc</code></a> is useful as a general-purpose GC if you just want a couple of things to participate in cycles without having to think about it too much. The general design can apply to a specialized GC integrating with another language runtime since it provides a clear way to keep track of roots; but it may not necessarily have the desired performance characteristics.</p>

<h2 id="servos-dom-integration">Servo’s DOM integration</h2>

<p><a href="https://github.com/servo/servo">Servo</a> is a browser engine in Rust that I used to work on full time. As mentioned earlier, browser engines typically implement a lot of their DOM types in native (i.e. Rust or C++, not JS) code, so for example <a href="https://doc.servo.org/script/dom/element/struct.Element.html"><code class="language-plaintext highlighter-rouge">Node</code></a> is a pure Rust object, and it <a href="https://doc.servo.org/script/dom/node/struct.Node.html#structfield.child_list">contains direct references to its children</a> so Rust code can do things like traverse the tree without having to go back and forth between JS and Rust.</p>

<p>Servo’s model is a little weird: roots are a <em>different type</em>, and lints enforce that unrooted heap references are never placed on the stack:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">#[dom_struct]</span> <span class="c1">// this is #[derive(JSTraceable)] plus some markers for lints</span>
<span class="k">pub</span> <span class="k">struct</span> <span class="n">Node</span> <span class="p">{</span>
    <span class="c1">// the parent type, for inheritance</span>
    <span class="n">eventtarget</span><span class="p">:</span> <span class="n">EventTarget</span><span class="p">,</span>
    <span class="c1">// in the actual code this is a different helper type that combines</span>
    <span class="c1">// the RefCell, Option, and Dom, but i've simplified it to use</span>
    <span class="c1">// stdlib types for this example</span>
    <span class="n">prev_sibling</span><span class="p">:</span> <span class="n">RefCell</span><span class="o">&lt;</span><span class="nb">Option</span><span class="o">&lt;</span><span class="n">Dom</span><span class="o">&lt;</span><span class="n">Node</span><span class="o">&gt;&gt;&gt;</span><span class="p">,</span>
    <span class="n">next_sibling</span><span class="p">:</span> <span class="n">RefCell</span><span class="o">&lt;</span><span class="nb">Option</span><span class="o">&lt;</span><span class="n">Dom</span><span class="o">&lt;</span><span class="n">Node</span><span class="o">&gt;&gt;&gt;</span><span class="p">,</span>
    <span class="c1">// ...</span>
<span class="p">}</span>

<span class="k">impl</span> <span class="n">Node</span> <span class="p">{</span>
    <span class="k">fn</span> <span class="nf">frob_next_sibling</span><span class="p">(</span><span class="o">&amp;</span><span class="k">self</span><span class="p">)</span> <span class="p">{</span>
        <span class="c1">// fields can be accessed as borrows without any rooting</span>
        <span class="k">if</span> <span class="k">let</span> <span class="nf">Some</span><span class="p">(</span><span class="n">next</span><span class="p">)</span> <span class="o">=</span> <span class="k">self</span><span class="py">.next_sibling</span><span class="nf">.borrow</span><span class="p">()</span><span class="nf">.as_ref</span><span class="p">()</span> <span class="p">{</span>
            <span class="n">next</span><span class="nf">.frob</span><span class="p">();</span>
        <span class="p">}</span>
    <span class="p">}</span>

    <span class="k">fn</span> <span class="nf">get_next_sibling</span><span class="p">(</span><span class="o">&amp;</span><span class="k">self</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">Option</span><span class="o">&lt;</span><span class="n">DomRoot</span><span class="o">&lt;</span><span class="n">Node</span><span class="o">&gt;&gt;</span> <span class="p">{</span>
        <span class="c1">// but you need to root things for them to escape the borrow</span>
        <span class="c1">// .root() turns Dom&lt;T&gt; into DomRoot&lt;T&gt;</span>
        <span class="k">self</span><span class="py">.next_sibling</span><span class="nf">.borrow</span><span class="p">()</span><span class="nf">.as_ref</span><span class="p">()</span><span class="nf">.map</span><span class="p">(|</span><span class="n">x</span><span class="p">|</span> <span class="n">x</span><span class="nf">.root</span><span class="p">())</span>
    <span class="p">}</span>

    <span class="k">fn</span> <span class="nf">illegal</span><span class="p">(</span><span class="o">&amp;</span><span class="k">self</span><span class="p">)</span> <span class="p">{</span>
        <span class="c1">// this line of code would get linted by a custom lint called unrooted_must_root</span>
        <span class="c1">// (which works somewhat similarly to the must_use stuff that Rust does)</span>
        <span class="k">let</span> <span class="n">ohno</span><span class="p">:</span> <span class="n">Dom</span><span class="o">&lt;</span><span class="n">Node</span><span class="o">&gt;</span> <span class="o">=</span> <span class="k">self</span><span class="py">.next_sibling</span><span class="nf">.borrow_mut</span><span class="p">()</span><span class="nf">.take</span><span class="p">();</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Dom&lt;T&gt;</code> is basically a smart pointer that behaves like <code class="language-plaintext highlighter-rouge">&amp;T</code> but without a lifetime, whereas <code class="language-plaintext highlighter-rouge">DomRoot&lt;T&gt;</code> has the additional behavior of rooting on creation (and unrooting on <code class="language-plaintext highlighter-rouge">Drop</code>). The custom lint plugin essentially enforces that <code class="language-plaintext highlighter-rouge">Dom&lt;T&gt;</code>, and any DOM structs (tagged with <code class="language-plaintext highlighter-rouge">#[dom_struct]</code>) are never accessible on the stack aside from through <code class="language-plaintext highlighter-rouge">DomRoot&lt;T&gt;</code> or <code class="language-plaintext highlighter-rouge">&amp;T</code>.</p>

<p>I wouldn’t recommend this approach; it works okay but we’ve wanted to move off of it for a while because it relies on custom plugin lints for soundness. But it’s worth mentioning for completeness.</p>

<h2 id="josephine-servos-experimental-gc-plans">Josephine (Servo’s experimental GC plans)</h2>

<p>Given that Servo’s existing GC solution depends on plugging in to the compiler to do additional static analysis, we wanted something better. So <a href="https://github.com/asajeffrey/">Alan</a> designed <a href="https://github.com/asajeffrey/josephine">Josephine</a> (“JS affine”), which uses Rust’s affine types and borrowing in a cleaner way to provide a safe GC system.</p>

<p>Josephine is explicitly designed for Servo’s use case and as such does a lot of neat things around “compartments” and such that are probably irrelevant unless you specifically wish for your GC to integrate with a JS engine.</p>

<p>I mentioned earlier that the fact that the garbage collection phase can only happen in certain well-known moments of the code actually can make things easier for GC design, and Josephine is an example of this.</p>

<p>Josephine has a “JS context”, which is to be passed around everywhere and essentially represents the GC itself. When doing operations which may trigger a GC, you have to borrow the context mutably, whereas when accessing heap objects you need to borrow the context immutably. You can root heap objects to remove this requirement:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// cx is a `JSContext`, `node` is a `JSManaged&lt;'a, C, Node&gt;`</span>
<span class="c1">// assuming next_sibling and prev_sibling are not Options for simplicity</span>

<span class="c1">// borrows cx for `'b`</span>
<span class="k">let</span> <span class="n">next_sibling</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">'b</span> <span class="n">Node</span> <span class="o">=</span> <span class="n">node</span><span class="py">.next_sibling</span><span class="nf">.borrow</span><span class="p">(</span><span class="n">cx</span><span class="p">);</span>
<span class="nd">println!</span><span class="p">(</span><span class="s">"Name: {:?}"</span><span class="p">,</span> <span class="n">next_sibling</span><span class="py">.name</span><span class="p">);</span>
<span class="c1">// illegal, because cx is immutably borrowed by next_sibling</span>
<span class="c1">// node.prev_sibling.borrow_mut(cx).frob();</span>

<span class="c1">// read from next_sibling to ensure it lives this long</span>
<span class="nd">println!</span><span class="p">(</span><span class="s">"{:?}"</span><span class="p">,</span> <span class="n">next_sibling</span><span class="py">.name</span><span class="p">);</span>

<span class="k">let</span> <span class="k">ref</span> <span class="k">mut</span> <span class="n">root</span> <span class="o">=</span> <span class="n">cx</span><span class="nf">.new_root</span><span class="p">();</span>
<span class="c1">// no longer needs to borrow cx, borrows root for 'root instead</span>
<span class="k">let</span> <span class="n">next_sibling</span><span class="p">:</span> <span class="n">JSManaged</span><span class="o">&lt;</span><span class="nv">'root</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">Node</span><span class="o">&gt;</span> <span class="o">=</span> <span class="n">node</span><span class="py">.next_sibling</span><span class="nf">.in_root</span><span class="p">(</span><span class="n">root</span><span class="p">);</span>
<span class="c1">// now it's fine, no outstanding borrows of `cx`</span>
<span class="n">node</span><span class="py">.prev_sibling</span><span class="nf">.borrow_mut</span><span class="p">(</span><span class="n">cx</span><span class="p">)</span><span class="nf">.frob</span><span class="p">();</span>

<span class="c1">// read from next_sibling to ensure it lives this long</span>
<span class="nd">println!</span><span class="p">(</span><span class="s">"{:?}"</span><span class="p">,</span> <span class="n">next_sibling</span><span class="py">.name</span><span class="p">);</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">new_root()</code> creates a new root, and <code class="language-plaintext highlighter-rouge">in_root</code> ties the lifetime of a JS managed type to the root instead of to the <code class="language-plaintext highlighter-rouge">JSContext</code> borrow, releasing the borrow of the <code class="language-plaintext highlighter-rouge">JSContext</code> and allowing it to be borrowed mutably in future <code class="language-plaintext highlighter-rouge">.borrow_mut()</code> calls.</p>

<p>Note that <code class="language-plaintext highlighter-rouge">.borrow()</code> and <code class="language-plaintext highlighter-rouge">.borrow_mut()</code> here do not have runtime borrow-checking cost despite their similarities to <code class="language-plaintext highlighter-rouge">RefCell::borrow()</code>, they instead are doing some lifetime juggling to make things safe. Creating roots typically does have runtime cost. Sometimes you <em>may</em> need to use <code class="language-plaintext highlighter-rouge">RefCell&lt;T&gt;</code> for the same reason it’s used in <code class="language-plaintext highlighter-rouge">Rc</code>, but mostly only for non-GCd fields.</p>

<p>Custom types are typically defined in two parts as so:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">#[derive(Copy,</span> <span class="nd">Clone,</span> <span class="nd">Debug,</span> <span class="nd">Eq,</span> <span class="nd">PartialEq,</span> <span class="nd">JSTraceable,</span> <span class="nd">JSLifetime,</span> <span class="nd">JSCompartmental)]</span>
<span class="k">pub</span> <span class="k">struct</span> <span class="n">Element</span><span class="o">&lt;</span><span class="nv">'a</span><span class="p">,</span> <span class="n">C</span><span class="o">&gt;</span> <span class="p">(</span><span class="k">pub</span> <span class="n">JSManaged</span><span class="o">&lt;</span><span class="nv">'a</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">NativeElement</span><span class="o">&lt;</span><span class="nv">'a</span><span class="p">,</span> <span class="n">C</span><span class="o">&gt;&gt;</span><span class="p">);</span>

<span class="nd">#[derive(JSTraceable,</span> <span class="nd">JSLifetime,</span> <span class="nd">JSCompartmental)]</span>
<span class="k">pub</span> <span class="k">struct</span> <span class="n">NativeElement</span><span class="o">&lt;</span><span class="nv">'a</span><span class="p">,</span> <span class="n">C</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="n">name</span><span class="p">:</span> <span class="n">JSString</span><span class="o">&lt;</span><span class="nv">'a</span><span class="p">,</span> <span class="n">C</span><span class="o">&gt;</span><span class="p">,</span>
    <span class="n">parent</span><span class="p">:</span> <span class="nb">Option</span><span class="o">&lt;</span><span class="n">Element</span><span class="o">&lt;</span><span class="nv">'a</span><span class="p">,</span> <span class="n">C</span><span class="o">&gt;&gt;</span><span class="p">,</span>
    <span class="n">children</span><span class="p">:</span> <span class="nb">Vec</span><span class="o">&lt;</span><span class="n">Element</span><span class="o">&lt;</span><span class="nv">'a</span><span class="p">,</span> <span class="n">C</span><span class="o">&gt;&gt;</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div></div>

<p>where <code class="language-plaintext highlighter-rouge">Element&lt;'a&gt;</code> is a convenient copyable reference that is to be used inside other GC types, and <code class="language-plaintext highlighter-rouge">NativeElement&lt;'a&gt;</code> is its backing storage. The <code class="language-plaintext highlighter-rouge">C</code> parameter has to do with compartments and can be ignored for now.</p>

<p>A neat thing worth pointing out is that there’s no runtime borrow checking necessary for manipulating other GC references, even though roots let you hold multiple references to the same object!</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">let</span> <span class="n">parent_root</span> <span class="o">=</span> <span class="n">cx</span><span class="nf">.new_root</span><span class="p">();</span>
<span class="k">let</span> <span class="n">parent</span> <span class="o">=</span> <span class="n">element</span><span class="nf">.borrow</span><span class="p">(</span><span class="n">cx</span><span class="p">)</span><span class="py">.parent</span><span class="nf">.in_root</span><span class="p">(</span><span class="n">parent_root</span><span class="p">);</span>
<span class="k">let</span> <span class="k">ref</span> <span class="k">mut</span> <span class="n">child_root</span> <span class="o">=</span> <span class="n">cx</span><span class="nf">.new_root</span><span class="p">();</span>

<span class="c1">// could potentially be a second reference to `element` if it was</span>
<span class="c1">// the first child</span>
<span class="k">let</span> <span class="n">first_child</span> <span class="o">=</span> <span class="n">parent</span><span class="py">.children</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="nf">.in_root</span><span class="p">(</span><span class="n">child_root</span><span class="p">);</span>

<span class="c1">// this is okay, even though we hold a reference to `parent`</span>
<span class="c1">// via element.parent, because we have rooted that reference so it's</span>
<span class="c1">// now independent of whether `element.parent` changes!</span>
<span class="n">first_child</span><span class="nf">.borrow_mut</span><span class="p">(</span><span class="n">cx</span><span class="p">)</span><span class="py">.parent</span> <span class="o">=</span> <span class="nb">None</span><span class="p">;</span>
</code></pre></div></div>

<p>Essentially, when mutating a field, you have to obtain mutable access to the context, so there will not be any references to the field itself still around (e.g. <code class="language-plaintext highlighter-rouge">element.borrow(cx).parent</code>), only to the GC’d data within it, so you can change what a field references without invalidating other references to the <em>contents</em> of what the field references. This is a pretty cool trick that enables GC <em>without runtime-checked interior mutability</em>, which is relatively rare in such designs.</p>

<h2 id="unfinished-design-for-a-builtin-rust-gc">Unfinished design for a builtin Rust GC</h2>

<p>For a while a couple of us worked on a way to make Rust <em>itself</em> extensible with a pluggable GC, using LLVM stack map support for finding roots. After all, if we know which types are GC-ish, we can include metadata on how to find roots for each function, similar to how Rust functions currently contain unwinding hooks to enable cleanly running destructors during a panic.</p>

<p>We never got around to figuring out a <em>complete</em> design, but you can find more information on what we figured out in <a href="https://manishearth.github.io/blog/2016/08/18/gc-support-in-rust-api-design/">my</a> and <a href="http://blog.pnkfx.org/blog/categories/gc/">Felix’s</a> posts on this subject. Essentially, it involved a <code class="language-plaintext highlighter-rouge">Trace</code> trait with more generic <code class="language-plaintext highlighter-rouge">trace</code> methods, an auto-implemented <code class="language-plaintext highlighter-rouge">Root</code> trait that works similar to <code class="language-plaintext highlighter-rouge">Send</code>, and compiler machinery to keep track of which <code class="language-plaintext highlighter-rouge">Root</code> types are on the stack.</p>

<p>This is probably not too useful for people attempting to implement a GC, but I’m mentioning it for completeness’ sake.</p>

<p>Note that pre-1.0 Rust did have a builtin GC (<code class="language-plaintext highlighter-rouge">@T</code>, known as “managed pointers”), but IIRC in practice the cycle-management parts were not ever implemented so it behaved exactly like <code class="language-plaintext highlighter-rouge">Rc&lt;T&gt;</code>. I believe it was intended to have a cycle collector (I’ll talk more about that in the next section).</p>

<h2 id="bacon-rajan-cc-and-cycle-collectors-in-general">bacon-rajan-cc (and cycle collectors in general)</h2>

<p><a href="https://fitzgeraldnick.com/">Nick Fitzgerald</a> wrote <a href="https://github.com/fitzgen/bacon-rajan-cc"><code class="language-plaintext highlighter-rouge">bacon-rajan-cc</code></a> to implement _<a href="https://researcher.watson.ibm.com/researcher/files/us-bacon/Bacon01Concurrent.pdf">“Concurrent Cycle Collection in Reference Counted Systems”</a>__ by David F. Bacon and V.T. Rajan.</p>

<p>This is what is colloquially called a <em>cycle collector</em>; a kind of garbage collector which is essentially “what if we took <code class="language-plaintext highlighter-rouge">Rc&lt;T&gt;</code> but made it detect cycles”. Some people do not consider these to be <em>tracing</em> garbage collectors, but they have a lot of similar characteristics (and they do still “trace” through types). They’re often categorized as “hybrid” approaches, much like <a href="https://docs.rs/gc/"><code class="language-plaintext highlighter-rouge">gc</code></a>.</p>

<p>The idea is that you don’t actually need to <em>know</em> what the roots are if you’re maintaining reference counts: if a heap object has a reference count that is more than the number of heap objects referencing it, it must be a root. In practice it’s pretty inefficient to traverse the entire heap, so optimizations are applied, often by applying different “colors” to nodes, and by only looking at the set of objects that have recently have their reference counts decremented.</p>

<p>A crucial observation here is that if you <em>only focus on potential garbage</em>, you can shift your definition of “root” a bit, when looking for cycles you don’t need to look for references from the stack, you can be satisfied with references from <em>any part of the heap you know for a fact is reachable from things which are not potential garbage</em>.</p>

<p>A neat property of cycle collectors is while mark and sweep tracing GCs have their performance scale by the size of the heap as a whole, cycle collectors scale by the size of <em>the actual garbage you have</em> <sup id="fnref:5" role="doc-noteref"><a href="#fn:5" class="footnote" rel="footnote">7</a></sup>. There are of course other tradeoffs:  deallocation is often cheaper or “free” in tracing GCs (amortizing those costs by doing it during the sweep phase) whereas cycle collectors have the constant allocator traffic involved in cleaning up objects when refcounts reach zero.</p>

<p>The way <a href="https://github.com/fitzgen/bacon-rajan-cc">bacon-rajan-cc</a> works is that every time a reference count is decremented, the object is added to a list of “potential cycle roots”, unless the reference count is decremented to 0 (in which case the object is immediately cleaned up, just like <code class="language-plaintext highlighter-rouge">Rc</code>). It then traces through this list; decrementing refcounts for every reference it follows, and cleaning up any elements that reach refcount 0. It then traverses this list <em>again</em> and reincrements refcounts for each reference it follows, to restore the original refcount. This basically treats any element not reachable from this “potential cycle root” list as “not garbage”, and doesn’t bother to visit it.</p>

<p>Cycle collectors require tighter control over the garbage collection algorithm, and have differing performance characteristics, so they may not necessarily be suitable for all use cases for GC integration in Rust, but it’s definitely worth considering!</p>

<h2 id="cell-gc">cell-gc</h2>

<p><a href="https://twitter.com/jorendorff/">Jason Orendorff</a>’s <a href="https://github.com/jorendorff/cell-gc">cell-gc</a> crate is interesting, it has a concept of “heap sessions”. Here’s a modified example from the readme:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">use</span> <span class="nn">cell_gc</span><span class="p">::</span><span class="n">Heap</span><span class="p">;</span>

<span class="c1">// implements IntoHeap, and also generates an IntListRef type and accessors</span>
<span class="nd">#[derive(cell_gc_derive::IntoHeap)]</span>
<span class="k">struct</span> <span class="n">IntList</span><span class="o">&lt;</span><span class="nv">'h</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="n">head</span><span class="p">:</span> <span class="nb">i64</span><span class="p">,</span>
    <span class="n">tail</span><span class="p">:</span> <span class="nb">Option</span><span class="o">&lt;</span><span class="n">IntListRef</span><span class="o">&lt;</span><span class="nv">'h</span><span class="o">&gt;&gt;</span>
<span class="p">}</span>

<span class="k">fn</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
    <span class="c1">// Create a heap (you'll only do this once in your whole program)</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">heap</span> <span class="o">=</span> <span class="nn">Heap</span><span class="p">::</span><span class="nf">new</span><span class="p">();</span>

    <span class="n">heap</span><span class="nf">.enter</span><span class="p">(|</span><span class="n">hs</span><span class="p">|</span> <span class="p">{</span>
        <span class="c1">// Allocate an object (returns an IntListRef)</span>
        <span class="k">let</span> <span class="n">obj1</span> <span class="o">=</span> <span class="n">hs</span><span class="nf">.alloc</span><span class="p">(</span><span class="n">IntList</span> <span class="p">{</span> <span class="n">head</span><span class="p">:</span> <span class="mi">17</span><span class="p">,</span> <span class="n">tail</span><span class="p">:</span> <span class="nb">None</span> <span class="p">});</span>
        <span class="nd">assert_eq!</span><span class="p">(</span><span class="n">obj1</span><span class="nf">.head</span><span class="p">(),</span> <span class="mi">17</span><span class="p">);</span>
        <span class="nd">assert_eq!</span><span class="p">(</span><span class="n">obj1</span><span class="nf">.tail</span><span class="p">(),</span> <span class="nb">None</span><span class="p">);</span>

        <span class="c1">// Allocate another object</span>
        <span class="k">let</span> <span class="n">obj2</span> <span class="o">=</span> <span class="n">hs</span><span class="nf">.alloc</span><span class="p">(</span><span class="n">IntList</span> <span class="p">{</span> <span class="n">head</span><span class="p">:</span> <span class="mi">33</span><span class="p">,</span> <span class="n">tail</span><span class="p">:</span> <span class="nf">Some</span><span class="p">(</span><span class="n">obj1</span><span class="p">)</span> <span class="p">});</span>
        <span class="nd">assert_eq!</span><span class="p">(</span><span class="n">obj2</span><span class="nf">.head</span><span class="p">(),</span> <span class="mi">33</span><span class="p">);</span>
        <span class="nd">assert_eq!</span><span class="p">(</span><span class="n">obj2</span><span class="nf">.tail</span><span class="p">()</span><span class="nf">.unwrap</span><span class="p">()</span><span class="nf">.head</span><span class="p">(),</span> <span class="mi">17</span><span class="p">);</span>

        <span class="c1">// mutate `tail`</span>
        <span class="n">obj2</span><span class="nf">.set_tail</span><span class="p">(</span><span class="nb">None</span><span class="p">);</span>
    <span class="p">});</span>
<span class="p">}</span>
</code></pre></div></div>

<p>All mutation goes through autogenerated accessors, so the crate has a little more control over traffic through the GC. These accessors help track roots via a scheme similar to what <a href="https://docs.rs/gc/"><code class="language-plaintext highlighter-rouge">gc</code></a> does; where there’s an <code class="language-plaintext highlighter-rouge">IntoHeap</code> trait used for modifying root refcounts when a reference is put into and taken out of the heap via accessors.</p>

<p>Heap sessions allow for the heap to moved around, even sent to other threads, and their lifetime prevents heap objects from being mixed between sessions. This uses a concept called <em>generativity</em>; you can read more about generativity in <em><a href="https://raw.githubusercontent.com/Gankra/thesis/master/thesis.pdf">“You Can’t Spell Trust Without Rust”</a></em> ch 6.3, by <a href="https://github.com/Gankra">Aria Beingessner</a>, or by looking at the <a href="https://github.com/bluss/indexing"><code class="language-plaintext highlighter-rouge">indexing</code></a> crate.</p>

<h2 id="interlude-the-similarities-between-async-and-gcs">Interlude: The similarities between <code class="language-plaintext highlighter-rouge">async</code> and GCs</h2>

<p>The next two examples use machinery from Rust’s <code class="language-plaintext highlighter-rouge">async</code> functionality despite having nothing to do with async I/O, and I think it’s important to talk about why that should make sense. I’ve <a href="https://twitter.com/ManishEarth/status/1073651552768819200">tweeted about this before</a>: I and <a href="https://github.com/kyren">Catherine West</a> figured this out when we were talking about <a href="https://github.com/kyren/gc-arena">her GC idea</a> based on <code class="language-plaintext highlighter-rouge">async</code>.</p>

<p>You can see some of this correspondence in Go: Go is a language that has both garbage collection and async I/O, and both of these use the same “safepoints” for yielding to the garbage collector or the scheduler. In Go, the compiler needs to automatically insert code that checks the “pulse” of the heap every now and then, and potentially runs garbage collection. It also needs to automatically insert code that can tell the scheduler “hey now is a safe time to interrupt me if a different goroutine wishes to run”. These are very similar in principle – they’re both essentially places where the compiler is inserting “it is okay to interrupt me now” checks, sometimes called “interruption points” or “yield points”.</p>

<p>Now, Rust’s compiler does not automatically insert interruption points. However, the design of <code class="language-plaintext highlighter-rouge">async</code> in Rust is essentially a way of adding <em>explicit</em> interruption points to Rust. <code class="language-plaintext highlighter-rouge">foo().await</code> in Rust is a way of running <code class="language-plaintext highlighter-rouge">foo()</code> and expecting that the scheduler <em>may</em> interrupt the code in between. The design of <a href="https://doc.rust-lang.org/nightly/std/future/trait.Future.html"><code class="language-plaintext highlighter-rouge">Future</code></a> and <a href="https://doc.rust-lang.org/nightly/std/pin/struct.Pin.html"><code class="language-plaintext highlighter-rouge">Pin&lt;P&gt;</code></a> come out of making this safe and pleasant to work with.</p>

<p>As we shall see, this same machinery can be used for creating safe interruption points for GCs in Rust.</p>

<h2 id="shifgrethor">Shifgrethor</h2>

<p><a href="https://github.com/withoutboats/shifgrethor">shifgrethor</a> is an experiment by <a href="https://github.com/withoutboats/">Saoirse</a> to try and build a GC that uses <a href="https://doc.rust-lang.org/nightly/std/pin/struct.Pin.html"><code class="language-plaintext highlighter-rouge">Pin&lt;P&gt;</code></a> for managing roots. They’ve written extensively on the design of <a href="https://github.com/withoutboats/shifgrethor">shifgrethor</a> <a href="https://without.boats/tags/shifgrethor/">on their blog</a>. In particular, the <a href="https://without.boats/blog/shifgrethor-iii/">post on rooting</a> goes through how rooting works.</p>

<p>The basic design is that there’s a <code class="language-plaintext highlighter-rouge">Root&lt;'root&gt;</code> type that contains a <code class="language-plaintext highlighter-rouge">Pin&lt;P&gt;</code>, which can be <em>immovably</em> tied to a stack frame using the same idea behind <code class="language-plaintext highlighter-rouge">pin-utils</code>’ <a href="https://docs.rs/pin-utils/0.1.0/pin_utils/macro.pin_mut.html"><code class="language-plaintext highlighter-rouge">pin_mut!()</code> macro</a>:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">letroot!</span><span class="p">(</span><span class="n">root</span><span class="p">);</span>
<span class="k">let</span> <span class="n">gc</span><span class="p">:</span> <span class="nb">Gc</span><span class="o">&lt;</span><span class="nv">'root</span><span class="p">,</span> <span class="n">Foo</span><span class="o">&gt;</span> <span class="o">=</span> <span class="n">root</span><span class="nf">.gc</span><span class="p">(</span><span class="nn">Foo</span><span class="p">::</span><span class="nf">new</span><span class="p">());</span>
</code></pre></div></div>

<p>The fact that <code class="language-plaintext highlighter-rouge">root</code> is immovable allows for it to be treated as a true marker for the <em>stack frame</em> over anything else. The list of rooted types can be neatly stored in an ordered stack-like vector in the GC implementation, popping when individual roots go out of scope.</p>

<p>If you wish to return a rooted object from a function, the function needs to accept a <code class="language-plaintext highlighter-rouge">Root&lt;'root&gt;</code>:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="n">new</span><span class="o">&lt;</span><span class="nv">'root</span><span class="o">&gt;</span><span class="p">(</span><span class="n">root</span><span class="p">:</span> <span class="n">Root</span><span class="o">&lt;</span><span class="nv">'root</span><span class="o">&gt;</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">Gc</span><span class="o">&lt;</span><span class="nv">'root</span><span class="p">,</span> <span class="k">Self</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="n">root</span><span class="nf">.gc</span><span class="p">(</span><span class="k">Self</span> <span class="p">{</span>
        <span class="c1">// ...</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>All GC’d types have a <code class="language-plaintext highlighter-rouge">'root</code> lifetime of the root they trace back to, and are declared with a custom derive:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">#[derive(GC)]</span>
<span class="k">struct</span> <span class="n">Foo</span><span class="o">&lt;</span><span class="nv">'root</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="nd">#[gc]</span> <span class="n">bar</span><span class="p">:</span> <span class="n">GcStore</span><span class="o">&lt;</span><span class="nv">'root</span><span class="p">,</span> <span class="n">Bar</span><span class="o">&gt;</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">GcStore</code> is a way to have fields use the rooting of their parent. Normally, if you wanted to put <code class="language-plaintext highlighter-rouge">Gc&lt;'root2, Bar&lt;'root2&gt;&gt;</code> inside <code class="language-plaintext highlighter-rouge">Foo&lt;'root1&gt;</code> you would not be able to because the lifetimes derive from different roots. <code class="language-plaintext highlighter-rouge">GcStore</code>, along with autogenerated accessors from <code class="language-plaintext highlighter-rouge">#[derive(GC)]</code>, will set <code class="language-plaintext highlighter-rouge">Bar</code>’s lifetime to be the same as <code class="language-plaintext highlighter-rouge">Foo</code> when you attempt to stick it inside <code class="language-plaintext highlighter-rouge">Foo</code>.</p>

<p>This design is somewhat similar to that of Servo where there’s a pair of types, one that lets us refer to GC types on the stack, and one that lets GC types refer to each other on the heap, but it uses <code class="language-plaintext highlighter-rouge">Pin&lt;P&gt;</code> instead of a lint to enforce this safely, which is way nicer. <code class="language-plaintext highlighter-rouge">Root&lt;'root&gt;</code> and <code class="language-plaintext highlighter-rouge">GcStore</code> do a bunch of lifetime tweaking that’s reminiscent of Josephine’s rooting system, however there’s no need for an <code class="language-plaintext highlighter-rouge">&amp;mut JsContext</code> type that needs to be passed around everywhere.</p>

<h2 id="gc-arena">gc-arena</h2>

<p><a href="https://github.com/kyren/gc-arena"><code class="language-plaintext highlighter-rouge">gc-arena</code></a> is <a href="https://github.com/kyren">Catherine West</a>’s experimental GC design for her Lua VM, <a href="https://github.com/kyren/luster"><code class="language-plaintext highlighter-rouge">luster</code></a>.</p>

<p>The <code class="language-plaintext highlighter-rouge">gc-arena</code> crate forces all GC-manipulating code to go within <code class="language-plaintext highlighter-rouge">arena.mutate()</code> calls, between which garbage collection may occur.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">#[derive(Collect)]</span>
<span class="nd">#[collect(no_drop)]</span>
<span class="k">struct</span> <span class="n">TestRoot</span><span class="o">&lt;</span><span class="nv">'gc</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="n">number</span><span class="p">:</span> <span class="nb">Gc</span><span class="o">&lt;</span><span class="nv">'gc</span><span class="p">,</span> <span class="nb">i32</span><span class="o">&gt;</span><span class="p">,</span>
    <span class="n">many_numbers</span><span class="p">:</span> <span class="n">GcCell</span><span class="o">&lt;</span><span class="nb">Vec</span><span class="o">&lt;</span><span class="nb">Gc</span><span class="o">&lt;</span><span class="nv">'gc</span><span class="p">,</span> <span class="nb">i32</span><span class="o">&gt;&gt;&gt;</span><span class="p">,</span>
<span class="p">}</span>

<span class="nd">make_arena!</span><span class="p">(</span><span class="n">TestArena</span><span class="p">,</span> <span class="n">TestRoot</span><span class="p">);</span>

<span class="k">let</span> <span class="k">mut</span> <span class="n">arena</span> <span class="o">=</span> <span class="nn">TestArena</span><span class="p">::</span><span class="nf">new</span><span class="p">(</span><span class="nn">ArenaParameters</span><span class="p">::</span><span class="nf">default</span><span class="p">(),</span> <span class="p">|</span><span class="n">mc</span><span class="p">|</span> <span class="n">TestRoot</span> <span class="p">{</span>
    <span class="n">number</span><span class="p">:</span> <span class="nn">Gc</span><span class="p">::</span><span class="nf">allocate</span><span class="p">(</span><span class="n">mc</span><span class="p">,</span> <span class="mi">42</span><span class="p">),</span>
    <span class="n">many_numbers</span><span class="p">:</span> <span class="nn">GcCell</span><span class="p">::</span><span class="nf">allocate</span><span class="p">(</span><span class="n">mc</span><span class="p">,</span> <span class="nn">Vec</span><span class="p">::</span><span class="nf">new</span><span class="p">()),</span>
<span class="p">});</span>

<span class="n">arena</span><span class="nf">.mutate</span><span class="p">(|</span><span class="n">_mc</span><span class="p">,</span> <span class="n">root</span><span class="p">|</span> <span class="p">{</span>
    <span class="nd">assert_eq!</span><span class="p">(</span><span class="o">*</span><span class="p">((</span><span class="o">*</span><span class="n">root</span><span class="p">)</span><span class="py">.number</span><span class="p">),</span> <span class="mi">42</span><span class="p">);</span>
    <span class="n">root</span><span class="py">.numbers</span><span class="nf">.write</span><span class="p">(</span><span class="n">mc</span><span class="p">)</span><span class="nf">.push</span><span class="p">(</span><span class="nn">Gc</span><span class="p">::</span><span class="nf">allocate</span><span class="p">(</span><span class="n">mc</span><span class="p">,</span> <span class="mi">0</span><span class="p">));</span>
<span class="p">});</span>
</code></pre></div></div>

<p>Mutation is done with <code class="language-plaintext highlighter-rouge">GcCell</code>, basically a fancier version of <code class="language-plaintext highlighter-rouge">Gc&lt;RefCell&lt;T&gt;&gt;</code>. All GC operations require a <code class="language-plaintext highlighter-rouge">MutationContext</code> (<code class="language-plaintext highlighter-rouge">mc</code>), which is only available within <code class="language-plaintext highlighter-rouge">arena.mutate()</code>.</p>

<p>Only the arena root may survive between <code class="language-plaintext highlighter-rouge">mutate()</code> calls, and garbage collection does not happen during <code class="language-plaintext highlighter-rouge">.mutate()</code>, so rooting is easy – just follow the arena root. This crate allows for multiple GCs to coexist with separate heaps, and, similarly to <a href="https://github.com/jorendorff/cell-gc">cell-gc</a>, it uses generativity to enforce that the heaps do not get mixed.</p>

<p>So far this is mostly like other arena-based systems, but with a GC.</p>

<p>The <em>really cool</em> part of the design is the <code class="language-plaintext highlighter-rouge">gc-sequence</code> crate, which essentially builds a <code class="language-plaintext highlighter-rouge">Future</code>-like API (using a <code class="language-plaintext highlighter-rouge">Sequence</code> trait) on top of <code class="language-plaintext highlighter-rouge">gc-arena</code> that can potentially make this very pleasant to use. Here’s a modified example from a test:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">#[derive(Collect)]</span>
<span class="nd">#[collect(no_drop)]</span>
<span class="k">struct</span> <span class="n">TestRoot</span><span class="o">&lt;</span><span class="nv">'gc</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="n">test</span><span class="p">:</span> <span class="nb">Gc</span><span class="o">&lt;</span><span class="nv">'gc</span><span class="p">,</span> <span class="nb">i32</span><span class="o">&gt;</span><span class="p">,</span>
<span class="p">}</span>

<span class="nd">make_sequencable_arena!</span><span class="p">(</span><span class="n">test_sequencer</span><span class="p">,</span> <span class="n">TestRoot</span><span class="p">);</span>
<span class="k">use</span> <span class="nn">test_sequencer</span><span class="p">::</span><span class="n">Arena</span> <span class="k">as</span> <span class="n">TestArena</span><span class="p">;</span>

<span class="k">let</span> <span class="n">arena</span> <span class="o">=</span> <span class="nn">TestArena</span><span class="p">::</span><span class="nf">new</span><span class="p">(</span><span class="nn">ArenaParameters</span><span class="p">::</span><span class="nf">default</span><span class="p">(),</span> <span class="p">|</span><span class="n">mc</span><span class="p">|</span> <span class="n">TestRoot</span> <span class="p">{</span>
    <span class="n">test</span><span class="p">:</span> <span class="nn">Gc</span><span class="p">::</span><span class="nf">allocate</span><span class="p">(</span><span class="n">mc</span><span class="p">,</span> <span class="mi">42</span><span class="p">),</span>
<span class="p">});</span>

<span class="k">let</span> <span class="k">mut</span> <span class="n">sequence</span> <span class="o">=</span> <span class="n">arena</span><span class="nf">.sequence</span><span class="p">(|</span><span class="n">root</span><span class="p">|</span> <span class="p">{</span>
    <span class="nn">sequence</span><span class="p">::</span><span class="nf">from_fn_with</span><span class="p">(</span><span class="n">root</span><span class="py">.test</span><span class="p">,</span> <span class="p">|</span><span class="n">_</span><span class="p">,</span> <span class="n">test</span><span class="p">|</span> <span class="p">{</span>
        <span class="k">if</span> <span class="o">*</span><span class="n">test</span> <span class="o">==</span> <span class="mi">42</span> <span class="p">{</span>
            <span class="nf">Ok</span><span class="p">(</span><span class="o">*</span><span class="n">test</span> <span class="o">+</span> <span class="mi">10</span><span class="p">)</span>
        <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
            <span class="nf">Err</span><span class="p">(</span><span class="s">"will not be generated"</span><span class="p">)</span>
        <span class="p">}</span>
    <span class="p">})</span>
    <span class="nf">.and_then</span><span class="p">(|</span><span class="n">_</span><span class="p">,</span> <span class="n">r</span><span class="p">|</span> <span class="nf">Ok</span><span class="p">(</span><span class="n">r</span> <span class="o">+</span> <span class="mi">12</span><span class="p">))</span>
    <span class="nf">.and_chain</span><span class="p">(|</span><span class="n">_</span><span class="p">,</span> <span class="n">r</span><span class="p">|</span> <span class="nf">Ok</span><span class="p">(</span><span class="nn">sequence</span><span class="p">::</span><span class="nf">ok</span><span class="p">(</span><span class="n">r</span> <span class="o">-</span> <span class="mi">10</span><span class="p">)))</span>
    <span class="nf">.then</span><span class="p">(|</span><span class="n">_</span><span class="p">,</span> <span class="n">res</span><span class="p">|</span> <span class="n">res</span><span class="nf">.expect</span><span class="p">(</span><span class="s">"should not be error"</span><span class="p">))</span>
    <span class="nf">.chain</span><span class="p">(|</span><span class="n">_</span><span class="p">,</span> <span class="n">r</span><span class="p">|</span> <span class="nn">sequence</span><span class="p">::</span><span class="nf">done</span><span class="p">(</span><span class="n">r</span> <span class="o">+</span> <span class="mi">10</span><span class="p">))</span>
    <span class="nf">.map</span><span class="p">(|</span><span class="n">r</span><span class="p">|</span> <span class="nn">sequence</span><span class="p">::</span><span class="nf">done</span><span class="p">(</span><span class="n">r</span> <span class="o">-</span> <span class="mi">60</span><span class="p">))</span>
    <span class="nf">.flatten</span><span class="p">()</span>
    <span class="nf">.boxed</span><span class="p">()</span>
<span class="p">});</span>

<span class="k">loop</span> <span class="p">{</span>
    <span class="k">match</span> <span class="n">sequence</span><span class="nf">.step</span><span class="p">()</span> <span class="p">{</span>
        <span class="nf">Ok</span><span class="p">((</span><span class="n">_</span><span class="p">,</span> <span class="n">output</span><span class="p">))</span> <span class="k">=&gt;</span> <span class="p">{</span>
            <span class="nd">assert_eq!</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="mi">4</span><span class="p">);</span>
            <span class="k">return</span><span class="p">;</span>
        <span class="p">}</span>
        <span class="nf">Err</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="k">=&gt;</span> <span class="n">sequence</span> <span class="o">=</span> <span class="n">s</span><span class="p">,</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>This is <em>very</em> similar to chained callback futures code; and if it could use the <code class="language-plaintext highlighter-rouge">Future</code> trait would be able to make use of <code class="language-plaintext highlighter-rouge">async</code> to convert this callback heavy code into sequential code with interrupt points using <code class="language-plaintext highlighter-rouge">await</code>. There were design constraints making <code class="language-plaintext highlighter-rouge">Future</code> not workable for this use case, though if Rust ever gets generators this would work well, and it’s quite possible that another GC with a similar design could be written, using <code class="language-plaintext highlighter-rouge">async</code>/<code class="language-plaintext highlighter-rouge">await</code> and <code class="language-plaintext highlighter-rouge">Future</code>.</p>

<p>Essentially, this paints a picture of an entire space of Rust GC design where GC mutations are performed using <code class="language-plaintext highlighter-rouge">await</code> (or <code class="language-plaintext highlighter-rouge">yield</code> if we ever get generators), and garbage collection can occur during those yield points, in a way that’s highly reminiscent of Go’s design.</p>

<h2 id="moving-forward">Moving forward</h2>

<p>As is hopefully obvious, the space of safe GC design in Rust is quite rich and has a lot of interesting ideas. I’m really excited to see what folks come up with here!</p>

<p>If you’re interested in reading more about GCs in general, <em><a href="https://courses.cs.washington.edu/courses/cse590p/05au/p50-bacon.pdf">“A Unified Theory of Garbage Collection”</a></em> by Bacon et al and the <a href="http://gchandbook.org/">GC Handbook</a> are great reads.</p>

<p><em>Thanks to <a href="https://mermaid.industries/">Andi McClure</a>, <a href="https://twitter.com/jorendorff/">Jason Orendorff</a>, <a href="https://fitzgeraldnick.com/">Nick Fitzgerald</a>, and <a href="https://twitter.com/kneecaw/">Nika Layzell</a> for providing feedback on drafts of this blog post</em></p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:0" role="doc-endnote">
      <p>I’m also going to completely ignore the field of <em>conservative</em> stack-scanning tracing GCs where you figure out your roots by looking at all the stack memory and considering anything with a remotely heap-object-like bit pattern to be a root. These are interesting, but can’t really be made 100% safe in the way Rust wants them to be unless you scan the heap as well. <a href="#fnref:0" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:1" role="doc-endnote">
      <p>Which currently does not have support for concurrent garbage collection, but it could be added. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>Some JNI-using APIs are also forced to have <a href="https://developer.android.com/ndk/reference/group/bitmap#androidbitmap_lockpixels">explicit rooting APIs</a> to give access to things like raw buffers. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>In general, finalizers in GCs are hard to implement soundly in any language, not just Rust, but Rust can sometimes be a bit more annoying about it. <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:4" role="doc-endnote">
      <p>Spolier: This is actually possible in Rust, and we’ll get into it further in this post! <a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:10" role="doc-endnote">
      <p>Such hybrid approaches are common in high performance GCs; <em><a href="https://courses.cs.washington.edu/courses/cse590p/05au/p50-bacon.pdf">“A Unified Theory of Garbage Collection”</a></em> by Bacon et al. covers a lot of the breadth of these approaches. <a href="#fnref:10" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:5" role="doc-endnote">
      <p>Firefox’s DOM actually uses a mark &amp; sweep tracing GC <em>mixed with</em> a cycle collector for this reason. The DOM types themselves are cycle collected, but JavaScript objects are managed by the Spidermonkey GC. Since some DOM types may contain references to arbitrary JS types (e.g. ones that store callbacks) there’s a fair amount of work required to break cycles manually in some cases, but it has performance benefits since the vast majority of DOM objects either never become garbage or become garbage by having a couple non-cycle-participating references get released. <a href="#fnref:5" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name>Manish Goregaokar</name></author><category term="mozilla" /><category term="programming" /><category term="rust" /><summary type="html"><![CDATA[I’ve been thinking about garbage collection in Rust for a long time, ever since I started working on Servo’s JS layer. I’ve designed a GC library, worked on GC integration ideas for Rust itself, worked on Servo’s JS GC integration, and helped out with a couple other GC projects in Rust. As a result, I tend to get pulled into GC discussions fairly often. I enjoy talking about GCs – don’t get me wrong – but I often end up going over the same stuff. Being lazy I’d much prefer to be able to refer people to a single place where they can get up to speed on the general space of GC design, after which it’s possible to have more in depth discussions about the specific tradeoffs necessary. I’ll note that some of the GCs in this post are experiments or unmaintained. The goal of this post is to showcase these as examples of design, not necessarily general-purpose crates you may wish to use, though some of them are usable crates as well. A note on terminology A thing that often muddles discussions about GCs is that according to some definition of “GC”, simple reference counting is a GC. Typically the definition of GC used in academia broadly refers to any kind of automatic memory management. However, most programmers familiar with the term “GC” will usually liken it to “what Java, Go, Haskell, and C# do”, which can be unambiguously referred to as tracing garbage collection. Tracing garbage collection is the kind which keeps track of which heap objects are directly reachable (“roots”), figures out the whole set of reachable heap objects (“tracing”, also, “marking”), and then cleans them up (“sweeping”). Throughout this blog post I will use the term “GC” to refer to tracing garbage collection/collectors unless otherwise stated1. Why write GCs for Rust? (If you already want to write a GC in Rust and are reading this post to get ideas for how, you can skip this section. You already know why someone would want to write a GC for Rust) Every time this topic is brought up someone will inevitably go “I thought the point of Rust was to avoid GCs” or “GCs will ruin Rust” or something. As a general rule it’s good to not give too much weight to the comments section, but I think it’s useful to explain why someone may wish for GC-like semantics in Rust. There are really two distinct kinds of use cases. Firstly, sometimes you need to manage memory with cycles and Rc&lt;T&gt; is inadequate for the job since Rc-cycles get leaked. petgraph or an arena are often acceptable solutions for this kind of pattern, but not always, especially if your data is super heterogeneous. This kind of thing crops up often when dealing with concurrent datastructures; for example crossbeam has an epoch-based memory management system which, while not a full tracing GC, has a lot of characteristics in common with GCs. For this use case it’s rarely necessary to design a custom GC, you can look for a reusable crate like gc 2. The second case is far more interesting in my experience, and since it cannot be solved by off-the-shelf solutions tends to crop up more often: integration with (or implementation of) programming languages that do use a garbage collector. Servo needs to do this for integrating with the Spidermonkey JS engine and luster needed to do this for implementing the GC of its Lua VM. boa, a pure Rust JS runtime, uses the gc crate to back its garbage collector. Sometimes when integrating with a GCd language you can get away with not needing to implement a full garbage collector: JNI does this; while C++ does not have native garbage collection, JNI gets around this by simply “rooting” (we’ll cover what that means in a bit) anything that crosses over to the C++ side3. This is often fine! The downside of this is that every interaction with objects managed by the GC has to go through an API call; you can’t “embed” efficient Rust/C++ objects in the GC with ease. For example, in browsers most DOM types (e.g. Element) are implemented in native code; and need to be able to contain references to other native GC’d types (it should be possible to inspect the children of a Node without needing to call back into the JavaScript engine). So sometimes you need to be able to integrate with a GC from a runtime; or even implement your own GC if you are writing a runtime that needs one. In both of these cases you typically want to be able to safely manipulate GC’d objects from Rust code, and even directly put Rust types on the GC heap. Why are GCs in Rust hard? In one word: Rooting. In a garbage collector, the objects “directly” in use on the stack are the “roots”, and you need to be able to identify them. Here, when I say “directly”, I mean “accessible without having to go through other GC’d objects”, so putting an object inside a Vec&lt;T&gt; does not make it stop being a root, but putting it inside some other GC’d object does. Unfortunately, Rust doesn’t really have a concept of “directly on the stack”: struct Foo { bar: Option&lt;Gc&lt;Bar&gt;&gt; } // this is a root let bar = Gc::new(Bar::new()); // this is also a root let foo = Gc::new(Foo::new()); // bar should no longer be a root (but we can't detect that!) foo.bar = Some(bar); // but foo should still be a root here since it's not inside // another GC'd object let v = vec![foo]; Rust’s ownership system actually makes it easier to have fewer roots since it’s relatively easy to state that taking &amp;T of a GC’d object doesn’t need to create a new root, and let Rust’s ownership system sort it out, but being able to distinguish between “directly owned” and “indirectly owned” is super tricky. Another aspect of this is that garbage collection is really a moment of global mutation – the garbage collector reads through the heap and then deletes some of the objects there. This is a moment of the rug being pulled out under your feet. Rust’s entire design is predicated on such rug-pulling being very very bad and not to be allowed, so this can be a bit problematic. This isn’t as bad as it may initially sound because after all the rug-pulling is mostly just cleaning up unreachable objects, but it does crop up a couple times when fitting things together, especially around destructors and finalizers4. Rooting would be far easier if, for example, you were able to declare areas of code where “no GC can happen”5 so you can tightly scope the rug-pulling and have to worry less about roots. Destructors and finalizers It’s worth calling out destructors in particular. A huge problem with custom destructors on GCd types is that the custom destructor totally can stash itself away into a long-lived reference during garbage collection, leading to a dangling reference: struct LongLived { dangle: RefCell&lt;Option&lt;Gc&lt;CantKillMe&gt;&gt;&gt; } struct CantKillMe { // set up to point to itself during construction self_ref: RefCell&lt;Option&lt;Gc&lt;CantKillMe&gt;&gt;&gt; long_lived: Gc&lt;LongLived&gt; } impl Drop for CantKillMe { fn drop(&amp;mut self) { // attach self to long_lived *self.long_lived.dangle.borrow_mut() = Some(self.self_ref.borrow().clone().unwrap()); } } let long = Gc::new(LongLived::new()); { let cant = Gc::new(CantKillMe::new()); *cant.self_ref.borrow_mut() = Some(cant.clone()); // cant goes out of scope, CantKillMe::drop is run // cant is attached to long_lived.dangle but still cleaned up } // Dangling reference! let dangling = long.dangle.borrow().unwrap(); The most common solution here is to disallow destructors on types that use #[derive(Trace)], which can be done by having the custom derive generate a Drop implementation, or have it generate something which causes a conflicting type error. You can additionally provide a Finalize trait that has different semantics: the GC calls it while cleaning up GC objects, but it may be called multiple times or not at all. This kind of thing is typical in GCs outside of Rust as well. How would you even garbage collect without a runtime? In most garbage collected languages, there’s a runtime that controls all execution, knows about every variable in the program, and is able to pause execution to run the GC whenever it likes. Rust has a minimal runtime and can’t do anything like this, especially not in a pluggable way your library can hook in to. For thread local GCs you basically have to write it such that GC operations (things like mutating a GC field; basically some subset of the APIs exposed by your GC library) are the only things that may trigger the garbage collector. Concurrent GCs can trigger the GC on a separate thread but will typically need to pause other threads whenever these threads attempt to perform a GC operation that could potentially be invalidated by the running garbage collector. While this may restrict the flexibility of the garbage collector itself, this is actually pretty good for us from the side of API design: the garbage collection phase can only happen in certain well-known moments of the code, which means we only need to make things safe across those boundaries. Many of the designs we shall look at build off of this observation. Commonalities Before getting into the actual examples of GC design, I want to point out some commonalities of design between all of them, especially around how they do tracing: Tracing “Tracing” is the operation of traversing the graph of GC objects, starting from your roots and perusing their children, and their children’s children, and so on. In Rust, the easiest way to implement this is via a custom derive: // unsafe to implement by hand since you can get it wrong unsafe trait Trace { fn trace(&amp;mut self, gc_context: &amp;mut GcContext); } #[derive(Trace)] struct Foo { vec: Vec&lt;Gc&lt;Bar&gt;&gt;, extra_thing: Gc&lt;Baz&gt;, just_a_string: String } The custom derive of Trace basically just calls trace() on all the fields. Vec’s Trace implementation will be written to call trace() on all of its fields, and String’s Trace implementation will do nothing. Gc&lt;T&gt; will likely have a trace() that marks its reachability in the GcContext, or something similar. This is a pretty standard pattern, and while the specifics of the Trace trait will typically vary, the general idea is roughly the same. I’m not going to get into the actual details of how mark-and-sweep algorithms work in this post; there are a lot of potential designs for them and they’re not that interesting from the point of view of designing a safe GC API in Rust. However, the general idea is to keep a queue of found objects initially populated by the root, trace them to find new objects and queue them up if they’ve not already been traced. Clean up any objects that were not found. Immutable-by-default Another commonality between these designs is that a Gc&lt;T&gt; is always potentially shared, and thus will need tight control over mutability to satisfy Rust’s ownership invariants. This is typically achieved by using interior mutability, much like how Rc&lt;T&gt; is almost always paired with RefCell&lt;T&gt; for mutation, however some approaches (like that in josephine) do allow for mutability without runtime checking. Threading Some GCs are single-threaded, and some are multi-threaded. The single threaded ones typically have a Gc&lt;T&gt; type that is not Send, so while you can set up multiple graphs of GC types on different threads, they’re essentially independent. Garbage collection only affects the thread it is being performed for, all other threads can continue unhindered. Multithreaded GCs will have a Send Gc&lt;T&gt; type. Garbage collection will typically, but not always, block any thread which attempts to access data managed by the GC during that time. In some languages there are “stop the world” garbage collectors which block all threads at “safepoints” inserted by the compiler; Rust does not have the capability to insert such safepoints and blocking threads on GCs is done at the library level. Most of the examples below are single-threaded, but their API design is not hard to extend towards a hypothetical multithreaded GC. rust-gc The gc crate is one I wrote with Nika Layzell mostly as a fun exercise, to figure out if a safe GC API is possible. I’ve written about the design in depth before, but the essence of the design is that it does something similar to reference counting to keep track of roots, and forces all GC mutations go through special GcCell types so that they can update the root count. Basically, a “root count” is updated whenever something becomes a root or stops being a root: struct Foo { bar: GcCell&lt;Option&lt;Gc&lt;Bar&gt;&gt;&gt; } // this is a root (root count = 1) let bar = Gc::new(Bar::new()); // this is also a root (root count = 1) let foo = Gc::new(Foo::new()); // .borrow_mut()'s RAII guard unroots bar (sets its root count to 0) *foo.bar.borrow_mut() = Some(bar); // foo is still a root here, no call to .set() let v = vec![foo]; // at destrucion time, foo's root count is set to 0 The actual garbage collection phase will occur when certain GC operations are performed at a time when the heap is considered to have gotten reasonably large according to some heuristics. While this is essentially “free” on reads, this is a fair amount of reference count traffic on any kind of write, which might not be desired; often the goal of using GCs is to avoid the performance characteristics of reference-counting-like patterns. Ultimately this is a hybrid approach that’s a mix of tracing and reference counting6. gc is useful as a general-purpose GC if you just want a couple of things to participate in cycles without having to think about it too much. The general design can apply to a specialized GC integrating with another language runtime since it provides a clear way to keep track of roots; but it may not necessarily have the desired performance characteristics. Servo’s DOM integration Servo is a browser engine in Rust that I used to work on full time. As mentioned earlier, browser engines typically implement a lot of their DOM types in native (i.e. Rust or C++, not JS) code, so for example Node is a pure Rust object, and it contains direct references to its children so Rust code can do things like traverse the tree without having to go back and forth between JS and Rust. Servo’s model is a little weird: roots are a different type, and lints enforce that unrooted heap references are never placed on the stack: #[dom_struct] // this is #[derive(JSTraceable)] plus some markers for lints pub struct Node { // the parent type, for inheritance eventtarget: EventTarget, // in the actual code this is a different helper type that combines // the RefCell, Option, and Dom, but i've simplified it to use // stdlib types for this example prev_sibling: RefCell&lt;Option&lt;Dom&lt;Node&gt;&gt;&gt;, next_sibling: RefCell&lt;Option&lt;Dom&lt;Node&gt;&gt;&gt;, // ... } impl Node { fn frob_next_sibling(&amp;self) { // fields can be accessed as borrows without any rooting if let Some(next) = self.next_sibling.borrow().as_ref() { next.frob(); } } fn get_next_sibling(&amp;self) -&gt; Option&lt;DomRoot&lt;Node&gt;&gt; { // but you need to root things for them to escape the borrow // .root() turns Dom&lt;T&gt; into DomRoot&lt;T&gt; self.next_sibling.borrow().as_ref().map(|x| x.root()) } fn illegal(&amp;self) { // this line of code would get linted by a custom lint called unrooted_must_root // (which works somewhat similarly to the must_use stuff that Rust does) let ohno: Dom&lt;Node&gt; = self.next_sibling.borrow_mut().take(); } } Dom&lt;T&gt; is basically a smart pointer that behaves like &amp;T but without a lifetime, whereas DomRoot&lt;T&gt; has the additional behavior of rooting on creation (and unrooting on Drop). The custom lint plugin essentially enforces that Dom&lt;T&gt;, and any DOM structs (tagged with #[dom_struct]) are never accessible on the stack aside from through DomRoot&lt;T&gt; or &amp;T. I wouldn’t recommend this approach; it works okay but we’ve wanted to move off of it for a while because it relies on custom plugin lints for soundness. But it’s worth mentioning for completeness. Josephine (Servo’s experimental GC plans) Given that Servo’s existing GC solution depends on plugging in to the compiler to do additional static analysis, we wanted something better. So Alan designed Josephine (“JS affine”), which uses Rust’s affine types and borrowing in a cleaner way to provide a safe GC system. Josephine is explicitly designed for Servo’s use case and as such does a lot of neat things around “compartments” and such that are probably irrelevant unless you specifically wish for your GC to integrate with a JS engine. I mentioned earlier that the fact that the garbage collection phase can only happen in certain well-known moments of the code actually can make things easier for GC design, and Josephine is an example of this. Josephine has a “JS context”, which is to be passed around everywhere and essentially represents the GC itself. When doing operations which may trigger a GC, you have to borrow the context mutably, whereas when accessing heap objects you need to borrow the context immutably. You can root heap objects to remove this requirement: // cx is a `JSContext`, `node` is a `JSManaged&lt;'a, C, Node&gt;` // assuming next_sibling and prev_sibling are not Options for simplicity // borrows cx for `'b` let next_sibling: &amp;'b Node = node.next_sibling.borrow(cx); println!("Name: {:?}", next_sibling.name); // illegal, because cx is immutably borrowed by next_sibling // node.prev_sibling.borrow_mut(cx).frob(); // read from next_sibling to ensure it lives this long println!("{:?}", next_sibling.name); let ref mut root = cx.new_root(); // no longer needs to borrow cx, borrows root for 'root instead let next_sibling: JSManaged&lt;'root, C, Node&gt; = node.next_sibling.in_root(root); // now it's fine, no outstanding borrows of `cx` node.prev_sibling.borrow_mut(cx).frob(); // read from next_sibling to ensure it lives this long println!("{:?}", next_sibling.name); new_root() creates a new root, and in_root ties the lifetime of a JS managed type to the root instead of to the JSContext borrow, releasing the borrow of the JSContext and allowing it to be borrowed mutably in future .borrow_mut() calls. Note that .borrow() and .borrow_mut() here do not have runtime borrow-checking cost despite their similarities to RefCell::borrow(), they instead are doing some lifetime juggling to make things safe. Creating roots typically does have runtime cost. Sometimes you may need to use RefCell&lt;T&gt; for the same reason it’s used in Rc, but mostly only for non-GCd fields. Custom types are typically defined in two parts as so: #[derive(Copy, Clone, Debug, Eq, PartialEq, JSTraceable, JSLifetime, JSCompartmental)] pub struct Element&lt;'a, C&gt; (pub JSManaged&lt;'a, C, NativeElement&lt;'a, C&gt;&gt;); #[derive(JSTraceable, JSLifetime, JSCompartmental)] pub struct NativeElement&lt;'a, C&gt; { name: JSString&lt;'a, C&gt;, parent: Option&lt;Element&lt;'a, C&gt;&gt;, children: Vec&lt;Element&lt;'a, C&gt;&gt;, } where Element&lt;'a&gt; is a convenient copyable reference that is to be used inside other GC types, and NativeElement&lt;'a&gt; is its backing storage. The C parameter has to do with compartments and can be ignored for now. A neat thing worth pointing out is that there’s no runtime borrow checking necessary for manipulating other GC references, even though roots let you hold multiple references to the same object! let parent_root = cx.new_root(); let parent = element.borrow(cx).parent.in_root(parent_root); let ref mut child_root = cx.new_root(); // could potentially be a second reference to `element` if it was // the first child let first_child = parent.children[0].in_root(child_root); // this is okay, even though we hold a reference to `parent` // via element.parent, because we have rooted that reference so it's // now independent of whether `element.parent` changes! first_child.borrow_mut(cx).parent = None; Essentially, when mutating a field, you have to obtain mutable access to the context, so there will not be any references to the field itself still around (e.g. element.borrow(cx).parent), only to the GC’d data within it, so you can change what a field references without invalidating other references to the contents of what the field references. This is a pretty cool trick that enables GC without runtime-checked interior mutability, which is relatively rare in such designs. Unfinished design for a builtin Rust GC For a while a couple of us worked on a way to make Rust itself extensible with a pluggable GC, using LLVM stack map support for finding roots. After all, if we know which types are GC-ish, we can include metadata on how to find roots for each function, similar to how Rust functions currently contain unwinding hooks to enable cleanly running destructors during a panic. We never got around to figuring out a complete design, but you can find more information on what we figured out in my and Felix’s posts on this subject. Essentially, it involved a Trace trait with more generic trace methods, an auto-implemented Root trait that works similar to Send, and compiler machinery to keep track of which Root types are on the stack. This is probably not too useful for people attempting to implement a GC, but I’m mentioning it for completeness’ sake. Note that pre-1.0 Rust did have a builtin GC (@T, known as “managed pointers”), but IIRC in practice the cycle-management parts were not ever implemented so it behaved exactly like Rc&lt;T&gt;. I believe it was intended to have a cycle collector (I’ll talk more about that in the next section). bacon-rajan-cc (and cycle collectors in general) Nick Fitzgerald wrote bacon-rajan-cc to implement _“Concurrent Cycle Collection in Reference Counted Systems”__ by David F. Bacon and V.T. Rajan. This is what is colloquially called a cycle collector; a kind of garbage collector which is essentially “what if we took Rc&lt;T&gt; but made it detect cycles”. Some people do not consider these to be tracing garbage collectors, but they have a lot of similar characteristics (and they do still “trace” through types). They’re often categorized as “hybrid” approaches, much like gc. The idea is that you don’t actually need to know what the roots are if you’re maintaining reference counts: if a heap object has a reference count that is more than the number of heap objects referencing it, it must be a root. In practice it’s pretty inefficient to traverse the entire heap, so optimizations are applied, often by applying different “colors” to nodes, and by only looking at the set of objects that have recently have their reference counts decremented. A crucial observation here is that if you only focus on potential garbage, you can shift your definition of “root” a bit, when looking for cycles you don’t need to look for references from the stack, you can be satisfied with references from any part of the heap you know for a fact is reachable from things which are not potential garbage. A neat property of cycle collectors is while mark and sweep tracing GCs have their performance scale by the size of the heap as a whole, cycle collectors scale by the size of the actual garbage you have 7. There are of course other tradeoffs: deallocation is often cheaper or “free” in tracing GCs (amortizing those costs by doing it during the sweep phase) whereas cycle collectors have the constant allocator traffic involved in cleaning up objects when refcounts reach zero. The way bacon-rajan-cc works is that every time a reference count is decremented, the object is added to a list of “potential cycle roots”, unless the reference count is decremented to 0 (in which case the object is immediately cleaned up, just like Rc). It then traces through this list; decrementing refcounts for every reference it follows, and cleaning up any elements that reach refcount 0. It then traverses this list again and reincrements refcounts for each reference it follows, to restore the original refcount. This basically treats any element not reachable from this “potential cycle root” list as “not garbage”, and doesn’t bother to visit it. Cycle collectors require tighter control over the garbage collection algorithm, and have differing performance characteristics, so they may not necessarily be suitable for all use cases for GC integration in Rust, but it’s definitely worth considering! cell-gc Jason Orendorff’s cell-gc crate is interesting, it has a concept of “heap sessions”. Here’s a modified example from the readme: use cell_gc::Heap; // implements IntoHeap, and also generates an IntListRef type and accessors #[derive(cell_gc_derive::IntoHeap)] struct IntList&lt;'h&gt; { head: i64, tail: Option&lt;IntListRef&lt;'h&gt;&gt; } fn main() { // Create a heap (you'll only do this once in your whole program) let mut heap = Heap::new(); heap.enter(|hs| { // Allocate an object (returns an IntListRef) let obj1 = hs.alloc(IntList { head: 17, tail: None }); assert_eq!(obj1.head(), 17); assert_eq!(obj1.tail(), None); // Allocate another object let obj2 = hs.alloc(IntList { head: 33, tail: Some(obj1) }); assert_eq!(obj2.head(), 33); assert_eq!(obj2.tail().unwrap().head(), 17); // mutate `tail` obj2.set_tail(None); }); } All mutation goes through autogenerated accessors, so the crate has a little more control over traffic through the GC. These accessors help track roots via a scheme similar to what gc does; where there’s an IntoHeap trait used for modifying root refcounts when a reference is put into and taken out of the heap via accessors. Heap sessions allow for the heap to moved around, even sent to other threads, and their lifetime prevents heap objects from being mixed between sessions. This uses a concept called generativity; you can read more about generativity in “You Can’t Spell Trust Without Rust” ch 6.3, by Aria Beingessner, or by looking at the indexing crate. Interlude: The similarities between async and GCs The next two examples use machinery from Rust’s async functionality despite having nothing to do with async I/O, and I think it’s important to talk about why that should make sense. I’ve tweeted about this before: I and Catherine West figured this out when we were talking about her GC idea based on async. You can see some of this correspondence in Go: Go is a language that has both garbage collection and async I/O, and both of these use the same “safepoints” for yielding to the garbage collector or the scheduler. In Go, the compiler needs to automatically insert code that checks the “pulse” of the heap every now and then, and potentially runs garbage collection. It also needs to automatically insert code that can tell the scheduler “hey now is a safe time to interrupt me if a different goroutine wishes to run”. These are very similar in principle – they’re both essentially places where the compiler is inserting “it is okay to interrupt me now” checks, sometimes called “interruption points” or “yield points”. Now, Rust’s compiler does not automatically insert interruption points. However, the design of async in Rust is essentially a way of adding explicit interruption points to Rust. foo().await in Rust is a way of running foo() and expecting that the scheduler may interrupt the code in between. The design of Future and Pin&lt;P&gt; come out of making this safe and pleasant to work with. As we shall see, this same machinery can be used for creating safe interruption points for GCs in Rust. Shifgrethor shifgrethor is an experiment by Saoirse to try and build a GC that uses Pin&lt;P&gt; for managing roots. They’ve written extensively on the design of shifgrethor on their blog. In particular, the post on rooting goes through how rooting works. The basic design is that there’s a Root&lt;'root&gt; type that contains a Pin&lt;P&gt;, which can be immovably tied to a stack frame using the same idea behind pin-utils’ pin_mut!() macro: letroot!(root); let gc: Gc&lt;'root, Foo&gt; = root.gc(Foo::new()); The fact that root is immovable allows for it to be treated as a true marker for the stack frame over anything else. The list of rooted types can be neatly stored in an ordered stack-like vector in the GC implementation, popping when individual roots go out of scope. If you wish to return a rooted object from a function, the function needs to accept a Root&lt;'root&gt;: fn new&lt;'root&gt;(root: Root&lt;'root&gt;) -&gt; Gc&lt;'root, Self&gt; { root.gc(Self { // ... } } All GC’d types have a 'root lifetime of the root they trace back to, and are declared with a custom derive: #[derive(GC)] struct Foo&lt;'root&gt; { #[gc] bar: GcStore&lt;'root, Bar&gt;, } GcStore is a way to have fields use the rooting of their parent. Normally, if you wanted to put Gc&lt;'root2, Bar&lt;'root2&gt;&gt; inside Foo&lt;'root1&gt; you would not be able to because the lifetimes derive from different roots. GcStore, along with autogenerated accessors from #[derive(GC)], will set Bar’s lifetime to be the same as Foo when you attempt to stick it inside Foo. This design is somewhat similar to that of Servo where there’s a pair of types, one that lets us refer to GC types on the stack, and one that lets GC types refer to each other on the heap, but it uses Pin&lt;P&gt; instead of a lint to enforce this safely, which is way nicer. Root&lt;'root&gt; and GcStore do a bunch of lifetime tweaking that’s reminiscent of Josephine’s rooting system, however there’s no need for an &amp;mut JsContext type that needs to be passed around everywhere. gc-arena gc-arena is Catherine West’s experimental GC design for her Lua VM, luster. The gc-arena crate forces all GC-manipulating code to go within arena.mutate() calls, between which garbage collection may occur. #[derive(Collect)] #[collect(no_drop)] struct TestRoot&lt;'gc&gt; { number: Gc&lt;'gc, i32&gt;, many_numbers: GcCell&lt;Vec&lt;Gc&lt;'gc, i32&gt;&gt;&gt;, } make_arena!(TestArena, TestRoot); let mut arena = TestArena::new(ArenaParameters::default(), |mc| TestRoot { number: Gc::allocate(mc, 42), many_numbers: GcCell::allocate(mc, Vec::new()), }); arena.mutate(|_mc, root| { assert_eq!(*((*root).number), 42); root.numbers.write(mc).push(Gc::allocate(mc, 0)); }); Mutation is done with GcCell, basically a fancier version of Gc&lt;RefCell&lt;T&gt;&gt;. All GC operations require a MutationContext (mc), which is only available within arena.mutate(). Only the arena root may survive between mutate() calls, and garbage collection does not happen during .mutate(), so rooting is easy – just follow the arena root. This crate allows for multiple GCs to coexist with separate heaps, and, similarly to cell-gc, it uses generativity to enforce that the heaps do not get mixed. So far this is mostly like other arena-based systems, but with a GC. The really cool part of the design is the gc-sequence crate, which essentially builds a Future-like API (using a Sequence trait) on top of gc-arena that can potentially make this very pleasant to use. Here’s a modified example from a test: #[derive(Collect)] #[collect(no_drop)] struct TestRoot&lt;'gc&gt; { test: Gc&lt;'gc, i32&gt;, } make_sequencable_arena!(test_sequencer, TestRoot); use test_sequencer::Arena as TestArena; let arena = TestArena::new(ArenaParameters::default(), |mc| TestRoot { test: Gc::allocate(mc, 42), }); let mut sequence = arena.sequence(|root| { sequence::from_fn_with(root.test, |_, test| { if *test == 42 { Ok(*test + 10) } else { Err("will not be generated") } }) .and_then(|_, r| Ok(r + 12)) .and_chain(|_, r| Ok(sequence::ok(r - 10))) .then(|_, res| res.expect("should not be error")) .chain(|_, r| sequence::done(r + 10)) .map(|r| sequence::done(r - 60)) .flatten() .boxed() }); loop { match sequence.step() { Ok((_, output)) =&gt; { assert_eq!(output, 4); return; } Err(s) =&gt; sequence = s, } } This is very similar to chained callback futures code; and if it could use the Future trait would be able to make use of async to convert this callback heavy code into sequential code with interrupt points using await. There were design constraints making Future not workable for this use case, though if Rust ever gets generators this would work well, and it’s quite possible that another GC with a similar design could be written, using async/await and Future. Essentially, this paints a picture of an entire space of Rust GC design where GC mutations are performed using await (or yield if we ever get generators), and garbage collection can occur during those yield points, in a way that’s highly reminiscent of Go’s design. Moving forward As is hopefully obvious, the space of safe GC design in Rust is quite rich and has a lot of interesting ideas. I’m really excited to see what folks come up with here! If you’re interested in reading more about GCs in general, “A Unified Theory of Garbage Collection” by Bacon et al and the GC Handbook are great reads. Thanks to Andi McClure, Jason Orendorff, Nick Fitzgerald, and Nika Layzell for providing feedback on drafts of this blog post I’m also going to completely ignore the field of conservative stack-scanning tracing GCs where you figure out your roots by looking at all the stack memory and considering anything with a remotely heap-object-like bit pattern to be a root. These are interesting, but can’t really be made 100% safe in the way Rust wants them to be unless you scan the heap as well. &#8617; Which currently does not have support for concurrent garbage collection, but it could be added. &#8617; Some JNI-using APIs are also forced to have explicit rooting APIs to give access to things like raw buffers. &#8617; In general, finalizers in GCs are hard to implement soundly in any language, not just Rust, but Rust can sometimes be a bit more annoying about it. &#8617; Spolier: This is actually possible in Rust, and we’ll get into it further in this post! &#8617; Such hybrid approaches are common in high performance GCs; “A Unified Theory of Garbage Collection” by Bacon et al. covers a lot of the breadth of these approaches. &#8617; Firefox’s DOM actually uses a mark &amp; sweep tracing GC mixed with a cycle collector for this reason. The DOM types themselves are cycle collected, but JavaScript objects are managed by the Spidermonkey GC. Since some DOM types may contain references to arbitrary JS types (e.g. ones that store callbacks) there’s a fair amount of work required to break cycles manually in some cases, but it has performance benefits since the vast majority of DOM objects either never become garbage or become garbage by having a couple non-cycle-participating references get released. &#8617;]]></summary></entry><entry><title type="html">Arenas in Rust</title><link href="http://manishearth.github.io/blog/2021/03/15/arenas-in-rust/" rel="alternate" type="text/html" title="Arenas in Rust" /><published>2021-03-15T00:00:00+00:00</published><updated>2021-03-15T00:00:00+00:00</updated><id>http://manishearth.github.io/blog/2021/03/15/arenas-in-rust</id><content type="html" xml:base="http://manishearth.github.io/blog/2021/03/15/arenas-in-rust/"><![CDATA[<p>There’s been some discussion about arenas in Rust recently, and I thought I’d write about them.</p>

<p>Arenas aren’t something you would typically reach for in Rust so fewer people know about them; you only really see them in applications for various niche use cases. Usually you can use an arena by pulling in a crate and not using additional <code class="language-plaintext highlighter-rouge">unsafe</code>, so there’s no need to be particularly skittish around them in Rust, and it seems like it would be useful knowledge, especially for people coming to Rust from fields where arenas are more common.</p>

<p>Furthermore, there’s a set of <em>really cool</em> lifetime effects involved when implementing self-referential arenas, that I don’t think have been written about before.</p>

<p>I’m mostly writing this to talk about the cool lifetime effects, but I figured it’s worth writing a general introduction that has something for all Rustaceans. If you know what arenas are and just want the cool lifetimes you can skip directly to <a href="#implementing-a-self-referential-arena">the section on implementing self-referential arenas</a>. Otherwise, read on.</p>

<h2 id="whats-an-arena">What’s an arena?</h2>

<p>An arena is essentially a way to group up allocations that are expected to have the same lifetime. Sometimes you need to allocate a bunch of objects for the lifetime of an event, after which they can all be thrown away wholesale. It’s inefficient to call into the system allocator each time, and far more preferable to <em>preallocate</em> a bunch of memory for your objects, cleaning it all up at once once you’re done with them.</p>

<p>Broadly speaking, there are two reasons you might wish to use an arena:</p>

<p>Firstly, your primary goal may be to reduce allocation pressure, as mentioned above. For example, in a game or application, there may be large mishmash of per-frame-tick objects that need to get allocated each frame, and then thrown away. This is <em>extremely</em> common in game development in particular, and allocator pressure is something gamedevs tend to care about. With arenas, it’s easy enough to allocate an arena, fill it up during each frame and clear it out once the frame is over. This has additional benefits of cache locality: you can ensure that most of the per-frame objects (which are likely used more often than other objects) are usually in cache during the frame, since they’ve been allocated adjacently.</p>

<p>Another goal might be that you want to write self referential data, like a complex graph with cycles, that can get cleaned up all at once. For example, when writing compilers, type information will likely need to reference other types and other such data, leading to a complex, potentially cyclic graph of types. Once you’ve computed a type you probably don’t need to throw it away individually, so you can use an arena to store all your computed type information, cleaning the whole thing up at once when you’re at a stage where the types don’t matter anymore. Using this pattern allows your code to not have to worry about whether the self-referential bits get deallocated “early”, it lets you make the assumption that if you have a <code class="language-plaintext highlighter-rouge">Ty</code> it lives as long as all the other <code class="language-plaintext highlighter-rouge">Ty</code>s and can reference them directly.</p>

<p>These two goals are not necessarily disjoint: You may wish to use an arena to achieve both goals simultaneously. But you can also just have an arena that disallows self referential types (but has other nice properties). Later in this post I’m going to implement an arena that allows self-referential types but is not great on allocation pressure, mostly for ease of implementation. <em>Typically</em> if you’re writing an arena for self-referential types you can make it simultaneously reduce allocator pressure, but there can be tradeoffs.</p>

<h2 id="how-can-i-use-an-arena-in-rust">How can I use an arena in Rust?</h2>

<p>Typically to <em>use</em> an arena you can just pull in a crate that implements the right kind of arena. There are two that I know of that I’ll talk about below, though <a href="https://crates.io/search?q=arena">a cursory search of “arena” on crates.io</a> turns up many other promising candidates.</p>

<p>I’ll note that if you just need cyclic graph structures, you don’t <em>have</em> to use an arena, the excellent <a href="https://docs.rs/petgraph/"><code class="language-plaintext highlighter-rouge">petgraph</code></a> crate is often sufficient. <a href="https://docs.rs/slotmap/"><code class="language-plaintext highlighter-rouge">slotmap</code></a> is also useful; it’s a map-like datastructure useful for self-referential data, based on generational indexing.</p>

<h3 id="bumpalo">Bumpalo</h3>

<p><a href="https://docs.rs/bumpalo"><code class="language-plaintext highlighter-rouge">Bumpalo</code></a> is a fast “bump allocator”, which allows heterogenous contents, and only allows cycles if you do not care about destructors getting run.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">use</span> <span class="nn">bumpalo</span><span class="p">::</span><span class="n">Bump</span><span class="p">;</span>

<span class="c1">// (example slightly modified from `bumpalo` docs)</span>

<span class="c1">// Create a new arena to bump allocate into.</span>
<span class="k">let</span> <span class="n">bump</span> <span class="o">=</span> <span class="nn">Bump</span><span class="p">::</span><span class="nf">new</span><span class="p">();</span>

<span class="c1">// Allocate values into the arena.</span>
<span class="k">let</span> <span class="n">scooter</span> <span class="o">=</span> <span class="n">bump</span><span class="nf">.alloc</span><span class="p">(</span><span class="n">Doggo</span> <span class="p">{</span>
    <span class="n">cuteness</span><span class="p">:</span> <span class="nn">u64</span><span class="p">::</span><span class="nf">max_value</span><span class="p">(),</span>
    <span class="n">age</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span>
    <span class="n">scritches_required</span><span class="p">:</span> <span class="k">true</span><span class="p">,</span>
<span class="p">});</span>

<span class="c1">// Happy birthday, Scooter!</span>
<span class="n">scooter</span><span class="py">.age</span> <span class="o">+=</span> <span class="mi">1</span><span class="p">;</span>
</code></pre></div></div>

<p>Every call to <a href="https://docs.rs/bumpalo/3.6.1/bumpalo/struct.Bump.html#method.alloc"><code class="language-plaintext highlighter-rouge">Bump::alloc()</code></a> returns a mutable reference to the allocated object. You can allocate different objects, and they can even reference each other<sup id="fnref:0" role="doc-noteref"><a href="#fn:0" class="footnote" rel="footnote">1</a></sup>. By default it does not call destructors on its contents; however you can use <a href="https://docs.rs/bumpalo/3.6.1/bumpalo/boxed/index.html"><code class="language-plaintext highlighter-rouge">bumpalo::boxed</code></a> (or custom allocators on Nightly) to get this behavior. You can similarly use <a href="https://docs.rs/bumpalo/3.6.1/bumpalo/collections/index.html"><code class="language-plaintext highlighter-rouge">bumpalo::collections</code></a> to get <a href="https://docs.rs/bumpalo"><code class="language-plaintext highlighter-rouge">bumpalo</code></a>-backed vectors and strings. <a href="https://docs.rs/bumpalo/3.6.1/bumpalo/boxed/index.html"><code class="language-plaintext highlighter-rouge">bumpalo::boxed</code></a> will not be allowed to participate in cycles.</p>

<h3 id="typed-arena"><code class="language-plaintext highlighter-rouge">typed-arena</code></h3>

<p><a href="https://docs.rs/typed-arena/"><code class="language-plaintext highlighter-rouge">typed-arena</code></a> is an arena allocator that can only store objects of a single type, but it does allow for setting up cyclic references:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Example from typed-arena docs</span>

<span class="k">use</span> <span class="nn">std</span><span class="p">::</span><span class="nn">cell</span><span class="p">::</span><span class="n">Cell</span><span class="p">;</span>
<span class="k">use</span> <span class="nn">typed_arena</span><span class="p">::</span><span class="n">Arena</span><span class="p">;</span>

<span class="k">struct</span> <span class="n">CycleParticipant</span><span class="o">&lt;</span><span class="nv">'a</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="n">other</span><span class="p">:</span> <span class="n">Cell</span><span class="o">&lt;</span><span class="nb">Option</span><span class="o">&lt;&amp;</span><span class="nv">'a</span> <span class="n">CycleParticipant</span><span class="o">&lt;</span><span class="nv">'a</span><span class="o">&gt;&gt;&gt;</span><span class="p">,</span>
<span class="p">}</span>

<span class="k">let</span> <span class="n">arena</span> <span class="o">=</span> <span class="nn">Arena</span><span class="p">::</span><span class="nf">new</span><span class="p">();</span>

<span class="k">let</span> <span class="n">a</span> <span class="o">=</span> <span class="n">arena</span><span class="nf">.alloc</span><span class="p">(</span><span class="n">CycleParticipant</span> <span class="p">{</span> <span class="n">other</span><span class="p">:</span> <span class="nn">Cell</span><span class="p">::</span><span class="nf">new</span><span class="p">(</span><span class="nb">None</span><span class="p">)</span> <span class="p">});</span>
<span class="k">let</span> <span class="n">b</span> <span class="o">=</span> <span class="n">arena</span><span class="nf">.alloc</span><span class="p">(</span><span class="n">CycleParticipant</span> <span class="p">{</span> <span class="n">other</span><span class="p">:</span> <span class="nn">Cell</span><span class="p">::</span><span class="nf">new</span><span class="p">(</span><span class="nb">None</span><span class="p">)</span> <span class="p">});</span>

<span class="c1">// mutate them after the fact to set up a cycle</span>
<span class="n">a</span><span class="py">.other</span><span class="nf">.set</span><span class="p">(</span><span class="nf">Some</span><span class="p">(</span><span class="n">b</span><span class="p">));</span>
<span class="n">b</span><span class="py">.other</span><span class="nf">.set</span><span class="p">(</span><span class="nf">Some</span><span class="p">(</span><span class="n">a</span><span class="p">));</span>
</code></pre></div></div>

<p>Unlike <a href="https://docs.rs/bumpalo"><code class="language-plaintext highlighter-rouge">bumpalo</code></a>, <a href="https://docs.rs/typed-arena/"><code class="language-plaintext highlighter-rouge">typed-arena</code></a> will always run destructors on its contents when the arena itself goes out of scope<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">2</a></sup>.</p>

<h2 id="implementing-a-self-referential-arena">Implementing a self-referential arena</h2>

<p>Self referential arenas are interesting because, typically, Rust is very very wary of self-referential data. But arenas let you clearly separate the step of “I don’t care about this object” and “this object can be deleted” in a way that is sufficient to allow self-referential and cyclic types.</p>

<p>It’s pretty rare to need to implement your own arena – <a href="https://docs.rs/bumpalo"><code class="language-plaintext highlighter-rouge">bumpalo</code></a> and <a href="https://docs.rs/typed-arena/"><code class="language-plaintext highlighter-rouge">typed-arena</code></a> cover most of the use cases, and if they don’t cover yours you probably can find something that does on <a href="https://crates.io/search?q=arena">crates.io</a>. But if you really need to, or if you’re interested in the nitty-gritty lifetime details, this section is for you.</p>

<div class="post-aside post-aside-note">For people less familiar with lifetimes: the lifetimes in the syntaxes <code class="language-plaintext highlighter-rouge">&amp;'a Foo</code> and <code class="language-plaintext highlighter-rouge">Foo&lt;'b&gt;</code> mean different things. <code class="language-plaintext highlighter-rouge">'a</code> in <code class="language-plaintext highlighter-rouge">&amp;'a Foo</code> is the lifetime <em>of</em> <code class="language-plaintext highlighter-rouge">Foo</code>, or, at least the lifetime of <em>this</em> reference to <code class="language-plaintext highlighter-rouge">Foo</code>. <code class="language-plaintext highlighter-rouge">'b</code> in <code class="language-plaintext highlighter-rouge">Foo&lt;'b&gt;</code> is a lifetime <em>parameter</em> of <code class="language-plaintext highlighter-rouge">Foo</code>, and typically means something like “the lifetime of data <code class="language-plaintext highlighter-rouge">Foo</code> is allowed to reference”.</div>

<p>The key to implementing an arena <code class="language-plaintext highlighter-rouge">Arena</code> with entries typed as <code class="language-plaintext highlighter-rouge">Entry</code> is in the following rules:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">Arena</code> and <code class="language-plaintext highlighter-rouge">Entry</code> should both have a lifetime parameter: <code class="language-plaintext highlighter-rouge">Arena&lt;'arena&gt;</code> and <code class="language-plaintext highlighter-rouge">Entry&lt;'arena&gt;</code></li>
  <li><code class="language-plaintext highlighter-rouge">Arena</code> methods should all receive <code class="language-plaintext highlighter-rouge">Arena&lt;'arena&gt;</code> as <code class="language-plaintext highlighter-rouge">&amp;'arena self</code>, i.e. their <code class="language-plaintext highlighter-rouge">self</code> type is <code class="language-plaintext highlighter-rouge">&amp;'arena Arena&lt;'arena&gt;</code></li>
  <li><code class="language-plaintext highlighter-rouge">Entry</code> should almost always be passed around as <code class="language-plaintext highlighter-rouge">&amp;'arena Entry&lt;'arena&gt;</code> (it’s useful to make an alias for this)</li>
  <li>Use interior mutability; <code class="language-plaintext highlighter-rouge">&amp;mut self</code> on <code class="language-plaintext highlighter-rouge">Arena</code> will make everything stop compiling. If using <code class="language-plaintext highlighter-rouge">unsafe</code> for mutability, make sure you have a <code class="language-plaintext highlighter-rouge">PhantomData</code> for <code class="language-plaintext highlighter-rouge">RefCell&lt;Entry&lt;'arena&gt;&gt;</code> somewhere.</li>
</ul>

<p>That’s basically it from the lifetime side, the rest is all in figuring what API you want and implementing the backing storage. Armed with the above rules you should be able to make your custom arena work with the guarantees you need without having to understand what’s going on with the underlying lifetimes.</p>

<p>Let’s go through an implementation example, and then dissect <em>why</em> it works.</p>

<h3 id="implementation">Implementation</h3>

<p>My crate <a href="https://docs.rs/elsa"><code class="language-plaintext highlighter-rouge">elsa</code></a> implements an arena in 100% safe code <a href="https://github.com/Manishearth/elsa/blob/915d26008d8bae069927c551da506dba05d2755b/examples/mutable_arena.rs">in one of its examples</a>. This arena does <em>not</em> save on allocations since <a href="https://docs.rs/elsa/1.4.0/elsa/vec/struct.FrozenVec.html"><code class="language-plaintext highlighter-rouge">elsa::FrozenVec</code></a> requires its contents be behind some indirection, and it’s not generic, but it’s a reasonable way to illustrate how the lifetimes work without getting into the weeds of implementing a <em>really good</em> arena with <code class="language-plaintext highlighter-rouge">unsafe</code>.</p>

<p>The example implements an arena of <code class="language-plaintext highlighter-rouge">Person&lt;'arena&gt;</code> types, <code class="language-plaintext highlighter-rouge">Arena&lt;'arena&gt;</code>. The goal is to implement some kind of directed social graph, which may have cycles.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">use</span> <span class="nn">elsa</span><span class="p">::</span><span class="n">FrozenVec</span><span class="p">;</span>

<span class="k">struct</span> <span class="n">Arena</span><span class="o">&lt;</span><span class="nv">'arena</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="n">people</span><span class="p">:</span> <span class="n">FrozenVec</span><span class="o">&lt;</span><span class="nb">Box</span><span class="o">&lt;</span><span class="n">Person</span><span class="o">&lt;</span><span class="nv">'arena</span><span class="o">&gt;&gt;&gt;</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div></div>

<p><a href="https://docs.rs/elsa/1.4.0/elsa/vec/struct.FrozenVec.html"><code class="language-plaintext highlighter-rouge">elsa::FrozenVec</code></a> is an append-only <code class="language-plaintext highlighter-rouge">Vec</code>-like abstraction that allows you to call <code class="language-plaintext highlighter-rouge">.push()</code> without needing a mutable reference, and is how we’ll be able to implement this arena in safe code.</p>

<p>Each <code class="language-plaintext highlighter-rouge">Person&lt;'arena&gt;</code> has a list of people they follow but also keeps track of people who follow them:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">struct</span> <span class="n">Person</span><span class="o">&lt;</span><span class="nv">'arena</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="k">pub</span> <span class="n">follows</span><span class="p">:</span> <span class="n">FrozenVec</span><span class="o">&lt;</span><span class="n">PersonRef</span><span class="o">&lt;</span><span class="nv">'arena</span><span class="o">&gt;&gt;</span><span class="p">,</span>
    <span class="k">pub</span> <span class="n">reverse_follows</span><span class="p">:</span> <span class="n">FrozenVec</span><span class="o">&lt;</span><span class="n">PersonRef</span><span class="o">&lt;</span><span class="nv">'arena</span><span class="o">&gt;&gt;</span><span class="p">,</span>
    <span class="k">pub</span> <span class="n">name</span><span class="p">:</span> <span class="o">&amp;</span><span class="k">'static</span> <span class="nb">str</span><span class="p">,</span>
<span class="p">}</span>

<span class="c1">// following the rule above about references to entry types</span>
<span class="k">type</span> <span class="n">PersonRef</span><span class="o">&lt;</span><span class="nv">'arena</span><span class="o">&gt;</span> <span class="o">=</span> <span class="o">&amp;</span><span class="nv">'arena</span> <span class="n">Person</span><span class="o">&lt;</span><span class="nv">'arena</span><span class="o">&gt;</span><span class="p">;</span>
</code></pre></div></div>

<p>The lifetime <code class="language-plaintext highlighter-rouge">'arena</code> is essentially “the lifetime of the arena itself”. This is where it starts getting weird: typically if your type has a lifetime <em>parameter</em>, the caller gets to pick what goes in there. You don’t get to just say “this is the lifetime of the object itself”, the caller would typically be able to instantiate an <code class="language-plaintext highlighter-rouge">Arena&lt;'static&gt;</code> if they wish, or an <code class="language-plaintext highlighter-rouge">Arena&lt;'a&gt;</code> for some <code class="language-plaintext highlighter-rouge">'a</code>. But here we’re declaring that <code class="language-plaintext highlighter-rouge">'arena</code> is the lifetime of the arena itself; clearly something fishy is happening here.</p>

<p>Here’s where we actually implement the arena:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">impl</span><span class="o">&lt;</span><span class="nv">'arena</span><span class="o">&gt;</span> <span class="n">Arena</span><span class="o">&lt;</span><span class="nv">'arena</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="k">fn</span> <span class="nf">new</span><span class="p">()</span> <span class="k">-&gt;</span> <span class="n">Arena</span><span class="o">&lt;</span><span class="nv">'arena</span><span class="o">&gt;</span> <span class="p">{</span>
        <span class="n">Arena</span> <span class="p">{</span>
            <span class="n">people</span><span class="p">:</span> <span class="nn">FrozenVec</span><span class="p">::</span><span class="nf">new</span><span class="p">(),</span>
        <span class="p">}</span>
    <span class="p">}</span>
    
    <span class="k">fn</span> <span class="nf">add_person</span><span class="p">(</span><span class="o">&amp;</span><span class="nv">'arena</span> <span class="k">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="o">&amp;</span><span class="k">'static</span> <span class="nb">str</span><span class="p">,</span>
                  <span class="n">follows</span><span class="p">:</span> <span class="nb">Vec</span><span class="o">&lt;</span><span class="n">PersonRef</span><span class="o">&lt;</span><span class="nv">'arena</span><span class="o">&gt;&gt;</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">PersonRef</span><span class="o">&lt;</span><span class="nv">'arena</span><span class="o">&gt;</span> <span class="p">{</span>
        <span class="k">let</span> <span class="n">idx</span> <span class="o">=</span> <span class="k">self</span><span class="py">.people</span><span class="nf">.len</span><span class="p">();</span>
        <span class="k">self</span><span class="py">.people</span><span class="nf">.push</span><span class="p">(</span><span class="nn">Box</span><span class="p">::</span><span class="nf">new</span><span class="p">(</span><span class="n">Person</span> <span class="p">{</span>
            <span class="n">name</span><span class="p">,</span>
            <span class="n">follows</span><span class="p">:</span> <span class="n">follows</span><span class="nf">.into</span><span class="p">(),</span>
            <span class="n">reverse_follows</span><span class="p">:</span> <span class="nn">Default</span><span class="p">::</span><span class="nf">default</span><span class="p">(),</span>
        <span class="p">}));</span>
        <span class="k">let</span> <span class="n">me</span> <span class="o">=</span> <span class="o">&amp;</span><span class="k">self</span><span class="py">.people</span><span class="p">[</span><span class="n">idx</span><span class="p">];</span>
        <span class="k">for</span> <span class="n">friend</span> <span class="k">in</span> <span class="o">&amp;</span><span class="n">me</span><span class="py">.follows</span> <span class="p">{</span>
            <span class="c1">// We're mutating existing arena entries to add references,</span>
            <span class="c1">// potentially creating cycles!</span>
            <span class="n">friend</span><span class="py">.reverse_follows</span><span class="nf">.push</span><span class="p">(</span><span class="n">me</span><span class="p">)</span>
        <span class="p">}</span>
        <span class="n">me</span>
    <span class="p">}</span>

    <span class="k">fn</span> <span class="nf">dump</span><span class="p">(</span><span class="o">&amp;</span><span class="nv">'arena</span> <span class="k">self</span><span class="p">)</span> <span class="p">{</span>
        <span class="c1">// code to print out every Person, their followers, and the people who follow them</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Note the <code class="language-plaintext highlighter-rouge">&amp;'arena self</code> in <code class="language-plaintext highlighter-rouge">add_person</code>.</p>

<p>A <em>good</em> implementation here would typically separate out code handling the higher level invariant of “if A <code class="language-plaintext highlighter-rouge">follows</code> B then B <code class="language-plaintext highlighter-rouge">reverse_follows</code> A”, but this is just an example.</p>

<p>And finally, we can use the arena like this:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">arena</span> <span class="o">=</span> <span class="nn">Arena</span><span class="p">::</span><span class="nf">new</span><span class="p">();</span>
    <span class="k">let</span> <span class="n">lonely</span> <span class="o">=</span> <span class="n">arena</span><span class="nf">.add_person</span><span class="p">(</span><span class="s">"lonely"</span><span class="p">,</span> <span class="nd">vec!</span><span class="p">[]);</span>
    <span class="k">let</span> <span class="n">best_friend</span> <span class="o">=</span> <span class="n">arena</span><span class="nf">.add_person</span><span class="p">(</span><span class="s">"best friend"</span><span class="p">,</span> <span class="nd">vec!</span><span class="p">[</span><span class="n">lonely</span><span class="p">]);</span>
    <span class="k">let</span> <span class="n">threes_a_crowd</span> <span class="o">=</span> <span class="n">arena</span><span class="nf">.add_person</span><span class="p">(</span><span class="s">"threes a crowd"</span><span class="p">,</span> <span class="nd">vec!</span><span class="p">[</span><span class="n">lonely</span><span class="p">,</span> <span class="n">best_friend</span><span class="p">]);</span>
    <span class="k">let</span> <span class="n">rando</span> <span class="o">=</span> <span class="n">arena</span><span class="nf">.add_person</span><span class="p">(</span><span class="s">"rando"</span><span class="p">,</span> <span class="nd">vec!</span><span class="p">[]);</span>
    <span class="k">let</span> <span class="n">_everyone</span> <span class="o">=</span> <span class="n">arena</span><span class="nf">.add_person</span><span class="p">(</span><span class="s">"follows everyone"</span><span class="p">,</span> <span class="nd">vec!</span><span class="p">[</span><span class="n">rando</span><span class="p">,</span> <span class="n">threes_a_crowd</span><span class="p">,</span> <span class="n">lonely</span><span class="p">,</span> <span class="n">best_friend</span><span class="p">]);</span>
    <span class="n">arena</span><span class="nf">.dump</span><span class="p">();</span>
<span class="p">}</span>
</code></pre></div></div>

<p>In this case all of the “mutability” happens in the implementation of the arena itself, but it would be possible for this code to add entries directly to the <code class="language-plaintext highlighter-rouge">follows</code>/<code class="language-plaintext highlighter-rouge">reverse_follows</code> lists, or <code class="language-plaintext highlighter-rouge">Person</code> could have <code class="language-plaintext highlighter-rouge">RefCell</code>s for other kinds of links, or whatever.</p>

<h3 id="how-the-lifetimes-work">How the lifetimes work</h3>

<p>So how does this work? As I said earlier, with such abstractions in Rust, the caller typically has freedom to set the lifetime based on what they do with it. For example, if you have a <code class="language-plaintext highlighter-rouge">HashMap&lt;K, &amp;'a str&gt;</code>, the <code class="language-plaintext highlighter-rouge">'a</code> will get set based on the lifetime of what you try to insert.</p>

<p>When you construct the <code class="language-plaintext highlighter-rouge">Arena</code> its lifetime parameter is indeed still unconstrained, and we can test this by checking that the following code, which forcibly constrains the lifetime, still compiles.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">let</span> <span class="n">arena</span><span class="p">:</span> <span class="n">Arena</span><span class="o">&lt;</span><span class="k">'static</span><span class="o">&gt;</span> <span class="o">=</span> <span class="nn">Arena</span><span class="p">::</span><span class="nf">new</span><span class="p">();</span>
</code></pre></div></div>

<p>But the moment you try to do anything with the arena, this stops working:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">let</span> <span class="n">arena</span><span class="p">:</span> <span class="n">Arena</span><span class="o">&lt;</span><span class="k">'static</span><span class="o">&gt;</span> <span class="o">=</span> <span class="nn">Arena</span><span class="p">::</span><span class="nf">new</span><span class="p">();</span>
<span class="k">let</span> <span class="n">lonely</span> <span class="o">=</span> <span class="n">arena</span><span class="nf">.add_person</span><span class="p">(</span><span class="s">"lonely"</span><span class="p">,</span> <span class="nd">vec!</span><span class="p">[]);</span>
</code></pre></div></div>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>error[E0597]: `arena` does not live long enough
  --&gt; examples/mutable_arena.rs:5:18
   |
4  |     let arena: Arena&lt;'static&gt; = Arena::new();
   |                -------------- type annotation requires that `arena` is borrowed for `'static`
5  |     let lonely = arena.add_person("lonely", vec![]);
   |                  ^^^^^ borrowed value does not live long enough
...
11 | }
   | - `arena` dropped here while still borrowed
</code></pre></div></div>

<p>The <code class="language-plaintext highlighter-rouge">add_person</code> method is somehow suddenly forcing the <code class="language-plaintext highlighter-rouge">'arena</code> parameter of <code class="language-plaintext highlighter-rouge">Arena</code> to be set to its <em>own</em> lifetime, constraining it (and making it impossible to force-constrain it to be anything else with type annotations).</p>

<p>What’s going on here is a neat interaction with the <code class="language-plaintext highlighter-rouge">&amp;'arena self</code> signature of <code class="language-plaintext highlighter-rouge">add_person</code> (i.e. <code class="language-plaintext highlighter-rouge">self</code> is <code class="language-plaintext highlighter-rouge">&amp;'arena Arena&lt;'self&gt;</code>), and the fact that <code class="language-plaintext highlighter-rouge">'arena</code> in <code class="language-plaintext highlighter-rouge">Arena&lt;'arena&gt;</code> is an <a href="https://doc.rust-lang.org/nomicon/subtyping.html#variance"><em>invariant lifetime</em></a>.</p>

<p>Usually in your Rust programs, lifetimes are a little bit stretchy-squeezy. The following code compiles just fine:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// ask for two strings *with the same lifetime*</span>
<span class="k">fn</span> <span class="n">take_strings</span><span class="o">&lt;</span><span class="nv">'a</span><span class="o">&gt;</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">'a</span> <span class="nb">str</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">'a</span> <span class="nb">str</span><span class="p">)</span> <span class="p">{}</span>

<span class="c1">// string literal with lifetime 'static</span>
<span class="k">let</span> <span class="n">lives_forever</span> <span class="o">=</span> <span class="s">"foo"</span><span class="p">;</span>
<span class="c1">// owned string with shorter, local lifetime</span>
<span class="k">let</span> <span class="n">short_lived</span> <span class="o">=</span> <span class="nn">String</span><span class="p">::</span><span class="nf">from</span><span class="p">(</span><span class="s">"bar"</span><span class="p">);</span>

<span class="c1">// still works!</span>
<span class="nf">take_strings</span><span class="p">(</span><span class="n">lives_forever</span><span class="p">,</span> <span class="o">&amp;*</span><span class="n">short_lived</span><span class="p">);</span>
</code></pre></div></div>

<p>In this code, Rust is happy to notice that while <code class="language-plaintext highlighter-rouge">lives_forever</code> and <code class="language-plaintext highlighter-rouge">&amp;*short_lived</code> have different lifetimes, it’s totally acceptable to <em>pretend</em> <code class="language-plaintext highlighter-rouge">lives_forever</code> has a shorter lifetime for the duration of the <code class="language-plaintext highlighter-rouge">take_strings</code> function. It’s just a reference, a reference valid for a long lifetime is <em>also</em> valid for a shorter lifetime.</p>

<p>The thing is, this stretchy-squeeziness is not the same for all lifetimes! The <a href="https://doc.rust-lang.org/nomicon/subtyping.html">nomicon chapter on subtyping and variance</a> goes into detail on <em>why</em> this is the case, but a general rule of thumb is that most lifetimes are “squeezy”<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">3</a></sup> like the one in <code class="language-plaintext highlighter-rouge">&amp;'a str</code> above, but if some form of mutability is involved, they are rigid, also known as “invariant”. You can also have “stretchy”<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote" rel="footnote">4</a></sup> lifetimes if you’re using function types, but they’re rare.</p>

<p>Our <code class="language-plaintext highlighter-rouge">Arena&lt;'arena&gt;</code> is using interior mutability (via the <code class="language-plaintext highlighter-rouge">FrozenVec</code>) in a way that makes <code class="language-plaintext highlighter-rouge">'arena</code> invariant.</p>

<p>Let’s look at our two lines of code again. When the compiler sees the first line of the code below, it constructs <code class="language-plaintext highlighter-rouge">arena</code>, whose lifetime we’ll call <code class="language-plaintext highlighter-rouge">'a</code>. At this point the type of <code class="language-plaintext highlighter-rouge">arena</code> is <code class="language-plaintext highlighter-rouge">Arena&lt;'?&gt;</code>, where <code class="language-plaintext highlighter-rouge">'?</code> is made up notation for a yet-unconstrained lifetime.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">let</span> <span class="n">arena</span> <span class="o">=</span> <span class="nn">Arena</span><span class="p">::</span><span class="nf">new</span><span class="p">();</span> 
<span class="k">let</span> <span class="n">lonely</span> <span class="o">=</span> <span class="n">arena</span><span class="nf">.add_person</span><span class="p">(</span><span class="s">"lonely"</span><span class="p">,</span> <span class="nd">vec!</span><span class="p">[]);</span>
</code></pre></div></div>

<p>Let’s actually rewrite this to be clearer on what the lifetimes are.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">let</span> <span class="n">arena</span> <span class="o">=</span> <span class="nn">Arena</span><span class="p">::</span><span class="nf">new</span><span class="p">();</span> <span class="c1">// type Arena&lt;'?&gt;, lives for 'a</span>

<span class="c1">// explicitly write the `self` that gets constructed when you call add_person</span>
<span class="k">let</span> <span class="n">ref_to_arena</span> <span class="o">=</span> <span class="o">&amp;</span><span class="n">arena</span><span class="p">;</span> <span class="c1">// type &amp;'a Arena&lt;'?&gt;</span>
<span class="k">let</span> <span class="n">lonely</span> <span class="o">=</span> <span class="nn">Arena</span><span class="p">::</span><span class="nf">add_person</span><span class="p">(</span><span class="n">ref_to_arena</span><span class="p">,</span> <span class="s">"lonely"</span><span class="p">,</span> <span class="nd">vec!</span><span class="p">[]);</span>

</code></pre></div></div>

<p>Remember the second rule I listed earlier?</p>

<blockquote>
  <p><code class="language-plaintext highlighter-rouge">Arena</code> methods should all receive <code class="language-plaintext highlighter-rouge">Arena&lt;'arena&gt;</code> as <code class="language-plaintext highlighter-rouge">&amp;'arena self</code>, i.e. their <code class="language-plaintext highlighter-rouge">self</code> type is <code class="language-plaintext highlighter-rouge">&amp;'arena Arena&lt;'arena&gt;</code></p>
</blockquote>

<p>We followed this rule; the signature of <code class="language-plaintext highlighter-rouge">add_person</code> is <code class="language-plaintext highlighter-rouge">fn add_person(&amp;'arena self)</code>. This means that <code class="language-plaintext highlighter-rouge">ref_to_arena</code> is <em>forced</em> to have a lifetime that matches the pattern <code class="language-plaintext highlighter-rouge">&amp;'arena Arena&lt;'arena&gt;</code>. Currently its lifetime is <code class="language-plaintext highlighter-rouge">&amp;'a Arena&lt;'?&gt;</code>, which means that <code class="language-plaintext highlighter-rouge">'?</code> is <em>forced</em> to be the same as <code class="language-plaintext highlighter-rouge">'a</code>, i.e. the lifetime of the <code class="language-plaintext highlighter-rouge">arena</code> variable itself. If the lifetime weren’t invariant, the compiler would be able to squeeze other lifetimes to fit, but it is invariant, and the unconstrained lifetime is forced to be exactly one lifetime.</p>

<p>And by this rather subtle sleight of hand we’re able to force the compiler to set the lifetime <em>parameter</em> of <code class="language-plaintext highlighter-rouge">Arena&lt;'arena&gt;</code> to the lifetime of its <em>instance</em>.</p>

<p>After this, the rest is pretty straightforward. <code class="language-plaintext highlighter-rouge">Arena&lt;'arena&gt;</code> holds entries of type <code class="language-plaintext highlighter-rouge">Person&lt;'arena&gt;</code>, which is basically a way of saying “a <code class="language-plaintext highlighter-rouge">Person</code> that is allowed to reference items of lifetime <code class="language-plaintext highlighter-rouge">'arena</code>, i.e. items in <code class="language-plaintext highlighter-rouge">Arena</code>”. <code class="language-plaintext highlighter-rouge">type PersonRef&lt;'arena&gt; = &amp;'arena Person&lt;'arena&gt;</code> is a convenient shorthand for “a reference to a <code class="language-plaintext highlighter-rouge">Person</code> that lives in <code class="language-plaintext highlighter-rouge">Arena</code> and is allowed to reference objects from it”.</p>

<h3 id="what-about-destructors">What about destructors?</h3>

<p>So a thing I’ve not covered so far is how this can be safe in the presence of destructors. If your arena is allowed to have cyclic references, and you write a destructor reading from those cyclic references, whichever participant in the cycle that is deleted later on will have dangling references.</p>

<p>This gets to a <em>really</em> obscure part of Rust, even more obscure than variance. You almost never need to really understand this, beyond “explicit destructors subtly change borrow check behavior”. But it’s useful to know to get a better mental model of what’s going on here.</p>

<p>If we add the following code to our arena example:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">impl</span><span class="o">&lt;</span><span class="nv">'arena</span><span class="o">&gt;</span> <span class="nb">Drop</span> <span class="k">for</span> <span class="n">Person</span><span class="o">&lt;</span><span class="nv">'arena</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="k">fn</span> <span class="nf">drop</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">)</span> <span class="p">{</span>
        <span class="nd">println!</span><span class="p">(</span><span class="s">"goodbye {:?}"</span><span class="p">,</span> <span class="k">self</span><span class="py">.name</span><span class="p">);</span>
        <span class="k">for</span> <span class="n">friend</span> <span class="k">in</span> <span class="o">&amp;</span><span class="k">self</span><span class="py">.reverse_follows</span> <span class="p">{</span>
            <span class="c1">// potentially dangling!</span>
            <span class="nd">println!</span><span class="p">(</span><span class="s">"</span><span class="se">\t\t</span><span class="s">{}"</span><span class="p">,</span> <span class="n">friend</span><span class="py">.name</span><span class="p">);</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>we actually get this error:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">error</span><span class="p">[</span><span class="n">E0597</span><span class="p">]:</span> <span class="err">`</span><span class="n">arena</span><span class="err">`</span> <span class="n">does</span> <span class="n">not</span> <span class="n">live</span> <span class="n">long</span> <span class="n">enough</span>
  <span class="o">-</span><span class="k">-&gt;</span> <span class="n">examples</span><span class="o">/</span><span class="n">mutable_arena</span><span class="py">.rs</span><span class="p">:</span><span class="mi">5</span><span class="p">:</span><span class="mi">18</span>
   <span class="p">|</span>
<span class="mi">5</span>  <span class="p">|</span>     <span class="k">let</span> <span class="n">lonely</span> <span class="o">=</span> <span class="n">arena</span><span class="nf">.add_person</span><span class="p">(</span><span class="s">"lonely"</span><span class="p">,</span> <span class="nd">vec!</span><span class="p">[]);</span>
   <span class="p">|</span>                  <span class="o">^^^^^</span> <span class="n">borrowed</span> <span class="n">value</span> <span class="n">does</span> <span class="n">not</span> <span class="n">live</span> <span class="n">long</span> <span class="n">enough</span>
<span class="o">...</span>
<span class="mi">11</span> <span class="p">|</span> <span class="p">}</span>
   <span class="p">|</span> <span class="o">-</span>
   <span class="p">|</span> <span class="p">|</span>
   <span class="p">|</span> <span class="err">`</span><span class="n">arena</span><span class="err">`</span> <span class="n">dropped</span> <span class="n">here</span> <span class="k">while</span> <span class="n">still</span> <span class="n">borrowed</span>
   <span class="p">|</span> <span class="n">borrow</span> <span class="n">might</span> <span class="n">be</span> <span class="n">used</span> <span class="n">here</span><span class="p">,</span> <span class="n">when</span> <span class="err">`</span><span class="n">arena</span><span class="err">`</span> <span class="n">is</span> <span class="n">dropped</span> <span class="n">and</span> <span class="n">runs</span> <span class="n">the</span> <span class="n">destructor</span> <span class="k">for</span> <span class="k">type</span> <span class="err">`</span><span class="n">Arena</span><span class="o">&lt;</span><span class="nv">'_</span><span class="o">&gt;</span><span class="err">`</span>
</code></pre></div></div>

<p>The presence of destructors subtly changes the behavior of the borrow checker around self-referential lifetimes. The exact rules are tricky and <a href="https://doc.rust-lang.org/nomicon/dropck.html">explained in the nomicon</a>, but <em>essentially</em> what happened was that the existence of a custom destructor on <code class="language-plaintext highlighter-rouge">Person&lt;'arena&gt;</code> made <code class="language-plaintext highlighter-rouge">'arena</code> in <code class="language-plaintext highlighter-rouge">Person</code> (and thus <code class="language-plaintext highlighter-rouge">Arena</code>) a lifetime which is “observed during destruction”. This is then taken into account during borrow checking – suddenly the implicit <code class="language-plaintext highlighter-rouge">drop()</code> at the end of the scope is known to be able to read <code class="language-plaintext highlighter-rouge">'arena</code> data, and Rust makes the appropriate conclusion that <code class="language-plaintext highlighter-rouge">drop()</code> will be able to read things after they’ve been cleaned up, since destruction is itself a mutable operation, and <code class="language-plaintext highlighter-rouge">drop()</code> is run interspersed in it.</p>

<p>Of course, a reasonable question to ask is how we can store things like <code class="language-plaintext highlighter-rouge">Box</code> and <code class="language-plaintext highlighter-rouge">FrozenVec</code> in this arena if destructors aren’t allowed to “wrap” types with <code class="language-plaintext highlighter-rouge">'arena</code>. The reason is that Rust knows that <code class="language-plaintext highlighter-rouge">Drop</code> on <code class="language-plaintext highlighter-rouge">Box</code> <em>cannot</em> inspect <code class="language-plaintext highlighter-rouge">person.follows</code> because <code class="language-plaintext highlighter-rouge">Box</code> does not even know what <code class="language-plaintext highlighter-rouge">Person</code> is, and has promised to never try and find out. This wouldn’t necessarily be true if we had a random generic type since the destructor can call trait methods (or specialized blanket methods) which <em>do</em> know how to read the contents of <code class="language-plaintext highlighter-rouge">Person</code>, but in such a case the subtly changed borrow checker rules would kick in again. The stdlib types and other custom datastructures achieve this with an escape hatch, <a href="https://doc.rust-lang.org/nomicon/dropck.html#an-escape-hatch"><code class="language-plaintext highlighter-rouge">#[may_dangle]</code></a> (also known as “the eyepatch”<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" class="footnote" rel="footnote">5</a></sup>), which allows you to pinky swear that you won’t be reading from a lifetime or generic parameter in a custom destructor.</p>

<p>This applies to crates like <a href="https://docs.rs/typed-arena/"><code class="language-plaintext highlighter-rouge">typed-arena</code></a> as well; if you are creating cycles you will not be able to write custom destructors on the types you put in the arena. You <em>can</em> write custom destructors with <a href="https://docs.rs/typed-arena/"><code class="language-plaintext highlighter-rouge">typed-arena</code></a> as long as you refrain from mutating things in ways that can create cycles; so you will not be able to use interior mutability to have one arena entry point to another.</p>

<p><em>Thanks to <a href="https://mpc.sh">Mark Cohen</a> and <a href="https://twitter.com/kneecaw/">Nika Layzell</a> for reviewing drafts of this post.</em></p>
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:0" role="doc-endnote">
      <p>But not in a cyclic way; the borrow checker will enforce this! <a href="#fnref:0" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:1" role="doc-endnote">
      <p>You may wonder how it is safe for destructors to be safely run on cyclic references – after all, the destructor of whichever entry gets destroyed second will be able to read a dangling reference. We’ll cover this later in the post but it has to do with drop check, and specifically that if you attempt to set up cycles, the only explicit destructors allowed on the arena entries themselves will be ones on appropriately marked types. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>The technical term for this is “covariant lifetime” <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>The technical term for this is “contravariant lifetime” <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:4" role="doc-endnote">
      <p>Because you’re claiming the destructor “can’t see” the type or lifetime, see? <a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name>Manish Goregaokar</name></author><category term="programming" /><category term="rust" /><category term="tidbits" /><summary type="html"><![CDATA[There’s been some discussion about arenas in Rust recently, and I thought I’d write about them. Arenas aren’t something you would typically reach for in Rust so fewer people know about them; you only really see them in applications for various niche use cases. Usually you can use an arena by pulling in a crate and not using additional unsafe, so there’s no need to be particularly skittish around them in Rust, and it seems like it would be useful knowledge, especially for people coming to Rust from fields where arenas are more common. Furthermore, there’s a set of really cool lifetime effects involved when implementing self-referential arenas, that I don’t think have been written about before. I’m mostly writing this to talk about the cool lifetime effects, but I figured it’s worth writing a general introduction that has something for all Rustaceans. If you know what arenas are and just want the cool lifetimes you can skip directly to the section on implementing self-referential arenas. Otherwise, read on. What’s an arena? An arena is essentially a way to group up allocations that are expected to have the same lifetime. Sometimes you need to allocate a bunch of objects for the lifetime of an event, after which they can all be thrown away wholesale. It’s inefficient to call into the system allocator each time, and far more preferable to preallocate a bunch of memory for your objects, cleaning it all up at once once you’re done with them. Broadly speaking, there are two reasons you might wish to use an arena: Firstly, your primary goal may be to reduce allocation pressure, as mentioned above. For example, in a game or application, there may be large mishmash of per-frame-tick objects that need to get allocated each frame, and then thrown away. This is extremely common in game development in particular, and allocator pressure is something gamedevs tend to care about. With arenas, it’s easy enough to allocate an arena, fill it up during each frame and clear it out once the frame is over. This has additional benefits of cache locality: you can ensure that most of the per-frame objects (which are likely used more often than other objects) are usually in cache during the frame, since they’ve been allocated adjacently. Another goal might be that you want to write self referential data, like a complex graph with cycles, that can get cleaned up all at once. For example, when writing compilers, type information will likely need to reference other types and other such data, leading to a complex, potentially cyclic graph of types. Once you’ve computed a type you probably don’t need to throw it away individually, so you can use an arena to store all your computed type information, cleaning the whole thing up at once when you’re at a stage where the types don’t matter anymore. Using this pattern allows your code to not have to worry about whether the self-referential bits get deallocated “early”, it lets you make the assumption that if you have a Ty it lives as long as all the other Tys and can reference them directly. These two goals are not necessarily disjoint: You may wish to use an arena to achieve both goals simultaneously. But you can also just have an arena that disallows self referential types (but has other nice properties). Later in this post I’m going to implement an arena that allows self-referential types but is not great on allocation pressure, mostly for ease of implementation. Typically if you’re writing an arena for self-referential types you can make it simultaneously reduce allocator pressure, but there can be tradeoffs. How can I use an arena in Rust? Typically to use an arena you can just pull in a crate that implements the right kind of arena. There are two that I know of that I’ll talk about below, though a cursory search of “arena” on crates.io turns up many other promising candidates. I’ll note that if you just need cyclic graph structures, you don’t have to use an arena, the excellent petgraph crate is often sufficient. slotmap is also useful; it’s a map-like datastructure useful for self-referential data, based on generational indexing. Bumpalo Bumpalo is a fast “bump allocator”, which allows heterogenous contents, and only allows cycles if you do not care about destructors getting run. use bumpalo::Bump; // (example slightly modified from `bumpalo` docs) // Create a new arena to bump allocate into. let bump = Bump::new(); // Allocate values into the arena. let scooter = bump.alloc(Doggo { cuteness: u64::max_value(), age: 8, scritches_required: true, }); // Happy birthday, Scooter! scooter.age += 1; Every call to Bump::alloc() returns a mutable reference to the allocated object. You can allocate different objects, and they can even reference each other1. By default it does not call destructors on its contents; however you can use bumpalo::boxed (or custom allocators on Nightly) to get this behavior. You can similarly use bumpalo::collections to get bumpalo-backed vectors and strings. bumpalo::boxed will not be allowed to participate in cycles. typed-arena typed-arena is an arena allocator that can only store objects of a single type, but it does allow for setting up cyclic references: // Example from typed-arena docs use std::cell::Cell; use typed_arena::Arena; struct CycleParticipant&lt;'a&gt; { other: Cell&lt;Option&lt;&amp;'a CycleParticipant&lt;'a&gt;&gt;&gt;, } let arena = Arena::new(); let a = arena.alloc(CycleParticipant { other: Cell::new(None) }); let b = arena.alloc(CycleParticipant { other: Cell::new(None) }); // mutate them after the fact to set up a cycle a.other.set(Some(b)); b.other.set(Some(a)); Unlike bumpalo, typed-arena will always run destructors on its contents when the arena itself goes out of scope2. Implementing a self-referential arena Self referential arenas are interesting because, typically, Rust is very very wary of self-referential data. But arenas let you clearly separate the step of “I don’t care about this object” and “this object can be deleted” in a way that is sufficient to allow self-referential and cyclic types. It’s pretty rare to need to implement your own arena – bumpalo and typed-arena cover most of the use cases, and if they don’t cover yours you probably can find something that does on crates.io. But if you really need to, or if you’re interested in the nitty-gritty lifetime details, this section is for you. For people less familiar with lifetimes: the lifetimes in the syntaxes &amp;'a Foo and Foo&lt;'b&gt; mean different things. 'a in &amp;'a Foo is the lifetime of Foo, or, at least the lifetime of this reference to Foo. 'b in Foo&lt;'b&gt; is a lifetime parameter of Foo, and typically means something like “the lifetime of data Foo is allowed to reference”. The key to implementing an arena Arena with entries typed as Entry is in the following rules: Arena and Entry should both have a lifetime parameter: Arena&lt;'arena&gt; and Entry&lt;'arena&gt; Arena methods should all receive Arena&lt;'arena&gt; as &amp;'arena self, i.e. their self type is &amp;'arena Arena&lt;'arena&gt; Entry should almost always be passed around as &amp;'arena Entry&lt;'arena&gt; (it’s useful to make an alias for this) Use interior mutability; &amp;mut self on Arena will make everything stop compiling. If using unsafe for mutability, make sure you have a PhantomData for RefCell&lt;Entry&lt;'arena&gt;&gt; somewhere. That’s basically it from the lifetime side, the rest is all in figuring what API you want and implementing the backing storage. Armed with the above rules you should be able to make your custom arena work with the guarantees you need without having to understand what’s going on with the underlying lifetimes. Let’s go through an implementation example, and then dissect why it works. Implementation My crate elsa implements an arena in 100% safe code in one of its examples. This arena does not save on allocations since elsa::FrozenVec requires its contents be behind some indirection, and it’s not generic, but it’s a reasonable way to illustrate how the lifetimes work without getting into the weeds of implementing a really good arena with unsafe. The example implements an arena of Person&lt;'arena&gt; types, Arena&lt;'arena&gt;. The goal is to implement some kind of directed social graph, which may have cycles. use elsa::FrozenVec; struct Arena&lt;'arena&gt; { people: FrozenVec&lt;Box&lt;Person&lt;'arena&gt;&gt;&gt;, } elsa::FrozenVec is an append-only Vec-like abstraction that allows you to call .push() without needing a mutable reference, and is how we’ll be able to implement this arena in safe code. Each Person&lt;'arena&gt; has a list of people they follow but also keeps track of people who follow them: struct Person&lt;'arena&gt; { pub follows: FrozenVec&lt;PersonRef&lt;'arena&gt;&gt;, pub reverse_follows: FrozenVec&lt;PersonRef&lt;'arena&gt;&gt;, pub name: &amp;'static str, } // following the rule above about references to entry types type PersonRef&lt;'arena&gt; = &amp;'arena Person&lt;'arena&gt;; The lifetime 'arena is essentially “the lifetime of the arena itself”. This is where it starts getting weird: typically if your type has a lifetime parameter, the caller gets to pick what goes in there. You don’t get to just say “this is the lifetime of the object itself”, the caller would typically be able to instantiate an Arena&lt;'static&gt; if they wish, or an Arena&lt;'a&gt; for some 'a. But here we’re declaring that 'arena is the lifetime of the arena itself; clearly something fishy is happening here. Here’s where we actually implement the arena: impl&lt;'arena&gt; Arena&lt;'arena&gt; { fn new() -&gt; Arena&lt;'arena&gt; { Arena { people: FrozenVec::new(), } } fn add_person(&amp;'arena self, name: &amp;'static str, follows: Vec&lt;PersonRef&lt;'arena&gt;&gt;) -&gt; PersonRef&lt;'arena&gt; { let idx = self.people.len(); self.people.push(Box::new(Person { name, follows: follows.into(), reverse_follows: Default::default(), })); let me = &amp;self.people[idx]; for friend in &amp;me.follows { // We're mutating existing arena entries to add references, // potentially creating cycles! friend.reverse_follows.push(me) } me } fn dump(&amp;'arena self) { // code to print out every Person, their followers, and the people who follow them } } Note the &amp;'arena self in add_person. A good implementation here would typically separate out code handling the higher level invariant of “if A follows B then B reverse_follows A”, but this is just an example. And finally, we can use the arena like this: fn main() { let arena = Arena::new(); let lonely = arena.add_person("lonely", vec![]); let best_friend = arena.add_person("best friend", vec![lonely]); let threes_a_crowd = arena.add_person("threes a crowd", vec![lonely, best_friend]); let rando = arena.add_person("rando", vec![]); let _everyone = arena.add_person("follows everyone", vec![rando, threes_a_crowd, lonely, best_friend]); arena.dump(); } In this case all of the “mutability” happens in the implementation of the arena itself, but it would be possible for this code to add entries directly to the follows/reverse_follows lists, or Person could have RefCells for other kinds of links, or whatever. How the lifetimes work So how does this work? As I said earlier, with such abstractions in Rust, the caller typically has freedom to set the lifetime based on what they do with it. For example, if you have a HashMap&lt;K, &amp;'a str&gt;, the 'a will get set based on the lifetime of what you try to insert. When you construct the Arena its lifetime parameter is indeed still unconstrained, and we can test this by checking that the following code, which forcibly constrains the lifetime, still compiles. let arena: Arena&lt;'static&gt; = Arena::new(); But the moment you try to do anything with the arena, this stops working: let arena: Arena&lt;'static&gt; = Arena::new(); let lonely = arena.add_person("lonely", vec![]); error[E0597]: `arena` does not live long enough --&gt; examples/mutable_arena.rs:5:18 | 4 | let arena: Arena&lt;'static&gt; = Arena::new(); | -------------- type annotation requires that `arena` is borrowed for `'static` 5 | let lonely = arena.add_person("lonely", vec![]); | ^^^^^ borrowed value does not live long enough ... 11 | } | - `arena` dropped here while still borrowed The add_person method is somehow suddenly forcing the 'arena parameter of Arena to be set to its own lifetime, constraining it (and making it impossible to force-constrain it to be anything else with type annotations). What’s going on here is a neat interaction with the &amp;'arena self signature of add_person (i.e. self is &amp;'arena Arena&lt;'self&gt;), and the fact that 'arena in Arena&lt;'arena&gt; is an invariant lifetime. Usually in your Rust programs, lifetimes are a little bit stretchy-squeezy. The following code compiles just fine: // ask for two strings *with the same lifetime* fn take_strings&lt;'a&gt;(x: &amp;'a str, y: &amp;'a str) {} // string literal with lifetime 'static let lives_forever = "foo"; // owned string with shorter, local lifetime let short_lived = String::from("bar"); // still works! take_strings(lives_forever, &amp;*short_lived); In this code, Rust is happy to notice that while lives_forever and &amp;*short_lived have different lifetimes, it’s totally acceptable to pretend lives_forever has a shorter lifetime for the duration of the take_strings function. It’s just a reference, a reference valid for a long lifetime is also valid for a shorter lifetime. The thing is, this stretchy-squeeziness is not the same for all lifetimes! The nomicon chapter on subtyping and variance goes into detail on why this is the case, but a general rule of thumb is that most lifetimes are “squeezy”3 like the one in &amp;'a str above, but if some form of mutability is involved, they are rigid, also known as “invariant”. You can also have “stretchy”4 lifetimes if you’re using function types, but they’re rare. Our Arena&lt;'arena&gt; is using interior mutability (via the FrozenVec) in a way that makes 'arena invariant. Let’s look at our two lines of code again. When the compiler sees the first line of the code below, it constructs arena, whose lifetime we’ll call 'a. At this point the type of arena is Arena&lt;'?&gt;, where '? is made up notation for a yet-unconstrained lifetime. let arena = Arena::new(); let lonely = arena.add_person("lonely", vec![]); Let’s actually rewrite this to be clearer on what the lifetimes are. let arena = Arena::new(); // type Arena&lt;'?&gt;, lives for 'a // explicitly write the `self` that gets constructed when you call add_person let ref_to_arena = &amp;arena; // type &amp;'a Arena&lt;'?&gt; let lonely = Arena::add_person(ref_to_arena, "lonely", vec![]); Remember the second rule I listed earlier? Arena methods should all receive Arena&lt;'arena&gt; as &amp;'arena self, i.e. their self type is &amp;'arena Arena&lt;'arena&gt; We followed this rule; the signature of add_person is fn add_person(&amp;'arena self). This means that ref_to_arena is forced to have a lifetime that matches the pattern &amp;'arena Arena&lt;'arena&gt;. Currently its lifetime is &amp;'a Arena&lt;'?&gt;, which means that '? is forced to be the same as 'a, i.e. the lifetime of the arena variable itself. If the lifetime weren’t invariant, the compiler would be able to squeeze other lifetimes to fit, but it is invariant, and the unconstrained lifetime is forced to be exactly one lifetime. And by this rather subtle sleight of hand we’re able to force the compiler to set the lifetime parameter of Arena&lt;'arena&gt; to the lifetime of its instance. After this, the rest is pretty straightforward. Arena&lt;'arena&gt; holds entries of type Person&lt;'arena&gt;, which is basically a way of saying “a Person that is allowed to reference items of lifetime 'arena, i.e. items in Arena”. type PersonRef&lt;'arena&gt; = &amp;'arena Person&lt;'arena&gt; is a convenient shorthand for “a reference to a Person that lives in Arena and is allowed to reference objects from it”. What about destructors? So a thing I’ve not covered so far is how this can be safe in the presence of destructors. If your arena is allowed to have cyclic references, and you write a destructor reading from those cyclic references, whichever participant in the cycle that is deleted later on will have dangling references. This gets to a really obscure part of Rust, even more obscure than variance. You almost never need to really understand this, beyond “explicit destructors subtly change borrow check behavior”. But it’s useful to know to get a better mental model of what’s going on here. If we add the following code to our arena example: impl&lt;'arena&gt; Drop for Person&lt;'arena&gt; { fn drop(&amp;mut self) { println!("goodbye {:?}", self.name); for friend in &amp;self.reverse_follows { // potentially dangling! println!("\t\t{}", friend.name); } } } we actually get this error: error[E0597]: `arena` does not live long enough --&gt; examples/mutable_arena.rs:5:18 | 5 | let lonely = arena.add_person("lonely", vec![]); | ^^^^^ borrowed value does not live long enough ... 11 | } | - | | | `arena` dropped here while still borrowed | borrow might be used here, when `arena` is dropped and runs the destructor for type `Arena&lt;'_&gt;` The presence of destructors subtly changes the behavior of the borrow checker around self-referential lifetimes. The exact rules are tricky and explained in the nomicon, but essentially what happened was that the existence of a custom destructor on Person&lt;'arena&gt; made 'arena in Person (and thus Arena) a lifetime which is “observed during destruction”. This is then taken into account during borrow checking – suddenly the implicit drop() at the end of the scope is known to be able to read 'arena data, and Rust makes the appropriate conclusion that drop() will be able to read things after they’ve been cleaned up, since destruction is itself a mutable operation, and drop() is run interspersed in it. Of course, a reasonable question to ask is how we can store things like Box and FrozenVec in this arena if destructors aren’t allowed to “wrap” types with 'arena. The reason is that Rust knows that Drop on Box cannot inspect person.follows because Box does not even know what Person is, and has promised to never try and find out. This wouldn’t necessarily be true if we had a random generic type since the destructor can call trait methods (or specialized blanket methods) which do know how to read the contents of Person, but in such a case the subtly changed borrow checker rules would kick in again. The stdlib types and other custom datastructures achieve this with an escape hatch, #[may_dangle] (also known as “the eyepatch”5), which allows you to pinky swear that you won’t be reading from a lifetime or generic parameter in a custom destructor. This applies to crates like typed-arena as well; if you are creating cycles you will not be able to write custom destructors on the types you put in the arena. You can write custom destructors with typed-arena as long as you refrain from mutating things in ways that can create cycles; so you will not be able to use interior mutability to have one arena entry point to another. Thanks to Mark Cohen and Nika Layzell for reviewing drafts of this post. But not in a cyclic way; the borrow checker will enforce this! &#8617; You may wonder how it is safe for destructors to be safely run on cyclic references – after all, the destructor of whichever entry gets destroyed second will be able to read a dangling reference. We’ll cover this later in the post but it has to do with drop check, and specifically that if you attempt to set up cycles, the only explicit destructors allowed on the arena entries themselves will be ones on appropriately marked types. &#8617; The technical term for this is “covariant lifetime” &#8617; The technical term for this is “contravariant lifetime” &#8617; Because you’re claiming the destructor “can’t see” the type or lifetime, see? &#8617;]]></summary></entry><entry><title type="html">Integrating Rust and C++ in Firefox</title><link href="http://manishearth.github.io/blog/2021/02/22/integrating-rust-and-c-plus-plus-in-firefox/" rel="alternate" type="text/html" title="Integrating Rust and C++ in Firefox" /><published>2021-02-22T00:00:00+00:00</published><updated>2021-02-22T00:00:00+00:00</updated><id>http://manishearth.github.io/blog/2021/02/22/integrating-rust-and-c-plus-plus-in-firefox</id><content type="html" xml:base="http://manishearth.github.io/blog/2021/02/22/integrating-rust-and-c-plus-plus-in-firefox/"><![CDATA[<p><em>This post was originally drafted in August 2018, but I never got around to finishing it. As such, parts of its framing (e.g. the focus on bindgen) are outdated, given the relative infancy of the interop space at the time. I was recently told that the post is still useful in this form so I decided to finish and publish it anyway, while attempting to mark outdated things as such when I notice them. Everything after the allocators section was written near the time of publication.</em></p>

<p>In 2017 I worked on the <a href="https://hacks.mozilla.org/2017/08/inside-a-super-fast-css-engine-quantum-css-aka-stylo/">Stylo</a> project, uplifting Servo’s CSS engine (“style system”) into Firefox’s browser engine
(“Gecko”). This involved a <em>lot</em> of gnarly FFI between Servo’s Rust codebase and Firefox’s C++ codebase. There were a
lot of challenges in doing this, and I feel like it’s worth sharing things from our experiences.</p>

<p>If you’re interested in Rust integrations, you may find <a href="https://www.youtube.com/watch?v=x9acx2zgx4Q">this talk by Katharina on Rust - C++ FFI</a>, and <a href="https://hsivonen.fi/modern-cpp-in-rust/">this blog post by Henri on integrating encoding-rs into Firefox</a> useful as well.</p>

<h2 id="who-is-this-post-for">Who is this post for?</h2>

<p>So, first off the bat, I’ll mention that when integrating Rust into a C++ codebase, you
want to <em>avoid</em> having integrations as tight as Stylo. Don’t do what we did; make your Rust
component mostly self-contained so that you just have to maintain something like ten FFI functions
for interacting with it. If this is possible to do, you should do it and your life will be <em>much</em> easier. Pick a clean API boundary, define a straightforward API, use cbindgen or bindgen if necessary without any tricks, and you should be good to go.</p>

<p>That said, sometimes you <em>have</em> to have gnarly integrations, and this blog post is for those use cases.
These techniques mostly use bindgen in their examples, however you can potentially use them with hand-rolled bindings or another tool as well. If you’re at this level of complexity, however, the potential for mistakes in the hand-rolled bindings is probably not worth it.</p>

<p><em>Note from 2021: <a href="https://github.com/dtolnay/cxx">cxx</a> is probably a better tool for many of the use cases here, though many of the techniques still transfer.</em></p>

<h2 id="what-was-involved-in-stylos-ffi">What was involved in Stylo’s FFI?</h2>

<p>So, what made Stylo’s FFI so complicated?</p>

<p>It turns out that browsers are quite monolithic. You can split them into vaguely-defined components, but
these components are still tightly integrated. If you intend to replace a component, you may need to
make a jagged edge of an integration surface.</p>

<p>The style system is more self-contained than other parts, but it’s still quite tightly integrated.</p>

<p>The main job of a “style system” is to take the CSS rules and DOM tree, and run them through “the cascade”<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup>
with an output of “computed styles” tagged on each node in the tree. So, for example, it will take a document like
the following:</p>

<div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;style </span><span class="na">type=</span><span class="s">"text/css"</span><span class="nt">&gt;</span>
    <span class="nt">body</span> <span class="p">{</span>
        <span class="nl">font-size</span><span class="p">:</span> <span class="m">12px</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="nt">div</span> <span class="p">{</span>
        <span class="nl">height</span><span class="p">:</span> <span class="m">2em</span><span class="p">;</span>
    <span class="p">}</span>
<span class="nt">&lt;/style&gt;</span>
<span class="nt">&lt;body&gt;</span>
    <span class="nt">&lt;div</span> <span class="na">id=</span><span class="s">"foo"</span><span class="nt">&gt;&lt;/div&gt;</span>

<span class="nt">&lt;/body&gt;</span>
</code></pre></div></div>

<p>and turn it into something like:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">&lt;body&gt;</code> has a <code class="language-plaintext highlighter-rouge">font-size</code> of <code class="language-plaintext highlighter-rouge">12px</code>, everything else is the default</li>
  <li>the <code class="language-plaintext highlighter-rouge">div</code> <code class="language-plaintext highlighter-rouge">#foo</code> has a computed <code class="language-plaintext highlighter-rouge">height</code> of <code class="language-plaintext highlighter-rouge">24px</code> <sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote" rel="footnote">2</a></sup>, everything else is the default. It “inherits” the <code class="language-plaintext highlighter-rouge">font-size</code> from <code class="language-plaintext highlighter-rouge">&lt;body&gt;</code> as <code class="language-plaintext highlighter-rouge">12px</code></li>
</ul>

<p>From a code point of view, this means that Stylo takes in Gecko’s C++ DOM tree. It parses all the CSS,
and then runs the cascade on the tree. It stores computed styles on each element in a way that Gecko can read
very cheaply.</p>

<p>Style computation can involve some complex steps that require calling back into C++ code. Servo’s style system
is multithreaded, but Gecko is mostly designed to work off of a single main thread per process, so we need to
deal with this impedence mismatch.</p>

<p>Since the output of Stylo is C++-readable structs, Stylo needs to be able to read and write nontrivial C++
abstractions. Typical FFI involves passing values over a boundary, never to be seen again, however here we’re
dealing with persistent state that is accessed by both sides.</p>

<p>To sum up, we have:</p>

<ul>
  <li>Lots and lots of back-and-forth FFI</li>
  <li>Thread safety concerns</li>
  <li>Rust code regularly dealing with nontrivial C++ abstractions</li>
  <li>A need for nontrivial abstractions to be passed over FFI</li>
</ul>

<p>All of this conspires to make for some really complicated FFI code.</p>

<h1 id="the-actual-techniques">The actual techniques</h1>

<p>I’ll try to structure this so that the more broadly useful (and/or less gnarly) techniques come earlier in the post.</p>

<h2 id="the-basics-of-bindgen">The basics of bindgen</h2>

<p><a href="https://github.com/rust-lang-nursery/rust-bindgen/">Bindgen</a> is a tool that generates Rust bindings for structs and functions from the provided C or C++ header files. It’s often used for writing Rust bindings to existing C/C++ libraries, however it’s useful for integrations as well.</p>

<p>To use it for an integration, write a header file containing the functions your Rust code needs (referencing structs from other header files if necessary), and <a href="https://rust-lang-nursery.github.io/rust-bindgen/command-line-usage.html">run bindgen on it</a>. For some codebases, doing this once and
checking in the generate file suffices, but if your C++ code is going to change a lot, <a href="https://rust-lang-nursery.github.io/rust-bindgen/tutorial-1.html">run it as a build dependency instead</a>. Beware that this can adversely impact build times, since your Rust build now has a partial
C++ compilation step.</p>

<p>For large C++ codebases, pulling in a single header will likely pull in a <em>lot</em> of stuff. You should <a href="https://rust-lang.github.io/rust-bindgen/allowlisting.html">allowlist</a>, <a href="https://rust-lang.github.io/rust-bindgen/blocklisting.html">blocklist</a>, and/or mark things as <a href="https://rust-lang.github.io/rust-bindgen/opaque.html">opaque</a> to reduce the amount of bindings generated. It’s best to go the allowlisting route — give bindgen an allowlisted list of functions / structs to generate bindings for, and it will transitively generate bindings for any dependencies they may have. Sometimes even this will end up generating a lot, it’s sometimes worth finding structs you’re not using and marking them as opaque so that their bindings aren’t necessary. Marking something as opaque replaces it with an array of the appropriate size and alignment, so from the Rust side it’s just some bits you don’t care about and can’t introspect further.</p>

<p>Bindgen <a href="https://rust-lang-nursery.github.io/rust-bindgen/cpp.html"><em>does</em> support some C++ features</a> (you may need to pass <code class="language-plaintext highlighter-rouge">-x c++</code>). This is pretty good for generating bindings to e.g. templated structs. However, it’s not possible to support <em>all</em> C++ features here, so you may need to blocklist, opaqueify, or use intermediate types if you have some complicated C++ abstractions in the deps. You’ll typically get an error when generating bindings or when compiling the generated bindings, so don’t worry about this unless that happens.</p>

<p>Bindgen is <em>quite</em> configurable. Stylo has a <a href="https://searchfox.org/mozilla-central/rev/819cd31a93fd50b7167979607371878c4d6f18e8/servo/components/style/build_gecko.rs">script</a> that consumes a <a href="https://searchfox.org/mozilla-central/source/layout/style/ServoBindings.toml">large toml file</a> containing all of the configuration.</p>

<h2 id="cbindgen">cbindgen</h2>

<p>We don’t use <a href="https://github.com/eqrion/cbindgen">cbindgen</a> in Stylo, but it’s used for Webrender. It does the inverse of what bindgen does: given a Rust crate, it generates C headers for its public <code class="language-plaintext highlighter-rouge">extern "C"</code> API. It’s also quite configurable.</p>

<h2 id="cxx">cxx</h2>

<p><a href="https://github.com/dtolnay/cxx">cxx</a> is the cool new hotness in 2021, which kind of approaches the problem from both sides, enabling you to write Rust bindings for C++ and C++ bindings for Rust. It’s definitely worth checking out, a lot of the things that are hard to make work with bindgen are trivial in cxx. For example, it automatically figures out what types need to be opaque, it automatically converts between <code class="language-plaintext highlighter-rouge">&amp;T</code> and <code class="language-plaintext highlighter-rouge">T*</code> across FFI, and it is overall more targeted for the use case of an FFI layer where Rust and C++ both call each other.</p>

<h2 id="bindgen-aided-c-calling-rust">Bindgen-aided C++ calling Rust</h2>

<p>So bindgen helps with creating things for Rust to call and manipulate, but not in the opposite direction. cbindgen can help here, but I’m not sure if it’s advisable to have <em>both</em> bindgen and cbindgen operating near each other on the same codebase.</p>

<p>In Stylo we use a bit of a hack for this. Firstly, all FFI functions defined in C++ that Rust calls are declared in <a href="https://searchfox.org/mozilla-central/rev/819cd31a93fd50b7167979607371878c4d6f18e8/layout/style/ServoBindingList.h">one file</a>, and are all named <code class="language-plaintext highlighter-rouge">Gecko_*</code>. Bindgen supports regexes for things like allowlisting, so this naming scheme makes it easy to deal with.</p>

<p>We also declare the FFI functions defined in Rust that C++ calls in <a href="https://searchfox.org/mozilla-central/rev/819cd31a93fd50b7167979607371878c4d6f18e8/layout/style/ServoBindingList.h">another file</a>, named <code class="language-plaintext highlighter-rouge">Servo_*</code>. They’re also all <a href="https://searchfox.org/mozilla-central/rev/819cd31a93fd50b7167979607371878c4d6f18e8/servo/ports/geckolib/glue.rs">defined in one place</a>.</p>

<p>However, there’s nothing ensuring that the signatures match! If we’re not careful, there may be mismatches, causing bad things to happen at link time or runtime. We use a small <a href="https://searchfox.org/mozilla-central/rev/819cd31a93fd50b7167979607371878c4d6f18e8/servo/ports/geckolib/tests/build.rs">autogenerated</a> <a href="https://searchfox.org/mozilla-central/rev/819cd31a93fd50b7167979607371878c4d6f18e8/servo/ports/geckolib/tests/servo_function_signatures.rs">unit test</a> to ensure the validity of the signatures.</p>

<p>This is especially important as we do things like type replacement, and we need tests to ensure that the rug isn’t pulled out from underneath us.</p>

<h2 id="type-replacing-for-fun-and-profit">Type replacing for fun and profit</h2>

<p>Using <a href="https://rust-lang.github.io/rust-bindgen/blocklisting.html">blocklisting</a> in conjunction with the <code class="language-plaintext highlighter-rouge">--raw-line</code>/<code class="language-plaintext highlighter-rouge">raw_line()</code> flag, one can effectively ask bindgen to “replace” types. Blocklisting asks bindgen not to generate bindings for a type, however bindgen will continue to generate bindings <em>referring</em> to that type if necessary. (Unlike opaque types where bindgen generates an opaque binding for the type and uses it everywhere). <code class="language-plaintext highlighter-rouge">--raw-line</code> lets you request bindgen to add a line of raw rust code to the file, and such a line can potentially define or import a new version of the type you blocklisted. Effectively, this lets you replace types.</p>

<p>Bindgen generates unit tests ensuring that the layout of your structs is correct (run them!), so if you accidentally replace a type with something incompatible, you will get warnings at the struct level (functions may not warn).</p>

<p>There are various ways this can be used:</p>

<h3 id="safe-references-across-ffi">Safe references across FFI</h3>

<p><em>Note from 2021: <a href="https://github.com/dtolnay/cxx">cxx</a> does this automatically</em></p>

<p>Calling into C++ (and accepting data from C++) is unsafe. However, there’s no reason we should have to worry about this more than we have to. For example, it would be nice if accessor FFI functions – functions which take a foreign object and return something from inside it –  could use lifetimes. It would be even nicer if nullability were represented on the FFI boundary so that you don’t miss null checks, and can assume non-nullness when the C++ API is okay with it.</p>

<p>In Stylo, we have lots of functions like the following:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">RawGeckoNodeBorrowedOrNull</span> <span class="nf">Gecko_GetLastChild</span><span class="p">(</span><span class="n">RawGeckoNodeBorrowed</span> <span class="n">node</span><span class="p">);</span>
</code></pre></div></div>

<p>which bindgen translates to:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">extern</span> <span class="s">"C"</span> <span class="p">{</span>
    <span class="k">fn</span> <span class="nf">Gecko_GetLastChild</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="o">&amp;</span><span class="n">RawGeckoNode</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">Option</span><span class="o">&lt;&amp;</span><span class="n">RawGeckoNode</span><span class="o">&gt;</span><span class="p">;</span>   
<span class="p">}</span>
</code></pre></div></div>

<p>Using the <a href="https://searchfox.org/mozilla-central/rev/819cd31a93fd50b7167979607371878c4d6f18e8/servo/components/style/build_gecko.rs">bindgen build script</a> on a provided <a href="https://searchfox.org/mozilla-central/rev/819cd31a93fd50b7167979607371878c4d6f18e8/layout/style/ServoBindings.toml#648-671">list of borrow-able types</a>, we’ve told bindgen that:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">FooBorrowedOrNull</code> is actually <code class="language-plaintext highlighter-rouge">Option&lt;&amp;Foo&gt;</code></li>
  <li><code class="language-plaintext highlighter-rouge">FooBorrowed</code> is actually <code class="language-plaintext highlighter-rouge">&amp;Foo</code></li>
</ul>

<p><code class="language-plaintext highlighter-rouge">Option&lt;&amp;Foo&gt;</code> <a href="https://doc.rust-lang.org/nomicon/repr-rust.html">is represented as a single nullable pointer in Rust</a>, so this is a clean translation. 
We’re forced to null-check it, but once we do we can safely assume that the reference is valid. Furthermore, due to lifetime elision the actual signature of the FFI function is <code class="language-plaintext highlighter-rouge">fn Gecko_GetLastChild&lt;'a&gt;(x: &amp;'a RawGeckoNode) -&gt; Option&lt;&amp;'a RawGeckoNode&gt;</code>, which ensures we won’t let the returned reference outlive the passed reference. Lifetime elision means that we can call C++ functions “safely” with the appropriate lifetime requirements, even though C++ has no such concept!</p>

<p>Note that this is shifting some of the safety invariants to the C++ side: We rely on the C++ to give us valid references, and we rely on it to not have nulls when the type is not marked as nullable. Most C++ codebases internally rely on such invariants for safety anyway, so this isn’t much of a stretch.</p>

<p>We do this on both sides, actually: Many of our Rust-defined <code class="language-plaintext highlighter-rouge">extern "C"</code> functions that C++ calls get to be internally-safe because the types let us assume the validity of the pointers obtained from C++.</p>

<h3 id="making-c-abstractions-rust-accessible">Making C++ abstractions Rust-accessible</h3>

<p>A very useful thing to do here is to replace various C++ abstractions with Rust versions of them that share semantics. In Gecko, most strings are stored in <code class="language-plaintext highlighter-rouge">nsString</code>/<code class="language-plaintext highlighter-rouge">nsAString</code>/etc.</p>

<p>We’ve written an <a href="https://searchfox.org/mozilla-central/rev/6ddb5fb144993fb5de044e2e8d900d7643b98a4d/servo/support/gecko/nsstring/src/lib.rs">nsstring</a> crate that represents layout-compatible <code class="language-plaintext highlighter-rouge">nsString</code>s in a more Rusty way, with Rusty APIs. We then ask bindgen to replace Gecko <code class="language-plaintext highlighter-rouge">nsString</code>s with these.</p>

<p>Usually it’s easier to just write an impl for the bindgen-generated abstraction, however sometimes you must replace it:</p>

<ul>
  <li>When the abstraction internally does a lot of template stuff not supported by bindgen</li>
  <li>When you want the code for the abstraction to be in a separate crate</li>
</ul>

<h2 id="potential-pitfall-passing-c-classes-by-value-over-ffi">Potential pitfall: Passing C++ classes by-value over FFI</h2>

<p>It’s quite tempting to do stuff like</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">RefPtr</span><span class="o">&lt;</span><span class="n">Foo</span><span class="o">&gt;</span> <span class="n">Servo_Gimme</span><span class="p">(...);</span>
</code></pre></div></div>

<p>where you pass complicated classes by-value over FFI (<code class="language-plaintext highlighter-rouge">RefPtr</code> is Gecko’s variant of <code class="language-plaintext highlighter-rouge">Rc&lt;T&gt;</code>/<code class="language-plaintext highlighter-rouge">Arc&lt;T&gt;</code>).</p>

<p>This works on some systems, but is broken on MSVC:
<a href="https://github.com/rust-lang/rust/issues/38258">The ABI for passing non-POD types through functions is different</a>. The linker usually notices this and complains, but it’s worth avoiding this entirely.</p>

<p>In Stylo we handle this by using some macro-generated intermediate types which are basically the same thing as the original class but without any constructors/destructors/operators. We convert to/from these types immediately before/after the FFI call, and on the Rust side we do similar conversions to Rust-compatible abstractions.</p>

<h2 id="sharing-abstractions-with-destructors">Sharing abstractions with destructors</h2>

<p>If you’re passing ownership of collections or other templated types across FFI, you probably want Rust code to be able to destroy C++ objects, and vice versa.</p>

<p>One way of doing this is to implement <code class="language-plaintext highlighter-rouge">Drop</code> on the generated struct. If you have <code class="language-plaintext highlighter-rouge">class MyString</code>, you can do:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MyString</span> <span class="p">{</span>
    <span class="c1">// ...</span>
    <span class="o">~</span><span class="n">MyString</span><span class="p">();</span>
<span class="p">}</span>

<span class="kt">void</span> <span class="nf">MyString_Destroy</span><span class="p">(</span><span class="o">*</span><span class="n">MyString</span> <span class="n">x</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">x</span><span class="o">-&gt;~</span><span class="n">MyString</span><span class="p">()</span>
<span class="p">}</span>
</code></pre></div></div>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">impl</span> <span class="nb">Drop</span> <span class="k">for</span> <span class="nn">bindings</span><span class="p">::</span><span class="n">MyString</span> <span class="p">{</span>
    <span class="k">fn</span> <span class="nf">drop</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">)</span> <span class="p">{</span>
        <span class="c1">// (bindgen only)</span>
        <span class="nn">bindings</span><span class="p">::</span><span class="nn">MyString</span><span class="p">::</span><span class="nf">destruct</span><span class="p">(</span><span class="k">self</span><span class="p">)</span>
        <span class="c1">// OR</span>
        <span class="nn">bindings</span><span class="p">::</span><span class="nf">MyString_Destroy</span><span class="p">(</span><span class="k">self</span><span class="p">)</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>The <code class="language-plaintext highlighter-rouge">MyString_Destroy</code> isn’t necessary with bindgen – bindgen will generate a <code class="language-plaintext highlighter-rouge">MyString::destruct()</code> function for you – but be careful, this will make your generated bindings very platform-specific, so be sure to only do this if running them at build time. In general, when bindgen generates C++ <em>methods</em>, your bindings become platform specific and are best regenerated at build time<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" class="footnote" rel="footnote">3</a></sup>.</p>

<p>In Stylo we went down the route of manually defining <code class="language-plaintext highlighter-rouge">_Destroy()</code> functions since we started off with checked-in platform-agnostic bindings, however we could probably switch to using <code class="language-plaintext highlighter-rouge">destruct()</code> if we want to now.</p>

<p>When it comes to generic types, it’s a bit trickier, since <code class="language-plaintext highlighter-rouge">Drop</code> can’t be implemented piecewise on a generic type (you cannot <code class="language-plaintext highlighter-rouge">impl Drop for MyVector&lt;Foo&gt;</code>). You have to do something like:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">template</span><span class="o">&lt;</span><span class="k">typename</span> <span class="nc">T</span><span class="p">&gt;</span>
<span class="k">class</span> <span class="nc">MyVector</span> <span class="p">{</span>
    <span class="c1">// ...</span>
<span class="p">}</span>

<span class="c1">// Deallocate buffer, but do not call destructors on elements</span>
<span class="kt">void</span> <span class="nf">MyVector_Deallocate_Buffer</span><span class="p">(</span><span class="n">MyVector</span><span class="o">&lt;</span><span class="kt">void</span><span class="o">&gt;*</span> <span class="n">x</span><span class="p">);</span>
</code></pre></div></div>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// assume we have an implementation of Iterator for MyVector&lt;T&gt; somewhere</span>

<span class="k">impl</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="nb">Drop</span> <span class="k">for</span> <span class="nn">bindings</span><span class="p">::</span><span class="n">MyVector</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="k">fn</span> <span class="nf">drop</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">for</span> <span class="n">v</span> <span class="k">in</span> <span class="k">self</span><span class="nf">.iter_mut</span><span class="p">()</span> <span class="p">{</span>
            <span class="c1">// calls the destructor for `v`, if any</span>
            <span class="nn">std</span><span class="p">::</span><span class="nn">ptr</span><span class="p">::</span><span class="nf">drop_in_place</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
        <span class="p">}</span>
        <span class="nn">bindings</span><span class="p">::</span><span class="nf">MyVector_Deallocate_Buffer</span><span class="p">(</span><span class="k">self</span> <span class="k">as</span> <span class="o">*</span><span class="k">mut</span> <span class="n">MyVector</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="k">as</span> <span class="o">*</span><span class="k">mut</span> <span class="n">MyVector</span><span class="o">&lt;</span><span class="nb">c_void</span><span class="o">&gt;</span><span class="p">)</span>
    <span class="p">}</span>
<span class="p">}</span>

</code></pre></div></div>

<p>Note that if you forget to add a <code class="language-plaintext highlighter-rouge">Drop</code> implementation for <code class="language-plaintext highlighter-rouge">T</code>, this will silently forget to clean up the contents of the vector. See <a href="#mirror-types">the next section</a> for some ways to handle this by creating a “safe” mirror type.</p>

<h2 id="mirror-types">Mirror types</h2>

<p>C++ libraries often have useful templated abstractions, and it’s nice to be able to manipulate them from Rust. Sometimes, it’s possible to just tack on semantics on the Rust side (either by adding an implementation or by doing type replacement), but in some cases this is tricky.</p>

<p>For example, Gecko has <code class="language-plaintext highlighter-rouge">RefPtr&lt;T&gt;</code>, which is similar to <code class="language-plaintext highlighter-rouge">Rc&lt;T&gt;</code>, except the actual refcounting logic is up to <code class="language-plaintext highlighter-rouge">T</code> to implement (it can choose between threadsafe, non-threadsafe, etc), which it does by writing <code class="language-plaintext highlighter-rouge">AddRef()</code> and <code class="language-plaintext highlighter-rouge">Release()</code> methods.</p>

<p>We mirror this in Rust by having a trait:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cd">/// Trait for all objects that have Addref() and Release</span>
<span class="cd">/// methods and can be placed inside RefPtr&lt;T&gt;</span>
<span class="k">pub</span> <span class="k">unsafe</span> <span class="k">trait</span> <span class="n">RefCounted</span> <span class="p">{</span>
    <span class="cd">/// Bump the reference count.</span>
    <span class="k">fn</span> <span class="nf">addref</span><span class="p">(</span><span class="o">&amp;</span><span class="k">self</span><span class="p">);</span>
    <span class="cd">/// Decrease the reference count.</span>
    <span class="k">unsafe</span> <span class="k">fn</span> <span class="nf">release</span><span class="p">(</span><span class="o">&amp;</span><span class="k">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="cd">/// A custom RefPtr implementation to take into account Drop semantics and</span>
<span class="cd">/// a bit less-painful memory management.</span>
<span class="k">pub</span> <span class="k">struct</span> <span class="n">RefPtr</span><span class="o">&lt;</span><span class="n">T</span><span class="p">:</span> <span class="n">RefCounted</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="n">ptr</span><span class="p">:</span> <span class="o">*</span><span class="k">mut</span> <span class="n">T</span><span class="p">,</span>
    <span class="n">_marker</span><span class="p">:</span> <span class="n">PhantomData</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div></div>

<p>We implement the <code class="language-plaintext highlighter-rouge">RefCounted</code> trait for C++ types that are wrapped in <code class="language-plaintext highlighter-rouge">RefPtr</code> which we wish to access through Rust. We have <a href="https://searchfox.org/mozilla-central/rev/cfaa5a1d48d6bc6552199e73004ecb05d0a9c921/servo/components/style/gecko_bindings/sugar/refptr.rs#258-315">some</a> <a href="https://searchfox.org/mozilla-central/rev/cfaa5a1d48d6bc6552199e73004ecb05d0a9c921/layout/style/GeckoBindings.h#52-60">macros</a> that make this easier to do. We have to have such a trait, because otherwise Rust code wouldn’t know how to manage various C++ types.</p>

<p>However, <code class="language-plaintext highlighter-rouge">RefPtr&lt;T&gt;</code> here can’t be the type that ends up being used in bindgen. Rust doesnt let us do things like <code class="language-plaintext highlighter-rouge">impl&lt;T: RefCounted&gt; Drop for RefPtr&lt;T&gt;</code> <sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">4</a></sup>, so we can’t effectively make this work with the bindgen generated type unless we write a <code class="language-plaintext highlighter-rouge">RefCounted</code> implementation for every refcounted type that shows up in the bindgen output at all – which would be a lot of work.</p>

<p>Instead, we let bindgen generate its own <code class="language-plaintext highlighter-rouge">RefPtr&lt;T&gt;</code>, called <code class="language-plaintext highlighter-rouge">structs::RefPtr&lt;T&gt;</code> (all the structs that bindgen generates for Gecko go in a <code class="language-plaintext highlighter-rouge">structs::</code> module). <code class="language-plaintext highlighter-rouge">structs::RefPtr&lt;T&gt;</code> itself doesn’t have enough semantics to be something we can pass around willy-nilly in Rust code without causing leaks. However, it has <a href="https://searchfox.org/mozilla-central/rev/cfaa5a1d48d6bc6552199e73004ecb05d0a9c921/servo/components/style/gecko_bindings/sugar/refptr.rs#150-234">some methods</a> that allow for conversion into the “safe” mirror <code class="language-plaintext highlighter-rouge">RefPtr&lt;T&gt;</code> (but only if <code class="language-plaintext highlighter-rouge">T: RefCounted</code>). So if you need to manipulate a <code class="language-plaintext highlighter-rouge">RefPtr&lt;T&gt;</code> in a C++ struct somewhere, you immediately use one of the conversion methods to get a safe version of it first, and <em>then</em> do things to it. Refcounted types that don’t have the <code class="language-plaintext highlighter-rouge">RefCounted</code> implementation won’t have conversion methods: they may exist in the data you’re manipulating, however you won’t be able to work with them.</p>

<p>In general, whenever attaching extra semantics to generic bindgen types doesn’t work create a mirror type that’s completely safe to use from Rust, with a trait that gates conversion to the mirror type.</p>

<h2 id="potential-pitfall-allocators">Potential pitfall: Allocators</h2>

<p>If you’re passing heap-managed abstractions across FFI, be careful about which code frees which objects. If your Rust
and C++ code don’t share allocators, deallocating memory allocated on the other side can have disastrous consequences.</p>

<p>If you’re building a cdylib or staticlib with Rust (this is likely if you’re linking it with a C++ application), the compiler will by default pick the system allocator (<code class="language-plaintext highlighter-rouge">malloc</code>), so if your C++ application also uses the same you’re all set.</p>

<p>On some platforms when building rlibs and binaries, Rust may choose jemalloc instead. It’s also possible that your C++ code uses a different allocator (lots of applications use allocators like jemalloc or tcmalloc, some have their own custom allocators like <code class="language-plaintext highlighter-rouge">tor_malloc</code> in Tor).</p>

<p>In such cases you have one of three options:</p>

<ul>
  <li>Avoid transferring ownership of heap-allocated items, only share things as borrowed references</li>
  <li>Call destructors over FFI, as detailed in <a href="#sharing-abstractions-with-destructors">the section on destructors above</a></li>
  <li>Set Rust’s allocator to be the same as documented <a href="https://doc.rust-lang.org/nightly/std/alloc/#the-global_allocator-attribute">in the <code class="language-plaintext highlighter-rouge">std::alloc</code> module</a>. Basically, can use the <code class="language-plaintext highlighter-rouge">#[global_allocator]</code> attribute to select which allocator you wish to use, and if necessary you can implement the <code class="language-plaintext highlighter-rouge">GlobalAlloc</code> trait on a custom allocator type that calls into whatever custom allocator C++ is using.</li>
</ul>

<p><em>Note from 2021: Most stdlib collections (<a href="https://doc.rust-lang.org/nightly/std/vec/struct.Vec.html"><code class="language-plaintext highlighter-rouge">Vec</code></a>, for example) now have an optional “custom allocator” parameter that can be used to swap in a different allocator for a specific use site.</em></p>

<h2 id="arcs-over-ffi-triomphe">Arcs over FFI: Triomphe</h2>

<p>This isn’t really a generalizable technique, but it’s pretty cool and generally instructive, so I’m including it here.</p>

<p>Stylo uses a lot of <code class="language-plaintext highlighter-rouge">Arc</code>s. A <em>lot</em> of them. The entire computation of styles makes heavy use of <code class="language-plaintext highlighter-rouge">Arc::make_mut</code>’s copy-on-write semantics so that we can build up the style tree in parallel but not have to make unnecessary copies of duplicated/defaulted styles for each element.</p>

<p>Many of these <code class="language-plaintext highlighter-rouge">Arc</code>s need to be readable from C++. Rust’s <code class="language-plaintext highlighter-rouge">Arc</code>, however, consists of a pointer to an allocation containing a refcount and the data, so if C++ needs to get access to the data it needs to know the layout of the <code class="language-plaintext highlighter-rouge">Arc</code> allocation, which we’d rather not do<sup id="fnref:5" role="doc-noteref"><a href="#fn:5" class="footnote" rel="footnote">5</a></sup>.</p>

<p>We picked a different route: We created a crate duplicating <code class="language-plaintext highlighter-rouge">Arc&lt;T&gt;</code> which behaves almost exactly the same as <code class="language-plaintext highlighter-rouge">Arc&lt;T&gt;</code>, but it can be converted to <code class="language-plaintext highlighter-rouge">OffsetArc&lt;T&gt;</code> which has its pointer point to the <em>middle</em> of the allocation, where the <code class="language-plaintext highlighter-rouge">T</code> begins. To C++, this just looks like a <code class="language-plaintext highlighter-rouge">*const T</code>! We were then able to make it work with <code class="language-plaintext highlighter-rouge">RefPtr&lt;T&gt;</code> on the C++ side so that C++ can transparently read from the <code class="language-plaintext highlighter-rouge">OffsetArc&lt;T&gt;</code>, and only needs to call into Rust if it wishes to clone or drop it.</p>

<p>The external version of this crate can be found in <a href="https://docs.rs/triomphe">triomphe</a>. It contains a bunch of other goodies that are additionally useful outside of the FFI world, like <code class="language-plaintext highlighter-rouge">ArcBorrow</code> which is essentially “<code class="language-plaintext highlighter-rouge">&amp;Arc&lt;T&gt;</code> without double indirection”, <code class="language-plaintext highlighter-rouge">UniqueArc&lt;T&gt;</code>, a mutable <code class="language-plaintext highlighter-rouge">Arc&lt;T&gt;</code> known to be uniquely owned, and <code class="language-plaintext highlighter-rouge">ArcUnion&lt;T, U&gt;</code>, which is a space-efficient union of <code class="language-plaintext highlighter-rouge">Arc&lt;T&gt;</code> and <code class="language-plaintext highlighter-rouge">Arc&lt;U&gt;</code>.</p>

<h2 id="other-pitfalls">Other pitfalls</h2>

<h3 id="transparent">Transparent</h3>

<p>It’s <em>very</em> tempting to wrap C++ types in tuple structs and pass them over FFI. For example, one might imagine that the following is okay:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">struct</span> <span class="nf">Wrapper</span><span class="p">(</span><span class="nn">bindings</span><span class="p">::</span><span class="n">SomeCppType</span><span class="p">);</span>

<span class="k">extern</span> <span class="s">"C"</span> <span class="p">{</span>
    <span class="c1">// C++ signature: `SomeCppType get_cpp_type();`</span>
    <span class="k">fn</span> <span class="nf">get_cpp_type</span><span class="p">()</span> <span class="k">-&gt;</span> <span class="n">Wrapper</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<p>This kind of thing is quite useful to get around coherence, or for adding additional semantics to a type.</p>

<p>While there’s basically one obvious way <code class="language-plaintext highlighter-rouge">Wrapper</code> can be represented, ABI stuff can be tricky, and Rust’s layout isn’t defined. It is safer to use <code class="language-plaintext highlighter-rouge">#[repr(transparent)]</code>, which guarantees that <code class="language-plaintext highlighter-rouge">Wrapper</code> will have the same representation as the type it contains.</p>

<h3 id="c-enums">C enums</h3>

<p>Rust supports C-like enums, but there’s a crucial difference between them. In C, it is not undefined behavior for an enum to have an unlisted value. In fact, the following pattern is not uncommon:</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">enum</span> <span class="n">Flags</span> <span class="p">{</span>
    <span class="n">Flag1</span> <span class="o">=</span> <span class="mi">0</span><span class="n">b0001</span><span class="p">,</span>
    <span class="n">Flag2</span> <span class="o">=</span> <span class="mi">0</span><span class="n">b0010</span><span class="p">,</span>
    <span class="n">Flag3</span> <span class="o">=</span> <span class="mi">0</span><span class="n">b0100</span><span class="p">,</span>
    <span class="n">Flag4</span> <span class="o">=</span> <span class="mi">0</span><span class="n">b1000</span><span class="p">;</span>
<span class="p">};</span>
</code></pre></div></div>

<p>where the enum is actually used for bitflags, and <code class="language-plaintext highlighter-rouge">Flag1 | Flag2</code> and <code class="language-plaintext highlighter-rouge">0</code> are both valid values for <code class="language-plaintext highlighter-rouge">Flags</code>.</p>

<p>This is not the case in Rust. If you are type-replacing C enums with Rust ones, make sure they are <code class="language-plaintext highlighter-rouge">#[repr(C)]</code>. The Rust compiler uses invalid enum values as space for packing other information while optimizing types, for example Rust is able to represent <code class="language-plaintext highlighter-rouge">Option&lt;Option&lt;... 255 times .. Option&lt;bool&gt;&gt;</code> as a single byte.</p>

<p>If you are working with a C enum that is used for bitflags like above, please use an integer type instead. <code class="language-plaintext highlighter-rouge">#[repr(C)]</code> on enums in Rust guarantees layout, but it is <a href="https://doc.rust-lang.org/stable/nomicon/other-reprs.html">still undefined behavior for any enum to take on invalid values</a>.</p>

<h3 id="abi-concerns">ABI concerns</h3>

<p>ABIs can be tricky. If you <em>just</em> use bindgen with no special flags, you can be pretty much guaranteed to have an okay ABI, but as you start doing type replacements, stuff can get murkier.</p>

<p>Firstly, make sure you’re not passing owned C++ classes with destructors/etc across FFI boundaries. See <a href="#potential-pitfall-passing-c-classes-by-value-over-ffi">above</a> for why. There’s a bunch of subtle stuff here, but you can avoid most of it it if you just don’t pass these things across FFI in an owned way.</p>

<p>Also, try to make sure everything is <code class="language-plaintext highlighter-rouge">#[repr(C)]</code> across the boundary. Rust’s <code class="language-plaintext highlighter-rouge">improper-ctypes</code> lints will help here.</p>

<h2 id="should-c-apis-be-unconditionally-unsafe">Should C++ APIs be unconditionally <code class="language-plaintext highlighter-rouge">unsafe</code>?</h2>

<p>Before I get into this, I want to reiterate that most of the recommendations in this post are for <em>complex</em> C++-Rust integrations, which are likely to only crop up when attempting to rewrite parts of a large C++ codebase in Rust. Such codebases have unique needs and it’s important to calibrate for that when judging what’s right for them.</p>

<p>I recall when <a href="https://www.chromium.org/Home/chromium-security/memory-safety/rust-and-c-interoperability">this Chromium post</a> and <a href="https://steveklabnik.com/writing/the-cxx-debate">Steve’s <code class="language-plaintext highlighter-rouge">cxx</code> post</a> came out, there was a bunch of discussion about C++ functions not being universally marked <code class="language-plaintext highlighter-rouge">unsafe</code>. Essentially, a lot of people are of the opinion that all FFI into C++ (or C) should be unconditionally marked <code class="language-plaintext highlighter-rouge">unsafe</code> (and that tools like <code class="language-plaintext highlighter-rouge">cxx</code> should follow these rules).</p>

<p>Back then I wrote <a href="https://www.reddit.com/r/rust/comments/ielvxu/the_cxx_debate/g2jurb3/?context=3">a Reddit comment</a> about my thoughts on this. It’s a comment that’s the length of a blog post in and of itself so I’m not going to reproduce all of it here, but I’ll try to get the gist. I highly suggest you read it instead of this section.</p>

<p>In short, I would recommend people in large, complex codebases doing heavy C++ interop to generally be okay with marking functions calling into C++ as “safe” provided that function would be considered “safe to call without thinking too much about it” on the C++ side, whatever that means for your codebase.</p>

<p>From <a href="https://manishearth.github.io/blog/2017/12/24/undefined-vs-unsafe-in-rust/">my post on “undefined” vs “unsafe”</a>, for Rust I define “safe” as</p>

<blockquote>
  <p>Basically, in Rust a bit of code is “safe” if it cannot exhibit undefined behavior under all circumstances of that code being used.</p>
</blockquote>

<p>C++ doesn’t have a rigid language-level concept of safety that can be applied the same way. Instead, most C++ code follows a similar heuristic:</p>

<blockquote>
  <p>a bit of code is “safe” if it cannot exhibit undefined behavior under all <strong>expected</strong> circumstances of that code being used.</p>
</blockquote>

<p>This is, perhaps, not as good or useful a heuristic as the one we have for Rust, but it’s still a heuristic that gets used in deciding how careful one needs to be when using various APIs. After all, there are <em>plenty</em> of giant C++ codebases out there, they have got to be able to reason about safety <em>somehow</em>.</p>

<p>When you decide to meld together a C++ and Rust codebase, or start rewriting parts of a C++ codebase in Rust, you have already in essence decided for a large part of the codebase to not exactly follow Rust’s safety rules (but hopefully still be safe). There is little to be gained by making that an explicit part of your FFI boundary. Rather, it is more useful to save <code class="language-plaintext highlighter-rouge">unsafe</code> on the FFI boundary for truly unsafe functions which you actually do need to be careful to call.</p>

<p><code class="language-plaintext highlighter-rouge">unsafe</code> is useful for finding potential sources of badness in your codebase. For a tightly-integrated Rust/C++ codebase it’s already well known that the C++-side is introducing badness, marking every simple C++ getter as <code class="language-plaintext highlighter-rouge">unsafe</code> will lead to alarm fatigue and make it <em>harder</em> to find the real problems.</p>

<p>It’s worth figuring out where this boundary lies for you. Tools like <code class="language-plaintext highlighter-rouge">cxx</code> make it straightforward to call C++ functions through a safe interface, and it’s valuable to make use of that support.</p>

<h2 id="closing-comments">Closing comments</h2>

<p>Again, before going down this route it’s worth wondering if you <em>really</em> need tight Rust-C++ integration. When possible, it’s always better to pick a small, well-defined API boundary, rather than Stylo-esque tight integration with shared objects and a highly criscrossed callgraph.</p>

<p>These days <a href="https://github.com/dtolnay/cxx">cxx</a> is probably the most complete tool for such integrations. <a href="https://github.com/rust-lang-nursery/rust-bindgen/">bindgen</a> and <a href="https://github.com/eqrion/cbindgen">cbindgen</a> are still quite good, but cxx is C++-first, with a lot more magic, and generally seems to Just Work without too much configuration.</p>

<p><a href="https://github.com/google/autocxx">autocxx</a> is a cool concept by Adrian Taylor which melds bindgen and cxx to make something even <em>more</em> magical. It’s currently experimental, but I’m going to be watching it with interest.</p>

<p>Overall the field of Rust and C++ integration is at a stage where it’s mature enough for integrations to be <em>possible</em> without too much effort, but there are still tons of ways things could be improved and I’m super excited to see that happen as more people work on such integrations!</p>

<p><em>Thanks to Adam Perry, Adrian Taylor, katie martin, Nika Layzell, and Tyler Mandry for reviewing drafts of this post</em></p>
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>The <em>cascade</em> in “Cascading Style Sheets” is the process used to take all the potential rules which could apply to an element and find the “most applicable” one that gets actually used. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>The <code class="language-plaintext highlighter-rouge">em</code> unit is font-size-relative, so <code class="language-plaintext highlighter-rouge">2em</code> with a <code class="language-plaintext highlighter-rouge">font-size</code> of <code class="language-plaintext highlighter-rouge">12px</code> is computed to <code class="language-plaintext highlighter-rouge">2 * 12 = 24px</code>. <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:4" role="doc-endnote">
      <p>C++ name mangling <a href="https://en.wikipedia.org/wiki/Name_mangling#How_different_compilers_mangle_the_same_functions">is not standardized</a>, so any function with the C++ ABI will generate a <code class="language-plaintext highlighter-rouge">#[link_name = "_Z1foobarbaz"]</code> attribute on the Rust side, and the exact string used here will differ across compiler implementations and platforms. Since GCC and Clang follow the same scheme, most people will encounter this problem when their code doesn’t work on Windows due to MSVC using a different scheme. <a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p><code class="language-plaintext highlighter-rouge">Drop</code> impls are restricted in a bunch of ways for safety, in particular you cannot write <code class="language-plaintext highlighter-rouge">impl&lt;T: RefCounted&gt; Drop for RefPtr&lt;T&gt;</code> unless <code class="language-plaintext highlighter-rouge">RefPtr</code> is defined as <code class="language-plaintext highlighter-rouge">RefPtr&lt;T: RefCounted&gt;</code>. It’s not possible to have a generic type that has an impl of <code class="language-plaintext highlighter-rouge">Drop</code> for only <em>some</em> possible instantiations of its generics. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:5" role="doc-endnote">
      <p>Rust’s standard library does not typically guarantee anything about the layout of its types, and furthermore, Rust does not make many guarantees about the stability of most types without a <code class="language-plaintext highlighter-rouge">#[repr]</code> attribute. This would <em>work</em>, but it would be brittle and prone to breakage. <a href="#fnref:5" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name>Manish Goregaokar</name></author><category term="rust" /><category term="c++" /><category term="programming" /><summary type="html"><![CDATA[This post was originally drafted in August 2018, but I never got around to finishing it. As such, parts of its framing (e.g. the focus on bindgen) are outdated, given the relative infancy of the interop space at the time. I was recently told that the post is still useful in this form so I decided to finish and publish it anyway, while attempting to mark outdated things as such when I notice them. Everything after the allocators section was written near the time of publication. In 2017 I worked on the Stylo project, uplifting Servo’s CSS engine (“style system”) into Firefox’s browser engine (“Gecko”). This involved a lot of gnarly FFI between Servo’s Rust codebase and Firefox’s C++ codebase. There were a lot of challenges in doing this, and I feel like it’s worth sharing things from our experiences. If you’re interested in Rust integrations, you may find this talk by Katharina on Rust - C++ FFI, and this blog post by Henri on integrating encoding-rs into Firefox useful as well. Who is this post for? So, first off the bat, I’ll mention that when integrating Rust into a C++ codebase, you want to avoid having integrations as tight as Stylo. Don’t do what we did; make your Rust component mostly self-contained so that you just have to maintain something like ten FFI functions for interacting with it. If this is possible to do, you should do it and your life will be much easier. Pick a clean API boundary, define a straightforward API, use cbindgen or bindgen if necessary without any tricks, and you should be good to go. That said, sometimes you have to have gnarly integrations, and this blog post is for those use cases. These techniques mostly use bindgen in their examples, however you can potentially use them with hand-rolled bindings or another tool as well. If you’re at this level of complexity, however, the potential for mistakes in the hand-rolled bindings is probably not worth it. Note from 2021: cxx is probably a better tool for many of the use cases here, though many of the techniques still transfer. What was involved in Stylo’s FFI? So, what made Stylo’s FFI so complicated? It turns out that browsers are quite monolithic. You can split them into vaguely-defined components, but these components are still tightly integrated. If you intend to replace a component, you may need to make a jagged edge of an integration surface. The style system is more self-contained than other parts, but it’s still quite tightly integrated. The main job of a “style system” is to take the CSS rules and DOM tree, and run them through “the cascade”1 with an output of “computed styles” tagged on each node in the tree. So, for example, it will take a document like the following: &lt;style type="text/css"&gt; body { font-size: 12px; } div { height: 2em; } &lt;/style&gt; &lt;body&gt; &lt;div id="foo"&gt;&lt;/div&gt; &lt;/body&gt; and turn it into something like: &lt;body&gt; has a font-size of 12px, everything else is the default the div #foo has a computed height of 24px 2, everything else is the default. It “inherits” the font-size from &lt;body&gt; as 12px From a code point of view, this means that Stylo takes in Gecko’s C++ DOM tree. It parses all the CSS, and then runs the cascade on the tree. It stores computed styles on each element in a way that Gecko can read very cheaply. Style computation can involve some complex steps that require calling back into C++ code. Servo’s style system is multithreaded, but Gecko is mostly designed to work off of a single main thread per process, so we need to deal with this impedence mismatch. Since the output of Stylo is C++-readable structs, Stylo needs to be able to read and write nontrivial C++ abstractions. Typical FFI involves passing values over a boundary, never to be seen again, however here we’re dealing with persistent state that is accessed by both sides. To sum up, we have: Lots and lots of back-and-forth FFI Thread safety concerns Rust code regularly dealing with nontrivial C++ abstractions A need for nontrivial abstractions to be passed over FFI All of this conspires to make for some really complicated FFI code. The actual techniques I’ll try to structure this so that the more broadly useful (and/or less gnarly) techniques come earlier in the post. The basics of bindgen Bindgen is a tool that generates Rust bindings for structs and functions from the provided C or C++ header files. It’s often used for writing Rust bindings to existing C/C++ libraries, however it’s useful for integrations as well. To use it for an integration, write a header file containing the functions your Rust code needs (referencing structs from other header files if necessary), and run bindgen on it. For some codebases, doing this once and checking in the generate file suffices, but if your C++ code is going to change a lot, run it as a build dependency instead. Beware that this can adversely impact build times, since your Rust build now has a partial C++ compilation step. For large C++ codebases, pulling in a single header will likely pull in a lot of stuff. You should allowlist, blocklist, and/or mark things as opaque to reduce the amount of bindings generated. It’s best to go the allowlisting route — give bindgen an allowlisted list of functions / structs to generate bindings for, and it will transitively generate bindings for any dependencies they may have. Sometimes even this will end up generating a lot, it’s sometimes worth finding structs you’re not using and marking them as opaque so that their bindings aren’t necessary. Marking something as opaque replaces it with an array of the appropriate size and alignment, so from the Rust side it’s just some bits you don’t care about and can’t introspect further. Bindgen does support some C++ features (you may need to pass -x c++). This is pretty good for generating bindings to e.g. templated structs. However, it’s not possible to support all C++ features here, so you may need to blocklist, opaqueify, or use intermediate types if you have some complicated C++ abstractions in the deps. You’ll typically get an error when generating bindings or when compiling the generated bindings, so don’t worry about this unless that happens. Bindgen is quite configurable. Stylo has a script that consumes a large toml file containing all of the configuration. cbindgen We don’t use cbindgen in Stylo, but it’s used for Webrender. It does the inverse of what bindgen does: given a Rust crate, it generates C headers for its public extern "C" API. It’s also quite configurable. cxx cxx is the cool new hotness in 2021, which kind of approaches the problem from both sides, enabling you to write Rust bindings for C++ and C++ bindings for Rust. It’s definitely worth checking out, a lot of the things that are hard to make work with bindgen are trivial in cxx. For example, it automatically figures out what types need to be opaque, it automatically converts between &amp;T and T* across FFI, and it is overall more targeted for the use case of an FFI layer where Rust and C++ both call each other. Bindgen-aided C++ calling Rust So bindgen helps with creating things for Rust to call and manipulate, but not in the opposite direction. cbindgen can help here, but I’m not sure if it’s advisable to have both bindgen and cbindgen operating near each other on the same codebase. In Stylo we use a bit of a hack for this. Firstly, all FFI functions defined in C++ that Rust calls are declared in one file, and are all named Gecko_*. Bindgen supports regexes for things like allowlisting, so this naming scheme makes it easy to deal with. We also declare the FFI functions defined in Rust that C++ calls in another file, named Servo_*. They’re also all defined in one place. However, there’s nothing ensuring that the signatures match! If we’re not careful, there may be mismatches, causing bad things to happen at link time or runtime. We use a small autogenerated unit test to ensure the validity of the signatures. This is especially important as we do things like type replacement, and we need tests to ensure that the rug isn’t pulled out from underneath us. Type replacing for fun and profit Using blocklisting in conjunction with the --raw-line/raw_line() flag, one can effectively ask bindgen to “replace” types. Blocklisting asks bindgen not to generate bindings for a type, however bindgen will continue to generate bindings referring to that type if necessary. (Unlike opaque types where bindgen generates an opaque binding for the type and uses it everywhere). --raw-line lets you request bindgen to add a line of raw rust code to the file, and such a line can potentially define or import a new version of the type you blocklisted. Effectively, this lets you replace types. Bindgen generates unit tests ensuring that the layout of your structs is correct (run them!), so if you accidentally replace a type with something incompatible, you will get warnings at the struct level (functions may not warn). There are various ways this can be used: Safe references across FFI Note from 2021: cxx does this automatically Calling into C++ (and accepting data from C++) is unsafe. However, there’s no reason we should have to worry about this more than we have to. For example, it would be nice if accessor FFI functions – functions which take a foreign object and return something from inside it – could use lifetimes. It would be even nicer if nullability were represented on the FFI boundary so that you don’t miss null checks, and can assume non-nullness when the C++ API is okay with it. In Stylo, we have lots of functions like the following: RawGeckoNodeBorrowedOrNull Gecko_GetLastChild(RawGeckoNodeBorrowed node); which bindgen translates to: extern "C" { fn Gecko_GetLastChild(x: &amp;RawGeckoNode) -&gt; Option&lt;&amp;RawGeckoNode&gt;; } Using the bindgen build script on a provided list of borrow-able types, we’ve told bindgen that: FooBorrowedOrNull is actually Option&lt;&amp;Foo&gt; FooBorrowed is actually &amp;Foo Option&lt;&amp;Foo&gt; is represented as a single nullable pointer in Rust, so this is a clean translation. We’re forced to null-check it, but once we do we can safely assume that the reference is valid. Furthermore, due to lifetime elision the actual signature of the FFI function is fn Gecko_GetLastChild&lt;'a&gt;(x: &amp;'a RawGeckoNode) -&gt; Option&lt;&amp;'a RawGeckoNode&gt;, which ensures we won’t let the returned reference outlive the passed reference. Lifetime elision means that we can call C++ functions “safely” with the appropriate lifetime requirements, even though C++ has no such concept! Note that this is shifting some of the safety invariants to the C++ side: We rely on the C++ to give us valid references, and we rely on it to not have nulls when the type is not marked as nullable. Most C++ codebases internally rely on such invariants for safety anyway, so this isn’t much of a stretch. We do this on both sides, actually: Many of our Rust-defined extern "C" functions that C++ calls get to be internally-safe because the types let us assume the validity of the pointers obtained from C++. Making C++ abstractions Rust-accessible A very useful thing to do here is to replace various C++ abstractions with Rust versions of them that share semantics. In Gecko, most strings are stored in nsString/nsAString/etc. We’ve written an nsstring crate that represents layout-compatible nsStrings in a more Rusty way, with Rusty APIs. We then ask bindgen to replace Gecko nsStrings with these. Usually it’s easier to just write an impl for the bindgen-generated abstraction, however sometimes you must replace it: When the abstraction internally does a lot of template stuff not supported by bindgen When you want the code for the abstraction to be in a separate crate Potential pitfall: Passing C++ classes by-value over FFI It’s quite tempting to do stuff like RefPtr&lt;Foo&gt; Servo_Gimme(...); where you pass complicated classes by-value over FFI (RefPtr is Gecko’s variant of Rc&lt;T&gt;/Arc&lt;T&gt;). This works on some systems, but is broken on MSVC: The ABI for passing non-POD types through functions is different. The linker usually notices this and complains, but it’s worth avoiding this entirely. In Stylo we handle this by using some macro-generated intermediate types which are basically the same thing as the original class but without any constructors/destructors/operators. We convert to/from these types immediately before/after the FFI call, and on the Rust side we do similar conversions to Rust-compatible abstractions. Sharing abstractions with destructors If you’re passing ownership of collections or other templated types across FFI, you probably want Rust code to be able to destroy C++ objects, and vice versa. One way of doing this is to implement Drop on the generated struct. If you have class MyString, you can do: class MyString { // ... ~MyString(); } void MyString_Destroy(*MyString x) { x-&gt;~MyString() } impl Drop for bindings::MyString { fn drop(&amp;mut self) { // (bindgen only) bindings::MyString::destruct(self) // OR bindings::MyString_Destroy(self) } } The MyString_Destroy isn’t necessary with bindgen – bindgen will generate a MyString::destruct() function for you – but be careful, this will make your generated bindings very platform-specific, so be sure to only do this if running them at build time. In general, when bindgen generates C++ methods, your bindings become platform specific and are best regenerated at build time3. In Stylo we went down the route of manually defining _Destroy() functions since we started off with checked-in platform-agnostic bindings, however we could probably switch to using destruct() if we want to now. When it comes to generic types, it’s a bit trickier, since Drop can’t be implemented piecewise on a generic type (you cannot impl Drop for MyVector&lt;Foo&gt;). You have to do something like: template&lt;typename T&gt; class MyVector { // ... } // Deallocate buffer, but do not call destructors on elements void MyVector_Deallocate_Buffer(MyVector&lt;void&gt;* x); // assume we have an implementation of Iterator for MyVector&lt;T&gt; somewhere impl&lt;T&gt; Drop for bindings::MyVector&lt;T&gt; { fn drop(&amp;mut self) { for v in self.iter_mut() { // calls the destructor for `v`, if any std::ptr::drop_in_place(v) } bindings::MyVector_Deallocate_Buffer(self as *mut MyVector&lt;T&gt; as *mut MyVector&lt;c_void&gt;) } } Note that if you forget to add a Drop implementation for T, this will silently forget to clean up the contents of the vector. See the next section for some ways to handle this by creating a “safe” mirror type. Mirror types C++ libraries often have useful templated abstractions, and it’s nice to be able to manipulate them from Rust. Sometimes, it’s possible to just tack on semantics on the Rust side (either by adding an implementation or by doing type replacement), but in some cases this is tricky. For example, Gecko has RefPtr&lt;T&gt;, which is similar to Rc&lt;T&gt;, except the actual refcounting logic is up to T to implement (it can choose between threadsafe, non-threadsafe, etc), which it does by writing AddRef() and Release() methods. We mirror this in Rust by having a trait: /// Trait for all objects that have Addref() and Release /// methods and can be placed inside RefPtr&lt;T&gt; pub unsafe trait RefCounted { /// Bump the reference count. fn addref(&amp;self); /// Decrease the reference count. unsafe fn release(&amp;self); } /// A custom RefPtr implementation to take into account Drop semantics and /// a bit less-painful memory management. pub struct RefPtr&lt;T: RefCounted&gt; { ptr: *mut T, _marker: PhantomData&lt;T&gt;, } We implement the RefCounted trait for C++ types that are wrapped in RefPtr which we wish to access through Rust. We have some macros that make this easier to do. We have to have such a trait, because otherwise Rust code wouldn’t know how to manage various C++ types. However, RefPtr&lt;T&gt; here can’t be the type that ends up being used in bindgen. Rust doesnt let us do things like impl&lt;T: RefCounted&gt; Drop for RefPtr&lt;T&gt; 4, so we can’t effectively make this work with the bindgen generated type unless we write a RefCounted implementation for every refcounted type that shows up in the bindgen output at all – which would be a lot of work. Instead, we let bindgen generate its own RefPtr&lt;T&gt;, called structs::RefPtr&lt;T&gt; (all the structs that bindgen generates for Gecko go in a structs:: module). structs::RefPtr&lt;T&gt; itself doesn’t have enough semantics to be something we can pass around willy-nilly in Rust code without causing leaks. However, it has some methods that allow for conversion into the “safe” mirror RefPtr&lt;T&gt; (but only if T: RefCounted). So if you need to manipulate a RefPtr&lt;T&gt; in a C++ struct somewhere, you immediately use one of the conversion methods to get a safe version of it first, and then do things to it. Refcounted types that don’t have the RefCounted implementation won’t have conversion methods: they may exist in the data you’re manipulating, however you won’t be able to work with them. In general, whenever attaching extra semantics to generic bindgen types doesn’t work create a mirror type that’s completely safe to use from Rust, with a trait that gates conversion to the mirror type. Potential pitfall: Allocators If you’re passing heap-managed abstractions across FFI, be careful about which code frees which objects. If your Rust and C++ code don’t share allocators, deallocating memory allocated on the other side can have disastrous consequences. If you’re building a cdylib or staticlib with Rust (this is likely if you’re linking it with a C++ application), the compiler will by default pick the system allocator (malloc), so if your C++ application also uses the same you’re all set. On some platforms when building rlibs and binaries, Rust may choose jemalloc instead. It’s also possible that your C++ code uses a different allocator (lots of applications use allocators like jemalloc or tcmalloc, some have their own custom allocators like tor_malloc in Tor). In such cases you have one of three options: Avoid transferring ownership of heap-allocated items, only share things as borrowed references Call destructors over FFI, as detailed in the section on destructors above Set Rust’s allocator to be the same as documented in the std::alloc module. Basically, can use the #[global_allocator] attribute to select which allocator you wish to use, and if necessary you can implement the GlobalAlloc trait on a custom allocator type that calls into whatever custom allocator C++ is using. Note from 2021: Most stdlib collections (Vec, for example) now have an optional “custom allocator” parameter that can be used to swap in a different allocator for a specific use site. Arcs over FFI: Triomphe This isn’t really a generalizable technique, but it’s pretty cool and generally instructive, so I’m including it here. Stylo uses a lot of Arcs. A lot of them. The entire computation of styles makes heavy use of Arc::make_mut’s copy-on-write semantics so that we can build up the style tree in parallel but not have to make unnecessary copies of duplicated/defaulted styles for each element. Many of these Arcs need to be readable from C++. Rust’s Arc, however, consists of a pointer to an allocation containing a refcount and the data, so if C++ needs to get access to the data it needs to know the layout of the Arc allocation, which we’d rather not do5. We picked a different route: We created a crate duplicating Arc&lt;T&gt; which behaves almost exactly the same as Arc&lt;T&gt;, but it can be converted to OffsetArc&lt;T&gt; which has its pointer point to the middle of the allocation, where the T begins. To C++, this just looks like a *const T! We were then able to make it work with RefPtr&lt;T&gt; on the C++ side so that C++ can transparently read from the OffsetArc&lt;T&gt;, and only needs to call into Rust if it wishes to clone or drop it. The external version of this crate can be found in triomphe. It contains a bunch of other goodies that are additionally useful outside of the FFI world, like ArcBorrow which is essentially “&amp;Arc&lt;T&gt; without double indirection”, UniqueArc&lt;T&gt;, a mutable Arc&lt;T&gt; known to be uniquely owned, and ArcUnion&lt;T, U&gt;, which is a space-efficient union of Arc&lt;T&gt; and Arc&lt;U&gt;. Other pitfalls Transparent It’s very tempting to wrap C++ types in tuple structs and pass them over FFI. For example, one might imagine that the following is okay: struct Wrapper(bindings::SomeCppType); extern "C" { // C++ signature: `SomeCppType get_cpp_type();` fn get_cpp_type() -&gt; Wrapper; } This kind of thing is quite useful to get around coherence, or for adding additional semantics to a type. While there’s basically one obvious way Wrapper can be represented, ABI stuff can be tricky, and Rust’s layout isn’t defined. It is safer to use #[repr(transparent)], which guarantees that Wrapper will have the same representation as the type it contains. C enums Rust supports C-like enums, but there’s a crucial difference between them. In C, it is not undefined behavior for an enum to have an unlisted value. In fact, the following pattern is not uncommon: enum Flags { Flag1 = 0b0001, Flag2 = 0b0010, Flag3 = 0b0100, Flag4 = 0b1000; }; where the enum is actually used for bitflags, and Flag1 | Flag2 and 0 are both valid values for Flags. This is not the case in Rust. If you are type-replacing C enums with Rust ones, make sure they are #[repr(C)]. The Rust compiler uses invalid enum values as space for packing other information while optimizing types, for example Rust is able to represent Option&lt;Option&lt;... 255 times .. Option&lt;bool&gt;&gt; as a single byte. If you are working with a C enum that is used for bitflags like above, please use an integer type instead. #[repr(C)] on enums in Rust guarantees layout, but it is still undefined behavior for any enum to take on invalid values. ABI concerns ABIs can be tricky. If you just use bindgen with no special flags, you can be pretty much guaranteed to have an okay ABI, but as you start doing type replacements, stuff can get murkier. Firstly, make sure you’re not passing owned C++ classes with destructors/etc across FFI boundaries. See above for why. There’s a bunch of subtle stuff here, but you can avoid most of it it if you just don’t pass these things across FFI in an owned way. Also, try to make sure everything is #[repr(C)] across the boundary. Rust’s improper-ctypes lints will help here. Should C++ APIs be unconditionally unsafe? Before I get into this, I want to reiterate that most of the recommendations in this post are for complex C++-Rust integrations, which are likely to only crop up when attempting to rewrite parts of a large C++ codebase in Rust. Such codebases have unique needs and it’s important to calibrate for that when judging what’s right for them. I recall when this Chromium post and Steve’s cxx post came out, there was a bunch of discussion about C++ functions not being universally marked unsafe. Essentially, a lot of people are of the opinion that all FFI into C++ (or C) should be unconditionally marked unsafe (and that tools like cxx should follow these rules). Back then I wrote a Reddit comment about my thoughts on this. It’s a comment that’s the length of a blog post in and of itself so I’m not going to reproduce all of it here, but I’ll try to get the gist. I highly suggest you read it instead of this section. In short, I would recommend people in large, complex codebases doing heavy C++ interop to generally be okay with marking functions calling into C++ as “safe” provided that function would be considered “safe to call without thinking too much about it” on the C++ side, whatever that means for your codebase. From my post on “undefined” vs “unsafe”, for Rust I define “safe” as Basically, in Rust a bit of code is “safe” if it cannot exhibit undefined behavior under all circumstances of that code being used. C++ doesn’t have a rigid language-level concept of safety that can be applied the same way. Instead, most C++ code follows a similar heuristic: a bit of code is “safe” if it cannot exhibit undefined behavior under all expected circumstances of that code being used. This is, perhaps, not as good or useful a heuristic as the one we have for Rust, but it’s still a heuristic that gets used in deciding how careful one needs to be when using various APIs. After all, there are plenty of giant C++ codebases out there, they have got to be able to reason about safety somehow. When you decide to meld together a C++ and Rust codebase, or start rewriting parts of a C++ codebase in Rust, you have already in essence decided for a large part of the codebase to not exactly follow Rust’s safety rules (but hopefully still be safe). There is little to be gained by making that an explicit part of your FFI boundary. Rather, it is more useful to save unsafe on the FFI boundary for truly unsafe functions which you actually do need to be careful to call. unsafe is useful for finding potential sources of badness in your codebase. For a tightly-integrated Rust/C++ codebase it’s already well known that the C++-side is introducing badness, marking every simple C++ getter as unsafe will lead to alarm fatigue and make it harder to find the real problems. It’s worth figuring out where this boundary lies for you. Tools like cxx make it straightforward to call C++ functions through a safe interface, and it’s valuable to make use of that support. Closing comments Again, before going down this route it’s worth wondering if you really need tight Rust-C++ integration. When possible, it’s always better to pick a small, well-defined API boundary, rather than Stylo-esque tight integration with shared objects and a highly criscrossed callgraph. These days cxx is probably the most complete tool for such integrations. bindgen and cbindgen are still quite good, but cxx is C++-first, with a lot more magic, and generally seems to Just Work without too much configuration. autocxx is a cool concept by Adrian Taylor which melds bindgen and cxx to make something even more magical. It’s currently experimental, but I’m going to be watching it with interest. Overall the field of Rust and C++ integration is at a stage where it’s mature enough for integrations to be possible without too much effort, but there are still tons of ways things could be improved and I’m super excited to see that happen as more people work on such integrations! Thanks to Adam Perry, Adrian Taylor, katie martin, Nika Layzell, and Tyler Mandry for reviewing drafts of this post The cascade in “Cascading Style Sheets” is the process used to take all the potential rules which could apply to an element and find the “most applicable” one that gets actually used. &#8617; The em unit is font-size-relative, so 2em with a font-size of 12px is computed to 2 * 12 = 24px. &#8617; C++ name mangling is not standardized, so any function with the C++ ABI will generate a #[link_name = "_Z1foobarbaz"] attribute on the Rust side, and the exact string used here will differ across compiler implementations and platforms. Since GCC and Clang follow the same scheme, most people will encounter this problem when their code doesn’t work on Windows due to MSVC using a different scheme. &#8617; Drop impls are restricted in a bunch of ways for safety, in particular you cannot write impl&lt;T: RefCounted&gt; Drop for RefPtr&lt;T&gt; unless RefPtr is defined as RefPtr&lt;T: RefCounted&gt;. It’s not possible to have a generic type that has an impl of Drop for only some possible instantiations of its generics. &#8617; Rust’s standard library does not typically guarantee anything about the layout of its types, and furthermore, Rust does not make many guarantees about the stability of most types without a #[repr] attribute. This would work, but it would be brittle and prone to breakage. &#8617;]]></summary></entry><entry><title type="html">On Voting Systems</title><link href="http://manishearth.github.io/blog/2019/10/09/on-voting-systems/" rel="alternate" type="text/html" title="On Voting Systems" /><published>2019-10-09T00:00:00+00:00</published><updated>2019-10-09T00:00:00+00:00</updated><id>http://manishearth.github.io/blog/2019/10/09/on-voting-systems</id><content type="html" xml:base="http://manishearth.github.io/blog/2019/10/09/on-voting-systems/"><![CDATA[<p>Election season is starting up again, and as with many other topics I’m seeing a lot of overconfident takes from people in tech wanting to “solve” how voting works with naïve techy solutions. Hell, <a href="https://cointelegraph.com/news/andrew-yang-wants-to-make-us-elections-fraud-proof-using-blockchain">even a presidential candidate seems to have proposed an extremely uninformed plan for “fixing” voting using blockchain technology</a>.</p>

<p>Last year I wrote <a href="https://twitter.com/ManishEarth/status/1056255900095340545">a thread on Twitter</a> covering some of the essential properties good voting systems uphold as well as how they prevent fraud. It was through the lens of Alameda County’s voting system, where I’ve volunteered as a poll worker in the past (and intend to do again). I’ve been meaning to write down the contents of that thread in blog form for a while, and now seemed like a good opportunity to do it.</p>

<p>I’ll be explaining more about most of these properties later, but ideally, a good voting system should uphold:</p>

<ul>
  <li>Secret ballot: Nobody, not even you, can verify who you voted for after you’re out of the polling place, to prevent vote-buying and coercion.</li>
  <li>Auditable paper trail: We should be able to audit the election. Paper trails are usually the most robust way to enable effective audits.</li>
  <li>Obviousness: It should be relatively obvious what individuals should be doing when they need to mark their ballots. A system that you can easily “mess up” with is a bad system.</li>
  <li>Accessibility: It should not exclude individuals with disabilities from being able to vote.</li>
</ul>

<h2 id="how-voting-works-in-alameda-county">How voting works in Alameda County</h2>

<p>I’ll first go over how voting in my county works. The system isn’t perfect, but it’s pretty good, and it’s a good springboard for understanding how voting systems in general can work. There’s a <a href="https://www.acvote.org/acvote-assets/04_resources/PDFs/pwmanuals/06042019/Guide-FINAL-june.pdf">poll worker guide</a> you can refer to if you’re really interested in all the specifics.</p>

<p>Broadly speaking, there are four ways to vote:</p>

<ul>
  <li>By mail</li>
  <li>In person at certain government offices, before election day (“early voting”)</li>
  <li>In person on election day at a polling place</li>
  <li>Provisionally, in person on election day at a polling place</li>
</ul>

<p>Voting by mail is pretty straightforward: When you register you can choose to vote by mail (or you can choose to do so online after the fact). You get a ballot in the mail, along with a special envelope. You fill in the ballot at your leisure, stick it in the envelope, write your name/address on the envelope, sign it, and mail it back. There are also convenient ballot dropboxes all over the place in case you’re a millenial like me and don’t want to figure out how to buy stamps<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup>.</p>

<p>If you’re voting by mail you can also show up at any polling place on the day of the election and drop off your ballots in a sealed bin. At the polling place I helped run roughly half of the people coming in were just there to drop off their vote by mail ballots!</p>

<p>Voting by mail is by far the easiest option here. Sadly not all counties support it<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup>. In some states <a href="https://en.wikipedia.org/wiki/Vote-by-mail_in_Oregon">this is even the <em>default</em> option</a>.</p>

<p>As I understand it, voting in person at designated government offices<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote" rel="footnote">3</a></sup> is pretty much the same as voting in person at a polling place, it’s just run by government employees instead of volunteers and open for a few weeks before election day.</p>

<figure class="caption-wrapper center" style="width: 400px"><img class="caption" src="/images/post/polls/bling.jpeg" width="400" /><figcaption class="caption-text"><p>Poll workers are given some neat bling to wear</p>
</figcaption></figure>

<h3 id="in-person-voting">In person voting</h3>

<p>If you’ve chosen to vote in person, you are supposed to turn up at your assigned polling place (you get your assignment in the mail along with other voter info booklets).</p>

<p>There’s a copy of the list of people assigned to the polling place posted outside, and another with the poll workers inside. When you tell your name to the poll workers, they cross your name off the list, and you have to sign your name next to it<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" class="footnote" rel="footnote">4</a></sup>.</p>

<ul>
  <li>If your name isn’t on the list, the poll workers will try and find your assigned precinct and inform you that you can go there instead, but you can still choose to vote provisionally at the existing precinct.</li>
  <li>If your name isn’t on the list of all voters (perhaps you registered very late, or were unable to register), you can also vote provisionally.</li>
  <li>If your name is on the list but marked as voting-by-mail (and you want to vote in person), you can vote normally only if you surrender your mail ballot (which poll workers will mark as spoiled and put in a separate pouch).</li>
  <li>If you lost/didn’t receive your ballot, you can always vote provisionally.</li>
</ul>

<p>When you are voting normally, signing your name on the list fraudulently is illegal.</p>

<p>If it is your first time voting, you need to show some form of ID, but it doesn’t need to be photo ID and <a href="https://en.wikipedia.org/wiki/Help_America_Vote_Act#Voter_identification">even a utility bill is fine</a>.</p>

<p>Once you’re done signing, you’ll be given your ballot cards and a privacy sleeve folder so you can carry your filled ballots around. Because this is California and there are tons of local and state measures, we had 4 (!!) ballot cards, six sides to fill in<sup id="fnref:5" role="doc-noteref"><a href="#fn:5" class="footnote" rel="footnote">5</a></sup>. Usually a poll worker will also detach the ballot stubs in front of you and hand them to you to keep. You can use these to check the status (but not the contents!) of your ballot online.</p>

<p>You take your cards to a voting booth, fill them in, and come back. A poll worker will then help you feed your ballot cards into a scanner machine. This machine will reject cards with any problems — which you can fix, rerequesting new ballot cards if necessary, but you then have to spoil and return the old ballot card.</p>

<p>The machine keeps an externally-visible tally of the number of ballots submitted, and an internal tally of all the votes made, ignoring write-ins. It also internally stores ballot cards in one of two bins (depending on write-ins). These bins are verified to be empty when polls open, and are inaccessible till polls close.</p>

<p>It’s important to note that the scanner is not a load-bearing component of the system: It could be replaced with a locked bin with a slot, and the system would still work. The scanner enables one to get <em>preliminary</em> results for the precinct, and provides a way to double-check results.</p>

<p>And that’s it! You’ll be given an I Voted sticker, and you can go home!</p>

<figure class="caption-wrapper center" style="width: 400px"><img class="caption" src="/images/post/polls/stickers.png" width="400" /><figcaption class="caption-text"><p>Some “I Voted!” stickers in Spanish</p>
</figcaption></figure>

<h3 id="using-a-voting-machine">Using a voting machine</h3>

<p>In case you think you will have trouble filling out a ballot card in pen (e.g. if your vision is heavily impared), there’s an alternate way to vote that doesn’t involve a pen. Instead, we have a machine which has a touchscreen and an audio unit, which prompts the voter for their selection for each ballot item on the touchscreen or audio unit. When they’re done, the machine will print out a “receipt” listing their choices inside a sealed box with a glass window, so they can verify that their vote was recorded correctly<sup id="fnref:6" role="doc-noteref"><a href="#fn:6" class="footnote" rel="footnote">6</a></sup>. Once they’re done the sealed box will scroll the “receipt” out of view so that the next voter can’t see it.</p>

<p>The sealed box is called a <a href="https://en.wikipedia.org/wiki/Voter-verified_paper_audit_trail">Voter-Verified Paper Trail</a> box: the election runners no longer need to trust the machine’s internal memory, they can trust the paper trail inside the box (which, while produced by a potentially-untrustworthy machine, was verified by the voters), and the machine’s internal memory is simply a way to double-check (and get fast preliminary results).</p>

<h3 id="provisional-voting">Provisional voting</h3>

<p>There are many, many situations in which you may not be able to vote normally. Perhaps you showed up at the wrong precinct but don’t have time to go to the right one. Perhaps you were signed up for vote-by-mail but didn’t receive (or lost) your ballot. Perhaps you recently moved into the county and weren’t able to register in time. Perhaps you were a first-time in-person voter and didn’t have some form of ID.</p>

<p>In such a case you can always vote provisionally. The beauty of this system is that it removes most liability from poll workers: we don’t have any reason to turn people away from the polls, all we can do is refuse to let people vote normally (and instead vote provisionally) in the case of any inconsistencies. This is not to say that malicious poll workers <em>can’t</em> turn people away; it’s illegal but it happens. But well-meaning poll workers cannot, by accident, disenfranchise a voter because we are always allowed to give them a provisional ballot, and that’s an easy rule to follow.</p>

<p>With provisional voting, the voters are given the same ballot cards, but they’re also given an envelope with a form on it. This envelope is equivalent to a voter registration form, (re)registering them in their appropriate county/district<sup id="fnref:7" role="doc-noteref"><a href="#fn:7" class="footnote" rel="footnote">7</a></sup>. They vote on the ballot cards normally, but instead of submitting the ballots to the scanner, they put them in the envelope, which goes into a sealed bin<sup id="fnref:8" role="doc-noteref"><a href="#fn:8" class="footnote" rel="footnote">8</a></sup>. You’re also given a number you can call to check the status of your ballot.</p>

<p>When you vote provisionally, the registrar of voters will manually process your envelope, remaking your ballot on the right set of cards if necessary, and feeding them into a scanner machine.</p>

<h3 id="integrity-checks">Integrity checks</h3>

<p>Underlying this system is a bevy of integrity checks. There’s an intricate seal system, with numbered seals of varying colors. Some are to be added and never removed, some are to be removed after checking the number, some are never supposed to be touched, some are added at the beginning of the day and removed at the end of the day.</p>

<p>For example, during setup we check that the bins in the scanner are empty, and seal it with a numbered seal. This number is noted down on a form, along with some numbers from the scanner/touchscreen display. The first person to vote is asked to verify all this, and signs the form along with the poll workers.</p>

<p>Election officials drop in multiple times during the day, and may check these numbers. At the end of the day, the numbers of all seals used, and any physical seals that were removed are sent back along with all the ballots.</p>

<p>Various ballot counts are also kept track of. We keep track of the number of provisional ballots, the number of submitted regular ballots (also kept track by the scanner), the number of ballot cards used, and the number of unused ballots left over. Everything needs to match up at the end of the day, and all unused ballots are sent back. These counts are also noted down.</p>

<p>Poll watchers are allowed to be around for most of this, though I think they’re not allowed to <em>touch</em> anything. I think poll watchers are also allowed to be around when the actual ballots are being counted by election officials.</p>

<h3 id="immediate-local-results">Immediate local results</h3>

<p>As mentioned before, the scanner isn’t a crucial part of the system, but if it happens to be working it can be used to get immediate local results. At the end of the day, the scanner prints out a bunch of stuff, including vote totals for races which got more than N votes (N=20, IIRC), so you get immediate results for your precinct. This printout is supposed to be taped to the polling place doors for everyone to see, and presumably the registrar of voters uses the copy submitted to them to publish quick preliminary results.</p>

<p>Using paper ballots doesn’t mean that we have to give up all the benefits of computers doing some of the work for us! We can still use computers to get fast results, without relying on them for the integrity of the system.</p>

<figure class="caption-wrapper center" style="width: 400px"><img class="caption" src="/images/post/polls/totals.jpeg" width="400" /><figcaption class="caption-text"><p>Vote totals posted outside. Our ballots are big and have lots of races on them; so the list of vote totals is absolutely ginormous.</p>
</figcaption></figure>

<h2 id="properties-of-this-voting-system">Properties of this voting system</h2>

<p>This system has some crucial properties.</p>

<h3 id="secret-ballot">Secret ballot</h3>

<p>It’s well known that nobody is supposed to be able to see who you voted for. But a crucial part of this system is that, once you submit your ballots, <em>you</em> can’t see who you voted for either. Of course, you probably can <em>remember</em>, but you have no <em>proof</em>. On the face of it this sounds like a bad property — wouldn’t it be nicer if people could verify that their vote was counted correctly?</p>

<p>The problem is that if <em>I</em> can verify that my vote was counted correctly, someone else can coerce me into doing this in front of them to ensure I voted a certain way. Any system that gives me the ability to verify my vote gives people who have power over me (or just people who want to buy my vote) the same ability.</p>

<p>Provisional voting doesn’t quite have this property, but it’s supposed to be for edge cases. Vote by mail trades off some of this property for convenience; people can now see who you voted for while you’re voting (and the people you live with can fradulently vote on your behalf, too).</p>

<h3 id="conservation-of-ballots-auditable-paper-trail">Conservation of ballots (Auditable paper trail)</h3>

<p>The total number of ballots in the system is roughly conserved and kept track of. If you’re registered to vote by mail, you cannot request a normal ballot without surrendering your vote by mail ballot and envelope (which we mark as spoiled and put in a separate pouch). If you re-request a ballot card because you made a mistake, the old card needs to be similarly spoiled and put away separately. It’s one set of ballot cards per voter, and almost all potential aberrations in this property result in a provisional vote<sup id="fnref:9" role="doc-noteref"><a href="#fn:9" class="footnote" rel="footnote">9</a></sup>. Even provisional votes are converted to normal ballot cards in the end.</p>

<p>Eventually, there will be a giant roomful of ballots that cannot be traced back to their individual voters, but it can still be traced back to the <em>entirety</em> of the voters — it’s hard to put a ballot into the system without a corresponding voter. This is perfect — the ballots can be hand-counted, but they can’t be individually corellated with their respective voters.</p>

<p>You don’t even need to recount the entire set of ballots to perform an audit, <a href="https://risklimitingaudits.org/">risk limiting audits</a> are quite effective and much more efficient to carry out.</p>

<h3 id="paper-ballots">Paper ballots</h3>

<p>The fact that they can (and should) be hand counted is itself an important property. Hand counting of ballots can be independently verified in ways that can’t be done for software. Despite not being able to trace a ballot back to its voter, there still is a paper trail of integrity for the ballots as a bulk unit.</p>

<p>This property leads to [software independance]: while we may use software in the process, it’s not possible for a bug in the software to cause an undetectable error in the final vote counts.</p>

<figure class="caption-wrapper center" style="width: 500px"><img class="caption" src="/images/post/polls/totals-zoom.png" width="500" /><figcaption class="caption-text"><p>Specific vote totals for the top races</p>
</figcaption></figure>

<h3 id="obviousness">Obviousness</h3>

<p>Figuring out what to do in the voting booth isn’t hard. You’re allowed to request assistance, but you’ll rarely have to. There are systems (like the scanner’s error checking) that are designed to ensure you don’t mess up, but the system is quite sound even without them; they just provide an additional buffer.</p>

<p>Compare this with <a href="https://www.texastribune.org/2018/11/01/texas-straight-ticket-voting-problems-old-machines/">the problems some Texas voting machines had last midterm</a>. The machines were somewhat buggy, but, crucially, there was an opaque right and wrong way to use them, and some voters accidentally used it the wrong way, and then didn’t check the final page before submitting. This kind of thing should never happen in a good voting system.</p>

<p>It’s really important that the system is intuitive and hard to make mistakes in.</p>

<h2 id="fraud-prevention">Fraud prevention</h2>

<p>So, how is this robust against fraud?</p>

<p>Firstly, voter fraud isn’t a major problem in the US, and it’s often used as an excuse to propagate voter suppression tactics, which <em>are</em> a major problem here.</p>

<p>But even then, we probably want our system to be robust against fraud.</p>

<p>Let’s see how an individual might thwart this system. They could vote multiple times, under assumed identites. This doesn’t scale well and isn’t really worth it: to influence an election you’d need to do this many times, or have many individuals do it a couple times, and the chance of getting caught (e.g., the people who you are voting as may come by and try to vote later, throwing up a flag) and investigated scales exponentially with the number of votes. That’s not worth it at all.</p>

<p>Maybe poll workers could do something malicious. Poll worker manipulation would largely exist in the form of submitting extra ballots. But that’s hard because the ballot counts need to match the list of voters. So you have the same problem as individual voters committing fraud: if the actual voter shows up, they’ll notice. Poll workers <em>could</em> wait till the end of the day to do this, but then to make any kind of difference you’d have to do a bulk scan of ballots, and that’s very noticeable. Poll workers would have to collude to make anything like this work, and poll watchers (and government staff) may be present.</p>

<p>Poll workers can also <em>discard</em> ballots to influence an election. But you can’t do this in front of the voters, and the receptacles with non-defaced ballots are all sealed so you can’t do this when nobody is watching without having to re-seal (which means you need a new numbered seal, which the election office will notice). The scanner’s inner receptacle is opened at the end of the day but you can’t tamper with that without messing up the various counts.</p>

<p>Election officials have access to giant piles of ballots and could mess with things there, but I suspect poll watchers are present during the ballot sorting and counting process, and again, it’s hard to tamper with anything without messing up the various counts.</p>

<p>Overall, this system is pretty robust. It’s important to note that fraud prevention is achieved by more social means, not technical means: there are seals, counts, and various properties of the system, but no computers involved in any crucial roles.</p>

<h2 id="techy-solutions-for-voting">Techy solutions for voting</h2>

<p>In general, amongst the three properties of “secret ballot”, “obviousness”, and “auditable paper trail”, computer-based voting systems almost always fail at one, and usually fail at two.</p>

<p>A lot of naïve tech solutions for voting are explicitly designed to not have the secret ballot property: they are instead designed specifically to let voters check that what their vote was counted as after the election. As mentioned earlier, this is a problem for vote-buying and coercion.</p>

<p>It’s theoretically possible to have a system where you can ensure your ballot, specifically, was correctly counted after the election, without losing the secret ballot property: <a href="https://en.wikipedia.org/wiki/ThreeBallot">ThreeBallot</a> is a cool example of such a system, though it fails the “obviousness” property.</p>

<p>Most systems end up not having an auditable paper trail since they rely on machines to record votes. This is vulnerable to bugs in the machine: you end up having to trust the output of the machine. Buggy/vulnerable voting machines are so common that every year at DEFCON <a href="https://media.defcon.org/DEF%20CON%2027/voting-village-report-defcon27.pdf">people get together to hack the latest voting machines, and typically succeed</a>.</p>

<p>Voting machines can still produce a paper trail: Voter-Verified Paper Trail systems partially succeed in doing this. They’re not as good with maintaining the “conservation of ballots” property that makes tampering much harder, and they’re not as good on the “obviousness” part since people need to check the VVPAT box for what their vote was recorded as.</p>

<p>Ballot-Marking devices are a bit better at this: These still produce paper ballots, it’s just that the ballot is marked by the machine on your behalf. There’s still a bit of an “obviousness” fail in that people may not double check the marked ballot, but at least there’s a nice paper trail with ballot conservation! Of course, these only work if the produced ballot is easily human-readable.</p>

<p>It’s not <em>impossible</em> to design good voting systems that rely on technology, but it’s hard to maintain the same properties you can with paper ballots. If you want to try, please keep the properties listed above in mind.</p>

<h3 id="blockchain">Blockchain?</h3>

<p>Every now and then people will suggest using blockchains for voting. This is a pretty large design space, but …. most of these proposals are <em>extremely</em> naïve and achieve very little.</p>

<p>For one, most of them are of the category that lose the “secret ballot” property, instead producing some kind of identifier you’re able to check in some published blockchain. This lets you see what your vote was after the election, and as I’ve covered already that’s not a good thing.</p>

<p>Even if this process only lets you verify that your vote was counted (but not what it was), it typically involves some understanding of cryptography to spot-check the validity of the machine output (e.g. you need to verify that some hash is the hash of your actual vote or something). This fails the obviousness property.</p>

<p>Blockchains don’t really bring much to the table here. They’re decent for byzantine fault tolerance in a space without a central authority, but elections <em>do</em> have some form of central authority and we’re not getting rid of that. The anonymity properties of blockchains can usually be achieved without blockchains for things like elections.</p>

<p>There are some kinds of cryptography that can be useful for auditability — zero knowledge proofs and homomorphic encryption come to mind — but you don’t need blockchains to use these, and using these still requires some form of technology as a key part of the voting system and this makes other properties of the system harder to achieve.</p>

<h2 id="become-a-poll-worker">Become a poll worker!</h2>

<p>It’s still a bit early for the next election, but I highly recommend you volunteer to be a poll worker for your county if you can!</p>

<p>It’s really fun, you get to learn about the inner workings of voting systems, and you get to meet a lot of people!</p>

<figure class="caption-wrapper center" style="width: 700px"><img class="caption" src="/images/post/polls/nancy.jpeg" width="700" /><figcaption class="caption-text">
<p>We had a cool kid come in and <a href="https://twitter.com/ManishEarth/status/1060052694772011008">more or less do this</a> at one point</p>

</figcaption></figure>

<p><em>Thanks to Nika Layzell, Sunjay Varma, Jane Lusby, and Arshia Mufti for providing feedback on drafts of this blog post.</em></p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>Last year they required postage, but I they’ve changed that with <a href="https://www.sos.ca.gov/administration/news-releases-and-advisories/2019/no-stamp-no-problem-all-vote-mail-ballots-now-come-prepaid-postage-return-envelopes/">a law</a> this year. Yay! <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>Ostensibly because of fears of voter fraud, but they’re largely unfounded — in practice this just reduces turnout <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>I think for Alameda county the only such office is the Registrar of Voters in Oakland <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:4" role="doc-endnote">
      <p>The crossing-off and signing lists are different, but this isn’t too important. <a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:5" role="doc-endnote">
      <p>I remember one particularly curmudgeonly voter loudly grumbling about all the propositions as they were voting. One doesn’t “vote” in California, one fills out social studies homework. <a href="#fnref:5" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:6" role="doc-endnote">
      <p>I don’t quite recall how the verifiability works for people using the audio unit, they may be allowed to ask someone else to verify for them? <a href="#fnref:6" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:7" role="doc-endnote">
      <p>If you vote in a different precinct, or worse, a different county, the ballot cards may not contain all the same races, so voting provisionally from the wrong district means that you only get to vote for the races common to both ballot cards. <a href="#fnref:7" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:8" role="doc-endnote">
      <p>It’s imperative that these do not go into the scanner (since that operation cannot be undone), and to prevent this poll workers are instructed to not give provisional voters a secrecy sleeve as the envelope acts as a secrecy sleeve. Whoever is supervising the scanner will only allow people with secrecy sleeves to slip their ballots into the scanner. <a href="#fnref:8" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:9" role="doc-endnote">
      <p>The exception is using the touchscreen machine, where you get to vote without using up a ballot card on voting day. However, tallies for the machine are kept separately, and I think these too are eventually turned into normal ballot cards. <a href="#fnref:9" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name>Manish Goregaokar</name></author><category term="politics" /><category term="elections" /><category term="programming" /><summary type="html"><![CDATA[Election season is starting up again, and as with many other topics I’m seeing a lot of overconfident takes from people in tech wanting to “solve” how voting works with naïve techy solutions. Hell, even a presidential candidate seems to have proposed an extremely uninformed plan for “fixing” voting using blockchain technology. Last year I wrote a thread on Twitter covering some of the essential properties good voting systems uphold as well as how they prevent fraud. It was through the lens of Alameda County’s voting system, where I’ve volunteered as a poll worker in the past (and intend to do again). I’ve been meaning to write down the contents of that thread in blog form for a while, and now seemed like a good opportunity to do it. I’ll be explaining more about most of these properties later, but ideally, a good voting system should uphold: Secret ballot: Nobody, not even you, can verify who you voted for after you’re out of the polling place, to prevent vote-buying and coercion. Auditable paper trail: We should be able to audit the election. Paper trails are usually the most robust way to enable effective audits. Obviousness: It should be relatively obvious what individuals should be doing when they need to mark their ballots. A system that you can easily “mess up” with is a bad system. Accessibility: It should not exclude individuals with disabilities from being able to vote. How voting works in Alameda County I’ll first go over how voting in my county works. The system isn’t perfect, but it’s pretty good, and it’s a good springboard for understanding how voting systems in general can work. There’s a poll worker guide you can refer to if you’re really interested in all the specifics. Broadly speaking, there are four ways to vote: By mail In person at certain government offices, before election day (“early voting”) In person on election day at a polling place Provisionally, in person on election day at a polling place Voting by mail is pretty straightforward: When you register you can choose to vote by mail (or you can choose to do so online after the fact). You get a ballot in the mail, along with a special envelope. You fill in the ballot at your leisure, stick it in the envelope, write your name/address on the envelope, sign it, and mail it back. There are also convenient ballot dropboxes all over the place in case you’re a millenial like me and don’t want to figure out how to buy stamps1. If you’re voting by mail you can also show up at any polling place on the day of the election and drop off your ballots in a sealed bin. At the polling place I helped run roughly half of the people coming in were just there to drop off their vote by mail ballots! Voting by mail is by far the easiest option here. Sadly not all counties support it2. In some states this is even the default option. As I understand it, voting in person at designated government offices3 is pretty much the same as voting in person at a polling place, it’s just run by government employees instead of volunteers and open for a few weeks before election day. Poll workers are given some neat bling to wear In person voting If you’ve chosen to vote in person, you are supposed to turn up at your assigned polling place (you get your assignment in the mail along with other voter info booklets). There’s a copy of the list of people assigned to the polling place posted outside, and another with the poll workers inside. When you tell your name to the poll workers, they cross your name off the list, and you have to sign your name next to it4. If your name isn’t on the list, the poll workers will try and find your assigned precinct and inform you that you can go there instead, but you can still choose to vote provisionally at the existing precinct. If your name isn’t on the list of all voters (perhaps you registered very late, or were unable to register), you can also vote provisionally. If your name is on the list but marked as voting-by-mail (and you want to vote in person), you can vote normally only if you surrender your mail ballot (which poll workers will mark as spoiled and put in a separate pouch). If you lost/didn’t receive your ballot, you can always vote provisionally. When you are voting normally, signing your name on the list fraudulently is illegal. If it is your first time voting, you need to show some form of ID, but it doesn’t need to be photo ID and even a utility bill is fine. Once you’re done signing, you’ll be given your ballot cards and a privacy sleeve folder so you can carry your filled ballots around. Because this is California and there are tons of local and state measures, we had 4 (!!) ballot cards, six sides to fill in5. Usually a poll worker will also detach the ballot stubs in front of you and hand them to you to keep. You can use these to check the status (but not the contents!) of your ballot online. You take your cards to a voting booth, fill them in, and come back. A poll worker will then help you feed your ballot cards into a scanner machine. This machine will reject cards with any problems — which you can fix, rerequesting new ballot cards if necessary, but you then have to spoil and return the old ballot card. The machine keeps an externally-visible tally of the number of ballots submitted, and an internal tally of all the votes made, ignoring write-ins. It also internally stores ballot cards in one of two bins (depending on write-ins). These bins are verified to be empty when polls open, and are inaccessible till polls close. It’s important to note that the scanner is not a load-bearing component of the system: It could be replaced with a locked bin with a slot, and the system would still work. The scanner enables one to get preliminary results for the precinct, and provides a way to double-check results. And that’s it! You’ll be given an I Voted sticker, and you can go home! Some “I Voted!” stickers in Spanish Using a voting machine In case you think you will have trouble filling out a ballot card in pen (e.g. if your vision is heavily impared), there’s an alternate way to vote that doesn’t involve a pen. Instead, we have a machine which has a touchscreen and an audio unit, which prompts the voter for their selection for each ballot item on the touchscreen or audio unit. When they’re done, the machine will print out a “receipt” listing their choices inside a sealed box with a glass window, so they can verify that their vote was recorded correctly6. Once they’re done the sealed box will scroll the “receipt” out of view so that the next voter can’t see it. The sealed box is called a Voter-Verified Paper Trail box: the election runners no longer need to trust the machine’s internal memory, they can trust the paper trail inside the box (which, while produced by a potentially-untrustworthy machine, was verified by the voters), and the machine’s internal memory is simply a way to double-check (and get fast preliminary results). Provisional voting There are many, many situations in which you may not be able to vote normally. Perhaps you showed up at the wrong precinct but don’t have time to go to the right one. Perhaps you were signed up for vote-by-mail but didn’t receive (or lost) your ballot. Perhaps you recently moved into the county and weren’t able to register in time. Perhaps you were a first-time in-person voter and didn’t have some form of ID. In such a case you can always vote provisionally. The beauty of this system is that it removes most liability from poll workers: we don’t have any reason to turn people away from the polls, all we can do is refuse to let people vote normally (and instead vote provisionally) in the case of any inconsistencies. This is not to say that malicious poll workers can’t turn people away; it’s illegal but it happens. But well-meaning poll workers cannot, by accident, disenfranchise a voter because we are always allowed to give them a provisional ballot, and that’s an easy rule to follow. With provisional voting, the voters are given the same ballot cards, but they’re also given an envelope with a form on it. This envelope is equivalent to a voter registration form, (re)registering them in their appropriate county/district7. They vote on the ballot cards normally, but instead of submitting the ballots to the scanner, they put them in the envelope, which goes into a sealed bin8. You’re also given a number you can call to check the status of your ballot. When you vote provisionally, the registrar of voters will manually process your envelope, remaking your ballot on the right set of cards if necessary, and feeding them into a scanner machine. Integrity checks Underlying this system is a bevy of integrity checks. There’s an intricate seal system, with numbered seals of varying colors. Some are to be added and never removed, some are to be removed after checking the number, some are never supposed to be touched, some are added at the beginning of the day and removed at the end of the day. For example, during setup we check that the bins in the scanner are empty, and seal it with a numbered seal. This number is noted down on a form, along with some numbers from the scanner/touchscreen display. The first person to vote is asked to verify all this, and signs the form along with the poll workers. Election officials drop in multiple times during the day, and may check these numbers. At the end of the day, the numbers of all seals used, and any physical seals that were removed are sent back along with all the ballots. Various ballot counts are also kept track of. We keep track of the number of provisional ballots, the number of submitted regular ballots (also kept track by the scanner), the number of ballot cards used, and the number of unused ballots left over. Everything needs to match up at the end of the day, and all unused ballots are sent back. These counts are also noted down. Poll watchers are allowed to be around for most of this, though I think they’re not allowed to touch anything. I think poll watchers are also allowed to be around when the actual ballots are being counted by election officials. Immediate local results As mentioned before, the scanner isn’t a crucial part of the system, but if it happens to be working it can be used to get immediate local results. At the end of the day, the scanner prints out a bunch of stuff, including vote totals for races which got more than N votes (N=20, IIRC), so you get immediate results for your precinct. This printout is supposed to be taped to the polling place doors for everyone to see, and presumably the registrar of voters uses the copy submitted to them to publish quick preliminary results. Using paper ballots doesn’t mean that we have to give up all the benefits of computers doing some of the work for us! We can still use computers to get fast results, without relying on them for the integrity of the system. Vote totals posted outside. Our ballots are big and have lots of races on them; so the list of vote totals is absolutely ginormous. Properties of this voting system This system has some crucial properties. Secret ballot It’s well known that nobody is supposed to be able to see who you voted for. But a crucial part of this system is that, once you submit your ballots, you can’t see who you voted for either. Of course, you probably can remember, but you have no proof. On the face of it this sounds like a bad property — wouldn’t it be nicer if people could verify that their vote was counted correctly? The problem is that if I can verify that my vote was counted correctly, someone else can coerce me into doing this in front of them to ensure I voted a certain way. Any system that gives me the ability to verify my vote gives people who have power over me (or just people who want to buy my vote) the same ability. Provisional voting doesn’t quite have this property, but it’s supposed to be for edge cases. Vote by mail trades off some of this property for convenience; people can now see who you voted for while you’re voting (and the people you live with can fradulently vote on your behalf, too). Conservation of ballots (Auditable paper trail) The total number of ballots in the system is roughly conserved and kept track of. If you’re registered to vote by mail, you cannot request a normal ballot without surrendering your vote by mail ballot and envelope (which we mark as spoiled and put in a separate pouch). If you re-request a ballot card because you made a mistake, the old card needs to be similarly spoiled and put away separately. It’s one set of ballot cards per voter, and almost all potential aberrations in this property result in a provisional vote9. Even provisional votes are converted to normal ballot cards in the end. Eventually, there will be a giant roomful of ballots that cannot be traced back to their individual voters, but it can still be traced back to the entirety of the voters — it’s hard to put a ballot into the system without a corresponding voter. This is perfect — the ballots can be hand-counted, but they can’t be individually corellated with their respective voters. You don’t even need to recount the entire set of ballots to perform an audit, risk limiting audits are quite effective and much more efficient to carry out. Paper ballots The fact that they can (and should) be hand counted is itself an important property. Hand counting of ballots can be independently verified in ways that can’t be done for software. Despite not being able to trace a ballot back to its voter, there still is a paper trail of integrity for the ballots as a bulk unit. This property leads to [software independance]: while we may use software in the process, it’s not possible for a bug in the software to cause an undetectable error in the final vote counts. Specific vote totals for the top races Obviousness Figuring out what to do in the voting booth isn’t hard. You’re allowed to request assistance, but you’ll rarely have to. There are systems (like the scanner’s error checking) that are designed to ensure you don’t mess up, but the system is quite sound even without them; they just provide an additional buffer. Compare this with the problems some Texas voting machines had last midterm. The machines were somewhat buggy, but, crucially, there was an opaque right and wrong way to use them, and some voters accidentally used it the wrong way, and then didn’t check the final page before submitting. This kind of thing should never happen in a good voting system. It’s really important that the system is intuitive and hard to make mistakes in. Fraud prevention So, how is this robust against fraud? Firstly, voter fraud isn’t a major problem in the US, and it’s often used as an excuse to propagate voter suppression tactics, which are a major problem here. But even then, we probably want our system to be robust against fraud. Let’s see how an individual might thwart this system. They could vote multiple times, under assumed identites. This doesn’t scale well and isn’t really worth it: to influence an election you’d need to do this many times, or have many individuals do it a couple times, and the chance of getting caught (e.g., the people who you are voting as may come by and try to vote later, throwing up a flag) and investigated scales exponentially with the number of votes. That’s not worth it at all. Maybe poll workers could do something malicious. Poll worker manipulation would largely exist in the form of submitting extra ballots. But that’s hard because the ballot counts need to match the list of voters. So you have the same problem as individual voters committing fraud: if the actual voter shows up, they’ll notice. Poll workers could wait till the end of the day to do this, but then to make any kind of difference you’d have to do a bulk scan of ballots, and that’s very noticeable. Poll workers would have to collude to make anything like this work, and poll watchers (and government staff) may be present. Poll workers can also discard ballots to influence an election. But you can’t do this in front of the voters, and the receptacles with non-defaced ballots are all sealed so you can’t do this when nobody is watching without having to re-seal (which means you need a new numbered seal, which the election office will notice). The scanner’s inner receptacle is opened at the end of the day but you can’t tamper with that without messing up the various counts. Election officials have access to giant piles of ballots and could mess with things there, but I suspect poll watchers are present during the ballot sorting and counting process, and again, it’s hard to tamper with anything without messing up the various counts. Overall, this system is pretty robust. It’s important to note that fraud prevention is achieved by more social means, not technical means: there are seals, counts, and various properties of the system, but no computers involved in any crucial roles. Techy solutions for voting In general, amongst the three properties of “secret ballot”, “obviousness”, and “auditable paper trail”, computer-based voting systems almost always fail at one, and usually fail at two. A lot of naïve tech solutions for voting are explicitly designed to not have the secret ballot property: they are instead designed specifically to let voters check that what their vote was counted as after the election. As mentioned earlier, this is a problem for vote-buying and coercion. It’s theoretically possible to have a system where you can ensure your ballot, specifically, was correctly counted after the election, without losing the secret ballot property: ThreeBallot is a cool example of such a system, though it fails the “obviousness” property. Most systems end up not having an auditable paper trail since they rely on machines to record votes. This is vulnerable to bugs in the machine: you end up having to trust the output of the machine. Buggy/vulnerable voting machines are so common that every year at DEFCON people get together to hack the latest voting machines, and typically succeed. Voting machines can still produce a paper trail: Voter-Verified Paper Trail systems partially succeed in doing this. They’re not as good with maintaining the “conservation of ballots” property that makes tampering much harder, and they’re not as good on the “obviousness” part since people need to check the VVPAT box for what their vote was recorded as. Ballot-Marking devices are a bit better at this: These still produce paper ballots, it’s just that the ballot is marked by the machine on your behalf. There’s still a bit of an “obviousness” fail in that people may not double check the marked ballot, but at least there’s a nice paper trail with ballot conservation! Of course, these only work if the produced ballot is easily human-readable. It’s not impossible to design good voting systems that rely on technology, but it’s hard to maintain the same properties you can with paper ballots. If you want to try, please keep the properties listed above in mind. Blockchain? Every now and then people will suggest using blockchains for voting. This is a pretty large design space, but …. most of these proposals are extremely naïve and achieve very little. For one, most of them are of the category that lose the “secret ballot” property, instead producing some kind of identifier you’re able to check in some published blockchain. This lets you see what your vote was after the election, and as I’ve covered already that’s not a good thing. Even if this process only lets you verify that your vote was counted (but not what it was), it typically involves some understanding of cryptography to spot-check the validity of the machine output (e.g. you need to verify that some hash is the hash of your actual vote or something). This fails the obviousness property. Blockchains don’t really bring much to the table here. They’re decent for byzantine fault tolerance in a space without a central authority, but elections do have some form of central authority and we’re not getting rid of that. The anonymity properties of blockchains can usually be achieved without blockchains for things like elections. There are some kinds of cryptography that can be useful for auditability — zero knowledge proofs and homomorphic encryption come to mind — but you don’t need blockchains to use these, and using these still requires some form of technology as a key part of the voting system and this makes other properties of the system harder to achieve. Become a poll worker! It’s still a bit early for the next election, but I highly recommend you volunteer to be a poll worker for your county if you can! It’s really fun, you get to learn about the inner workings of voting systems, and you get to meet a lot of people! We had a cool kid come in and more or less do this at one point Thanks to Nika Layzell, Sunjay Varma, Jane Lusby, and Arshia Mufti for providing feedback on drafts of this blog post. Last year they required postage, but I they’ve changed that with a law this year. Yay! &#8617; Ostensibly because of fears of voter fraud, but they’re largely unfounded — in practice this just reduces turnout &#8617; I think for Alameda county the only such office is the Registrar of Voters in Oakland &#8617; The crossing-off and signing lists are different, but this isn’t too important. &#8617; I remember one particularly curmudgeonly voter loudly grumbling about all the propositions as they were voting. One doesn’t “vote” in California, one fills out social studies homework. &#8617; I don’t quite recall how the verifiability works for people using the audio unit, they may be allowed to ask someone else to verify for them? &#8617; If you vote in a different precinct, or worse, a different county, the ballot cards may not contain all the same races, so voting provisionally from the wrong district means that you only get to vote for the races common to both ballot cards. &#8617; It’s imperative that these do not go into the scanner (since that operation cannot be undone), and to prevent this poll workers are instructed to not give provisional voters a secrecy sleeve as the envelope acts as a secrecy sleeve. Whoever is supervising the scanner will only allow people with secrecy sleeves to slip their ballots into the scanner. &#8617; The exception is using the touchscreen machine, where you get to vote without using up a ballot card on voting day. However, tallies for the machine are kept separately, and I think these too are eventually turned into normal ballot cards. &#8617;]]></summary></entry><entry><title type="html">Rust Governance: Scaling Empathy</title><link href="http://manishearth.github.io/blog/2019/02/04/rust-governance-scaling-empathy/" rel="alternate" type="text/html" title="Rust Governance: Scaling Empathy" /><published>2019-02-04T00:00:00+00:00</published><updated>2019-02-04T00:00:00+00:00</updated><id>http://manishearth.github.io/blog/2019/02/04/rust-governance-scaling-empathy</id><content type="html" xml:base="http://manishearth.github.io/blog/2019/02/04/rust-governance-scaling-empathy/"><![CDATA[<p>There’s been a lot of talk about improving Rust’s governance model lately. As we decompress from last year’s hectic edition work, we’re slowly starting to look at all the bits of <a href="https://twitter.com/ManishEarth/status/1073088515041198080">debt</a> we accumulated, and <a href="https://boats.gitlab.io/blog/post/rust-2019/">organizational debt</a> is high on that list.</p>

<p>I’ve been talking in private with people about a bunch of these things for quite a while now, and I felt it worthwhile to write down as much of my thoughts as I can before the Rust All Hands in Berlin this week.</p>

<p>In the interest of brevity<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup> I’m going to assume the reader is roughly familiar with most of the stuff that’s happened with the Rust community in the past few years. I’m probably going to omit concrete examples of incidents, both to avoid mischaracterizing individual actions (as with most such analyses, I wish to talk in more general terms about trends), and also just because it would take me forever to write this if I were to supply all the layers of context. If you feel something is inaccurate, please let me know.</p>

<p>This blog post is probably going to reach the eyes of non-Rust-community members. You’re welcome to read it, but please accept my apologies in advance if it doesn’t make any sense. This is something that I initially planned to circulate as a private post (writing for a general audience is <em>hard</em>), but I felt this would be more widely useful. However due to time constraints I haven’t had time to edit it to make it acceptable to a wider audience.</p>

<h2 id="the-symptoms">The symptoms</h2>

<p>Before I actually get into it, I’d like to carefully delineate <em>what</em> the problem is that I’m talking about. Or more accurately, the <em>symptoms</em> I am talking about — as I’ll explain soon I feel like these are not the actual problem but symptoms of a more general problem.</p>

<p>Basically, as time has gone by our decisionmaking process has become more and more arduous, both for community members and the teams. Folks have to deal with:</p>

<ul>
  <li>The same arguments getting brought up over and over again</li>
  <li>Accusations of bad faith</li>
  <li>Derailing</li>
  <li>Not feeling heard</li>
  <li>Just getting exhausted by all the stuff that’s going on</li>
</ul>

<p>The RFC process is the primary exhibitor of these symptoms, but semi-official consensus-building threads on <a href="https://internals.rust-lang.org">internals.rust-lang.org</a> have similar problems.</p>

<p>Aaron <a href="http://aturon.github.io/2018/05/25/listening-part-1/">has written some extremely empathetic blog posts</a> about a bunch of these problems, starting with concrete examples and ending with a takeaway of a bunch of values for us to apply as well as thoughts on what our next steps can be. I highly recommend you read them if you haven’t already.</p>

<p>Fundamentally I consider our problems to be social problems, not technical ones. In my opinion, technical solutions like changing the discussion forum format may be necessary but are not sufficient for fixing this.</p>

<h2 id="the-scaling-problem">The scaling problem</h2>

<p>I contend that all of these issues are symptoms of an underlying <em>scaling issue</em>, but also a failure of how our moderation works.</p>

<p>The scaling issue is somewhat straightforward. Such forum discussions are inherently N-to-N discussions. When you leave a comment, you’re leaving a comment for <em>everyone</em> to read and interpret, and this is hard to get right. It’s <em>much</em> easier to have one-on-one discussions because it’s easy to build a shared vocabulary and avoid misunderstandings; any misunderstandings can often be quickly detected and corrected.</p>

<p>I find that most unpleasant technical arguments stem from an unenumerated mismatch of assumptions, or sometimes what I call a mismatch of axioms (i.e. when there is fundamental conflict between core beliefs). A mismatch of assumptions, if identified, can be resolved, leading to an amicable conclusion. Mismatches of axioms are harder to resolve, however recognizing them can take most of the vitriol out of an argument, because both parties will <em>understand</em> each other, even if they don’t <em>agree</em>. In such situations the end result may leave one or both parties <em>unhappy</em>, but rarely <em>angry</em>. (It’s also not necessary that axiom mismatches leave people unhappy, embracing <a href="http://aturon.github.io/2018/06/02/listening-part-2/#pluralism-and-positive-sums">positive sum thinking</a> helps us come to mutually beneficial conclusions)</p>

<p>All of these mismatches are easy to identify in one-on-one discussions, because it’s easy to switch gears to the meta discussion for a bit.</p>

<p>One-on-one discussions are pleasant. They foster empathy.</p>

<p>N-to-N discussions are <em>not</em>. It’s harder to converge on this shared vocabulary amongst N other people. It’s harder to identify these mismatches, partly because it’s hard to switch into the meta-mode of a discussion at all, but also because there’s a lot going on. It’s harder to build empathy.</p>

<p>As we’ve grown, discussion complexity has grown quadratically, and we’re not really attempting to relinearize them.</p>

<h3 id="hanabi-and-parallel-universes">Hanabi and parallel universes</h3>

<p>I quite enjoy the game of <a href="https://en.wikipedia.org/wiki/Hanabi_(card_game)">Hanabi</a>. It’s a game of information and trust, and I find it extremely fun, especially with the right group.</p>

<p>Hanabi is a cooperative game. You can see everyone’s cards (or tiles) but your own, and information-sharing is severely restricted. The goal is to play the right cards in the right order to collectively win. The gimmick is to share additional information through the side-channel of <em>the choice of move you make</em>.</p>

<p>A very common occurrence in this game is that people start making plans in their mind. You typically have a decent understanding of what information everyone has, and you can use this to make predictions as to what everyone’s moves will be. With this in mind, you can attempt to “set up” situations where the game progresses rapidly in a short period of time. This is somewhat necessary for the game to work, but a common pitfall is for these plans to be <em>extremely</em> elaborate, leading to frustration as the game doesn’t actually play out as planned.</p>

<p>The core issue behind this is forgetting that you actually <em>can’t</em> see the entire game state, since your own cards are hidden. It’s not just <em>you</em> who has plans — everyone does! And each of those plans is incomplete since they’re missing a piece of the picture, just as you are.</p>

<p>In Hanabi it’s very easy to forget that you’re missing a piece of the picture — in competitive card games you mostly can’t see the game state since everyone else’s cards are hidden. But in Hanabi you can see <em>most</em> of the cards and it’s easy to forget that your own four cards are hidden from you.</p>

<p>So what ends up happening is that due to incomplete information, everyone is operating in their own little parallel universe, occasionally getting frustrated when it becomes clear that other players are not operating in the same universe. As long as you recognize the existence of these parallel universes beforehand you’re fine, but if you don’t you will be frustrated.</p>

<p>This is largely true of N-to-N discussions as well. Because most of what’s being said makes sense to an individual in a particular way, it’s very easy for them to forget that other people may not share your assumptions and thus may be on a different page. Every time someone leaves a comment, different people may interpret it differently, “forking” the common understanding of the state of the discussion into multiple parallel universes. Eventually there are enough parallel universes that everyone’s talking past each other.</p>

<p>One thing I often prefer doing in such cases is to have a one on one discussion with people who disagree with me — typically the shared understanding that is the end result of such discussions is super useful and can be brought back to the discussion as something that all participants interpret the same way. I’m not consistent in doing this — in the midst of a heated argument it’s easy to get too wrapped up in the argument to think about getting results and I’ve certainly had my time arguing instead of resolving — but overall whenever I’ve chosen to do this it’s been a useful policy.</p>

<p>This is a good example of how relinearization and communication can help move N-to-N discussions along. Operating in different parallel universes is kind of the <em>point</em> of Hanabi, but it’s not the point of having a technical discussion.</p>

<h2 id="the-moderation-problem">The moderation problem</h2>

<p>In a technical discussion, broadly speaking, I find that there are three kinds of comments disagreeing with you:</p>

<ul>
  <li>Constructive: Comments which disagree with you constructively. We’re glad these exist, disagreement can hurt but is necessary for us to collaboratively reach the best outcomes.</li>
  <li>Disruptive: Comments which may be written in good faith but end up being disruptive. For example, this includes people who don’t read enough of the discussion and end up rehashing the same points. It also includes taking discussions off topic. These kinds of things are problematic but not covered by the code of conduct.</li>
  <li>Abrasive: Comments which are rude/abrasive. These are covered by the code of conduct. The mod team tries to handle these.</li>
</ul>

<p>(For a long time I and <a href="http://twitter.com/aaron_turon/">Aaron</a> had a shared vocabulary of “Type A, B, C” for these, mostly because I’m often unimaginative when it comes to such things, thanks to <a href="https://github.com/mark-simulacrum">Mark</a> for coming up with, better, descriptive titles)</p>

<p>Note that while I’m talking about “disruptive” comments it’s not a judgement on the <em>intent</em> of the participants, but rather a judgement on the harm it has caused.</p>

<p>The second category – disruptive comments – are the thing we’re currently unable to handle well. They snowball pretty badly too — as more and more of these collect, more and more people get frustrated and in turn leave comments that cause further disruption. As the discussion progresses into more and more “parallel universes” it also just becomes <em>easier</em> for a comment to be disruptive.</p>

<p>The Rust moderation team operates mostly passively, we simply don’t have the scale<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup> to watch for and nip these things in the bud. Active moderation requires a degree of involvement we cannot provide. So while the best response would be to work with participants and resolve issues early as we see them crop up, we typically get pulled in at a point where some participants are already causing harm, and our response has to be more severe. It’s a bit of a catch-22: it’s not exactly our job to deal with this stuff<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote" rel="footnote">3</a></sup>, but by the time it <em>becomes</em> our job (or even, by the time we <em>notice</em>), most acceptable actions for us to take are extremely suboptimal. The problem with passive moderation is that it’s largely reactive — it’s harder to proactively nudge the discussion in the right direction when you don’t even <em>notice</em> what’s going on until it’s too late. This is largely okay for dealing with bad-faith actors (the main goal of the mod team); it’s hard to <em>prevent</em> someone from deciding to harass someone else. But for dealing with disruptive buildups, we kind of need something different.</p>

<h2 id="participation-guidelines">Participation guidelines</h2>

<p>Part of the solution here is recognizing that spaces for official discussion are <em>different</em> from community hangout spaces. Our code of conduct attempts to handle abrasive behavior, which can disrupt discussions anywhere, but the comments that can disrupt consensus building in official discussions aren’t really covered. Nor are the repercussions of code of conduct violations really <em>appropriate</em> for such disruptive comments anyway.</p>

<p>A proposal I’ve circulated in the past is to have a notion of participation guidelines. Discussions in team spaces (RFCs, pre-RFCs, discord/zulip/IRC channels during team meetings) follow a set of rules set forth by the individual teams. It might be worth having a base set of participation guidelines defined by the core team. Something like the following is a very rough strawman:</p>

<ul>
  <li>Don’t have irrelevant discussions during team meetings on Discord/IRC/Zulip</li>
  <li>Don’t take threads off topic</li>
  <li>Don’t rehash discussions</li>
</ul>

<p>We ask people to read these before participating, but also breaking these rules isn’t considered serious, it just triggers a conversation (and maybe the hiding/deletion of a comment). If someone repeatedly breaks these rules they may be asked to not participate in a given thread anymore. The primary goal here is to empower team members to better deal with disruptive comments by giving them a formalized framework. Having codified rules helps team members confidently deal with such situations without having to worry as much about drawing direct ire from affected community members.</p>

<p>A base participation guidelines document can also be a value statement, not just a set of rules but also set of values. These values can be things like:</p>

<ul>
  <li>“We explicitly value high empathy interactions”</li>
  <li>“How everyone is feeling is everyone’s business”</li>
</ul>

<p>(h/t <a href="http://twitter.com/adam_n_p/">Adam</a> for the articulate wording here)</p>

<p>Having such words written somewhere — both the high level values we expect people to hold, and the individual behaviors we expect people to exhibit (or not exhibit) — is really valuable in and of itself, even if not enforced. The value of such documents is not that everyone reads them before participating — most don’t — but they serve as a good starting point for people interested in learning how to best conduct themselves, as well as an easy place to point people to where they’re having trouble doing so.</p>

<p>On its own, I find that this is a powerful framework but may not achieve the goal of improving the situation. I recently realized that this actually couples really well with a <em>different</em> idea I’ve been talking about for quite a while now, the idea of having facilitators:</p>

<h2 id="facilitators">Facilitators</h2>

<p>A common conflict I see occurring is that in many cases it’s a team’s job to think about and opine on a technical decision, but it’s also the team’s job to shepherd the discussion for that decision. This often works out great, but it also leads to people just feeling unheard. It kinda hurts when someone who has just strongly disagreed with you goes on to summarize the state of the discussion in a way that you feel you’ve been unfairly represented. The natural response to that for most people isn’t to work with that person and try to be properly represented, it’s to just get angry, leading to less empathy over time.</p>

<p>By design, Rust team members are <em>partisan</em>. The teams exist to build well-informed, carefully crafted opinions, and present them to the community. They also exist to make final decisions based on the results of a consensusbuilding discussion, which can involve picking sides. This is fine, there is always going to be some degree of partisanship amongst decisionmakers, or decisions would not get made.</p>

<p>Having team members also facilitate discussions is somewhat at odds with all of this. Furthermore, I feel like they don’t have enough bandwidth to do this well anyway. Some teams do have a concept of “sheriffs”, but this is more of an onramp to full team membership and the role of a sheriff is largely the same as the role of a team member, just without a binding vote.</p>

<p>I feel like it would be useful to have a group of (per-team?) <em>facilitators</em> to help with this. Facilitators are people who are interested in seeing progress happening, and largely don’t have <em>much</em> of an opinion on a given discussion, or are able to set aside this opinion in the interest of moving a discussion forward. They operate largely at the meta level of the discussion. Actions they may take are:</p>

<ul>
  <li>Summarizing the discussion every now and then</li>
  <li>Calling out one sided discussions</li>
  <li>Encouraging one-on-one tangents to be discussed elsewhere (perhaps creating a space for them, like an issue)</li>
  <li>Calling out specific people to do a thing that helps move the discussion forward. For example, something like “hey @Manishearth, I noticed you’ve been vocal in <a href="https://github.com/mystor/slag">arguing that Rust should switch to whitespace-sensitive syntax</a>, could you summarize all the arguments made by people on your side?” would help.</li>
  <li>Reinforcing positive behavior</li>
  <li>Occasionally pinging participants privately to help them improve their comments</li>
  <li>Attempting to identify the root cause of a disagreement, or empowering people to work together to identify this. This one is important but tricky. I’ve often enjoyed doing it — noticing the core axiomatic disagreement at play and spelling it out is a great feeling. But I’ve also found that it’s incredibly hard to do when you’re emotionally involved, and I’ve often needed a nudge from someone else to get there.</li>
</ul>

<p>At a high level, the job of the facilitators is to:</p>

<ul>
  <li>help foster empathy between participants</li>
  <li>help linearize complex discussions</li>
  <li>nudge towards cooperative behavior, away from adversarial behavior. Get people playing not to win, but to win-win.</li>
</ul>

<p>It’s important to note that facilitators don’t make decisions — the team does. In fact, they almost completely avoid making technical points, they instead keep their comments largely at the meta level, perhaps occasionally making factual corrections.</p>

<p>The teams <em>could</em> do most of this themselves<sup id="fnref:5" role="doc-noteref"><a href="#fn:5" class="footnote" rel="footnote">4</a></sup>, but as I’ve mentioned before it’s harder for others to not perceive all of your actions as partisan when some of them are. Furthermore, it can come off as patronizing at times.</p>

<p>This is also something the moderation team could do, however it’s <em>much</em> harder to scale the moderation team this way. Given that the moderation team deals with harassment and stuff like that, we need to be careful about how we build it up. On the other hand facilitating discussions is largely a public task, and the stakes aren’t as high: screwups can get noticed, and they don’t cause much harm. As a fundamentally <em>proactive</em> moderation effort, most actions taken will be to nudge things in a positive direction; getting this wrong usually just means that the status quo is maintained, not that harm is caused. Also, from talking to people it seems that while very few people want to be involved in moderating Rust, this notion of <em>facilitating</em> sounds much more fun and rewarding (I’d love to hear from people who would like to help).</p>

<p>And to me, this pairs really well with the idea of participation guidelines: teams can write down how they want discussions to take place on their venues, and facilitators can help ensure this works out. It’s good to look at the participation guidelines less as a set of rules and more as an aspiration for how we conduct ourselves, with the facilitators as a means to achieving that goal.</p>

<p>There are a lot of specifics we can twiddle with this proposal. For example, we can have a per-team group of appointed facilitators (with no overlap with the team), and for a given discussion one facilitator is picked (if they don’t have time or feel like they have strong opinions, try someone else). But there’s also no strong need for there to be such a group, facilitators can be picked as a discussion is starting, too. I don’t expect <em>most</em> discussions to need facilitators, so this is mostly reserved for discussions we expect will get heated, or discussions that have started to get heated. I’m not really going to spend time analysing these specifics; I have opinions but I’d rather have us figure out if we want to do something like this and how before getting into the weeds.</p>

<h2 id="prospective-outcomes">Prospective outcomes</h2>

<p>The real goal here is to bootstrap better empathy within the community. In an ideal world we don’t need facilitators, instead everyone is able to facilitate well. The explicitly non-partisan nature of facilitators is <em>useful</em>, but if everyone was able to operate in this manner it would largely be unnecessary. But as with any organization, being able to horizontally scale specific skills is really tricky without specialization.</p>

<p>I suspect that in the process of building up such a team of facilitators, we will also end up building a set of resources that can help others learn to act the same way, and eventually overall improve how empathetic our community is.</p>

<p>The concept of facilitators directly addresses the moderation problem, but it also handles the scaling problem pretty well! Facilitators are key in re-linearizing the n-to-n discussions, bringing the “parallel universes” together again. This should overall help people (especially team members) who are feeling overwhelmed by all the things that are going on.</p>

<p>This also helps with concerns people have that they’re not getting heard, as facilitators are basically posed as allies on all sides of the argument; people whose primary goal is to <em>help communication happen</em>.</p>

<hr />

<p>Overall what I’ve proposed here isn’t a fully-formed idea; but it’s the seed of one. There are a lot of interesting bits to discuss and build upon. I’m hoping through this post we might push forward some of the discussions about governance — both by providing a strawman idea, as well as by providing a perspective on the problem that I hope is useful.</p>

<p>I’m really interested to hear what people think!</p>

<p><em>Thanks to <a href="http://twitter.com/aaron_turon/">Aaron</a>, <a href="https://twitter.com/ag_dubs">Ashley</a>, <a href="http://twitter.com/adam_n_p/">Adam</a>, <a href="https://twitter.com/ember_arlynx">Ember</a>, <a href="http://twitter.com/arshia__">Arshia</a>, <a href="https://twitter.com/mgattozzi">Michael</a>, <a href="https://twitter.com/sunjay03">Sunjay</a>, <a href="http://twitter.com/fitzgen/">Nick</a> and other people I’ve probably forgotten for having been part of these discussions with me over the last few years, helping me refine my thoughts</em></p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>I am way too verbose for “brief” to be an accurate description of anything I write, but might as well <em>try</em>. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>Scaling the moderation team properly is another piece of this puzzle that I’m working on; we’ve made some progress recently. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>I helped draft <a href="https://www.rust-lang.org/policies/code-of-conduct#moderation">our moderation policy</a>, so this is a somewhat a lack of foresight on my part, but as I’ll explain later it’s suboptimal for the mod team to be dealing with this anyway. <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:5" role="doc-endnote">
      <p>In particular, I feel like Aaron has done an <em>excellent</em> and consistent job of facilitating discussions this way in many cases. <a href="#fnref:5" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name>Manish Goregaokar</name></author><category term="rust" /><category term="programming" /><summary type="html"><![CDATA[There’s been a lot of talk about improving Rust’s governance model lately. As we decompress from last year’s hectic edition work, we’re slowly starting to look at all the bits of debt we accumulated, and organizational debt is high on that list. I’ve been talking in private with people about a bunch of these things for quite a while now, and I felt it worthwhile to write down as much of my thoughts as I can before the Rust All Hands in Berlin this week. In the interest of brevity1 I’m going to assume the reader is roughly familiar with most of the stuff that’s happened with the Rust community in the past few years. I’m probably going to omit concrete examples of incidents, both to avoid mischaracterizing individual actions (as with most such analyses, I wish to talk in more general terms about trends), and also just because it would take me forever to write this if I were to supply all the layers of context. If you feel something is inaccurate, please let me know. This blog post is probably going to reach the eyes of non-Rust-community members. You’re welcome to read it, but please accept my apologies in advance if it doesn’t make any sense. This is something that I initially planned to circulate as a private post (writing for a general audience is hard), but I felt this would be more widely useful. However due to time constraints I haven’t had time to edit it to make it acceptable to a wider audience. The symptoms Before I actually get into it, I’d like to carefully delineate what the problem is that I’m talking about. Or more accurately, the symptoms I am talking about — as I’ll explain soon I feel like these are not the actual problem but symptoms of a more general problem. Basically, as time has gone by our decisionmaking process has become more and more arduous, both for community members and the teams. Folks have to deal with: The same arguments getting brought up over and over again Accusations of bad faith Derailing Not feeling heard Just getting exhausted by all the stuff that’s going on The RFC process is the primary exhibitor of these symptoms, but semi-official consensus-building threads on internals.rust-lang.org have similar problems. Aaron has written some extremely empathetic blog posts about a bunch of these problems, starting with concrete examples and ending with a takeaway of a bunch of values for us to apply as well as thoughts on what our next steps can be. I highly recommend you read them if you haven’t already. Fundamentally I consider our problems to be social problems, not technical ones. In my opinion, technical solutions like changing the discussion forum format may be necessary but are not sufficient for fixing this. The scaling problem I contend that all of these issues are symptoms of an underlying scaling issue, but also a failure of how our moderation works. The scaling issue is somewhat straightforward. Such forum discussions are inherently N-to-N discussions. When you leave a comment, you’re leaving a comment for everyone to read and interpret, and this is hard to get right. It’s much easier to have one-on-one discussions because it’s easy to build a shared vocabulary and avoid misunderstandings; any misunderstandings can often be quickly detected and corrected. I find that most unpleasant technical arguments stem from an unenumerated mismatch of assumptions, or sometimes what I call a mismatch of axioms (i.e. when there is fundamental conflict between core beliefs). A mismatch of assumptions, if identified, can be resolved, leading to an amicable conclusion. Mismatches of axioms are harder to resolve, however recognizing them can take most of the vitriol out of an argument, because both parties will understand each other, even if they don’t agree. In such situations the end result may leave one or both parties unhappy, but rarely angry. (It’s also not necessary that axiom mismatches leave people unhappy, embracing positive sum thinking helps us come to mutually beneficial conclusions) All of these mismatches are easy to identify in one-on-one discussions, because it’s easy to switch gears to the meta discussion for a bit. One-on-one discussions are pleasant. They foster empathy. N-to-N discussions are not. It’s harder to converge on this shared vocabulary amongst N other people. It’s harder to identify these mismatches, partly because it’s hard to switch into the meta-mode of a discussion at all, but also because there’s a lot going on. It’s harder to build empathy. As we’ve grown, discussion complexity has grown quadratically, and we’re not really attempting to relinearize them. Hanabi and parallel universes I quite enjoy the game of Hanabi. It’s a game of information and trust, and I find it extremely fun, especially with the right group. Hanabi is a cooperative game. You can see everyone’s cards (or tiles) but your own, and information-sharing is severely restricted. The goal is to play the right cards in the right order to collectively win. The gimmick is to share additional information through the side-channel of the choice of move you make. A very common occurrence in this game is that people start making plans in their mind. You typically have a decent understanding of what information everyone has, and you can use this to make predictions as to what everyone’s moves will be. With this in mind, you can attempt to “set up” situations where the game progresses rapidly in a short period of time. This is somewhat necessary for the game to work, but a common pitfall is for these plans to be extremely elaborate, leading to frustration as the game doesn’t actually play out as planned. The core issue behind this is forgetting that you actually can’t see the entire game state, since your own cards are hidden. It’s not just you who has plans — everyone does! And each of those plans is incomplete since they’re missing a piece of the picture, just as you are. In Hanabi it’s very easy to forget that you’re missing a piece of the picture — in competitive card games you mostly can’t see the game state since everyone else’s cards are hidden. But in Hanabi you can see most of the cards and it’s easy to forget that your own four cards are hidden from you. So what ends up happening is that due to incomplete information, everyone is operating in their own little parallel universe, occasionally getting frustrated when it becomes clear that other players are not operating in the same universe. As long as you recognize the existence of these parallel universes beforehand you’re fine, but if you don’t you will be frustrated. This is largely true of N-to-N discussions as well. Because most of what’s being said makes sense to an individual in a particular way, it’s very easy for them to forget that other people may not share your assumptions and thus may be on a different page. Every time someone leaves a comment, different people may interpret it differently, “forking” the common understanding of the state of the discussion into multiple parallel universes. Eventually there are enough parallel universes that everyone’s talking past each other. One thing I often prefer doing in such cases is to have a one on one discussion with people who disagree with me — typically the shared understanding that is the end result of such discussions is super useful and can be brought back to the discussion as something that all participants interpret the same way. I’m not consistent in doing this — in the midst of a heated argument it’s easy to get too wrapped up in the argument to think about getting results and I’ve certainly had my time arguing instead of resolving — but overall whenever I’ve chosen to do this it’s been a useful policy. This is a good example of how relinearization and communication can help move N-to-N discussions along. Operating in different parallel universes is kind of the point of Hanabi, but it’s not the point of having a technical discussion. The moderation problem In a technical discussion, broadly speaking, I find that there are three kinds of comments disagreeing with you: Constructive: Comments which disagree with you constructively. We’re glad these exist, disagreement can hurt but is necessary for us to collaboratively reach the best outcomes. Disruptive: Comments which may be written in good faith but end up being disruptive. For example, this includes people who don’t read enough of the discussion and end up rehashing the same points. It also includes taking discussions off topic. These kinds of things are problematic but not covered by the code of conduct. Abrasive: Comments which are rude/abrasive. These are covered by the code of conduct. The mod team tries to handle these. (For a long time I and Aaron had a shared vocabulary of “Type A, B, C” for these, mostly because I’m often unimaginative when it comes to such things, thanks to Mark for coming up with, better, descriptive titles) Note that while I’m talking about “disruptive” comments it’s not a judgement on the intent of the participants, but rather a judgement on the harm it has caused. The second category – disruptive comments – are the thing we’re currently unable to handle well. They snowball pretty badly too — as more and more of these collect, more and more people get frustrated and in turn leave comments that cause further disruption. As the discussion progresses into more and more “parallel universes” it also just becomes easier for a comment to be disruptive. The Rust moderation team operates mostly passively, we simply don’t have the scale2 to watch for and nip these things in the bud. Active moderation requires a degree of involvement we cannot provide. So while the best response would be to work with participants and resolve issues early as we see them crop up, we typically get pulled in at a point where some participants are already causing harm, and our response has to be more severe. It’s a bit of a catch-22: it’s not exactly our job to deal with this stuff3, but by the time it becomes our job (or even, by the time we notice), most acceptable actions for us to take are extremely suboptimal. The problem with passive moderation is that it’s largely reactive — it’s harder to proactively nudge the discussion in the right direction when you don’t even notice what’s going on until it’s too late. This is largely okay for dealing with bad-faith actors (the main goal of the mod team); it’s hard to prevent someone from deciding to harass someone else. But for dealing with disruptive buildups, we kind of need something different. Participation guidelines Part of the solution here is recognizing that spaces for official discussion are different from community hangout spaces. Our code of conduct attempts to handle abrasive behavior, which can disrupt discussions anywhere, but the comments that can disrupt consensus building in official discussions aren’t really covered. Nor are the repercussions of code of conduct violations really appropriate for such disruptive comments anyway. A proposal I’ve circulated in the past is to have a notion of participation guidelines. Discussions in team spaces (RFCs, pre-RFCs, discord/zulip/IRC channels during team meetings) follow a set of rules set forth by the individual teams. It might be worth having a base set of participation guidelines defined by the core team. Something like the following is a very rough strawman: Don’t have irrelevant discussions during team meetings on Discord/IRC/Zulip Don’t take threads off topic Don’t rehash discussions We ask people to read these before participating, but also breaking these rules isn’t considered serious, it just triggers a conversation (and maybe the hiding/deletion of a comment). If someone repeatedly breaks these rules they may be asked to not participate in a given thread anymore. The primary goal here is to empower team members to better deal with disruptive comments by giving them a formalized framework. Having codified rules helps team members confidently deal with such situations without having to worry as much about drawing direct ire from affected community members. A base participation guidelines document can also be a value statement, not just a set of rules but also set of values. These values can be things like: “We explicitly value high empathy interactions” “How everyone is feeling is everyone’s business” (h/t Adam for the articulate wording here) Having such words written somewhere — both the high level values we expect people to hold, and the individual behaviors we expect people to exhibit (or not exhibit) — is really valuable in and of itself, even if not enforced. The value of such documents is not that everyone reads them before participating — most don’t — but they serve as a good starting point for people interested in learning how to best conduct themselves, as well as an easy place to point people to where they’re having trouble doing so. On its own, I find that this is a powerful framework but may not achieve the goal of improving the situation. I recently realized that this actually couples really well with a different idea I’ve been talking about for quite a while now, the idea of having facilitators: Facilitators A common conflict I see occurring is that in many cases it’s a team’s job to think about and opine on a technical decision, but it’s also the team’s job to shepherd the discussion for that decision. This often works out great, but it also leads to people just feeling unheard. It kinda hurts when someone who has just strongly disagreed with you goes on to summarize the state of the discussion in a way that you feel you’ve been unfairly represented. The natural response to that for most people isn’t to work with that person and try to be properly represented, it’s to just get angry, leading to less empathy over time. By design, Rust team members are partisan. The teams exist to build well-informed, carefully crafted opinions, and present them to the community. They also exist to make final decisions based on the results of a consensusbuilding discussion, which can involve picking sides. This is fine, there is always going to be some degree of partisanship amongst decisionmakers, or decisions would not get made. Having team members also facilitate discussions is somewhat at odds with all of this. Furthermore, I feel like they don’t have enough bandwidth to do this well anyway. Some teams do have a concept of “sheriffs”, but this is more of an onramp to full team membership and the role of a sheriff is largely the same as the role of a team member, just without a binding vote. I feel like it would be useful to have a group of (per-team?) facilitators to help with this. Facilitators are people who are interested in seeing progress happening, and largely don’t have much of an opinion on a given discussion, or are able to set aside this opinion in the interest of moving a discussion forward. They operate largely at the meta level of the discussion. Actions they may take are: Summarizing the discussion every now and then Calling out one sided discussions Encouraging one-on-one tangents to be discussed elsewhere (perhaps creating a space for them, like an issue) Calling out specific people to do a thing that helps move the discussion forward. For example, something like “hey @Manishearth, I noticed you’ve been vocal in arguing that Rust should switch to whitespace-sensitive syntax, could you summarize all the arguments made by people on your side?” would help. Reinforcing positive behavior Occasionally pinging participants privately to help them improve their comments Attempting to identify the root cause of a disagreement, or empowering people to work together to identify this. This one is important but tricky. I’ve often enjoyed doing it — noticing the core axiomatic disagreement at play and spelling it out is a great feeling. But I’ve also found that it’s incredibly hard to do when you’re emotionally involved, and I’ve often needed a nudge from someone else to get there. At a high level, the job of the facilitators is to: help foster empathy between participants help linearize complex discussions nudge towards cooperative behavior, away from adversarial behavior. Get people playing not to win, but to win-win. It’s important to note that facilitators don’t make decisions — the team does. In fact, they almost completely avoid making technical points, they instead keep their comments largely at the meta level, perhaps occasionally making factual corrections. The teams could do most of this themselves4, but as I’ve mentioned before it’s harder for others to not perceive all of your actions as partisan when some of them are. Furthermore, it can come off as patronizing at times. This is also something the moderation team could do, however it’s much harder to scale the moderation team this way. Given that the moderation team deals with harassment and stuff like that, we need to be careful about how we build it up. On the other hand facilitating discussions is largely a public task, and the stakes aren’t as high: screwups can get noticed, and they don’t cause much harm. As a fundamentally proactive moderation effort, most actions taken will be to nudge things in a positive direction; getting this wrong usually just means that the status quo is maintained, not that harm is caused. Also, from talking to people it seems that while very few people want to be involved in moderating Rust, this notion of facilitating sounds much more fun and rewarding (I’d love to hear from people who would like to help). And to me, this pairs really well with the idea of participation guidelines: teams can write down how they want discussions to take place on their venues, and facilitators can help ensure this works out. It’s good to look at the participation guidelines less as a set of rules and more as an aspiration for how we conduct ourselves, with the facilitators as a means to achieving that goal. There are a lot of specifics we can twiddle with this proposal. For example, we can have a per-team group of appointed facilitators (with no overlap with the team), and for a given discussion one facilitator is picked (if they don’t have time or feel like they have strong opinions, try someone else). But there’s also no strong need for there to be such a group, facilitators can be picked as a discussion is starting, too. I don’t expect most discussions to need facilitators, so this is mostly reserved for discussions we expect will get heated, or discussions that have started to get heated. I’m not really going to spend time analysing these specifics; I have opinions but I’d rather have us figure out if we want to do something like this and how before getting into the weeds. Prospective outcomes The real goal here is to bootstrap better empathy within the community. In an ideal world we don’t need facilitators, instead everyone is able to facilitate well. The explicitly non-partisan nature of facilitators is useful, but if everyone was able to operate in this manner it would largely be unnecessary. But as with any organization, being able to horizontally scale specific skills is really tricky without specialization. I suspect that in the process of building up such a team of facilitators, we will also end up building a set of resources that can help others learn to act the same way, and eventually overall improve how empathetic our community is. The concept of facilitators directly addresses the moderation problem, but it also handles the scaling problem pretty well! Facilitators are key in re-linearizing the n-to-n discussions, bringing the “parallel universes” together again. This should overall help people (especially team members) who are feeling overwhelmed by all the things that are going on. This also helps with concerns people have that they’re not getting heard, as facilitators are basically posed as allies on all sides of the argument; people whose primary goal is to help communication happen. Overall what I’ve proposed here isn’t a fully-formed idea; but it’s the seed of one. There are a lot of interesting bits to discuss and build upon. I’m hoping through this post we might push forward some of the discussions about governance — both by providing a strawman idea, as well as by providing a perspective on the problem that I hope is useful. I’m really interested to hear what people think! Thanks to Aaron, Ashley, Adam, Ember, Arshia, Michael, Sunjay, Nick and other people I’ve probably forgotten for having been part of these discussions with me over the last few years, helping me refine my thoughts I am way too verbose for “brief” to be an accurate description of anything I write, but might as well try. &#8617; Scaling the moderation team properly is another piece of this puzzle that I’m working on; we’ve made some progress recently. &#8617; I helped draft our moderation policy, so this is a somewhat a lack of foresight on my part, but as I’ll explain later it’s suboptimal for the mod team to be dealing with this anyway. &#8617; In particular, I feel like Aaron has done an excellent and consistent job of facilitating discussions this way in many cases. &#8617;]]></summary></entry><entry><title type="html">Converting a WebGL application to WebVR</title><link href="http://manishearth.github.io/blog/2018/09/11/converting-a-webgl-application-to-webvr/" rel="alternate" type="text/html" title="Converting a WebGL application to WebVR" /><published>2018-09-11T00:00:00+00:00</published><updated>2018-09-11T00:00:00+00:00</updated><id>http://manishearth.github.io/blog/2018/09/11/converting-a-webgl-application-to-webvr</id><content type="html" xml:base="http://manishearth.github.io/blog/2018/09/11/converting-a-webgl-application-to-webvr/"><![CDATA[<p>I wrote a post for Mozilla Hacks on converting WebGL applications to WebVR,
<a href="https://hacks.mozilla.org/2018/09/converting-a-webgl-application-to-webvr/">you can read it there</a></p>]]></content><author><name>Manish Goregaokar</name></author><category term="programming" /><category term="web" /><category term="js" /><summary type="html"><![CDATA[I wrote a post for Mozilla Hacks on converting WebGL applications to WebVR, you can read it there]]></summary></entry><entry><title type="html">Why I enjoy blogging</title><link href="http://manishearth.github.io/blog/2018/08/26/why-i-enjoy-blogging/" rel="alternate" type="text/html" title="Why I enjoy blogging" /><published>2018-08-26T00:00:00+00:00</published><updated>2018-08-26T00:00:00+00:00</updated><id>http://manishearth.github.io/blog/2018/08/26/why-i-enjoy-blogging</id><content type="html" xml:base="http://manishearth.github.io/blog/2018/08/26/why-i-enjoy-blogging/"><![CDATA[<p><em>See also: <a href="https://myrrlyn.net/blog/misc/to-all-the-posts-ive-blogged-before">Alex’s version of this blog post</a></em></p>

<p>I started this blog three years ago, moving from my <a href="http://inpursuitoflaziness.blogspot.com/">older blog</a>, hoping to written about programming, math, physics, books, and miscellenia. I’ve not quite written about everything I wanted to, but I’ve been very very happy with the experience of blogging. <code class="language-plaintext highlighter-rouge">wc</code> says I’ve written almost 75k words, which is mind-boggling to me!</p>

<p>I often get asked by others — usually trying to decide if they should start blogging — what it’s like. I also often try to convince friends to blog by enumerating why I think it’s awesome. Might as well write it down so that it’s generally useful for everyone! 😃</p>

<h2 id="blogging-helps-cement-my-understanding-of-things">Blogging helps cement my understanding of things!</h2>

<p>I’ve often noticed that I’ll start blogging about something I <em>think</em> I understand, and it turns out that my understanding of the subject was somewhat nebulous. Turns out it’s pretty easy to convince ourselves that we understand something.</p>

<p>The act of writing stuff down helps cement my own understanding — words are usually not as nebulous as thoughts so I’m forced to figure out little details.</p>

<p>I recall when I wrote my post on <a href="https://manishearth.github.io/blog/2015/05/30/how-rust-achieves-thread-safety/">how Rust’s thread safety guarantees work</a>, I <em>thought</em> I understood <code class="language-plaintext highlighter-rouge">Send</code> and <code class="language-plaintext highlighter-rouge">Sync</code> in Rust. I understood what they did, but I didn’t have a clear mental model for them. I obtained this mental model through the process of writing the post; to be able to explain it to others I had to first explain it to myself.</p>

<p>I point out this post in particular because this was both one of the first posts for me where I’d noticed this, and, more importantly, my more concrete mental model led to me <a href="https://github.com/rust-lang/rust/issues/25894">finding a soundness bug in Rust’s standard library</a>. When I was thinking about my mental model I realized “an impl that looks like this should never exist”,
so I grepped the source code and found one<sup id="fnref:11" role="doc-noteref"><a href="#fn:11" class="footnote" rel="footnote">1</a></sup>.</p>

<p>I’ve even noticed a difference between one-on-one explaining and explaining things through blog posts. I <em>love</em> explaining things one-on-one, it’s much easier to tailor the explanation to the other person’s background,
as well as what they’re actually asking for help with. Plus, it’s interactive. A <em>lot</em> of my posts are of the “okay I get this question a lot I’m going to write down the answer so I don’t have to repeat myself” kind and I’ve found that I’ve often learned things from these despite having talked about the thing in the article contents multiple times.</p>

<p>I guess it’s basically that blogging is inherently one-many — you’re trying to explain to a whole group of people with varied backgrounds — which means you need to cover all your bases<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote" rel="footnote">2</a></sup> and explain everything together instead of the minimum necessary.</p>

<h2 id="its-really-fun-to-revisit-old-posts">It’s really fun to revisit old posts!</h2>

<p>Okay, I’ll admit that I never really write blog posts with this in mind. But when I <em>do</em> reread them, I’m usually quite thankful I wrote them!</p>

<p>I’m a fan of rereading in general, I’ve reread most of my favorite books tens of times; I make a yearly pilgrimage to <a href="https://mickens.seas.harvard.edu/wisdom-james-mickens">James Mickens’ website</a>; I reread many of my favorite posts and articles on the internet; and I often reread my <em>own</em> posts from the past.</p>

<p>Sometimes I’ll do it because I want a refresher in a topic. Sometimes I’ll do it because I’m bored. Whatever the reason, it’s always been a useful and fun thing to do.</p>

<p>Rereading old posts is a great way to transport myself back to my mindset from when I wrote the post. It’s easy to see progress in my understanding of things as well as in my writing. It’s interesting to note what I thought super important to include in the post <em>then</em> that I consider totally obvious <em>now</em><sup id="fnref:5" role="doc-noteref"><a href="#fn:5" class="footnote" rel="footnote">3</a></sup>. It’s interesting to relearn what I’ve forgotten. It’s reassuring to realize that my terrible jokes were just as terrible as they are now.</p>

<p>One of my favorite posts to reread is <a href="https://manishearth.github.io/blog/2016/03/05/exploring-zero-knowledge-proofs/">this really long one on generalized zero knowledge proofs</a>. It’s the longest post I’ve written so far<sup id="fnref:6" role="doc-noteref"><a href="#fn:6" class="footnote" rel="footnote">4</a></sup>, and it’s on a topic I don’t deal with often — cryptography. Not only does it help put me back in a mindset for thinking about cryptography, it’s about something super interesting but also complicated enough that rereading the post is like learning it all over again.</p>

<h2 id="it-lets-me-exercise-a-different-headspace">It lets me exercise a different headspace!</h2>

<p>I like programming a lot, but if programming was <em>all</em> I did, I’d get tired pretty quickly. When I was a student learning physics I’d often contribute to open source in my spare time, but now I write code full time so I’m less inclined to do it in my free time<sup id="fnref:8" role="doc-noteref"><a href="#fn:8" class="footnote" rel="footnote">5</a></sup>.</p>

<p>But I still sometimes feel like doing programmery things in my spare time just … not programming.</p>

<p>Turns out that blogging doesn’t tire me out the same way! I’m sure that if I spent the whole day writing I’d not want to write when I go home, but I don’t spend the whole day writing, so it’s all good. It’s refreshing to sit down to write a blog post and discover a fresh reserve of energy. I’m not sure if this is the right term, but I usually call this “using a different headspace”.</p>

<p>I’ve also started using this to plan my work, I mix up the kinds of headspace I’m employing for various tasks so that I feel energetic throughout the day.</p>

<p>This is also why I really enjoy mentoring — mentoring often requires the same effort from me as fixing it myself, but it’s a different headspace I’m employing so it’s less tiring.</p>

<h2 id="blogging-lets-me-be-lazy">Blogging lets me be lazy!</h2>

<p>I often find myself explaining things often. I like helping folks and explaining things, but I’m also lazy<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">6</a></sup>, so writing stuff down really makes stuff easy for me! If folks ask me a question I can give a quick answer and then go “if you want to learn more, I’ve written about it here!”. If folks are asking a question a lot, there’s probably something missing in the documentation or learning materials about it. Some things can be fixed upstream in documentation, but other things — like <a href="https://manishearth.github.io/blog/2017/05/14/mentally-modelling-modules/">“how should I reason about modules in Rust?”</a> deserve to be tackled as a separate problem and addressed with their own post.</p>

<p>(Yes, this post is in this category!)</p>

<h2 id="its-okay-if-folks-have-written-about-it-before">It’s okay if folks have written about it before!</h2>

<p>A common question I’ve gotten is “Well I can write about X but … there are a lot of other posts out there about it, should I still?”</p>

<p>Yes!!</p>

<p>People think differently, people learn differently, and people come from different backgrounds. Existing posts may be useful for some folks but less useful for others.</p>

<p>My personal rule of thumb is that if it took <em>me</em> some effort to understand something after reading about it, that’s something worth writing about, so it’s easier to understand for others like me encountering the subject.</p>

<p>One of my favorite bloggers, <a href="https://jvns.ca/">Julia Evans</a> very often writes posts explaining computer concepts. Most of the times these have been explained before in other blog posts or manuals. But that doesn’t matter — her posts are <em>different</em>, and they’re <em>amazing</em>. They’re upbeat, fun to read, and often get me excited to learn more about things I knew about but never really looked at closely before.</p>

<h2 id="i-kinda-feel-its-my-duty-to">I kinda feel it’s my duty to?</h2>

<p>There’s a quote by Toni Morrison I quite enjoy:</p>

<blockquote>
  <p>I tell my students, ‘When you get these jobs that you have been so brilliantly trained for, just remember that your real job is that if you are free, you need to free somebody else. If you have some power, then your job is to empower somebody else. This is not just a grab-bag candy game.</p>
</blockquote>

<p>I enjoy it so much I <a href="https://manishearth.github.io/rustfest-slides/#/13">concluded my talk at RustFest Kyiv with it</a>!</p>

<p>I have the privilege of having time to do things like blogging and mentoring. Given that, I feel that it really is my duty to share what I know as much as possible; to help others attempting to tread the path I’m treading; and to battle against tribal knowledge.</p>

<p>When it comes to programming I’m mostly “self-taught”. But when I say that, I really mean that I wasn’t taught in a traditional way by other humans — I learned things by trying stuff out and <em>reading what others had written</em>. I didn’t learn Rust by taking <code class="language-plaintext highlighter-rouge">rustc</code> and pretending to be a fuzzer and just trying random nonsense till stuff made sense, I went through the tutorial (and <em>then</em> started exploring by trying random stuff). I didn’t figure out cool algorithms by discovering them from first principles, I picked them up from books and blog posts. I’m “self-taught” because I’ve been in charge of my learning process, but I’ve definitely relied on the work of other people throughout this process.</p>

<p>This means that for me, personally, knowledge-sharing is especially important. If I had to spend time figuring something out, I should make it easier for the next people to try<sup id="fnref:10" role="doc-noteref"><a href="#fn:10" class="footnote" rel="footnote">7</a></sup>.</p>

<p>(All this said, I probably don’t blog as much as I <em>should</em>)</p>

<h2 id="you-should-blog-too">You should blog too!</h2>

<p>I wish everyone wrote more. I know not everyone has the time/privilege to do this, but if you do, I urge you to start!</p>

<p>I feel like tips on <em>how</em> to blog would fill up an entire other blog post, but Julia Evans has <a href="https://jvns.ca/blog/2016/05/22/how-do-you-write-blog-posts//">multiple</a> <a href="https://jvns.ca/blog/2017/03/20/blogging-principles/">posts</a> on this that I strongly recommend. Feel free to ask me for review on posts!</p>

<p>As for the technicalities of setting up a blog, my colleague Emily recently <a href="https://www.emilykager.com/writing/2018/07/27/myo-website.html">wrote a great post about doing this with Jekyll</a>. This blog uses <a href="http://octopress.org">Octopress</a> which is similar to set up.</p>

<p><em>Thanks to <a href="https://twitter.com/arshia__">Arshia</a>, <a href="https://twitter.com/QuietMisdreavus">QuietMisdreavus</a>, and <a href="https://twitter.com/myrrlyn">Alex</a> for reviewing drafts of this blog post.</em></p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:11" role="doc-endnote">
      <p>Who needs to <a href="https://www.ralfj.de/blog/2017/06/09/mutexguard-sync.html">look for unsoundness with rigorous formal verification</a> when you have <code class="language-plaintext highlighter-rouge">grep</code>? <a href="#fnref:11" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>Incidentally, I find there’s a similar dynamic when it comes to forum discussions vs hashing things out one-on-one, it’s way harder to get anywhere with forum discussions because they’re one-many and you have to put in that much more work to empathize with everyone else and also phrase things in a way that is resilient to accidental misinterpretation. <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:5" role="doc-endnote">
      <p>This is especially important as I get more and more “used” to subjects I’m familiar with – it’s easy to lose the ability to explain things when I think half of it is obvious. <a href="#fnref:5" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:6" role="doc-endnote">
      <p>This is probably the <em>real</em> reason I love rereading it — I like being verbose and would nest parentheses and footnotes if society let me <a href="#fnref:6" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:8" role="doc-endnote">
      <p>I also am in general less inclined to do technical things in my free time and have a better work-life balance, glad that worked out! <a href="#fnref:8" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:1" role="doc-endnote">
      <p>See blog title <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:10" role="doc-endnote">
      <p>One of my former title ideas for this post was “Knowledge is Theft”, riffing off of this concept, but I felt that was a bit too tongue-in-cheek. <a href="#fnref:10" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name>Manish Goregaokar</name></author><category term="writing" /><category term="programming" /><category term="meta" /><summary type="html"><![CDATA[See also: Alex’s version of this blog post I started this blog three years ago, moving from my older blog, hoping to written about programming, math, physics, books, and miscellenia. I’ve not quite written about everything I wanted to, but I’ve been very very happy with the experience of blogging. wc says I’ve written almost 75k words, which is mind-boggling to me! I often get asked by others — usually trying to decide if they should start blogging — what it’s like. I also often try to convince friends to blog by enumerating why I think it’s awesome. Might as well write it down so that it’s generally useful for everyone! 😃 Blogging helps cement my understanding of things! I’ve often noticed that I’ll start blogging about something I think I understand, and it turns out that my understanding of the subject was somewhat nebulous. Turns out it’s pretty easy to convince ourselves that we understand something. The act of writing stuff down helps cement my own understanding — words are usually not as nebulous as thoughts so I’m forced to figure out little details. I recall when I wrote my post on how Rust’s thread safety guarantees work, I thought I understood Send and Sync in Rust. I understood what they did, but I didn’t have a clear mental model for them. I obtained this mental model through the process of writing the post; to be able to explain it to others I had to first explain it to myself. I point out this post in particular because this was both one of the first posts for me where I’d noticed this, and, more importantly, my more concrete mental model led to me finding a soundness bug in Rust’s standard library. When I was thinking about my mental model I realized “an impl that looks like this should never exist”, so I grepped the source code and found one1. I’ve even noticed a difference between one-on-one explaining and explaining things through blog posts. I love explaining things one-on-one, it’s much easier to tailor the explanation to the other person’s background, as well as what they’re actually asking for help with. Plus, it’s interactive. A lot of my posts are of the “okay I get this question a lot I’m going to write down the answer so I don’t have to repeat myself” kind and I’ve found that I’ve often learned things from these despite having talked about the thing in the article contents multiple times. I guess it’s basically that blogging is inherently one-many — you’re trying to explain to a whole group of people with varied backgrounds — which means you need to cover all your bases2 and explain everything together instead of the minimum necessary. It’s really fun to revisit old posts! Okay, I’ll admit that I never really write blog posts with this in mind. But when I do reread them, I’m usually quite thankful I wrote them! I’m a fan of rereading in general, I’ve reread most of my favorite books tens of times; I make a yearly pilgrimage to James Mickens’ website; I reread many of my favorite posts and articles on the internet; and I often reread my own posts from the past. Sometimes I’ll do it because I want a refresher in a topic. Sometimes I’ll do it because I’m bored. Whatever the reason, it’s always been a useful and fun thing to do. Rereading old posts is a great way to transport myself back to my mindset from when I wrote the post. It’s easy to see progress in my understanding of things as well as in my writing. It’s interesting to note what I thought super important to include in the post then that I consider totally obvious now3. It’s interesting to relearn what I’ve forgotten. It’s reassuring to realize that my terrible jokes were just as terrible as they are now. One of my favorite posts to reread is this really long one on generalized zero knowledge proofs. It’s the longest post I’ve written so far4, and it’s on a topic I don’t deal with often — cryptography. Not only does it help put me back in a mindset for thinking about cryptography, it’s about something super interesting but also complicated enough that rereading the post is like learning it all over again. It lets me exercise a different headspace! I like programming a lot, but if programming was all I did, I’d get tired pretty quickly. When I was a student learning physics I’d often contribute to open source in my spare time, but now I write code full time so I’m less inclined to do it in my free time5. But I still sometimes feel like doing programmery things in my spare time just … not programming. Turns out that blogging doesn’t tire me out the same way! I’m sure that if I spent the whole day writing I’d not want to write when I go home, but I don’t spend the whole day writing, so it’s all good. It’s refreshing to sit down to write a blog post and discover a fresh reserve of energy. I’m not sure if this is the right term, but I usually call this “using a different headspace”. I’ve also started using this to plan my work, I mix up the kinds of headspace I’m employing for various tasks so that I feel energetic throughout the day. This is also why I really enjoy mentoring — mentoring often requires the same effort from me as fixing it myself, but it’s a different headspace I’m employing so it’s less tiring. Blogging lets me be lazy! I often find myself explaining things often. I like helping folks and explaining things, but I’m also lazy6, so writing stuff down really makes stuff easy for me! If folks ask me a question I can give a quick answer and then go “if you want to learn more, I’ve written about it here!”. If folks are asking a question a lot, there’s probably something missing in the documentation or learning materials about it. Some things can be fixed upstream in documentation, but other things — like “how should I reason about modules in Rust?” deserve to be tackled as a separate problem and addressed with their own post. (Yes, this post is in this category!) It’s okay if folks have written about it before! A common question I’ve gotten is “Well I can write about X but … there are a lot of other posts out there about it, should I still?” Yes!! People think differently, people learn differently, and people come from different backgrounds. Existing posts may be useful for some folks but less useful for others. My personal rule of thumb is that if it took me some effort to understand something after reading about it, that’s something worth writing about, so it’s easier to understand for others like me encountering the subject. One of my favorite bloggers, Julia Evans very often writes posts explaining computer concepts. Most of the times these have been explained before in other blog posts or manuals. But that doesn’t matter — her posts are different, and they’re amazing. They’re upbeat, fun to read, and often get me excited to learn more about things I knew about but never really looked at closely before. I kinda feel it’s my duty to? There’s a quote by Toni Morrison I quite enjoy: I tell my students, ‘When you get these jobs that you have been so brilliantly trained for, just remember that your real job is that if you are free, you need to free somebody else. If you have some power, then your job is to empower somebody else. This is not just a grab-bag candy game. I enjoy it so much I concluded my talk at RustFest Kyiv with it! I have the privilege of having time to do things like blogging and mentoring. Given that, I feel that it really is my duty to share what I know as much as possible; to help others attempting to tread the path I’m treading; and to battle against tribal knowledge. When it comes to programming I’m mostly “self-taught”. But when I say that, I really mean that I wasn’t taught in a traditional way by other humans — I learned things by trying stuff out and reading what others had written. I didn’t learn Rust by taking rustc and pretending to be a fuzzer and just trying random nonsense till stuff made sense, I went through the tutorial (and then started exploring by trying random stuff). I didn’t figure out cool algorithms by discovering them from first principles, I picked them up from books and blog posts. I’m “self-taught” because I’ve been in charge of my learning process, but I’ve definitely relied on the work of other people throughout this process. This means that for me, personally, knowledge-sharing is especially important. If I had to spend time figuring something out, I should make it easier for the next people to try7. (All this said, I probably don’t blog as much as I should) You should blog too! I wish everyone wrote more. I know not everyone has the time/privilege to do this, but if you do, I urge you to start! I feel like tips on how to blog would fill up an entire other blog post, but Julia Evans has multiple posts on this that I strongly recommend. Feel free to ask me for review on posts! As for the technicalities of setting up a blog, my colleague Emily recently wrote a great post about doing this with Jekyll. This blog uses Octopress which is similar to set up. Thanks to Arshia, QuietMisdreavus, and Alex for reviewing drafts of this blog post. Who needs to look for unsoundness with rigorous formal verification when you have grep? &#8617; Incidentally, I find there’s a similar dynamic when it comes to forum discussions vs hashing things out one-on-one, it’s way harder to get anywhere with forum discussions because they’re one-many and you have to put in that much more work to empathize with everyone else and also phrase things in a way that is resilient to accidental misinterpretation. &#8617; This is especially important as I get more and more “used” to subjects I’m familiar with – it’s easy to lose the ability to explain things when I think half of it is obvious. &#8617; This is probably the real reason I love rereading it — I like being verbose and would nest parentheses and footnotes if society let me &#8617; I also am in general less inclined to do technical things in my free time and have a better work-life balance, glad that worked out! &#8617; See blog title &#8617; One of my former title ideas for this post was “Knowledge is Theft”, riffing off of this concept, but I felt that was a bit too tongue-in-cheek. &#8617;]]></summary></entry><entry><title type="html">The future of Clippy</title><link href="http://manishearth.github.io/blog/2018/06/05/the-future-of-clippy-the-rust-linter/" rel="alternate" type="text/html" title="The future of Clippy" /><published>2018-06-05T00:00:00+00:00</published><updated>2018-06-05T00:00:00+00:00</updated><id>http://manishearth.github.io/blog/2018/06/05/the-future-of-clippy-the-rust-linter</id><content type="html" xml:base="http://manishearth.github.io/blog/2018/06/05/the-future-of-clippy-the-rust-linter/"><![CDATA[<p>We’ve recently been making lots of progress on future plans for <a href="https://github.com/rust-lang-nursery/rust-clippy">clippy</a> and I
thought I’d post an update.</p>

<p>For some background, Clippy is the linter for Rust. We have more than 250 lints, and
are steadily growing.</p>

<h2 id="clippy-and-nightly">Clippy and Nightly</h2>

<p>Sadly, Clippy has been nightly-only for a very long time. The reason behind this is
that to perform its analyses it hooks into the compiler so that it doesn’t have to
reimplement half the compiler’s info to get things like type information. But
these are internal APIs and as such will never stabilize, so Clippy needs to be
used with nightly Rust.</p>

<p>We’re hoping this will change soon! The plan is that Clippy will eventually
be distributed by Rustup, so something like <code class="language-plaintext highlighter-rouge">rustup component add clippy</code> will
get you the clippy binary.</p>

<p>The first steps are <a href="https://github.com/rust-lang/rust/pull/51122">happening</a>, we’re planning on setting it up so that when it compiles
Rustup will be able to fetch a clippy component (however this won’t be the recommended way
to use clippy until we figure out the workflow here, so sit tight!)</p>

<p>Eventually, clippy will probably block nightlies<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup>; and after a bunch of cycles of letting that
work itself out, hopefully clippy will be available with the stable compiler. There’s a lot of
stuff that needs to be figured out, and we want to do this in a way that minimally impacts
compiler development, so this may move in fits and starts.</p>

<h2 id="lint-audit">Lint audit</h2>

<p>A couple months ago <a href="https://github.com/oli-obk">Oliver</a> and I<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup> did a <a href="https://github.com/rust-lang-nursery/rust-clippy/pull/2579">lint audit</a> in Clippy. Previously,
clippy lints were classified as simply “clippy”, “clippy_pedantic”, and “restriction”.
“restriction” was for allow-by-default lints for things which are generally not a problem but may
be something you specifically want to forbid based on the situation, and “pedantic”
was for all the lints which were allow-by-default for other reasons.</p>

<p>Usually these reasons included stuff like “somewhat controversial lint”, “lint is very buggy”,
or for lints which are actually exceedingly pedantic and may only be wanted by folks
who very seriously prefer their code to be <em>perfect</em>.</p>

<p>We had a lot of buggy lints, and these categories weren’t as helpful. People use clippy
for different reasons. Some folks only care about clippy catching bugs, whereas others want
its help enforcing the general “Rust Style”.</p>

<p>So we came up with a better division of lints:</p>

<ul>
  <li>Correctness (Deny): Probable bugs, e.g. calling <code class="language-plaintext highlighter-rouge">.clone()</code> on <code class="language-plaintext highlighter-rouge">&amp;&amp;T</code>, which clones the (<code class="language-plaintext highlighter-rouge">Copy</code>) reference and not the actual type</li>
  <li>Style (Warn): Style issues; where the fix usually doesn’t semantically change the code. For example, having a method named <code class="language-plaintext highlighter-rouge">into_foo()</code> that doesn’t take <code class="language-plaintext highlighter-rouge">self</code> by-move</li>
  <li>Complexity (Warn): For detecting unnecessary code complexities and helping simplify them. For example, replacing <code class="language-plaintext highlighter-rouge">.filter(..).next()</code> with <code class="language-plaintext highlighter-rouge">.find(..)</code></li>
  <li>Perf (Warn): Detecting potential performance footguns, like using <code class="language-plaintext highlighter-rouge">Box&lt;Vec&lt;T&gt;&gt;</code> or calling <code class="language-plaintext highlighter-rouge">.or(foo())</code> instead of <code class="language-plaintext highlighter-rouge">or_else(foo)</code>.</li>
  <li>Pedantic (Allow): Controversial or exceedingly pedantic lints</li>
  <li>Nursery (Allow): For lints which are buggy or need more work</li>
  <li>Cargo (Allow): Lints about your Cargo setup</li>
  <li>Restriction (Allow): Lints for things which are not usually a problem, but may be something specific situations may dictate disallowing.</li>
</ul>

<p>and applied it to the codebase. You can see the results on our <a href="https://rust-lang-nursery.github.io/rust-clippy/master/index.html">lint list</a></p>

<p>Some lints could belong in more than one group, and we picked the best one in that case. Feedback welcome!</p>

<h2 id="clippy-10">Clippy 1.0</h2>

<p>In the run up to making Clippy a rustup component we’d like to do a 1.0 release of Clippy. This involves an RFC,
and pinning down an idea of stability.</p>

<p>The general plan we have right now is to have the same idea of lint stability as rustc; essentially
we do not guarantee stability under <code class="language-plaintext highlighter-rouge">#[deny(lintname)]</code>. This is mostly fine since <code class="language-plaintext highlighter-rouge">deny</code> only affects
the current crate (dependencies have their lints capped) so at most you’ll be forced to slap on an <code class="language-plaintext highlighter-rouge">allow</code>
somewhere after a rustup.</p>

<p>With specifics, this means that we’ll never remove lints. We may recategorize them, or “deprecate” them
(which makes the lint do nothing, but keeps the name around so that <code class="language-plaintext highlighter-rouge">#[allow(lintname)]</code> doesn’t break the build
aside from emitting a warning).</p>

<p>We’ll also not change what individual lints do fundamentally. The kinds of changes you can expect are:</p>

<ul>
  <li>Entirely new lints</li>
  <li>Fixing false positives (a lint may no longer lint in a buggy case)</li>
  <li>Fixing false negatives (A case where the lint <em>should</em> be linting but doesn’t is fixed)</li>
  <li>Bugfixes (When the lint panics or does something otherwise totally broken)</li>
</ul>

<p>When fixing false negatives this will usually be fixing things that can be understood as comfortably within the
scope of the lint as documented/named</p>

<p>I’ll be posting an RFC soonish that both contains this general plan of stability, as well as a list of the current
lint categorization for folks to discuss.</p>

<hr />

<p>Anyway, thought I’d just post a general update on everything, since stuff’s changing quickly.</p>

<p>There’s still time for stable or even just reliably rustuppable nightly clippy to happen but the path to it is pretty clear now!</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>As in, if clippy is broken there will not be a nightly that day. Rustfmt and RLS work this way right now AIUI. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>Okay, mostly Oliver <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name>Manish Goregaokar</name></author><category term="rust" /><category term="programming" /><summary type="html"><![CDATA[We’ve recently been making lots of progress on future plans for clippy and I thought I’d post an update. For some background, Clippy is the linter for Rust. We have more than 250 lints, and are steadily growing. Clippy and Nightly Sadly, Clippy has been nightly-only for a very long time. The reason behind this is that to perform its analyses it hooks into the compiler so that it doesn’t have to reimplement half the compiler’s info to get things like type information. But these are internal APIs and as such will never stabilize, so Clippy needs to be used with nightly Rust. We’re hoping this will change soon! The plan is that Clippy will eventually be distributed by Rustup, so something like rustup component add clippy will get you the clippy binary. The first steps are happening, we’re planning on setting it up so that when it compiles Rustup will be able to fetch a clippy component (however this won’t be the recommended way to use clippy until we figure out the workflow here, so sit tight!) Eventually, clippy will probably block nightlies1; and after a bunch of cycles of letting that work itself out, hopefully clippy will be available with the stable compiler. There’s a lot of stuff that needs to be figured out, and we want to do this in a way that minimally impacts compiler development, so this may move in fits and starts. Lint audit A couple months ago Oliver and I2 did a lint audit in Clippy. Previously, clippy lints were classified as simply “clippy”, “clippy_pedantic”, and “restriction”. “restriction” was for allow-by-default lints for things which are generally not a problem but may be something you specifically want to forbid based on the situation, and “pedantic” was for all the lints which were allow-by-default for other reasons. Usually these reasons included stuff like “somewhat controversial lint”, “lint is very buggy”, or for lints which are actually exceedingly pedantic and may only be wanted by folks who very seriously prefer their code to be perfect. We had a lot of buggy lints, and these categories weren’t as helpful. People use clippy for different reasons. Some folks only care about clippy catching bugs, whereas others want its help enforcing the general “Rust Style”. So we came up with a better division of lints: Correctness (Deny): Probable bugs, e.g. calling .clone() on &amp;&amp;T, which clones the (Copy) reference and not the actual type Style (Warn): Style issues; where the fix usually doesn’t semantically change the code. For example, having a method named into_foo() that doesn’t take self by-move Complexity (Warn): For detecting unnecessary code complexities and helping simplify them. For example, replacing .filter(..).next() with .find(..) Perf (Warn): Detecting potential performance footguns, like using Box&lt;Vec&lt;T&gt;&gt; or calling .or(foo()) instead of or_else(foo). Pedantic (Allow): Controversial or exceedingly pedantic lints Nursery (Allow): For lints which are buggy or need more work Cargo (Allow): Lints about your Cargo setup Restriction (Allow): Lints for things which are not usually a problem, but may be something specific situations may dictate disallowing. and applied it to the codebase. You can see the results on our lint list Some lints could belong in more than one group, and we picked the best one in that case. Feedback welcome! Clippy 1.0 In the run up to making Clippy a rustup component we’d like to do a 1.0 release of Clippy. This involves an RFC, and pinning down an idea of stability. The general plan we have right now is to have the same idea of lint stability as rustc; essentially we do not guarantee stability under #[deny(lintname)]. This is mostly fine since deny only affects the current crate (dependencies have their lints capped) so at most you’ll be forced to slap on an allow somewhere after a rustup. With specifics, this means that we’ll never remove lints. We may recategorize them, or “deprecate” them (which makes the lint do nothing, but keeps the name around so that #[allow(lintname)] doesn’t break the build aside from emitting a warning). We’ll also not change what individual lints do fundamentally. The kinds of changes you can expect are: Entirely new lints Fixing false positives (a lint may no longer lint in a buggy case) Fixing false negatives (A case where the lint should be linting but doesn’t is fixed) Bugfixes (When the lint panics or does something otherwise totally broken) When fixing false negatives this will usually be fixing things that can be understood as comfortably within the scope of the lint as documented/named I’ll be posting an RFC soonish that both contains this general plan of stability, as well as a list of the current lint categorization for folks to discuss. Anyway, thought I’d just post a general update on everything, since stuff’s changing quickly. There’s still time for stable or even just reliably rustuppable nightly clippy to happen but the path to it is pretty clear now! As in, if clippy is broken there will not be a nightly that day. Rustfmt and RLS work this way right now AIUI. &#8617; Okay, mostly Oliver &#8617;]]></summary></entry><entry><title type="html">Down a Rusty rabbit hole</title><link href="http://manishearth.github.io/blog/2018/04/12/down-a-rusty-rabbit-hole/" rel="alternate" type="text/html" title="Down a Rusty rabbit hole" /><published>2018-04-12T00:00:00+00:00</published><updated>2018-04-12T00:00:00+00:00</updated><id>http://manishearth.github.io/blog/2018/04/12/down-a-rusty-rabbit-hole</id><content type="html" xml:base="http://manishearth.github.io/blog/2018/04/12/down-a-rusty-rabbit-hole/"><![CDATA[<p>Last week I fell down a rather interesting rabbit hole in Rust, which was basically
me discovering a series of quirks of the Rust compiler/language, each one leading to the
next when I asked “why?”.</p>

<p>It started when someone asked why autogenerated <code class="language-plaintext highlighter-rouge">Debug</code> impls use argument names like <code class="language-plaintext highlighter-rouge">__arg_0</code>
which start with a double underscore.</p>

<p>This happened to be <a href="https://github.com/rust-lang/rust/pull/32294">my fault</a>. The reason <a href="https://github.com/rust-lang/rust/pull/32251#issuecomment-197481726">we used a double underscore</a> was that
while a single underscore tells rustc not to warn about a possibly-unused variable, there’s an off-
by-default clippy lint that warns about variables that start with a single underscore that are used,
which can be silenced with a double underscore. Now, the correct fix here is to make the lint ignore
derive/macros (which I believe we did as well), but at the time we needed to add an underscore
anyway so a double underscore didn’t seem worse.</p>

<p>Except of course, this double underscore appears in the docs. Oops.</p>

<p>Ideally the rustc derive infrastructure would have a way of specifying the argument name to use so
that we can at least have descriptive things here, but that’s a bit more work (I’m willing to mentor
this work though!). So I thought I’d fix this by at least removing the double underscore, and making
the unused lint ignore <code class="language-plaintext highlighter-rouge">#[derive()]</code> output.</p>

<p>While going through the code to look for underscores I also discovered a hygiene issue. The following code
throws a bunch of very weird type errors:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">pub</span> <span class="k">const</span> <span class="n">__cmp</span><span class="p">:</span> <span class="nb">u8</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="nd">#[derive(PartialOrd,</span> <span class="nd">PartialEq)]</span>
<span class="k">pub</span> <span class="k">enum</span> <span class="n">Foo</span> <span class="p">{</span>
    <span class="nf">A</span><span class="p">(</span><span class="nb">u8</span><span class="p">),</span> <span class="nf">B</span><span class="p">(</span><span class="nb">u8</span><span class="p">)</span>
<span class="p">}</span>
</code></pre></div></div>

<p>(<a href="https://play.rust-lang.org/?gist=2352b6a2192f38caba70bc2b1fa889e7&amp;version=stable">playpen</a>)</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>error[E0308]: mismatched types
 --&gt; src/main.rs:6:7
  |
6 |     A(u8), B(u8)
  |       ^^^ expected enum `std::option::Option`, found u8
  |
  = note: expected type `std::option::Option&lt;std::cmp::Ordering&gt;`
             found type `u8`
.....
</code></pre></div></div>

<p>This is because the generated code for PartialOrd contains the following:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">match</span> <span class="n">foo</span><span class="nf">.cmp</span><span class="p">(</span><span class="n">bar</span><span class="p">)</span> <span class="p">{</span>
    <span class="nf">Some</span><span class="p">(</span><span class="nn">Ordering</span><span class="p">::</span><span class="n">Equal</span><span class="p">)</span> <span class="k">=&gt;</span> <span class="o">.....</span><span class="p">,</span>
    <span class="n">__cmp</span> <span class="k">=&gt;</span> <span class="n">__cmp</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">__cmp</code> can both be a binding to a wildcard pattern match as well as a match against a constant
named <code class="language-plaintext highlighter-rouge">__cmp</code>, and in the presence of such a constant it resolves to the constant, causing
type errors.</p>

<p>One way to fix this is to bind <code class="language-plaintext highlighter-rouge">foo.cmp(bar)</code> to some temporary variable <code class="language-plaintext highlighter-rouge">x</code> and use that directly in
a <code class="language-plaintext highlighter-rouge">_ =&gt; x</code> branch.</p>

<p>I thought I could be clever and try <code class="language-plaintext highlighter-rouge">cmp @ _ =&gt; cmp</code> instead. <code class="language-plaintext highlighter-rouge">match</code> supports syntax where you can
do <code class="language-plaintext highlighter-rouge">foo @ &lt;pattern&gt;</code>, where <code class="language-plaintext highlighter-rouge">foo</code> is bound to the entire matched variable. The <code class="language-plaintext highlighter-rouge">cmp</code> here is unambiguously
a binding; it cannot be a pattern. So no conflicting with the <code class="language-plaintext highlighter-rouge">const</code>, problem solved!</p>

<p>So I made <a href="https://github.com/rust-lang/rust/pull/49676">a PR for both removing the underscores and also fixing this</a>. The change for <code class="language-plaintext highlighter-rouge">__cmp</code>
is no longer in that PR, but you can find it <a href="https://github.com/Manishearth/rust/commit/partial-cmp-hygiene">here</a>.</p>

<p>Except I hit a problem. With that PR, the following still breaks:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">pub</span> <span class="k">const</span> <span class="n">cmp</span><span class="p">:</span> <span class="nb">u8</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="nd">#[derive(PartialOrd,</span> <span class="nd">PartialEq)]</span>
<span class="k">pub</span> <span class="k">enum</span> <span class="n">Foo</span> <span class="p">{</span>
    <span class="nf">A</span><span class="p">(</span><span class="nb">u8</span><span class="p">),</span> <span class="nf">B</span><span class="p">(</span><span class="nb">u8</span><span class="p">)</span>
<span class="p">}</span>
</code></pre></div></div>

<p>throwing a slightly cryptic error:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>error[E0530]: match bindings cannot shadow constants
 --&gt; test.rs:9:7
  |
4 | pub const cmp: u8 = 1;
  | ---------------------- a constant `cmp` is defined here
...
9 |     B(u8)
  |       ^^^ cannot be named the same as a constant
</code></pre></div></div>

<p>You can see a reduced version of this error in the following code:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">pub</span> <span class="k">const</span> <span class="n">cmp</span> <span class="p">:</span> <span class="nb">u8</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="k">fn</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
    <span class="k">match</span> <span class="mi">1</span> <span class="p">{</span>
        <span class="n">cmp</span> <span class="o">@</span> <span class="n">_</span> <span class="k">=&gt;</span> <span class="p">()</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>(<a href="https://play.rust-lang.org/?gist=feebbc048b47c286d5720b9926c6925e&amp;version=stable">playpen</a>)</p>

<p>Huh. Wat. Why? <code class="language-plaintext highlighter-rouge">cmp @ _</code> seems to be pretty unambiguous, what’s wrong with it shadowing a constant?</p>

<p>Turns out bindings cannot shadow constants at all, for a <a href="https://github.com/rust-lang/rust/issues/33118#issuecomment-233962221">rather subtle reason</a>:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">const</span> <span class="n">A</span><span class="p">:</span> <span class="nb">u8</span> <span class="o">=</span> <span class="o">...</span><span class="p">;</span> <span class="c1">// A_const</span>
<span class="k">let</span> <span class="n">A</span> <span class="o">@</span> <span class="n">_</span> <span class="o">=</span> <span class="o">...</span><span class="p">;</span> <span class="c1">// A_let</span>
<span class="k">match</span> <span class="o">..</span> <span class="p">{</span>
    <span class="n">A</span> <span class="k">=&gt;</span> <span class="o">...</span><span class="p">;</span> <span class="c1">// A_match</span>
<span class="p">}</span>
</code></pre></div></div>

<p>What happens here is that constants and variables occupy the same namespace. So <code class="language-plaintext highlighter-rouge">A_let</code> shadows
<code class="language-plaintext highlighter-rouge">A_const</code> here, and when we attempt to <code class="language-plaintext highlighter-rouge">match</code>, <code class="language-plaintext highlighter-rouge">A_match</code> is resolved to <code class="language-plaintext highlighter-rouge">A_let</code> and rejected (since
you can’t match against a variable), and <code class="language-plaintext highlighter-rouge">A_match</code> falls back to resolving as a fresh binding
pattern, instead of resolving to a pattern that matches against <code class="language-plaintext highlighter-rouge">A_const</code>.</p>

<p>This is kinda weird, so we disallow shadowing constants with variables. This is rarely a problem
because variables are lowercase and constants are uppercase. We could <em>technically</em> allow this
language-wise, but it’s hard on the implementation (and irrelevant in practice) so we don’t.</p>

<hr />

<p>So I dropped that fix. The temporary local variable approach is broken as well since
you can also name a constant the same as the local variable and have a clash (so again, you
need the underscores to avoid surprises).</p>

<p>But then I realized that we had an issue with removing the underscores from <code class="language-plaintext highlighter-rouge">__arg_0</code> as well.</p>

<p>The following code is also broken:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">pub</span> <span class="k">const</span> <span class="n">__arg_0</span><span class="p">:</span> <span class="nb">u8</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="nd">#[derive(Debug)]</span>
<span class="k">struct</span> <span class="nf">Foo</span><span class="p">(</span><span class="nb">u8</span><span class="p">);</span>
</code></pre></div></div>

<p>(<a href="https://play.rust-lang.org/?gist=6e10fd8de1123c6f6f695c891e879f70&amp;version=stable">playpen</a>)</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>error[E0308]: mismatched types
 --&gt; src/main.rs:3:10
  |
3 | #[derive(Debug)]
  |          ^^^^^ expected mutable reference, found u8
  |
  = note: expected type `&amp;mut std::fmt::Formatter&lt;'_&gt;`
             found type `u8`
</code></pre></div></div>

<p>You can see a reduced version of this error in the following code:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">pub</span> <span class="k">const</span> <span class="n">__arg_0</span><span class="p">:</span> <span class="nb">u8</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="k">fn</span> <span class="nf">foo</span><span class="p">(</span><span class="n">__arg_0</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="p">{}</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>error[E0308]: mismatched types
 --&gt; src/main.rs:3:8
  |
3 | fn foo(__arg_0: bool) {}
  |        ^^^^^^^ expected bool, found u8
</code></pre></div></div>

<p>(<a href="https://play.rust-lang.org/?gist=2cf2c8b3520d5b343de1b76f80ea3fe7&amp;version=stable">playpen</a>)</p>

<p>This breakage is not an issue with the current code because of the double underscores – there’s a
very low chance someone will create a constant that is both lowercase and starts with a double
underscore. But it’s a problem when I remove the underscores since that chance shoots up.</p>

<p>Anyway, this failure is even weirder. Why are we attempting to match against the constant in the
first place? <code class="language-plaintext highlighter-rouge">fn</code> argument patterns<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup> are irrefutable, i.e. all possible values of the type should match
the argument. For example, <code class="language-plaintext highlighter-rouge">fn foo(Some(foo): Option&lt;u8&gt;) {}</code> will fail to compile with
“refutable pattern in function argument: <code class="language-plaintext highlighter-rouge">None</code> not covered”.</p>

<p>There’s no point trying to match against constants here; because even if we find a constant it will be rejected
later. Instead, we can unambiguously resolve identifiers as new bindings, yes?</p>

<p>Right?</p>

<p>Firm in my belief, <a href="https://github.com/rust-lang/rust/issues/49680">I filed an issue</a>.</p>

<p>I was wrong, it’s <a href="https://github.com/rust-lang/rust/issues/49680#issuecomment-379029404">not going to always be rejected later</a>. With zero-sized types this
can totally still work:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">struct</span> <span class="n">S</span><span class="p">;</span>

<span class="k">const</span> <span class="n">C</span><span class="p">:</span> <span class="n">S</span> <span class="o">=</span> <span class="n">S</span><span class="p">;</span>

<span class="k">fn</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">C</span> <span class="o">=</span> <span class="n">S</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Here because <code class="language-plaintext highlighter-rouge">S</code> has only one state, matching against a constant of the type is still irrefutable.</p>

<p>I argued that this doesn’t matter – since the type has a single value, it doesn’t matter whether we resolved to
a new binding or the constant; the value and semantics are the same.</p>

<p>This is true.</p>

<p>Except.</p>

<p><a href="https://github.com/rust-lang/rust/issues/49680#issuecomment-379032842">Except for when destructors come in</a>.</p>

<p>It was at this point that my table found itself in the perplexing state of being upside-down.</p>

<p>This is still really fine, zero-sized-constants-with-destructors is a pretty rare thing in Rust
and I don’t really see folks <em>relying</em> on this behavior.</p>

<p>However I later realized that this entire detour was pointless because even if we fix this, we end up
with a way for bindings to shadow constants. Which … which we already realized isn’t allowed by the
compiler till we fix some bugs.</p>

<p>Damn.</p>

<hr />

<p>The <em>actual</em> fix to the macro stuff is to use hygenic generated variable names, which the current
infrastructure supports. I plan to make a PR for this eventually.</p>

<p>But it was a very interesting dive into the nuances of pattern matching in Rust.</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>Yes, function arguments in Rust are patterns. You can totally do things like <code class="language-plaintext highlighter-rouge">(a, b): (u8, u8)</code> in function arguments (like you can do in <code class="language-plaintext highlighter-rouge">let</code>) <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name>Manish Goregaokar</name></author><category term="programming" /><category term="mozilla" /><category term="rust" /><summary type="html"><![CDATA[Last week I fell down a rather interesting rabbit hole in Rust, which was basically me discovering a series of quirks of the Rust compiler/language, each one leading to the next when I asked “why?”. It started when someone asked why autogenerated Debug impls use argument names like __arg_0 which start with a double underscore. This happened to be my fault. The reason we used a double underscore was that while a single underscore tells rustc not to warn about a possibly-unused variable, there’s an off- by-default clippy lint that warns about variables that start with a single underscore that are used, which can be silenced with a double underscore. Now, the correct fix here is to make the lint ignore derive/macros (which I believe we did as well), but at the time we needed to add an underscore anyway so a double underscore didn’t seem worse. Except of course, this double underscore appears in the docs. Oops. Ideally the rustc derive infrastructure would have a way of specifying the argument name to use so that we can at least have descriptive things here, but that’s a bit more work (I’m willing to mentor this work though!). So I thought I’d fix this by at least removing the double underscore, and making the unused lint ignore #[derive()] output. While going through the code to look for underscores I also discovered a hygiene issue. The following code throws a bunch of very weird type errors: pub const __cmp: u8 = 1; #[derive(PartialOrd, PartialEq)] pub enum Foo { A(u8), B(u8) } (playpen) error[E0308]: mismatched types --&gt; src/main.rs:6:7 | 6 | A(u8), B(u8) | ^^^ expected enum `std::option::Option`, found u8 | = note: expected type `std::option::Option&lt;std::cmp::Ordering&gt;` found type `u8` ..... This is because the generated code for PartialOrd contains the following: match foo.cmp(bar) { Some(Ordering::Equal) =&gt; ....., __cmp =&gt; __cmp, } __cmp can both be a binding to a wildcard pattern match as well as a match against a constant named __cmp, and in the presence of such a constant it resolves to the constant, causing type errors. One way to fix this is to bind foo.cmp(bar) to some temporary variable x and use that directly in a _ =&gt; x branch. I thought I could be clever and try cmp @ _ =&gt; cmp instead. match supports syntax where you can do foo @ &lt;pattern&gt;, where foo is bound to the entire matched variable. The cmp here is unambiguously a binding; it cannot be a pattern. So no conflicting with the const, problem solved! So I made a PR for both removing the underscores and also fixing this. The change for __cmp is no longer in that PR, but you can find it here. Except I hit a problem. With that PR, the following still breaks: pub const cmp: u8 = 1; #[derive(PartialOrd, PartialEq)] pub enum Foo { A(u8), B(u8) } throwing a slightly cryptic error: error[E0530]: match bindings cannot shadow constants --&gt; test.rs:9:7 | 4 | pub const cmp: u8 = 1; | ---------------------- a constant `cmp` is defined here ... 9 | B(u8) | ^^^ cannot be named the same as a constant You can see a reduced version of this error in the following code: pub const cmp : u8 = 1; fn main() { match 1 { cmp @ _ =&gt; () } } (playpen) Huh. Wat. Why? cmp @ _ seems to be pretty unambiguous, what’s wrong with it shadowing a constant? Turns out bindings cannot shadow constants at all, for a rather subtle reason: const A: u8 = ...; // A_const let A @ _ = ...; // A_let match .. { A =&gt; ...; // A_match } What happens here is that constants and variables occupy the same namespace. So A_let shadows A_const here, and when we attempt to match, A_match is resolved to A_let and rejected (since you can’t match against a variable), and A_match falls back to resolving as a fresh binding pattern, instead of resolving to a pattern that matches against A_const. This is kinda weird, so we disallow shadowing constants with variables. This is rarely a problem because variables are lowercase and constants are uppercase. We could technically allow this language-wise, but it’s hard on the implementation (and irrelevant in practice) so we don’t. So I dropped that fix. The temporary local variable approach is broken as well since you can also name a constant the same as the local variable and have a clash (so again, you need the underscores to avoid surprises). But then I realized that we had an issue with removing the underscores from __arg_0 as well. The following code is also broken: pub const __arg_0: u8 = 1; #[derive(Debug)] struct Foo(u8); (playpen) error[E0308]: mismatched types --&gt; src/main.rs:3:10 | 3 | #[derive(Debug)] | ^^^^^ expected mutable reference, found u8 | = note: expected type `&amp;mut std::fmt::Formatter&lt;'_&gt;` found type `u8` You can see a reduced version of this error in the following code: pub const __arg_0: u8 = 1; fn foo(__arg_0: bool) {} error[E0308]: mismatched types --&gt; src/main.rs:3:8 | 3 | fn foo(__arg_0: bool) {} | ^^^^^^^ expected bool, found u8 (playpen) This breakage is not an issue with the current code because of the double underscores – there’s a very low chance someone will create a constant that is both lowercase and starts with a double underscore. But it’s a problem when I remove the underscores since that chance shoots up. Anyway, this failure is even weirder. Why are we attempting to match against the constant in the first place? fn argument patterns1 are irrefutable, i.e. all possible values of the type should match the argument. For example, fn foo(Some(foo): Option&lt;u8&gt;) {} will fail to compile with “refutable pattern in function argument: None not covered”. There’s no point trying to match against constants here; because even if we find a constant it will be rejected later. Instead, we can unambiguously resolve identifiers as new bindings, yes? Right? Firm in my belief, I filed an issue. I was wrong, it’s not going to always be rejected later. With zero-sized types this can totally still work: struct S; const C: S = S; fn main() { let C = S; } Here because S has only one state, matching against a constant of the type is still irrefutable. I argued that this doesn’t matter – since the type has a single value, it doesn’t matter whether we resolved to a new binding or the constant; the value and semantics are the same. This is true. Except. Except for when destructors come in. It was at this point that my table found itself in the perplexing state of being upside-down. This is still really fine, zero-sized-constants-with-destructors is a pretty rare thing in Rust and I don’t really see folks relying on this behavior. However I later realized that this entire detour was pointless because even if we fix this, we end up with a way for bindings to shadow constants. Which … which we already realized isn’t allowed by the compiler till we fix some bugs. Damn. The actual fix to the macro stuff is to use hygenic generated variable names, which the current infrastructure supports. I plan to make a PR for this eventually. But it was a very interesting dive into the nuances of pattern matching in Rust. Yes, function arguments in Rust are patterns. You can totally do things like (a, b): (u8, u8) in function arguments (like you can do in let) &#8617;]]></summary></entry><entry><title type="html">Picking apart the crashing iOS string</title><link href="http://manishearth.github.io/blog/2018/02/15/picking-apart-the-crashing-ios-string/" rel="alternate" type="text/html" title="Picking apart the crashing iOS string" /><published>2018-02-15T00:00:00+00:00</published><updated>2018-02-15T00:00:00+00:00</updated><id>http://manishearth.github.io/blog/2018/02/15/picking-apart-the-crashing-ios-string</id><content type="html" xml:base="http://manishearth.github.io/blog/2018/02/15/picking-apart-the-crashing-ios-string/"><![CDATA[<p>So there’s <a href="https://www.theverge.com/2018/2/15/17015654/apple-iphone-crash-ios-11-bug-imessage">yet another iOS text crash</a>, where just looking at a particular string crashes
iOS. Basically, if you put this string in any system text box (and other places), it crashes that
process. I’ve been testing it by copy-pasting characters into Spotlight so I don’t end up crashing
my browser.</p>

<p>The original sequence is U+0C1C U+0C4D U+0C1E U+200C U+0C3E, which is a sequence of Telugu
characters: the consonant ja (జ), a virama ( ్ ), the consonant nya (ఞ), a zero-width non-joiner, and
the vowel aa ( ా).</p>

<p>I was pretty interested in what made this sequence “special”, and started investigating.</p>

<p>So first when looking into this, I thought that the &lt;ja, virama, nya&gt; sequence was the culprit.
That sequence forms a special ligature in many Indic scripts (ज्ञ in Devanagari) which is often
considered a letter of its own. However, the ligature for Telugu doesn’t seem very “special”.</p>

<p>Also, from some experimentation, this bug seemed to occur for <em>any</em> pair of Telugu consonants with
a vowel, as long as the vowel is not   ై (ai). Huh.</p>

<p>The ZWNJ must be doing something weird, then. &lt;consonant, virama, consonant, vowel&gt; is a
pretty common sequence in any Indic script; but ZWNJ before a vowel isn’t very useful for most
scripts (except for Bengali and Oriya, but I’ll get to that).</p>

<p>And then I saw that <a href="https://twitter.com/FakeUnicode/status/963300865762254848">there was a sequence in Bengali</a> that also crashed.</p>

<p>The sequence is U+09B8 U+09CD U+09B0 U+200C U+09C1, which is the consonant “so” (স), a virama ( ্ ),
the consonant “ro” (র), a ZWNJ, and vowel u (  ু).</p>

<p>Before we get too into this, let’s first take a little detour to learn how Indic scripts work:</p>

<h2 id="indic-scripts-and-consonant-clusters">Indic scripts and consonant clusters</h2>

<p>Indic scripts are <em>abugidas</em>; which means that their “letters” are consonants, which you
can attach diacritics to to change the vowel. By default, consonants have a base vowel.
So, for example, क is “kuh” (kə, often transcribed as “ka”), but I can change the vowel to make it के
(the “ka” in “okay”) का (“kaa”, like “car”).</p>

<p>Usually, the default vowel is the ə sound, though not always (in Bengali it’s more of an o sound).</p>

<p>Because of the “default” vowel, you need a way to combine consonants. For example, if you wished to
write the word “ski”, you can’t write it as स + की (sa + ki = “saki”), you must write it as स्की.
What’s happened here is that the स got its vowel “killed”, and got tacked on to the की to form a
consonant cluster ligature.</p>

<p>You can <em>also</em> write this as स्‌की . That little tail you see on the स is known as a “virama”;
it basically means “remove this vowel”. Explicit viramas are sometimes used when there’s no easy way
to form a ligature, e.g. in ङ्‌ठ because there is no simple way to ligatureify ङ into ठ. Some scripts
also <em>prefer</em> explicit viramas, e.g. “ski” in Malayalam is written as സ്കീ, where the little crescent
is the explicit virama.</p>

<p>In unicode, the virama character is always used to form a consonant cluster. So स्की was written as
&lt;स,  ्, क,  ी&gt;, or &lt;sa, virama, ka, i&gt;. If the font supports the cluster, it will show up
as a ligature, otherwise it will use an explicit virama.</p>

<p>For Devanagari and Bengali, <em>usually</em>, in a consonant cluster the first consonant is munged a bit and the second consonant stays intact.
There are exceptions – sometimes they’ll form an entirely new glyph (क + ष = क्ष), and sometimes both
glyphs will change (ड + ड = ड्ड, द + म = द्म, द + ब = द्ब). Those last ones should look like this in conjunct form:</p>

<p><img class="center" src="/images/post/unicode-crash/conjuncts.png" width="200" /></p>

<h2 id="investigating-the-bengali-case">Investigating the Bengali case</h2>

<p>Now, interestingly, unlike the Telugu crash, the Bengali crash seemed to only occur when the second
consonant is র (“ro”). However, I can trigger it for any choice of the first consonant or vowel, except
when the vowel is  ো (o) or  ৌ (au).</p>

<p>Now, র is an interesting consonant in some Indic scripts, including Devanagari. In Devanagari,
it looks like र (“ra”). However, it does all kinds of things when forming a cluster. If you’re having it
precede another consonant in a cluster, it forms a little feather-like stroke, like in र्क (rka). In Marathi,
that stroke can also look like a tusk, as in र्‍क. As a suffix consonant, it can provide a little
“extra leg”, as in क्र (kra). For letters without a vertical stroke, like ठ (tha), it does this caret-like thing,
ठ्र (thra).</p>

<p>Basically, while most consonants retain some of their form when put inside a cluster, र does not. And
a more special thing about र is that this happens even when र is the <em>second</em> consonant in a cluster – as I mentioned
before, for most consonant clusters the second consonant stays intact. While there are exceptions, they are usually
specific to the cluster; it is only र for which this happens for all clusters.</p>

<p>It’s similar in Bengali, র as the second consonant adds a tentacle-like thing on the existing consonant. For example,
প + র (po + ro) gives প্র (pro).</p>

<p>But it’s not just র that does this in Bengali, the consonant “jo” does as well. প + য (po + jo) forms প্য (pjo),
and the য is transformed into a wavy line called a “jophola”.</p>

<p>So I tried it with য  — , and it turns out that the Bengali crash occurs for  য as well!
So the general Bengali case is &lt;consonant, virama, র OR য, ZWNJ, vowel&gt;, where the vowel is not   ো or  ৌ.</p>

<h2 id="suffix-joining-consonants">Suffix-joining consonants</h2>

<p>So we’re getting close, here. At least for Bengali, it occurs when the second consonant is such that it often
combines with the first consonant without modifying its form much.</p>

<p>In fact, this is the case for Telugu as well! Consonant clusters in Telugu are usually formed by preserving the
original consonant, and tacking the second consonant on below!</p>

<p>For example, the original crashy string contains the cluster జ + ఞ, which looks like జ్ఞ. The first letter isn’t
really modified, but the second is.</p>

<p>From this, we can guess that it will also occur for Devanagari with र. Indeed it does! U+0915 U+094D U+0930 U+200C U+093E, that is,
&lt;क,  ्, र, zwnj,  ा&gt; (&lt; ka, virama, ra, zwnj, aa &gt;) is one such crashing sequence.</p>

<p>But this isn’t really the whole story, is it? For example, the crash does occur for “kro” + zwnj + vowel in Bengali,
and in “kro” (ক্র = ক + র = ko + ro) the resultant cluster involves the munging of both the prefix and suffix. But
the crash doesn’t occur for द्ब or ड्ड. It seems to be specific to the letter, not the nature of the cluster.</p>

<p>Digging deeper, the reason is that for many fonts (presumably the ones in use), these consonants
form “suffix joining consonants”<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup> (a term I made up) when preceded by a virama. This seems to
correspond to the <a href="https://docs.microsoft.com/en-us/typography/opentype/spec/features_pt#tag-pstf"><code class="language-plaintext highlighter-rouge">pstf</code> OpenType feature</a>, as well as <a href="https://docs.microsoft.com/en-us/typography/opentype/spec/features_uz#vatu"><code class="language-plaintext highlighter-rouge">vatu</code></a>.</p>

<p>For example, the sequence virama + क gives   ्क, i.e. it renders a virama with a placeholder followed by a क.</p>

<p>But, for र, virama + र renders  ्र, which for me looks like this:</p>

<p><img class="center" src="/images/post/unicode-crash/virama-ra.png" width="200" /></p>

<p>In fact, this is the case for the other consonants as well. For me,  ्र  ্র  ্য  ్ఞ  ్క
(Devanagari virama-ra, Bengali virama-ro, Bengali virama-jo, Telugu virama-nya, Telugu virama-ka)
all render as “suffix joining consonants”:</p>

<p><img class="center" src="/images/post/unicode-crash/virama-consonant.png" width="200" /></p>

<p>(This is true for all Telugu consonants, not just the ones listed).</p>

<p>An interesting bit is that the crash does not occur for &lt;र, virama, र, zwnj, vowel&gt;, because र-virama-र
uses the prefix-joining form of the first र (र्र). The same occurs for র with itself or ৰ or য. Because the virama
is “stickier” to the left in these cases, it doesn’t cause a crash. (h/t <a href="https://github.com/hackbunny">hackbunny</a> for discovering this
using a <a href="https://github.com/hackbunny/viramarama">script</a> to enumerate all cases).</p>

<p>Kannada <em>also</em> has “suffix joining consonants”, but for some reason I cannot trigger the crash with it. Ya in Gurmukhi
is also suffix-joining.</p>

<h2 id="the-zwnj">The ZWNJ</h2>

<p>The ZWNJ is curious. The crash doesn’t happen without it, but as I mentioned before a ZWNJ before a vowel
doesn’t really <em>do</em> anything for most Indic scripts. In Indic scripts, a ZWNJ can be used to explicitly force a
virama if used after the virama (I used it to write स्‌की in this post), however that’s not how it’s being used here.</p>

<p>In Bengali and Oriya specifically, a ZWNJ can be used to force a different vowel form when used before a vowel
(e.g. রু vs র‌ু), however this bug seems to apply to vowels for which there is only one form, and this bug
also applies to other scripts where this isn’t the case anyway.</p>

<p>The exception vowels are interesting. They’re basically all vowels that are made up of <em>two</em> glyph components. Philippe Verdy
points out:</p>

<blockquote>
  <p>And why this bug does not occur with some vowels is because these are vowels in two parts,
that are first decomposed into two separate glyphs reordered in the buffer of glyphs, while
other vowels do not need this prior mapping and keep their initial direct mapping from their
codepoints in fonts, which means that this has to do to the way the ZWNJ looks for the glyphs
of the vowels in the glyphs buffer and not in the initial codepoints buffer: there’s some desynchronization,
and more probably an uninitialized data field (for the lookup made in handling ZWNJ) if no vowel decomposition was done
(the same data field is correctly initialized when it is the first consonnant which takes an alternate form before
a virama, like in most Indic consonnant clusters, because the a glyph buffer is created.</p>
</blockquote>

<h2 id="generalizing">Generalizing</h2>

<p>So, ultimately, the full set of cases that cause the crash are:</p>

<p>Any sequence <code class="language-plaintext highlighter-rouge">&lt;consonant1, virama, consonant2, ZWNJ, vowel&gt;</code> in Devanagari, Bengali, and Telugu, where:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">consonant2</code> is suffix-joining (<code class="language-plaintext highlighter-rouge">pstf</code>/<code class="language-plaintext highlighter-rouge">vatu</code>) – i.e. र, র, য, ৰ, and all Telugu consonants</li>
  <li><code class="language-plaintext highlighter-rouge">consonant1</code> is not a reph-forming letter like र/র (or a variant, like ৰ)</li>
  <li><code class="language-plaintext highlighter-rouge">vowel</code> does not have two glyph components, i.e. it is not   ై,   ো, or   ৌ</li>
</ul>

<p>This leaves one question open:</p>

<p>Why doesn’t it apply to Kannada? Or, for that matter, Khmer, which has a similar virama-like thing called a “coeng”?</p>

<h2 id="are-these-valid-strings">Are these valid strings?</h2>

<p>A recurring question I’m getting is if these strings are valid in the language, or unicode gibberish
like Zalgo text. Breaking it down:</p>

<ul>
  <li>All of the <em>rendered</em> glyphs are valid. The original Telugu one is the root of the word for
“knowledge” (and I’ve taken to calling this bug “forbidden knowledge” for that reason).</li>
  <li>In Telugu and Devanagari, there is no functional use of the ZWNJ as used before a vowel. It
should not be there, and one would not expect it in typical text.</li>
  <li>In Bengali (also Oriya), putting a ZWNJ before some vowels prevents them from ligatureifying, and this is
mentioned in the Unicode spec. However, it seems rare for native speakers to use this.</li>
  <li>In all of these scripts, putting a ZWNJ after viramas can be used to force an explicit virama
over a ligature. That is not the position ZWNJ is used here, but it gives a hint that this
might have been a mistype. Doing this is <em>also</em> rare at least for Devanagari (and I believe
for the other two scripts as well)</li>
  <li>Android has an explicit key for ZWNJ on its keyboards for these languages<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup>, right next to the spacebar. iOS has this as
well on the long-press of the virama key. <em>Very</em> easy to mistype, at least for Android.</li>
</ul>

<p>So while the crashing strings are usually invalid, and when not, very rare, they are easy enough to mistype.</p>

<p>An example by <a href="https://twitter.com/FakeUnicode">@FakeUnicode</a> was the string “For/k” (or “Foŕk”, if accents were easier to type). A
slash isn’t something you’d normally type there, and the produced string is gibberish, but it’s easy enough to type
by accident.</p>

<p>Except of course that the mistake in “For/k”/”Foŕk” is visually obvious and would be fixed; this
isn’t the case for most of the crashing strings.</p>

<h2 id="conclusion">Conclusion</h2>

<p>I don’t really have <em>one</em> guess as to what’s going on here – I’d love to see what people think – but my current
guess is that the “affinity” of the virama to the left instead of the right confuses the algorithm that handles ZWNJs after
viramas into thinking the ZWNJ applies to the virama (it doesn’t, there’s a consonant in between), and this leads to some numbers
not matching up and causing a buffer overflow or something. Philippe’s diagnosis of the vowel situation matches up with this.</p>

<p>An interesting thing is that I can cause this crash to happen more reliably in browsers by clicking on the string.</p>

<p>Additionally, <em>sometimes</em> it actually renders in spotlight for a split second before crashing; which
means that either the crash isn’t deterministic, or it occurs in some process <em>after</em> rendering. I’m
not sure what to think of either. Looking at the backtraces, the crash seems to occur in different
places, so it’s likely that it’s memory corruption that gets uncovered later.</p>

<p>I’d love to hear if folks have further insight into this.</p>

<p>Update: Philippe on the Unicode mailing list has <a href="https://www.unicode.org/mail-arch/unicode-ml/y2018-m02/0103.html">an interesting theory</a></p>

<p><small>Yes, I could attach a debugger to the crashing process and investigate that instead, but that’s no fun 😂</small></p>
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>Philippe Verdy points out that these may be called “phala forms” at least for Bengali <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>I don’t think the Android keyboard <em>needs</em> this key; the keyboard seems very much a dump of “what does this unicode block let us do”, and includes things like Sindhi-specific or Kashmiri-specific characters for the Marathi keyboard as well as <em>extremely</em> archaic characters, whilst neglecting more common things like the eyelash reph (which doesn’t have its own code point but is a special unicode sequence; native speakers should not be expected to be aware of this sequence). <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name>Manish Goregaokar</name></author><category term="programming" /><category term="unicode" /><summary type="html"><![CDATA[So there’s yet another iOS text crash, where just looking at a particular string crashes iOS. Basically, if you put this string in any system text box (and other places), it crashes that process. I’ve been testing it by copy-pasting characters into Spotlight so I don’t end up crashing my browser. The original sequence is U+0C1C U+0C4D U+0C1E U+200C U+0C3E, which is a sequence of Telugu characters: the consonant ja (జ), a virama ( ్ ), the consonant nya (ఞ), a zero-width non-joiner, and the vowel aa ( ా). I was pretty interested in what made this sequence “special”, and started investigating. So first when looking into this, I thought that the &lt;ja, virama, nya&gt; sequence was the culprit. That sequence forms a special ligature in many Indic scripts (ज्ञ in Devanagari) which is often considered a letter of its own. However, the ligature for Telugu doesn’t seem very “special”. Also, from some experimentation, this bug seemed to occur for any pair of Telugu consonants with a vowel, as long as the vowel is not   ై (ai). Huh. The ZWNJ must be doing something weird, then. &lt;consonant, virama, consonant, vowel&gt; is a pretty common sequence in any Indic script; but ZWNJ before a vowel isn’t very useful for most scripts (except for Bengali and Oriya, but I’ll get to that). And then I saw that there was a sequence in Bengali that also crashed. The sequence is U+09B8 U+09CD U+09B0 U+200C U+09C1, which is the consonant “so” (স), a virama ( ্ ), the consonant “ro” (র), a ZWNJ, and vowel u (  ু). Before we get too into this, let’s first take a little detour to learn how Indic scripts work: Indic scripts and consonant clusters Indic scripts are abugidas; which means that their “letters” are consonants, which you can attach diacritics to to change the vowel. By default, consonants have a base vowel. So, for example, क is “kuh” (kə, often transcribed as “ka”), but I can change the vowel to make it के (the “ka” in “okay”) का (“kaa”, like “car”). Usually, the default vowel is the ə sound, though not always (in Bengali it’s more of an o sound). Because of the “default” vowel, you need a way to combine consonants. For example, if you wished to write the word “ski”, you can’t write it as स + की (sa + ki = “saki”), you must write it as स्की. What’s happened here is that the स got its vowel “killed”, and got tacked on to the की to form a consonant cluster ligature. You can also write this as स्‌की . That little tail you see on the स is known as a “virama”; it basically means “remove this vowel”. Explicit viramas are sometimes used when there’s no easy way to form a ligature, e.g. in ङ्‌ठ because there is no simple way to ligatureify ङ into ठ. Some scripts also prefer explicit viramas, e.g. “ski” in Malayalam is written as സ്കീ, where the little crescent is the explicit virama. In unicode, the virama character is always used to form a consonant cluster. So स्की was written as &lt;स,  ्, क,  ी&gt;, or &lt;sa, virama, ka, i&gt;. If the font supports the cluster, it will show up as a ligature, otherwise it will use an explicit virama. For Devanagari and Bengali, usually, in a consonant cluster the first consonant is munged a bit and the second consonant stays intact. There are exceptions – sometimes they’ll form an entirely new glyph (क + ष = क्ष), and sometimes both glyphs will change (ड + ड = ड्ड, द + म = द्म, द + ब = द्ब). Those last ones should look like this in conjunct form: Investigating the Bengali case Now, interestingly, unlike the Telugu crash, the Bengali crash seemed to only occur when the second consonant is র (“ro”). However, I can trigger it for any choice of the first consonant or vowel, except when the vowel is  ো (o) or  ৌ (au). Now, র is an interesting consonant in some Indic scripts, including Devanagari. In Devanagari, it looks like र (“ra”). However, it does all kinds of things when forming a cluster. If you’re having it precede another consonant in a cluster, it forms a little feather-like stroke, like in र्क (rka). In Marathi, that stroke can also look like a tusk, as in र्‍क. As a suffix consonant, it can provide a little “extra leg”, as in क्र (kra). For letters without a vertical stroke, like ठ (tha), it does this caret-like thing, ठ्र (thra). Basically, while most consonants retain some of their form when put inside a cluster, र does not. And a more special thing about र is that this happens even when र is the second consonant in a cluster – as I mentioned before, for most consonant clusters the second consonant stays intact. While there are exceptions, they are usually specific to the cluster; it is only र for which this happens for all clusters. It’s similar in Bengali, র as the second consonant adds a tentacle-like thing on the existing consonant. For example, প + র (po + ro) gives প্র (pro). But it’s not just র that does this in Bengali, the consonant “jo” does as well. প + য (po + jo) forms প্য (pjo), and the য is transformed into a wavy line called a “jophola”. So I tried it with য — , and it turns out that the Bengali crash occurs for য as well! So the general Bengali case is &lt;consonant, virama, র OR য, ZWNJ, vowel&gt;, where the vowel is not  ো or  ৌ. Suffix-joining consonants So we’re getting close, here. At least for Bengali, it occurs when the second consonant is such that it often combines with the first consonant without modifying its form much. In fact, this is the case for Telugu as well! Consonant clusters in Telugu are usually formed by preserving the original consonant, and tacking the second consonant on below! For example, the original crashy string contains the cluster జ + ఞ, which looks like జ్ఞ. The first letter isn’t really modified, but the second is. From this, we can guess that it will also occur for Devanagari with र. Indeed it does! U+0915 U+094D U+0930 U+200C U+093E, that is, &lt;क,  ्, र, zwnj,  ा&gt; (&lt; ka, virama, ra, zwnj, aa &gt;) is one such crashing sequence. But this isn’t really the whole story, is it? For example, the crash does occur for “kro” + zwnj + vowel in Bengali, and in “kro” (ক্র = ক + র = ko + ro) the resultant cluster involves the munging of both the prefix and suffix. But the crash doesn’t occur for द्ब or ड्ड. It seems to be specific to the letter, not the nature of the cluster. Digging deeper, the reason is that for many fonts (presumably the ones in use), these consonants form “suffix joining consonants”1 (a term I made up) when preceded by a virama. This seems to correspond to the pstf OpenType feature, as well as vatu. For example, the sequence virama + क gives   ्क, i.e. it renders a virama with a placeholder followed by a क. But, for र, virama + र renders  ्र, which for me looks like this: In fact, this is the case for the other consonants as well. For me,  ्र  ্র  ্য  ్ఞ  ్క (Devanagari virama-ra, Bengali virama-ro, Bengali virama-jo, Telugu virama-nya, Telugu virama-ka) all render as “suffix joining consonants”: (This is true for all Telugu consonants, not just the ones listed). An interesting bit is that the crash does not occur for &lt;र, virama, र, zwnj, vowel&gt;, because र-virama-र uses the prefix-joining form of the first र (र्र). The same occurs for র with itself or ৰ or য. Because the virama is “stickier” to the left in these cases, it doesn’t cause a crash. (h/t hackbunny for discovering this using a script to enumerate all cases). Kannada also has “suffix joining consonants”, but for some reason I cannot trigger the crash with it. Ya in Gurmukhi is also suffix-joining. The ZWNJ The ZWNJ is curious. The crash doesn’t happen without it, but as I mentioned before a ZWNJ before a vowel doesn’t really do anything for most Indic scripts. In Indic scripts, a ZWNJ can be used to explicitly force a virama if used after the virama (I used it to write स्‌की in this post), however that’s not how it’s being used here. In Bengali and Oriya specifically, a ZWNJ can be used to force a different vowel form when used before a vowel (e.g. রু vs র‌ু), however this bug seems to apply to vowels for which there is only one form, and this bug also applies to other scripts where this isn’t the case anyway. The exception vowels are interesting. They’re basically all vowels that are made up of two glyph components. Philippe Verdy points out: And why this bug does not occur with some vowels is because these are vowels in two parts, that are first decomposed into two separate glyphs reordered in the buffer of glyphs, while other vowels do not need this prior mapping and keep their initial direct mapping from their codepoints in fonts, which means that this has to do to the way the ZWNJ looks for the glyphs of the vowels in the glyphs buffer and not in the initial codepoints buffer: there’s some desynchronization, and more probably an uninitialized data field (for the lookup made in handling ZWNJ) if no vowel decomposition was done (the same data field is correctly initialized when it is the first consonnant which takes an alternate form before a virama, like in most Indic consonnant clusters, because the a glyph buffer is created. Generalizing So, ultimately, the full set of cases that cause the crash are: Any sequence &lt;consonant1, virama, consonant2, ZWNJ, vowel&gt; in Devanagari, Bengali, and Telugu, where: consonant2 is suffix-joining (pstf/vatu) – i.e. र, র, য, ৰ, and all Telugu consonants consonant1 is not a reph-forming letter like र/র (or a variant, like ৰ) vowel does not have two glyph components, i.e. it is not   ై,   ো, or   ৌ This leaves one question open: Why doesn’t it apply to Kannada? Or, for that matter, Khmer, which has a similar virama-like thing called a “coeng”? Are these valid strings? A recurring question I’m getting is if these strings are valid in the language, or unicode gibberish like Zalgo text. Breaking it down: All of the rendered glyphs are valid. The original Telugu one is the root of the word for “knowledge” (and I’ve taken to calling this bug “forbidden knowledge” for that reason). In Telugu and Devanagari, there is no functional use of the ZWNJ as used before a vowel. It should not be there, and one would not expect it in typical text. In Bengali (also Oriya), putting a ZWNJ before some vowels prevents them from ligatureifying, and this is mentioned in the Unicode spec. However, it seems rare for native speakers to use this. In all of these scripts, putting a ZWNJ after viramas can be used to force an explicit virama over a ligature. That is not the position ZWNJ is used here, but it gives a hint that this might have been a mistype. Doing this is also rare at least for Devanagari (and I believe for the other two scripts as well) Android has an explicit key for ZWNJ on its keyboards for these languages2, right next to the spacebar. iOS has this as well on the long-press of the virama key. Very easy to mistype, at least for Android. So while the crashing strings are usually invalid, and when not, very rare, they are easy enough to mistype. An example by @FakeUnicode was the string “For/k” (or “Foŕk”, if accents were easier to type). A slash isn’t something you’d normally type there, and the produced string is gibberish, but it’s easy enough to type by accident. Except of course that the mistake in “For/k”/”Foŕk” is visually obvious and would be fixed; this isn’t the case for most of the crashing strings. Conclusion I don’t really have one guess as to what’s going on here – I’d love to see what people think – but my current guess is that the “affinity” of the virama to the left instead of the right confuses the algorithm that handles ZWNJs after viramas into thinking the ZWNJ applies to the virama (it doesn’t, there’s a consonant in between), and this leads to some numbers not matching up and causing a buffer overflow or something. Philippe’s diagnosis of the vowel situation matches up with this. An interesting thing is that I can cause this crash to happen more reliably in browsers by clicking on the string. Additionally, sometimes it actually renders in spotlight for a split second before crashing; which means that either the crash isn’t deterministic, or it occurs in some process after rendering. I’m not sure what to think of either. Looking at the backtraces, the crash seems to occur in different places, so it’s likely that it’s memory corruption that gets uncovered later. I’d love to hear if folks have further insight into this. Update: Philippe on the Unicode mailing list has an interesting theory Yes, I could attach a debugger to the crashing process and investigate that instead, but that’s no fun 😂 Philippe Verdy points out that these may be called “phala forms” at least for Bengali &#8617; I don’t think the Android keyboard needs this key; the keyboard seems very much a dump of “what does this unicode block let us do”, and includes things like Sindhi-specific or Kashmiri-specific characters for the Marathi keyboard as well as extremely archaic characters, whilst neglecting more common things like the eyelash reph (which doesn’t have its own code point but is a special unicode sequence; native speakers should not be expected to be aware of this sequence). &#8617;]]></summary></entry></feed>