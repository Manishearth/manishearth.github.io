
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>In Pursuit of Laziness</title>
  <meta name="author" content="Manish Goregaokar">

  
  <meta name="description" content="This post was originally drafted in August 2018, but I never got around to finishing it. As such, parts of its framing (e.g. the focus on bindgen) &hellip;">
  
  <!-- Tweaked https://harimenon.com/blog/2013/02/23/twitter-cards-for-octopress-blogs/ -->
  
      <meta property="twitter:card" content="summary">
      <meta property="twitter:site" content="Manishearth">
      <meta property="twitter:url" content="http://manishearth.github.io">
      <meta property="twitter:title" content="In Pursuit of Laziness">
      <meta property="twitter:description" content="This post was originally drafted in August 2018, but I never got around to finishing it. As such, parts of its framing (e.g. the focus on bindgen) are outdated, given the relative infancy of the &hellip;">
      <meta name="twitter:image" content="http://manishearth.github.io/images/me.png" />
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://manishearth.github.io/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/stylesheets/data-table.css" media="screen, projection" rel="stylesheet" type="text/css" />
  <link href="/stylesheets/custom.css" media="screen, projection" rel="stylesheet" type="text/css" />
  <link href="/atom.xml" rel="alternate" title="In Pursuit of Laziness" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="/javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <script src="/javascripts/manish.js" type="text/javascript"></script>
  <!--- MathJax Configuration -->
  
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-62537162-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">In Pursuit of Laziness</a></h1>
  
    <h2>Manish Goregaokar's blog</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="sitesearch" value="manishearth.github.io">
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2021/02/22/integrating-rust-and-c-plus-plus-in-firefox/">Integrating Rust and C++ in Firefox</a></h1>
    
    
      <p class="meta">
        





        
      </p>
    
  </header>


  <div class="entry-content"><p><em>This post was originally drafted in August 2018, but I never got around to finishing it. As such, parts of its framing (e.g. the focus on bindgen) are outdated, given the relative infancy of the interop space at the time. I was recently told that the post is still useful in this form so I decided to finish and publish it anyway, while attempting to mark outdated things as such when I notice them. Everything after the allocators section was written near the time of publication.</em></p>

<p>In 2017 I worked on the <a href="https://hacks.mozilla.org/2017/08/inside-a-super-fast-css-engine-quantum-css-aka-stylo/">Stylo</a> project, uplifting Servo’s CSS engine (“style system”) into Firefox’s browser engine
(“Gecko”). This involved a <em>lot</em> of gnarly FFI between Servo’s Rust codebase and Firefox’s C++ codebase. There were a
lot of challenges in doing this, and I feel like it’s worth sharing things from our experiences.</p>

<p>If you’re interested in Rust integrations, you may find <a href="https://www.youtube.com/watch?v=x9acx2zgx4Q">this talk by Katharina on Rust - C++ FFI</a>, and <a href="https://hsivonen.fi/modern-cpp-in-rust/">this blog post by Henri on integrating encoding-rs into Firefox</a> useful as well.</p>

<h2 id="who-is-this-post-for">Who is this post for?</h2>

<p>So, first off the bat, I’ll mention that when integrating Rust into a C++ codebase, you
want to <em>avoid</em> having integrations as tight as Stylo. Don’t do what we did; make your Rust
component mostly self-contained so that you just have to maintain something like ten FFI functions
for interacting with it. If this is possible to do, you should do it and your life will be <em>much</em> easier. Pick a clean API boundary, define a straightforward API, use cbindgen or bindgen if necessary without any tricks, and you should be good to go.</p>

<p>That said, sometimes you <em>have</em> to have gnarly integrations, and this blog post is for those use cases.
These techniques mostly use bindgen in their examples, however you can potentially use them with hand-rolled bindings or another tool as well. If you’re at this level of complexity, however, the potential for mistakes in the hand-rolled bindings is probably not worth it.</p>

<p><em>Note from 2021: <a href="https://github.com/dtolnay/cxx">cxx</a> is probably a better tool for many of the use cases here, though many of the techniques still transfer.</em></p>

<h2 id="what-was-involved-in-stylos-ffi">What was involved in Stylo’s FFI?</h2>

<p>So, what made Stylo’s FFI so complicated?</p>

<p>It turns out that browsers are quite monolithic. You can split them into vaguely-defined components, but
these components are still tightly integrated. If you intend to replace a component, you may need to
make a jagged edge of an integration surface.</p>

<p>The style system is more self-contained than other parts, but it’s still quite tightly integrated.</p>

<p>The main job of a “style system” is to take the CSS rules and DOM tree, and run them through “the cascade”<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">1</a></sup>
with an output of “computed styles” tagged on each node in the tree. So, for example, it will take a document like
the following:</p>

<pre><code class="language-html">&lt;style type="text/css"&gt;
    body {
        font-size: 12px;
    }
    div {
        height: 2em;
    }
&lt;/style&gt;
&lt;body&gt;
    &lt;div id="foo"&gt;&lt;/div&gt;

&lt;/body&gt;
</code></pre>

<p>and turn it into something like:</p>

<ul>
  <li><code>&lt;body&gt;</code> has a <code>font-size</code> of <code>12px</code>, everything else is the default</li>
  <li>the <code>div</code> <code>#foo</code> has a computed <code>height</code> of <code>24px</code> <sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote">2</a></sup>, everything else is the default. It “inherits” the <code>font-size</code> from <code>&lt;body&gt;</code> as <code>12px</code></li>
</ul>

<p>From a code point of view, this means that Stylo takes in Gecko’s C++ DOM tree. It parses all the CSS,
and then runs the cascade on the tree. It stores computed styles on each element in a way that Gecko can read
very cheaply.</p>

<p>Style computation can involve some complex steps that require calling back into C++ code. Servo’s style system
is multithreaded, but Gecko is mostly designed to work off of a single main thread per process, so we need to
deal with this impedence mismatch.</p>

<p>Since the output of Stylo is C++-readable structs, Stylo needs to be able to read and write nontrivial C++
abstractions. Typical FFI involves passing values over a boundary, never to be seen again, however here we’re
dealing with persistent state that is accessed by both sides.</p>

<p>To sum up, we have:</p>

<ul>
  <li>Lots and lots of back-and-forth FFI</li>
  <li>Thread safety concerns</li>
  <li>Rust code regularly dealing with nontrivial C++ abstractions</li>
  <li>A need for nontrivial abstractions to be passed over FFI</li>
</ul>

<p>All of this conspires to make for some really complicated FFI code.</p>

<h1 id="the-actual-techniques">The actual techniques</h1>

<p>I’ll try to structure this so that the more broadly useful (and/or less gnarly) techniques come earlier in the post.</p>

<h2 id="the-basics-of-bindgen">The basics of bindgen</h2>

<p><a href="https://github.com/rust-lang-nursery/rust-bindgen/">Bindgen</a> is a tool that generates Rust bindings for structs and functions from the provided C or C++ header files. It’s often used for writing Rust bindings to existing C/C++ libraries, however it’s useful for integrations as well.</p>

<p>To use it for an integration, write a header file containing the functions your Rust code needs (referencing structs from other header files if necessary), and <a href="https://rust-lang-nursery.github.io/rust-bindgen/command-line-usage.html">run bindgen on it</a>. For some codebases, doing this once and
checking in the generate file suffices, but if your C++ code is going to change a lot, <a href="https://rust-lang-nursery.github.io/rust-bindgen/tutorial-1.html">run it as a build dependency instead</a>. Beware that this can adversely impact build times, since your Rust build now has a partial
C++ compilation step.</p>

<p>For large C++ codebases, pulling in a single header will likely pull in a <em>lot</em> of stuff. You should <a href="https://rust-lang.github.io/rust-bindgen/allowlisting.html">allowlist</a>, <a href="https://rust-lang.github.io/rust-bindgen/blocklisting.html">blocklist</a>, and/or mark things as <a href="https://rust-lang.github.io/rust-bindgen/opaque.html">opaque</a> to reduce the amount of bindings generated. It’s best to go the allowlisting route — give bindgen an allowlisted list of functions / structs to generate bindings for, and it will transitively generate bindings for any dependencies they may have. Sometimes even this will end up generating a lot, it’s sometimes worth finding structs you’re not using and marking them as opaque so that their bindings aren’t necessary. Marking something as opaque replaces it with an array of the appropriate size and alignment, so from the Rust side it’s just some bits you don’t care about and can’t introspect further.</p>

<p>Bindgen <a href="https://rust-lang-nursery.github.io/rust-bindgen/cpp.html"><em>does</em> support some C++ features</a> (you may need to pass <code>-x c++</code>). This is pretty good for generating bindings to e.g. templated structs. However, it’s not possible to support <em>all</em> C++ features here, so you may need to blocklist, opaqueify, or use intermediate types if you have some complicated C++ abstractions in the deps. You’ll typically get an error when generating bindings or when compiling the generated bindings, so don’t worry about this unless that happens.</p>

<p>Bindgen is <em>quite</em> configurable. Stylo has a <a href="https://searchfox.org/mozilla-central/rev/819cd31a93fd50b7167979607371878c4d6f18e8/servo/components/style/build_gecko.rs">script</a> that consumes a <a href="https://searchfox.org/mozilla-central/source/layout/style/ServoBindings.toml">large toml file</a> containing all of the configuration.</p>

<h2 id="cbindgen">cbindgen</h2>

<p>We don’t use <a href="https://github.com/eqrion/cbindgen">cbindgen</a> in Stylo, but it’s used for Webrender. It does the inverse of what bindgen does: given a Rust crate, it generates C headers for its public <code>extern "C"</code> API. It’s also quite configurable.</p>

<h2 id="cxx">cxx</h2>

<p><a href="https://github.com/dtolnay/cxx">cxx</a> is the cool new hotness in 2021, which kind of approaches the problem from both sides, enabling you to write Rust bindings for C++ and C++ bindings for Rust. It’s definitely worth checking out, a lot of the things that are hard to make work with bindgen are trivial in cxx. For example, it automatically figures out what types need to be opaque, it automatically converts between <code>&amp;T</code> and <code>T*</code> across FFI, and it is overall more targeted for the use case of an FFI layer where Rust and C++ both call each other.</p>

<h2 id="bindgen-aided-c-calling-rust">Bindgen-aided C++ calling Rust</h2>

<p>So bindgen helps with creating things for Rust to call and manipulate, but not in the opposite direction. cbindgen can help here, but I’m not sure if it’s advisable to have <em>both</em> bindgen and cbindgen operating near each other on the same codebase.</p>

<p>In Stylo we use a bit of a hack for this. Firstly, all FFI functions defined in C++ that Rust calls are declared in <a href="https://searchfox.org/mozilla-central/rev/819cd31a93fd50b7167979607371878c4d6f18e8/layout/style/ServoBindingList.h">one file</a>, and are all named <code>Gecko_*</code>. Bindgen supports regexes for things like allowlisting, so this naming scheme makes it easy to deal with.</p>

<p>We also declare the FFI functions defined in Rust that C++ calls in <a href="https://searchfox.org/mozilla-central/rev/819cd31a93fd50b7167979607371878c4d6f18e8/layout/style/ServoBindingList.h">another file</a>, named <code>Servo_*</code>. They’re also all <a href="https://searchfox.org/mozilla-central/rev/819cd31a93fd50b7167979607371878c4d6f18e8/servo/ports/geckolib/glue.rs">defined in one place</a>.</p>

<p>However, there’s nothing ensuring that the signatures match! If we’re not careful, there may be mismatches, causing bad things to happen at link time or runtime. We use a small <a href="https://searchfox.org/mozilla-central/rev/819cd31a93fd50b7167979607371878c4d6f18e8/servo/ports/geckolib/tests/build.rs">autogenerated</a> <a href="https://searchfox.org/mozilla-central/rev/819cd31a93fd50b7167979607371878c4d6f18e8/servo/ports/geckolib/tests/servo_function_signatures.rs">unit test</a> to ensure the validity of the signatures.</p>

<p>This is especially important as we do things like type replacement, and we need tests to ensure that the rug isn’t pulled out from underneath us.</p>

<h2 id="type-replacing-for-fun-and-profit">Type replacing for fun and profit</h2>

<p>Using <a href="https://rust-lang.github.io/rust-bindgen/blocklisting.html">blocklisting</a> in conjunction with the <code>--raw-line</code>/<code>raw_line()</code> flag, one can effectively ask bindgen to “replace” types. Blocklisting asks bindgen not to generate bindings for a type, however bindgen will continue to generate bindings <em>referring</em> to that type if necessary. (Unlike opaque types where bindgen generates an opaque binding for the type and uses it everywhere). <code>--raw-line</code> lets you request bindgen to add a line of raw rust code to the file, and such a line can potentially define or import a new version of the type you blocklisted. Effectively, this lets you replace types.</p>

<p>Bindgen generates unit tests ensuring that the layout of your structs is correct (run them!), so if you accidentally replace a type with something incompatible, you will get warnings at the struct level (functions may not warn).</p>

<p>There are various ways this can be used:</p>

<h3 id="safe-references-across-ffi">Safe references across FFI</h3>

<p><em>Note from 2021: <a href="https://github.com/dtolnay/cxx">cxx</a> does this automatically</em></p>

<p>Calling into C++ (and accepting data from C++) is unsafe. However, there’s no reason we should have to worry about this more than we have to. For example, it would be nice if accessor FFI functions – functions which take a foreign object and return something from inside it –  could use lifetimes. It would be even nicer if nullability were represented on the FFI boundary so that you don’t miss null checks, and can assume non-nullness when the C++ API is okay with it.</p>

<p>In Stylo, we have lots of functions like the following:</p>

<pre><code class="language-cpp">RawGeckoNodeBorrowedOrNull Gecko_GetLastChild(RawGeckoNodeBorrowed node);
</code></pre>

<p>which bindgen translates to:</p>

<pre><code class="language-rust">extern "C" {
    fn Gecko_GetLastChild(x: &amp;RawGeckoNode) -&gt; Option&lt;&amp;RawGeckoNode&gt;;   
}
</code></pre>

<p>Using the <a href="https://searchfox.org/mozilla-central/rev/819cd31a93fd50b7167979607371878c4d6f18e8/servo/components/style/build_gecko.rs">bindgen build script</a> on a provided <a href="https://searchfox.org/mozilla-central/rev/819cd31a93fd50b7167979607371878c4d6f18e8/layout/style/ServoBindings.toml#648-671">list of borrow-able types</a>, we’ve told bindgen that:</p>

<ul>
  <li><code>FooBorrowedOrNull</code> is actually <code>Option&lt;&amp;Foo&gt;</code></li>
  <li><code>FooBorrowed</code> is actually <code>&amp;Foo</code></li>
</ul>

<p><code>Option&lt;&amp;Foo&gt;</code> <a href="https://doc.rust-lang.org/nomicon/repr-rust.html">is represented as a single nullable pointer in Rust</a>, so this is a clean translation. 
We’re forced to null-check it, but once we do we can safely assume that the reference is valid. Furthermore, due to lifetime elision the actual signature of the FFI function is <code>fn Gecko_GetLastChild&lt;'a&gt;(x: &amp;'a RawGeckoNode) -&gt; Option&lt;&amp;'a RawGeckoNode&gt;</code>, which ensures we won’t let the returned reference outlive the passed reference. Lifetime elision means that we can call C++ functions “safely” with the appropriate lifetime requirements, even though C++ has no such concept!</p>

<p>Note that this is shifting some of the safety invariants to the C++ side: We rely on the C++ to give us valid references, and we rely on it to not have nulls when the type is not marked as nullable. Most C++ codebases internally rely on such invariants for safety anyway, so this isn’t much of a stretch.</p>

<p>We do this on both sides, actually: Many of our Rust-defined <code>extern "C"</code> functions that C++ calls get to be internally-safe because the types let us assume the validity of the pointers obtained from C++.</p>

<h3 id="making-c-abstractions-rust-accessible">Making C++ abstractions Rust-accessible</h3>

<p>A very useful thing to do here is to replace various C++ abstractions with Rust versions of them that share semantics. In Gecko, most strings are stored in <code>nsString</code>/<code>nsAString</code>/etc.</p>

<p>We’ve written an <a href="https://searchfox.org/mozilla-central/rev/6ddb5fb144993fb5de044e2e8d900d7643b98a4d/servo/support/gecko/nsstring/src/lib.rs">nsstring</a> crate that represents layout-compatible <code>nsString</code>s in a more Rusty way, with Rusty APIs. We then ask bindgen to replace Gecko <code>nsString</code>s with these.</p>

<p>Usually it’s easier to just write an impl for the bindgen-generated abstraction, however sometimes you must replace it:</p>

<ul>
  <li>When the abstraction internally does a lot of template stuff not supported by bindgen</li>
  <li>When you want the code for the abstraction to be in a separate crate</li>
</ul>

<h2 id="potential-pitfall-passing-c-classes-by-value-over-ffi">Potential pitfall: Passing C++ classes by-value over FFI</h2>

<p>It’s quite tempting to do stuff like</p>

<pre><code class="language-cpp">RefPtr&lt;Foo&gt; Servo_Gimme(...);
</code></pre>

<p>where you pass complicated classes by-value over FFI (<code>RefPtr</code> is Gecko’s variant of <code>Rc&lt;T&gt;</code>/<code>Arc&lt;T&gt;</code>).</p>

<p>This works on some systems, but is broken on MSVC:
<a href="https://github.com/rust-lang/rust/issues/38258">The ABI for passing non-POD types through functions is different</a>. The linker usually notices this and complains, but it’s worth avoiding this entirely.</p>

<p>In Stylo we handle this by using some macro-generated intermediate types which are basically the same thing as the original class but without any constructors/destructors/operators. We convert to/from these types immediately before/after the FFI call, and on the Rust side we do similar conversions to Rust-compatible abstractions.</p>

<h2 id="sharing-abstractions-with-destructors">Sharing abstractions with destructors</h2>

<p>If you’re passing ownership of collections or other templated types across FFI, you probably want Rust code to be able to destroy C++ objects, and vice versa.</p>

<p>One way of doing this is to implement <code>Drop</code> on the generated struct. If you have <code>class MyString</code>, you can do:</p>

<pre><code class="language-cpp">class MyString {
    // ...
    ~MyString();
}

void MyString_Destroy(*MyString x) {
    x-&gt;~MyString()
}
</code></pre>

<pre><code class="language-rust">impl Drop for bindings::MyString {
    fn drop(&amp;mut self) {
        // (bindgen only)
        bindings::MyString::destruct(self)
        // OR
        bindings::MyString_Destroy(self)
    }
}
</code></pre>

<p>The <code>MyString_Destroy</code> isn’t necessary with bindgen – bindgen will generate a <code>MyString::destruct()</code> function for you – but be careful, this will make your generated bindings very platform-specific, so be sure to only do this if running them at build time. In general, when bindgen generates C++ <em>methods</em>, your bindings become platform specific and are best regenerated at build time<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" class="footnote">3</a></sup>.</p>

<p>In Stylo we went down the route of manually defining <code>_Destroy()</code> functions since we started off with checked-in platform-agnostic bindings, however we could probably switch to using <code>destruct()</code> if we want to now.</p>

<p>When it comes to generic types, it’s a bit trickier, since <code>Drop</code> can’t be implemented piecewise on a generic type (you cannot <code>impl Drop for MyVector&lt;Foo&gt;</code>). You have to do something like:</p>

<pre><code class="language-cpp">template&lt;typename T&gt;
class MyVector {
    // ...
}

// Deallocate buffer, but do not call destructors on elements
void MyVector_Deallocate_Buffer(MyVector&lt;void&gt;* x);
</code></pre>

<pre><code class="language-rust">// assume we have an implementation of Iterator for MyVector&lt;T&gt; somewhere

impl&lt;T&gt; Drop for bindings::MyVector&lt;T&gt; {
    fn drop(&amp;mut self) {
        for v in self.iter_mut() {
            // calls the destructor for `v`, if any
            std::ptr::drop_in_place(v)
        }
        bindings::MyVector_Deallocate_Buffer(self as *mut MyVector&lt;T&gt; as *mut MyVector&lt;c_void&gt;)
    }
}

</code></pre>

<p>Note that if you forget to add a <code>Drop</code> implementation for <code>T</code>, this will silently forget to clean up the contents of the vector. See <a href="#mirror-types">the next section</a> for some ways to handle this by creating a “safe” mirror type.</p>

<h2 id="mirror-types">Mirror types</h2>

<p>C++ libraries often have useful templated abstractions, and it’s nice to be able to manipulate them from Rust. Sometimes, it’s possible to just tack on semantics on the Rust side (either by adding an implementation or by doing type replacement), but in some cases this is tricky.</p>

<p>For example, Gecko has <code>RefPtr&lt;T&gt;</code>, which is similar to <code>Rc&lt;T&gt;</code>, except the actual refcounting logic is up to <code>T</code> to implement (it can choose between threadsafe, non-threadsafe, etc), which it does by writing <code>AddRef()</code> and <code>Release()</code> methods.</p>

<p>We mirror this in Rust by having a trait:</p>

<pre><code class="language-rust">/// Trait for all objects that have Addref() and Release
/// methods and can be placed inside RefPtr&lt;T&gt;
pub unsafe trait RefCounted {
    /// Bump the reference count.
    fn addref(&amp;self);
    /// Decrease the reference count.
    unsafe fn release(&amp;self);
}

/// A custom RefPtr implementation to take into account Drop semantics and
/// a bit less-painful memory management.
pub struct RefPtr&lt;T: RefCounted&gt; {
    ptr: *mut T,
    _marker: PhantomData&lt;T&gt;,
}
</code></pre>

<p>We implement the <code>RefCounted</code> trait for C++ types that are wrapped in <code>RefPtr</code> which we wish to access through Rust. We have <a href="https://searchfox.org/mozilla-central/rev/cfaa5a1d48d6bc6552199e73004ecb05d0a9c921/servo/components/style/gecko_bindings/sugar/refptr.rs#258-315">some</a> <a href="https://searchfox.org/mozilla-central/rev/cfaa5a1d48d6bc6552199e73004ecb05d0a9c921/layout/style/GeckoBindings.h#52-60">macros</a> that make this easier to do. We have to have such a trait, because otherwise Rust code wouldn’t know how to manage various C++ types.</p>

<p>However, <code>RefPtr&lt;T&gt;</code> here can’t be the type that ends up being used in bindgen. Rust doesnt let us do things like <code>impl&lt;T: RefCounted&gt; Drop for RefPtr&lt;T&gt;</code> <sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote">4</a></sup>, so we can’t effectively make this work with the bindgen generated type unless we write a <code>RefCounted</code> implementation for every refcounted type that shows up in the bindgen output at all – which would be a lot of work.</p>

<p>Instead, we let bindgen generate its own <code>RefPtr&lt;T&gt;</code>, called <code>structs::RefPtr&lt;T&gt;</code> (all the structs that bindgen generates for Gecko go in a <code>structs::</code> module). <code>structs::RefPtr&lt;T&gt;</code> itself doesn’t have enough semantics to be something we can pass around willy-nilly in Rust code without causing leaks. However, it has <a href="https://searchfox.org/mozilla-central/rev/cfaa5a1d48d6bc6552199e73004ecb05d0a9c921/servo/components/style/gecko_bindings/sugar/refptr.rs#150-234">some methods</a> that allow for conversion into the “safe” mirror <code>RefPtr&lt;T&gt;</code> (but only if <code>T: RefCounted</code>). So if you need to manipulate a <code>RefPtr&lt;T&gt;</code> in a C++ struct somewhere, you immediately use one of the conversion methods to get a safe version of it first, and <em>then</em> do things to it. Refcounted types that don’t have the <code>RefCounted</code> implementation won’t have conversion methods: they may exist in the data you’re manipulating, however you won’t be able to work with them.</p>

<p>In general, whenever attaching extra semantics to generic bindgen types doesn’t work create a mirror type that’s completely safe to use from Rust, with a trait that gates conversion to the mirror type.</p>

<h2 id="potential-pitfall-allocators">Potential pitfall: Allocators</h2>

<p>If you’re passing heap-managed abstractions across FFI, be careful about which code frees which objects. If your Rust
and C++ code don’t share allocators, deallocating memory allocated on the other side can have disastrous consequences.</p>

<p>If you’re building a cdylib or staticlib with Rust (this is likely if you’re linking it with a C++ application), the compiler will by default pick the system allocator (<code>malloc</code>), so if your C++ application also uses the same you’re all set.</p>

<p>On some platforms when building rlibs and binaries, Rust may choose jemalloc instead. It’s also possible that your C++ code uses a different allocator (lots of applications use allocators like jemalloc or tcmalloc, some have their own custom allocators like <code>tor_malloc</code> in Tor).</p>

<p>In such cases you have one of three options:</p>

<ul>
  <li>Avoid transferring ownership of heap-allocated items, only share things as borrowed references</li>
  <li>Call destructors over FFI, as detailed in <a href="#sharing-abstractions-with-destructors">the section on destructors above</a></li>
  <li>Set Rust’s allocator to be the same as documented <a href="https://doc.rust-lang.org/nightly/std/alloc/#the-global_allocator-attribute">in the <code>std::alloc</code> module</a>. Basically, can use the <code>#[global_allocator]</code> attribute to select which allocator you wish to use, and if necessary you can implement the <code>GlobalAlloc</code> trait on a custom allocator type that calls into whatever custom allocator C++ is using.</li>
</ul>

<p><em>Note from 2021: Most stdlib collections (<a href="https://doc.rust-lang.org/nightly/std/vec/struct.Vec.html"><code>Vec</code></a>, for example) now have an optional “custom allocator” parameter that can be used to swap in a different allocator for a specific use site.</em></p>

<h2 id="arcs-over-ffi-triomphe">Arcs over FFI: Triomphe</h2>

<p>This isn’t really a generalizable technique, but it’s pretty cool and generally instructive, so I’m including it here.</p>

<p>Stylo uses a lot of <code>Arc</code>s. A <em>lot</em> of them. The entire computation of styles makes heavy use of <code>Arc::make_mut</code>’s copy-on-write semantics so that we can build up the style tree in parallel but not have to make unnecessary copies of duplicated/defaulted styles for each element.</p>

<p>Many of these <code>Arc</code>s need to be readable from C++. Rust’s <code>Arc</code>, however, consists of a pointer to an allocation containing a refcount and the data, so if C++ needs to get access to the data it needs to know the layout of the <code>Arc</code> allocation, which we’d rather not do<sup id="fnref:5" role="doc-noteref"><a href="#fn:5" class="footnote">5</a></sup>.</p>

<p>We picked a different route: We created a crate duplicating <code>Arc&lt;T&gt;</code> which behaves almost exactly the same as <code>Arc&lt;T&gt;</code>, but it can be converted to <code>OffsetArc&lt;T&gt;</code> which has its pointer point to the <em>middle</em> of the allocation, where the <code>T</code> begins. To C++, this just looks like a <code>*const T</code>! We were then able to make it work with <code>RefPtr&lt;T&gt;</code> on the C++ side so that C++ can transparently read from the <code>OffsetArc&lt;T&gt;</code>, and only needs to call into Rust if it wishes to clone or drop it.</p>

<p>The external version of this crate can be found in <a href="https://docs.rs/triomphe">triomphe</a>. It contains a bunch of other goodies that are additionally useful outside of the FFI world, like <code>ArcBorrow</code> which is essentially “<code>&amp;Arc&lt;T&gt;</code> without double indirection”, <code>UniqueArc&lt;T&gt;</code>, a mutable <code>Arc&lt;T&gt;</code> known to be uniquely owned, and <code>ArcUnion&lt;T, U&gt;</code>, which is a space-efficient union of <code>Arc&lt;T&gt;</code> and <code>Arc&lt;U&gt;</code>.</p>

<h2 id="other-pitfalls">Other pitfalls</h2>

<h3 id="transparent">Transparent</h3>

<p>It’s <em>very</em> tempting to wrap C++ types in tuple structs and pass them over FFI. For example, one might imagine that the following is okay:</p>

<pre><code class="language-rust">struct Wrapper(bindings::SomeCppType);

extern "C" {
    // C++ signature: `SomeCppType get_cpp_type();`
    fn get_cpp_type() -&gt; Wrapper;
}
</code></pre>

<p>This kind of thing is quite useful to get around coherence, or for adding additional semantics to a type.</p>

<p>While there’s basically one obvious way <code>Wrapper</code> can be represented, ABI stuff can be tricky, and Rust’s layout isn’t defined. It is safer to use <code>#[repr(transparent)]</code>, which guarantees that <code>Wrapper</code> will have the same representation as the type it contains.</p>

<h3 id="c-enums">C enums</h3>

<p>Rust supports C-like enums, but there’s a crucial difference between them. In C, it is not undefined behavior for an enum to have an unlisted value. In fact, the following pattern is not uncommon:</p>

<pre><code class="language-c">enum Flags {
    Flag1 = 0b0001,
    Flag2 = 0b0010,
    Flag3 = 0b0100,
    Flag4 = 0b1000;
};
</code></pre>

<p>where the enum is actually used for bitflags, and <code>Flag1 | Flag2</code> and <code>0</code> are both valid values for <code>Flags</code>.</p>

<p>This is not the case in Rust. If you are type-replacing C enums with Rust ones, make sure they are <code>#[repr(C)]</code>. The Rust compiler uses invalid enum values as space for packing other information while optimizing types, for example Rust is able to represent <code>Option&lt;Option&lt;... 255 times .. Option&lt;bool&gt;&gt;</code> as a single byte.</p>

<p>If you are working with a C enum that is used for bitflags like above, please use an integer type instead. <code>#[repr(C)]</code> on enums in Rust guarantees layout, but it is <a href="https://doc.rust-lang.org/stable/nomicon/other-reprs.html">still undefined behavior for any enum to take on invalid values</a>.</p>

<h3 id="abi-concerns">ABI concerns</h3>

<p>ABIs can be tricky. If you <em>just</em> use bindgen with no special flags, you can be pretty much guaranteed to have an okay ABI, but as you start doing type replacements, stuff can get murkier.</p>

<p>Firstly, make sure you’re not passing owned C++ classes with destructors/etc across FFI boundaries. See <a href="#potential-pitfall-passing-c-classes-by-value-over-ffi">above</a> for why. There’s a bunch of subtle stuff here, but you can avoid most of it it if you just don’t pass these things across FFI in an owned way.</p>

<p>Also, try to make sure everything is <code>#[repr(C)]</code> across the boundary. Rust’s <code>improper-ctypes</code> lints will help here.</p>

<h2 id="should-c-apis-be-unconditionally-unsafe">Should C++ APIs be unconditionally <code>unsafe</code>?</h2>

<p>Before I get into this, I want to reiterate that most of the recommendations in this post are for <em>complex</em> C++-Rust integrations, which are likely to only crop up when attempting to rewrite parts of a large C++ codebase in Rust. Such codebases have unique needs and it’s important to calibrate for that when judging what’s right for them.</p>

<p>I recall when <a href="https://www.chromium.org/Home/chromium-security/memory-safety/rust-and-c-interoperability">this Chromium post</a> and <a href="https://steveklabnik.com/writing/the-cxx-debate">Steve’s <code>cxx</code> post</a> came out, there was a bunch of discussion about C++ functions not being universally marked <code>unsafe</code>. Essentially, a lot of people are of the opinion that all FFI into C++ (or C) should be unconditionally marked <code>unsafe</code> (and that tools like <code>cxx</code> should follow these rules).</p>

<p>Back then I wrote <a href="https://www.reddit.com/r/rust/comments/ielvxu/the_cxx_debate/g2jurb3/?context=3">a Reddit comment</a> about my thoughts on this. It’s a comment that’s the length of a blog post in and of itself so I’m not going to reproduce all of it here, but I’ll try to get the gist. I highly suggest you read it instead of this section.</p>

<p>In short, I would recommend people in large, complex codebases doing heavy C++ interop to generally be okay with marking functions calling into C++ as “safe” provided that function would be considered “safe to call without thinking too much about it” on the C++ side, whatever that means for your codebase.</p>

<p>From <a href="https://manishearth.github.io/blog/2017/12/24/undefined-vs-unsafe-in-rust/">my post on “undefined” vs “unsafe”</a>, for Rust I define “safe” as</p>

<blockquote>
  <p>Basically, in Rust a bit of code is “safe” if it cannot exhibit undefined behavior under all circumstances of that code being used.</p>
</blockquote>

<p>C++ doesn’t have a rigid language-level concept of safety that can be applied the same way. Instead, most C++ code follows a similar heuristic:</p>

<blockquote>
  <p>a bit of code is “safe” if it cannot exhibit undefined behavior under all <strong>expected</strong> circumstances of that code being used.</p>
</blockquote>

<p>This is, perhaps, not as good or useful a heuristic as the one we have for Rust, but it’s still a heuristic that gets used in deciding how careful one needs to be when using various APIs. After all, there are <em>plenty</em> of giant C++ codebases out there, they have got to be able to reason about safety <em>somehow</em>.</p>

<p>When you decide to meld together a C++ and Rust codebase, or start rewriting parts of a C++ codebase in Rust, you have already in essence decided for a large part of the codebase to not exactly follow Rust’s safety rules (but hopefully still be safe). There is little to be gained by making that an explicit part of your FFI boundary. Rather, it is more useful to save <code>unsafe</code> on the FFI boundary for truly unsafe functions which you actually do need to be careful to call.</p>

<p><code>unsafe</code> is useful for finding potential sources of badness in your codebase. For a tightly-integrated Rust/C++ codebase it’s already well known that the C++-side is introducing badness, marking every simple C++ getter as <code>unsafe</code> will lead to alarm fatigue and make it <em>harder</em> to find the real problems.</p>

<p>It’s worth figuring out where this boundary lies for you. Tools like <code>cxx</code> make it straightforward to call C++ functions through a safe interface, and it’s valuable to make use of that support.</p>

<h2 id="closing-comments">Closing comments</h2>

<p>Again, before going down this route it’s worth wondering if you <em>really</em> need tight Rust-C++ integration. When possible, it’s always better to pick a small, well-defined API boundary, rather than Stylo-esque tight integration with shared objects and a highly criscrossed callgraph.</p>

<p>These days <a href="https://github.com/dtolnay/cxx">cxx</a> is probably the most complete tool for such integrations. <a href="https://github.com/rust-lang-nursery/rust-bindgen/">bindgen</a> and <a href="https://github.com/eqrion/cbindgen">cbindgen</a> are still quite good, but cxx is C++-first, with a lot more magic, and generally seems to Just Work without too much configuration.</p>

<p><a href="https://github.com/google/autocxx">autocxx</a> is a cool concept by Adrian Taylor which melds bindgen and cxx to make something even <em>more</em> magical. It’s currently experimental, but I’m going to be watching it with interest.</p>

<p>Overall the field of Rust and C++ integration is at a stage where it’s mature enough for integrations to be <em>possible</em> without too much effort, but there are still tons of ways things could be improved and I’m super excited to see that happen as more people work on such integrations!</p>

<p><em>Thanks to Adam Perry, Adrian Taylor, Nika Layzell, and Tyler Mandry for reviewing drafts of this post</em></p>
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>The <em>cascade</em> in “Cascading Style Sheets” is the process used to take all the potential rules which could apply to an element and find the “most applicable” one that gets actually used. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>The <code>em</code> unit is font-size-relative, so <code>2em</code> with a <code>font-size</code> of <code>12px</code> is computed to <code>2 * 12 = 24px</code>. <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:4" role="doc-endnote">
      <p>C++ name mangling <a href="https://en.wikipedia.org/wiki/Name_mangling#How_different_compilers_mangle_the_same_functions">is not standardized</a>, so any function with the C++ ABI will generate a <code>#[link_name = "_Z1foobarbaz"]</code> attribute on the Rust side, and the exact string used here will differ across compiler implementations and platforms. Since GCC and Clang follow the same scheme, most people will encounter this problem when their code doesn’t work on Windows due to MSVC using a different scheme. <a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p><code>Drop</code> impls are restricted in a bunch of ways for safety, in particular you cannot write <code>impl&lt;T: RefCounted&gt; Drop for RefPtr&lt;T&gt;</code> unless <code>RefPtr</code> is defined as <code>RefPtr&lt;T: RefCounted&gt;</code>. It’s not possible to have a generic type that has an impl of <code>Drop</code> for only <em>some</em> possible instantiations of its generics. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:5" role="doc-endnote">
      <p>Rust’s standard library does not typically guarantee anything about the layout of its types, and furthermore, Rust does not make many guarantees about the stability of most types without a <code>#[repr]</code> attribute. This would <em>work</em>, but it would be brittle and prone to breakage. <a href="#fnref:5" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2019/10/09/on-voting-systems/">On Voting Systems</a></h1>
    
    
      <p class="meta">
        





        
      </p>
    
  </header>


  <div class="entry-content"><p>Election season is starting up again, and as with many other topics I’m seeing a lot of overconfident takes from people in tech wanting to “solve” how voting works with naïve techy solutions. Hell, <a href="https://cointelegraph.com/news/andrew-yang-wants-to-make-us-elections-fraud-proof-using-blockchain">even a presidential candidate seems to have proposed an extremely uninformed plan for “fixing” voting using blockchain technology</a>.</p>

<p>Last year I wrote <a href="https://twitter.com/ManishEarth/status/1056255900095340545">a thread on Twitter</a> covering some of the essential properties good voting systems uphold as well as how they prevent fraud. It was through the lens of Alameda County’s voting system, where I’ve volunteered as a poll worker in the past (and intend to do again). I’ve been meaning to write down the contents of that thread in blog form for a while, and now seemed like a good opportunity to do it.</p>

<p>I’ll be explaining more about most of these properties later, but ideally, a good voting system should uphold:</p>

<ul>
  <li>Secret ballot: Nobody, not even you, can verify who you voted for after you’re out of the polling place, to prevent vote-buying and coercion.</li>
  <li>Auditable paper trail: We should be able to audit the election. Paper trails are usually the most robust way to enable effective audits.</li>
  <li>Obviousness: It should be relatively obvious what individuals should be doing when they need to mark their ballots. A system that you can easily “mess up” with is a bad system.</li>
  <li>Accessibility: It should not exclude individuals with disabilities from being able to vote.</li>
</ul>

<h2 id="how-voting-works-in-alameda-county">How voting works in Alameda County</h2>

<p>I’ll first go over how voting in my county works. The system isn’t perfect, but it’s pretty good, and it’s a good springboard for understanding how voting systems in general can work. There’s a <a href="https://www.acvote.org/acvote-assets/04_resources/PDFs/pwmanuals/06042019/Guide-FINAL-june.pdf">poll worker guide</a> you can refer to if you’re really interested in all the specifics.</p>

<p>Broadly speaking, there are four ways to vote:</p>

<ul>
  <li>By mail</li>
  <li>In person at certain government offices, before election day (“early voting”)</li>
  <li>In person on election day at a polling place</li>
  <li>Provisionally, in person on election day at a polling place</li>
</ul>

<p>Voting by mail is pretty straightforward: When you register you can choose to vote by mail (or you can choose to do so online after the fact). You get a ballot in the mail, along with a special envelope. You fill in the ballot at your leisure, stick it in the envelope, write your name/address on the envelope, sign it, and mail it back. There are also convenient ballot dropboxes all over the place in case you’re a millenial like me and don’t want to figure out how to buy stamps<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">1</a></sup>.</p>

<p>If you’re voting by mail you can also show up at any polling place on the day of the election and drop off your ballots in a sealed bin. At the polling place I helped run roughly half of the people coming in were just there to drop off their vote by mail ballots!</p>

<p>Voting by mail is by far the easiest option here. Sadly not all counties support it<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote">2</a></sup>. In some states <a href="https://en.wikipedia.org/wiki/Vote-by-mail_in_Oregon">this is even the <em>default</em> option</a>.</p>

<p>As I understand it, voting in person at designated government offices<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote">3</a></sup> is pretty much the same as voting in person at a polling place, it’s just run by government employees instead of volunteers and open for a few weeks before election day.</p>

<figure class="caption-wrapper center" style="width: 400px"><img class="caption" src="/images/post/polls/bling.jpeg" width="400" /><figcaption class="caption-text"><p>Poll workers are given some neat bling to wear</p>
</figcaption></figure>

<h3 id="in-person-voting">In person voting</h3>

<p>If you’ve chosen to vote in person, you are supposed to turn up at your assigned polling place (you get your assignment in the mail along with other voter info booklets).</p>

<p>There’s a copy of the list of people assigned to the polling place posted outside, and another with the poll workers inside. When you tell your name to the poll workers, they cross your name off the list, and you have to sign your name next to it<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" class="footnote">4</a></sup>.</p>

<ul>
  <li>If your name isn’t on the list, the poll workers will try and find your assigned precinct and inform you that you can go there instead, but you can still choose to vote provisionally at the existing precinct.</li>
  <li>If your name isn’t on the list of all voters (perhaps you registered very late, or were unable to register), you can also vote provisionally.</li>
  <li>If your name is on the list but marked as voting-by-mail (and you want to vote in person), you can vote normally only if you surrender your mail ballot (which poll workers will mark as spoiled and put in a separate pouch).</li>
  <li>If you lost/didn’t receive your ballot, you can always vote provisionally.</li>
</ul>

<p>When you are voting normally, signing your name on the list fraudulently is illegal.</p>

<p>If it is your first time voting, you need to show some form of ID, but it doesn’t need to be photo ID and <a href="https://en.wikipedia.org/wiki/Help_America_Vote_Act#Voter_identification">even a utility bill is fine</a>.</p>

<p>Once you’re done signing, you’ll be given your ballot cards and a privacy sleeve folder so you can carry your filled ballots around. Because this is California and there are tons of local and state measures, we had 4 (!!) ballot cards, six sides to fill in<sup id="fnref:5" role="doc-noteref"><a href="#fn:5" class="footnote">5</a></sup>. Usually a poll worker will also detach the ballot stubs in front of you and hand them to you to keep. You can use these to check the status (but not the contents!) of your ballot online.</p>

<p>You take your cards to a voting booth, fill them in, and come back. A poll worker will then help you feed your ballot cards into a scanner machine. This machine will reject cards with any problems — which you can fix, rerequesting new ballot cards if necessary, but you then have to spoil and return the old ballot card.</p>

<p>The machine keeps an externally-visible tally of the number of ballots submitted, and an internal tally of all the votes made, ignoring write-ins. It also internally stores ballot cards in one of two bins (depending on write-ins). These bins are verified to be empty when polls open, and are inaccessible till polls close.</p>

<p>It’s important to note that the scanner is not a load-bearing component of the system: It could be replaced with a locked bin with a slot, and the system would still work. The scanner enables one to get <em>preliminary</em> results for the precinct, and provides a way to double-check results.</p>

<p>And that’s it! You’ll be given an I Voted sticker, and you can go home!</p>

<figure class="caption-wrapper center" style="width: 400px"><img class="caption" src="/images/post/polls/stickers.png" width="400" /><figcaption class="caption-text"><p>Some “I Voted!” stickers in Spanish</p>
</figcaption></figure>

<h3 id="using-a-voting-machine">Using a voting machine</h3>

<p>In case you think you will have trouble filling out a ballot card in pen (e.g. if your vision is heavily impared), there’s an alternate way to vote that doesn’t involve a pen. Instead, we have a machine which has a touchscreen and an audio unit, which prompts the voter for their selection for each ballot item on the touchscreen or audio unit. When they’re done, the machine will print out a “receipt” listing their choices inside a sealed box with a glass window, so they can verify that their vote was recorded correctly<sup id="fnref:6" role="doc-noteref"><a href="#fn:6" class="footnote">6</a></sup>. Once they’re done the sealed box will scroll the “receipt” out of view so that the next voter can’t see it.</p>

<p>The sealed box is called a <a href="https://en.wikipedia.org/wiki/Voter-verified_paper_audit_trail">Voter-Verified Paper Trail</a> box: the election runners no longer need to trust the machine’s internal memory, they can trust the paper trail inside the box (which, while produced by a potentially-untrustworthy machine, was verified by the voters), and the machine’s internal memory is simply a way to double-check (and get fast preliminary results).</p>

<h3 id="provisional-voting">Provisional voting</h3>

<p>There are many, many situations in which you may not be able to vote normally. Perhaps you showed up at the wrong precinct but don’t have time to go to the right one. Perhaps you were signed up for vote-by-mail but didn’t receive (or lost) your ballot. Perhaps you recently moved into the county and weren’t able to register in time. Perhaps you were a first-time in-person voter and didn’t have some form of ID.</p>

<p>In such a case you can always vote provisionally. The beauty of this system is that it removes most liability from poll workers: we don’t have any reason to turn people away from the polls, all we can do is refuse to let people vote normally (and instead vote provisionally) in the case of any inconsistencies. This is not to say that malicious poll workers <em>can’t</em> turn people away; it’s illegal but it happens. But well-meaning poll workers cannot, by accident, disenfranchise a voter because we are always allowed to give them a provisional ballot, and that’s an easy rule to follow.</p>

<p>With provisional voting, the voters are given the same ballot cards, but they’re also given an envelope with a form on it. This envelope is equivalent to a voter registration form, (re)registering them in their appropriate county/district<sup id="fnref:7" role="doc-noteref"><a href="#fn:7" class="footnote">7</a></sup>. They vote on the ballot cards normally, but instead of submitting the ballots to the scanner, they put them in the envelope, which goes into a sealed bin<sup id="fnref:8" role="doc-noteref"><a href="#fn:8" class="footnote">8</a></sup>. You’re also given a number you can call to check the status of your ballot.</p>

<p>When you vote provisionally, the registrar of voters will manually process your envelope, remaking your ballot on the right set of cards if necessary, and feeding them into a scanner machine.</p>

<h3 id="integrity-checks">Integrity checks</h3>

<p>Underlying this system is a bevy of integrity checks. There’s an intricate seal system, with numbered seals of varying colors. Some are to be added and never removed, some are to be removed after checking the number, some are never supposed to be touched, some are added at the beginning of the day and removed at the end of the day.</p>

<p>For example, during setup we check that the bins in the scanner are empty, and seal it with a numbered seal. This number is noted down on a form, along with some numbers from the scanner/touchscreen display. The first person to vote is asked to verify all this, and signs the form along with the poll workers.</p>

<p>Election officials drop in multiple times during the day, and may check these numbers. At the end of the day, the numbers of all seals used, and any physical seals that were removed are sent back along with all the ballots.</p>

<p>Various ballot counts are also kept track of. We keep track of the number of provisional ballots, the number of submitted regular ballots (also kept track by the scanner), the number of ballot cards used, and the number of unused ballots left over. Everything needs to match up at the end of the day, and all unused ballots are sent back. These counts are also noted down.</p>

<p>Poll watchers are allowed to be around for most of this, though I think they’re not allowed to <em>touch</em> anything. I think poll watchers are also allowed to be around when the actual ballots are being counted by election officials.</p>

<h3 id="immediate-local-results">Immediate local results</h3>

<p>As mentioned before, the scanner isn’t a crucial part of the system, but if it happens to be working it can be used to get immediate local results. At the end of the day, the scanner prints out a bunch of stuff, including vote totals for races which got more than N votes (N=20, IIRC), so you get immediate results for your precinct. This printout is supposed to be taped to the polling place doors for everyone to see, and presumably the registrar of voters uses the copy submitted to them to publish quick preliminary results.</p>

<p>Using paper ballots doesn’t mean that we have to give up all the benefits of computers doing some of the work for us! We can still use computers to get fast results, without relying on them for the integrity of the system.</p>

<figure class="caption-wrapper center" style="width: 400px"><img class="caption" src="/images/post/polls/totals.jpeg" width="400" /><figcaption class="caption-text"><p>Vote totals posted outside. Our ballots are big and have lots of races on them; so the list of vote totals is absolutely ginormous.</p>
</figcaption></figure>

<h2 id="properties-of-this-voting-system">Properties of this voting system</h2>

<p>This system has some crucial properties.</p>

<h3 id="secret-ballot">Secret ballot</h3>

<p>It’s well known that nobody is supposed to be able to see who you voted for. But a crucial part of this system is that, once you submit your ballots, <em>you</em> can’t see who you voted for either. Of course, you probably can <em>remember</em>, but you have no <em>proof</em>. On the face of it this sounds like a bad property — wouldn’t it be nicer if people could verify that their vote was counted correctly?</p>

<p>The problem is that if <em>I</em> can verify that my vote was counted correctly, someone else can coerce me into doing this in front of them to ensure I voted a certain way. Any system that gives me the ability to verify my vote gives people who have power over me (or just people who want to buy my vote) the same ability.</p>

<p>Provisional voting doesn’t quite have this property, but it’s supposed to be for edge cases. Vote by mail trades off some of this property for convenience; people can now see who you voted for while you’re voting (and the people you live with can fradulently vote on your behalf, too).</p>

<h3 id="conservation-of-ballots-auditable-paper-trail">Conservation of ballots (Auditable paper trail)</h3>

<p>The total number of ballots in the system is roughly conserved and kept track of. If you’re registered to vote by mail, you cannot request a normal ballot without surrendering your vote by mail ballot and envelope (which we mark as spoiled and put in a separate pouch). If you re-request a ballot card because you made a mistake, the old card needs to be similarly spoiled and put away separately. It’s one set of ballot cards per voter, and almost all potential aberrations in this property result in a provisional vote<sup id="fnref:9" role="doc-noteref"><a href="#fn:9" class="footnote">9</a></sup>. Even provisional votes are converted to normal ballot cards in the end.</p>

<p>Eventually, there will be a giant roomful of ballots that cannot be traced back to their individual voters, but it can still be traced back to the <em>entirety</em> of the voters — it’s hard to put a ballot into the system without a corresponding voter. This is perfect — the ballots can be hand-counted, but they can’t be individually corellated with their respective voters.</p>

<p>You don’t even need to recount the entire set of ballots to perform an audit, <a href="https://risklimitingaudits.org/">risk limiting audits</a> are quite effective and much more efficient to carry out.</p>

<h3 id="paper-ballots">Paper ballots</h3>

<p>The fact that they can (and should) be hand counted is itself an important property. Hand counting of ballots can be independently verified in ways that can’t be done for software. Despite not being able to trace a ballot back to its voter, there still is a paper trail of integrity for the ballots as a bulk unit.</p>

<p>This property leads to [software independance]: while we may use software in the process, it’s not possible for a bug in the software to cause an undetectable error in the final vote counts.</p>

<figure class="caption-wrapper center" style="width: 500px"><img class="caption" src="/images/post/polls/totals-zoom.png" width="500" /><figcaption class="caption-text"><p>Specific vote totals for the top races</p>
</figcaption></figure>

<h3 id="obviousness">Obviousness</h3>

<p>Figuring out what to do in the voting booth isn’t hard. You’re allowed to request assistance, but you’ll rarely have to. There are systems (like the scanner’s error checking) that are designed to ensure you don’t mess up, but the system is quite sound even without them; they just provide an additional buffer.</p>

<p>Compare this with <a href="https://www.texastribune.org/2018/11/01/texas-straight-ticket-voting-problems-old-machines/">the problems some Texas voting machines had last midterm</a>. The machines were somewhat buggy, but, crucially, there was an opaque right and wrong way to use them, and some voters accidentally used it the wrong way, and then didn’t check the final page before submitting. This kind of thing should never happen in a good voting system.</p>

<p>It’s really important that the system is intuitive and hard to make mistakes in.</p>

<h2 id="fraud-prevention">Fraud prevention</h2>

<p>So, how is this robust against fraud?</p>

<p>Firstly, voter fraud isn’t a major problem in the US, and it’s often used as an excuse to propagate voter suppression tactics, which <em>are</em> a major problem here.</p>

<p>But even then, we probably want our system to be robust against fraud.</p>

<p>Let’s see how an individual might thwart this system. They could vote multiple times, under assumed identites. This doesn’t scale well and isn’t really worth it: to influence an election you’d need to do this many times, or have many individuals do it a couple times, and the chance of getting caught (e.g., the people who you are voting as may come by and try to vote later, throwing up a flag) and investigated scales exponentially with the number of votes. That’s not worth it at all.</p>

<p>Maybe poll workers could do something malicious. Poll worker manipulation would largely exist in the form of submitting extra ballots. But that’s hard because the ballot counts need to match the list of voters. So you have the same problem as individual voters committing fraud: if the actual voter shows up, they’ll notice. Poll workers <em>could</em> wait till the end of the day to do this, but then to make any kind of difference you’d have to do a bulk scan of ballots, and that’s very noticeable. Poll workers would have to collude to make anything like this work, and poll watchers (and government staff) may be present.</p>

<p>Poll workers can also <em>discard</em> ballots to influence an election. But you can’t do this in front of the voters, and the receptacles with non-defaced ballots are all sealed so you can’t do this when nobody is watching without having to re-seal (which means you need a new numbered seal, which the election office will notice). The scanner’s inner receptacle is opened at the end of the day but you can’t tamper with that without messing up the various counts.</p>

<p>Election officials have access to giant piles of ballots and could mess with things there, but I suspect poll watchers are present during the ballot sorting and counting process, and again, it’s hard to tamper with anything without messing up the various counts.</p>

<p>Overall, this system is pretty robust. It’s important to note that fraud prevention is achieved by more social means, not technical means: there are seals, counts, and various properties of the system, but no computers involved in any crucial roles.</p>

<h2 id="techy-solutions-for-voting">Techy solutions for voting</h2>

<p>In general, amongst the three properties of “secret ballot”, “obviousness”, and “auditable paper trail”, computer-based voting systems almost always fail at one, and usually fail at two.</p>

<p>A lot of naïve tech solutions for voting are explicitly designed to not have the secret ballot property: they are instead designed specifically to let voters check that what their vote was counted as after the election. As mentioned earlier, this is a problem for vote-buying and coercion.</p>

<p>It’s theoretically possible to have a system where you can ensure your ballot, specifically, was correctly counted after the election, without losing the secret ballot property: <a href="https://en.wikipedia.org/wiki/ThreeBallot">ThreeBallot</a> is a cool example of such a system, though it fails the “obviousness” property.</p>

<p>Most systems end up not having an auditable paper trail since they rely on machines to record votes. This is vulnerable to bugs in the machine: you end up having to trust the output of the machine. Buggy/vulnerable voting machines are so common that every year at DEFCON <a href="https://media.defcon.org/DEF%20CON%2027/voting-village-report-defcon27.pdf">people get together to hack the latest voting machines, and typically succeed</a>.</p>

<p>Voting machines can still produce a paper trail: Voter-Verified Paper Trail systems partially succeed in doing this. They’re not as good with maintaining the “conservation of ballots” property that makes tampering much harder, and they’re not as good on the “obviousness” part since people need to check the VVPAT box for what their vote was recorded as.</p>

<p>Ballot-Marking devices are a bit better at this: These still produce paper ballots, it’s just that the ballot is marked by the machine on your behalf. There’s still a bit of an “obviousness” fail in that people may not double check the marked ballot, but at least there’s a nice paper trail with ballot conservation! Of course, these only work if the produced ballot is easily human-readable.</p>

<p>It’s not <em>impossible</em> to design good voting systems that rely on technology, but it’s hard to maintain the same properties you can with paper ballots. If you want to try, please keep the properties listed above in mind.</p>

<h3 id="blockchain">Blockchain?</h3>

<p>Every now and then people will suggest using blockchains for voting. This is a pretty large design space, but …. most of these proposals are <em>extremely</em> naïve and achieve very little.</p>

<p>For one, most of them are of the category that lose the “secret ballot” property, instead producing some kind of identifier you’re able to check in some published blockchain. This lets you see what your vote was after the election, and as I’ve covered already that’s not a good thing.</p>

<p>Even if this process only lets you verify that your vote was counted (but not what it was), it typically involves some understanding of cryptography to spot-check the validity of the machine output (e.g. you need to verify that some hash is the hash of your actual vote or something). This fails the obviousness property.</p>

<p>Blockchains don’t really bring much to the table here. They’re decent for byzantine fault tolerance in a space without a central authority, but elections <em>do</em> have some form of central authority and we’re not getting rid of that. The anonymity properties of blockchains can usually be achieved without blockchains for things like elections.</p>

<p>There are some kinds of cryptography that can be useful for auditability — zero knowledge proofs and homomorphic encryption come to mind — but you don’t need blockchains to use these, and using these still requires some form of technology as a key part of the voting system and this makes other properties of the system harder to achieve.</p>

<h2 id="become-a-poll-worker">Become a poll worker!</h2>

<p>It’s still a bit early for the next election, but I highly recommend you volunteer to be a poll worker for your county if you can!</p>

<p>It’s really fun, you get to learn about the inner workings of voting systems, and you get to meet a lot of people!</p>

<figure class="caption-wrapper center" style="width: 700px"><img class="caption" src="/images/post/polls/nancy.jpeg" width="700" /><figcaption class="caption-text">
<p>We had a cool kid come in and <a href="https://twitter.com/ManishEarth/status/1060052694772011008">more or less do this</a> at one point</p>

</figcaption></figure>

<p><em>Thanks to Nika Layzell, Sunjay Varma, Jane Lusby, and Arshia Mufti for providing feedback on drafts of this blog post.</em></p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>Last year they required postage, but I they’ve changed that with <a href="https://www.sos.ca.gov/administration/news-releases-and-advisories/2019/no-stamp-no-problem-all-vote-mail-ballots-now-come-prepaid-postage-return-envelopes/">a law</a> this year. Yay! <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>Ostensibly because of fears of voter fraud, but they’re largely unfounded — in practice this just reduces turnout <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>I think for Alameda county the only such office is the Registrar of Voters in Oakland <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:4" role="doc-endnote">
      <p>The crossing-off and signing lists are different, but this isn’t too important. <a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:5" role="doc-endnote">
      <p>I remember one particularly curmudgeonly voter loudly grumbling about all the propositions as they were voting. One doesn’t “vote” in California, one fills out social studies homework. <a href="#fnref:5" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:6" role="doc-endnote">
      <p>I don’t quite recall how the verifiability works for people using the audio unit, they may be allowed to ask someone else to verify for them? <a href="#fnref:6" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:7" role="doc-endnote">
      <p>If you vote in a different precinct, or worse, a different county, the ballot cards may not contain all the same races, so voting provisionally from the wrong district means that you only get to vote for the races common to both ballot cards. <a href="#fnref:7" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:8" role="doc-endnote">
      <p>It’s imperative that these do not go into the scanner (since that operation cannot be undone), and to prevent this poll workers are instructed to not give provisional voters a secrecy sleeve as the envelope acts as a secrecy sleeve. Whoever is supervising the scanner will only allow people with secrecy sleeves to slip their ballots into the scanner. <a href="#fnref:8" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:9" role="doc-endnote">
      <p>The exception is using the touchscreen machine, where you get to vote without using up a ballot card on voting day. However, tallies for the machine are kept separately, and I think these too are eventually turned into normal ballot cards. <a href="#fnref:9" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2019/02/04/rust-governance-scaling-empathy/">Rust Governance: Scaling Empathy</a></h1>
    
    
      <p class="meta">
        





        
      </p>
    
  </header>


  <div class="entry-content"><p>There’s been a lot of talk about improving Rust’s governance model lately. As we decompress from last year’s hectic edition work, we’re slowly starting to look at all the bits of <a href="https://twitter.com/ManishEarth/status/1073088515041198080">debt</a> we accumulated, and <a href="https://boats.gitlab.io/blog/post/rust-2019/">organizational debt</a> is high on that list.</p>

<p>I’ve been talking in private with people about a bunch of these things for quite a while now, and I felt it worthwhile to write down as much of my thoughts as I can before the Rust All Hands in Berlin this week.</p>

<p>In the interest of brevity<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">1</a></sup> I’m going to assume the reader is roughly familiar with most of the stuff that’s happened with the Rust community in the past few years. I’m probably going to omit concrete examples of incidents, both to avoid mischaracterizing individual actions (as with most such analyses, I wish to talk in more general terms about trends), and also just because it would take me forever to write this if I were to supply all the layers of context. If you feel something is inaccurate, please let me know.</p>

<p>This blog post is probably going to reach the eyes of non-Rust-community members. You’re welcome to read it, but please accept my apologies in advance if it doesn’t make any sense. This is something that I initially planned to circulate as a private post (writing for a general audience is <em>hard</em>), but I felt this would be more widely useful. However due to time constraints I haven’t had time to edit it to make it acceptable to a wider audience.</p>

<h2 id="the-symptoms">The symptoms</h2>

<p>Before I actually get into it, I’d like to carefully delineate <em>what</em> the problem is that I’m talking about. Or more accurately, the <em>symptoms</em> I am talking about — as I’ll explain soon I feel like these are not the actual problem but symptoms of a more general problem.</p>

<p>Basically, as time has gone by our decisionmaking process has become more and more arduous, both for community members and the teams. Folks have to deal with:</p>

<ul>
  <li>The same arguments getting brought up over and over again</li>
  <li>Accusations of bad faith</li>
  <li>Derailing</li>
  <li>Not feeling heard</li>
  <li>Just getting exhausted by all the stuff that’s going on</li>
</ul>

<p>The RFC process is the primary exhibitor of these symptoms, but semi-official consensus-building threads on https://internals.rust-lang.org have similar problems.</p>

<p>Aaron <a href="http://aturon.github.io/2018/05/25/listening-part-1/">has written some extremely empathetic blog posts</a> about a bunch of these problems, starting with concrete examples and ending with a takeaway of a bunch of values for us to apply as well as thoughts on what our next steps can be. I highly recommend you read them if you haven’t already.</p>

<p>Fundamentally I consider our problems to be social problems, not technical ones. In my opinion, technical solutions like changing the discussion forum format may be necessary but are not sufficient for fixing this.</p>

<h2 id="the-scaling-problem">The scaling problem</h2>

<p>I contend that all of these issues are symptoms of an underlying <em>scaling issue</em>, but also a failure of how our moderation works.</p>

<p>The scaling issue is somewhat straightforward. Such forum discussions are inherently N-to-N discussions. When you leave a comment, you’re leaving a comment for <em>everyone</em> to read and interpret, and this is hard to get right. It’s <em>much</em> easier to have one-on-one discussions because it’s easy to build a shared vocabulary and avoid misunderstandings. Any misunderstandings can often be quickly detected and corrected.</p>

<p>I find that most unpleasant technical arguments stem from an unenumerated mismatch of assumptions, or sometimes what I call a mismatch of axioms (i.e. when there is fundamental conflict between core beliefs). A mismatch of assumptions, if identified, can be resolved, leading to an amicable conclusion. Mismatches of axioms are harder to resolve, however recognizing them can take most of the vitriol out of an argument, because both parties will <em>understand</em> each other, even if they don’t <em>agree</em>. In such situations the end result may leave one or both parties <em>unhappy</em>, but rarely <em>angry</em>. (It’s also not necessary that axiom mismatches leave people unhappy, embracing <a href="http://aturon.github.io/2018/06/02/listening-part-2/#pluralism-and-positive-sums">positive sum thinking</a> helps us come to mutually beneficial conclusions)</p>

<p>All of these mismatches are easy to identify in one-on-one discussions, because it’s easy to switch gears to the meta discussion for a bit.</p>

<p>One-on-one discussions are pleasant. They foster empathy.</p>

<p>N-to-N discussions are <em>not</em>. It’s harder to converge on this shared vocabulary amongst N other people. It’s harder to identify these mismatches, partly because it’s hard to switch into the meta-mode of a discussion at all, but also because there’s a lot going on. It’s harder to build empathy.</p>

<p>As we’ve grown, discussion complexity has grown quadratically, and we’re not really attempting to relinearize them.</p>

<h3 id="hanabi-and-parallel-universes">Hanabi and parallel universes</h3>

<p>I quite enjoy the game of <a href="https://en.wikipedia.org/wiki/Hanabi_(card_game)">Hanabi</a>. It’s a game of information and trust, and I find it extremely fun, especially with the right group.</p>

<p>Hanabi is a cooperative game. You can see everyone’s cards (or tiles) but your own, and information-sharing is severely restricted. The goal is to play the right cards in the right order to collectively win. The gimmick is to share additional information through the side-channel of <em>the choice of move you make</em>.</p>

<p>A very common occurrence in this game is that people start making plans in their mind. You typically have a decent understanding of what information everyone has, and you can use this to make predictions as to what everyone’s moves will be. With this in mind, you can attempt to “set up” situations where the game progresses rapidly in a short period of time. This is somewhat necessary for the game to work, but a common pitfall is for these plans to be <em>extremely</em> elaborate, leading to frustration as the game doesn’t actually play out as planned.</p>

<p>The core issue behind this is forgetting that you actually <em>can’t</em> see the entire game state, since your own cards are hidden. It’s not just <em>you</em> who has plans — everyone does! And each of those plans is incomplete since they’re missing a piece of the picture, just as you are.</p>

<p>In Hanabi it’s very easy to forget that you’re missing a piece of the picture — in competitive card games you mostly can’t see the game state since everyone else’s cards are hidden. But in Hanabi you can see <em>most</em> of the cards and it’s easy to forget that your own four cards are hidden from you.</p>

<p>So what ends up happening is that due to incomplete information, everyone is operating in their own little parallel universe, occasionally getting frustrated when it becomes clear that other players are not operating in the same universe. As long as you recognize the existence of these parallel universes beforehand you’re fine, but if you don’t you will be frustrated.</p>

<p>This is largely true of N-to-N discussions as well. Because most of what’s being said makes sense to an individual in a particular way, it’s very easy for them to forget that other people may not share your assumptions and thus may be on a different page. Every time someone leaves a comment, different people may interpret it differently, “forking” the common understanding of the state of the discussion into multiple parallel universes. Eventually there are enough parallel universes that everyone’s talking past each other.</p>

<p>One thing I often prefer doing in such cases is to have a one on one discussion with people who disagree with me — typically the shared understanding that is the end result of such discussions is super useful and can be brought back to the discussion as something that all participants interpret the same way. I’m not consistent in doing this — in the midst of a heated argument it’s easy to get too wrapped up in the argument to think about getting results and I’ve certainly had my time arguing instead of resolving — but overall whenever I’ve chosen to do this it’s been a useful policy.</p>

<p>This is a good example of how relinearization and communication can help move N-to-N discussions along. Operating in different parallel universes is kind of the <em>point</em> of Hanabi, but it’s not the point of having a technical discussion.</p>

<h2 id="the-moderation-problem">The moderation problem</h2>

<p>In a technical discussion, broadly speaking, I find that there are three kinds of comments disagreeing with you:</p>

<ul>
  <li>Constructive: Comments which disagree with you constructively. We’re glad these exist, disagreement can hurt but is necessary for us to collaboratively reach the best outcomes.</li>
  <li>Disruptive: Comments which may be written in good faith but end up being disruptive. For example, this includes people who don’t read enough of the discussion and end up rehashing the same points. It also includes taking discussions off topic. These kinds of things are problematic but not covered by the code of conduct.</li>
  <li>Abrasive: Comments which are rude/abrasive. These are covered by the code of conduct. The mod team tries to handle these.</li>
</ul>

<p>(For a long time I and <a href="http://twitter.com/aaron_turon/">Aaron</a> had a shared vocabulary of “Type A, B, C” for these, mostly because I’m often unimaginative when it comes to such things, thanks to <a href="https://github.com/mark-simulacrum">Mark</a> for coming up with, better, descriptive titles)</p>

<p>Note that while I’m talking about “disruptive” comments it’s not a judgement on the <em>intent</em> of the participants, but rather a judgement on the harm it has caused.</p>

<p>The second category – disruptive comments – are the thing we’re currently unable to handle well. They snowball pretty badly too — as more and more of these collect, more and more people get frustrated and in turn leave comments that cause further disruption. As the discussion progresses into more and more “parallel universes” it also just becomes <em>easier</em> for a comment to be disruptive.</p>

<p>The Rust moderation team operates mostly passively, we simply don’t have the scale<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote">2</a></sup> to watch for and nip these things in the bud. Active moderation requires a degree of involvement we cannot provide. So while the best response would be to work with participants and resolve issues early as we see them crop up, we typically get pulled in at a point where some participants are already causing harm, and our response has to be more severe. It’s a bit of a catch-22: it’s not exactly our job to deal with this stuff<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote">3</a></sup>, but by the time it <em>becomes</em> our job (or even, by the time we <em>notice</em>), most acceptable actions for us to take are extremely suboptimal. The problem with passive moderation is that it’s largely reactive — it’s harder to proactively nudge the discussion in the right direction when you don’t even <em>notice</em> what’s going on until it’s too late. This is largely okay for dealing with bad-faith actors (the main goal of the mod team); it’s hard to <em>prevent</em> someone from deciding to harass someone else. But for dealing with disruptive buildups, we kind of need something different.</p>

<h2 id="participation-guidelines">Participation guidelines</h2>

<p>Part of the solution here is recognizing that spaces for official discussion are <em>different</em> from community hangout spaces. Our code of conduct attempts to handle abrasive behavior, which can disrupt discussions anywhere, but the comments that can disrupt consensusbuilding official discussions aren’t really covered. Nor are the repercussions of code of conduct violations really <em>appropriate</em> for such disruptive comments anyway.</p>

<p>A proposal I’ve circulated in the past is to have a notion of participation guidelines. Discussions in team spaces (RFCs, pre-RFCs, discord/zulip/IRC channels during team meetings) follow a set of rules set forth by the individual teams. It might be worth having a base set of participation guidelines defined by the core team. Something like the following is a very rough strawman:</p>

<ul>
  <li>Don’t have irrelevant discussions during team meetings on Discord/IRC/Zulip</li>
  <li>Don’t take threads off topic</li>
  <li>Don’t rehash discussions</li>
</ul>

<p>We ask people to read these before participating, but also breaking these rules isn’t considered serious, it just triggers a conversation (and maybe the hiding/deletion of a comment). If someone repeatedly breaks these rules they may be asked to not participate in a given thread anymore. The primary goal here is to empower team members to better deal with disruptive comments by giving them a formalized framework. Having codified rules helps team members confidently deal with such situations without having to worry as much about drawing direct ire from affected community members.</p>

<p>A base participation guidelines document can also be a value statement, not just a set of rules but also set of values. These values can be things like:</p>

<ul>
  <li>“We explicitly value high empathy interactions”</li>
  <li>“How everyone is feeling is everyone’s business”</li>
</ul>

<p>(h/t <a href="http://twitter.com/adam_n_p/">Adam</a> for the articulate wording here)</p>

<p>Having such words written somewhere — both the high level values we expect people to hold, and the individual behaviors we expect people to exhibit (or not exhibit) — is really valuable in and of itself, even if not enforced. The value of such documents is not that everyone reads them before participating — most don’t — but they serve as a good starting point for people interested in learning how to best conduct themselves, as well as an easy place to point people to where they’re having trouble doing so.</p>

<p>On its own, I find that this is a powerful framework but may not achieve the goal of improving the situation. I recently realized that this actually couples really well with a <em>different</em> idea I’ve been talking about for quite a while now, the idea of having facilitators:</p>

<h2 id="facilitators">Facilitators</h2>

<p>A common conflict I see occurring is that in many cases it’s a team’s job to think about and opine on a technical decision, but it’s also the team’s job to shepherd the discussion for that decision. This often works out great, but it also leads to people just feeling unheard. It kinda hurts when someone who has just strongly disagreed with you goes on to summarize the state of the discussion in a way that you feel you’ve been unfairly represented. The natural response to that for most people isn’t to work with that person and try to be properly represented, it’s to just get angry, leading to less empathy over time.</p>

<p>By design, Rust team members are <em>partisan</em>. The teams exist to build well-informed, carefully crafted opinions, and present them to the community. They also exist to make final decisions based on the results of a consensusbuilding discussion, which can involve picking sides. This is fine, there is always going to be some degree of partisanship amongst decisionmakers, or decisions would not get made.</p>

<p>Having team members also facilitate discussions is somewhat at odds with all of this. Furthermore, I feel like they don’t have enough bandwidth to do this well anyway. Some teams do have a concept of “sheriffs”, but this is more of an onramp to full team membership and the role of a sheriff is largely the same as the role of a team member, just without a binding vote.</p>

<p>I feel like it would be useful to have a group of (per-team?) <em>facilitators</em> to help with this. Facilitators are people who are interested in seeing progress happening, and largely don’t have <em>much</em> of an opinion on a given discussion, or are able to set aside this opinion in the interest of moving a discussion forward. They operate largely at the meta level of the discussion. Actions they may take are:</p>

<ul>
  <li>Summarizing the discussion every now and then</li>
  <li>Calling out one sided discussions</li>
  <li>Encouraging one-on-one tangents to be discussed elsewhere (perhaps creating a space for them, like an issue)</li>
  <li>Calling out specific people to do a thing that helps move the discussion forward. For example, something like “hey @Manishearth, I noticed you’ve been vocal in <a href="https://github.com/mystor/slag">arguing that Rust should switch to whitespace-sensitive syntax</a>, could you summarize all the arguments made by people on your side?” would help.</li>
  <li>Reinforcing positive behavior</li>
  <li>Occasionally pinging participants privately to help them improve their comments</li>
  <li>Attempting to identify the root cause of a disagreement, or empowering people to work together to identify this. This one is important but tricky. I’ve often enjoyed doing it — noticing the core axiomatic disagreement at play and spelling it out is a great feeling. But I’ve also found that it’s incredibly hard to do when you’re emotionally involved, and I’ve often needed a nudge from someone else to get there.</li>
</ul>

<p>At a high level, the job of the facilitators is to:</p>

<ul>
  <li>help foster empathy between participants</li>
  <li>help linearize complex discussions</li>
  <li>nudge towards cooperative behavior, away from adversarial behavior. Get people playing not to win, but to win-win.</li>
</ul>

<p>It’s important to note that facilitators don’t make decisions — the team does. In fact, they almost completely avoid making technical points, they instead keep their comments largely at the meta level, perhaps occasionally making factual corrections.</p>

<p>The teams <em>could</em> do most of this themselves<sup id="fnref:5" role="doc-noteref"><a href="#fn:5" class="footnote">4</a></sup>, but as I’ve mentioned before it’s harder for others to not perceive all of your actions as partisan when some of them are. Furthermore, it can come off as patronizing at times.</p>

<p>This is also something the moderation team could do, however it’s <em>much</em> harder to scale the moderation team this way. Given that the moderation team deals with harassment and stuff like that, we need to be careful about how we build it up. On the other hand facilitating discussions is largely a public task, and the stakes aren’t as high: screwups can get noticed, and they don’t cause much harm. As a fundamentally <em>proactive</em> moderation effort, most actions taken will be to nudge things in a positive direction; getting this wrong usually just means that the status quo is maintained, not that harm is caused. Also, from talking to people it seems that while very few people want to be involved in moderating Rust, this notion of <em>facilitating</em> sounds much more fun and rewarding (I’d love to hear from people who would like to help).</p>

<p>And to me, this pairs really well with the idea of participation guidelines: teams can write down how they want discussions to take place on their venues, and facilitators can help ensure this works out. It’s good to look at the participation guidelines less as a set of rules and more as an aspiration for how we conduct ourselves, with the facilitators as a means to achieving that goal.</p>

<p>There are a lot of specifics we can twiddle with this proposal. For example, we can have a per-team group of appointed facilitators (with no overlap with the team), and for a given discussion one facilitator is picked (if they don’t have time or feel like they have strong opinions, try someone else). But there’s also no strong need for there to be such a group, facilitators can be picked as a discussion is starting, too. I don’t expect <em>most</em> discussions to need facilitators, so this is mostly reserved for discussions we expect will get heated, or discussions that have started to get heated. I’m not really going to spend time analysing these specifics; I have opinions but I’d rather have us figure out if we want to do something like this and how before getting into the weeds.</p>

<h2 id="prospective-outcomes">Prospective outcomes</h2>

<p>The real goal here is to bootstrap better empathy within the community. In an ideal world we don’t need facilitators, instead everyone is able to facilitate well. The explicitly non-partisan nature of facilitators is <em>useful</em>, but if everyone was able to operate in this manner it would largely be unnecessary. But as with any organization, being able to horizontally scale specific skills is really tricky without specialization.</p>

<p>I suspect that in the process of building up such a team of facilitators, we will also end up building a set of resources that can help others learn to act the same way, and eventually overall improve how empathetic our community is.</p>

<p>The concept of facilitators directly addresses the moderation problem, but it also handles the scaling problem pretty well! Facilitators are key in re-linearizing the n-to-n discussions, bringing the “parallel universes” together again. This should overall help people (especially team members) who are feeling overwhelmed by all the things that are going on.</p>

<p>This also helps with concerns people have that they’re not getting heard, as facilitators are basically posed as allies on all sides of the argument; people whose primary goal is to <em>help communication happen</em>.</p>

<hr />

<p>Overall what I’ve proposed here isn’t a fully-formed idea; but it’s the seed of one. There are a lot of interesting bits to discuss and build upon. I’m hoping through this post we might push forward some of the discussions about governance — both by providing a strawman idea, as well as by providing a perspective on the problem that I hope is useful.</p>

<p>I’m really interested to hear what people think!</p>

<p><em>Thanks to <a href="http://twitter.com/aaron_turon/">Aaron</a>, <a href="https://twitter.com/ag_dubs">Ashley</a>, <a href="http://twitter.com/adam_n_p/">Adam</a>, <a href="https://twitter.com/cmrx64/">Corey</a>, <a href="http://twitter.com/arshia__">Arshia</a>, <a href="https://twitter.com/mgattozzi">Michael</a>, <a href="https://twitter.com/sunjay03">Sunjay</a>, <a href="http://twitter.com/fitzgen/">Nick</a> and other people I’ve probably forgotten for having been part of these discussions with me over the last few years, helping me refine my thoughts</em></p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>I am way too verbose for “brief” to be an accurate description of anything I write, but might as well <em>try</em>. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>Scaling the moderation team properly is another piece of this puzzle that I’m working on; we’ve made some progress recently. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>I helped draft <a href="https://www.rust-lang.org/policies/code-of-conduct#moderation">our moderation policy</a>, so this is a somewhat a lack of foresight on my part, but as I’ll explain later it’s suboptimal for the mod team to be dealing with this anyway. <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:5" role="doc-endnote">
      <p>In particular, I feel like Aaron has done an <em>excellent</em> and consistent job of facilitating discussions this way in many cases. <a href="#fnref:5" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2018/09/11/converting-a-webgl-application-to-webvr/">Converting a WebGL Application to WebVR</a></h1>
    
    
      <p class="meta">
        





        
      </p>
    
  </header>


  <div class="entry-content"><p>I wrote a post for Mozilla Hacks on converting WebGL applications to WebVR,
<a href="https://hacks.mozilla.org/2018/09/converting-a-webgl-application-to-webvr/">you can read it there</a></p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2018/08/26/why-i-enjoy-blogging/">Why I Enjoy Blogging</a></h1>
    
    
      <p class="meta">
        





        
      </p>
    
  </header>


  <div class="entry-content"><p><em>See also: <a href="https://myrrlyn.net/blog/misc/to-all-the-posts-ive-blogged-before">Alex’s version of this blog post</a></em></p>

<p>I started this blog three years ago, moving from my <a href="http://inpursuitoflaziness.blogspot.com/">older blog</a>, hoping to written about programming, math, physics, books, and miscellenia. I’ve not quite written about everything I wanted to, but I’ve been very very happy with the experience of blogging. <code>wc</code> says I’ve written almost 75k words, which is mind-boggling to me!</p>

<p>I often get asked by others — usually trying to decide if they should start blogging — what it’s like. I also often try to convince friends to blog by enumerating why I think it’s awesome. Might as well write it down so that it’s generally useful for everyone! 😃</p>

<h2 id="blogging-helps-cement-my-understanding-of-things">Blogging helps cement my understanding of things!</h2>

<p>I’ve often noticed that I’ll start blogging about something I <em>think</em> I understand, and it turns out that my understanding of the subject was somewhat nebulous. Turns out it’s pretty easy to convince ourselves that we understand something.</p>

<p>The act of writing stuff down helps cement my own understanding — words are usually not as nebulous as thoughts so I’m forced to figure out little details.</p>

<p>I recall when I wrote my post on <a href="https://manishearth.github.io/blog/2015/05/30/how-rust-achieves-thread-safety/">how Rust’s thread safety guarantees work</a>, I <em>thought</em> I understood <code>Send</code> and <code>Sync</code> in Rust. I understood what they did, but I didn’t have a clear mental model for them. I obtained this mental model through the process of writing the post; to be able to explain it to others I had to first explain it to myself.</p>

<p>I point out this post in particular because this was both one of the first posts for me where I’d noticed this, and, more importantly, my more concrete mental model led to me <a href="https://github.com/rust-lang/rust/issues/25894">finding a soundness bug in Rust’s standard library</a>. When I was thinking about my mental model I realized “an impl that looks like this should never exist”,
so I grepped the source code and found one<sup id="fnref:11" role="doc-noteref"><a href="#fn:11" class="footnote">1</a></sup>.</p>

<p>I’ve even noticed a difference between one-on-one explaining and explaining things through blog posts. I <em>love</em> explaining things one-on-one, it’s much easier to tailor the explanation to the other person’s background,
as well as what they’re actually asking for help with. Plus, it’s interactive. A <em>lot</em> of my posts are of the “okay I get this question a lot I’m going to write down the answer so I don’t have to repeat myself” kind and I’ve found that I’ve often learned things from these despite having talked about the thing in the article contents multiple times.</p>

<p>I guess it’s basically that blogging is inherently one-many — you’re trying to explain to a whole group of people with varied backgrounds — which means you need to cover all your bases<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote">2</a></sup> and explain everything together instead of the minimum necessary.</p>

<h2 id="its-really-fun-to-revisit-old-posts">It’s really fun to revisit old posts!</h2>

<p>Okay, I’ll admit that I never really write blog posts with this in mind. But when I <em>do</em> reread them, I’m usually quite thankful I wrote them!</p>

<p>I’m a fan of rereading in general, I’ve reread most of my favorite books tens of times; I make a yearly pilgrimage to <a href="https://mickens.seas.harvard.edu/wisdom-james-mickens">James Mickens’ website</a>; I reread many of my favorite posts and articles on the internet; and I often reread my <em>own</em> posts from the past.</p>

<p>Sometimes I’ll do it because I want a refresher in a topic. Sometimes I’ll do it because I’m bored. Whatever the reason, it’s always been a useful and fun thing to do.</p>

<p>Rereading old posts is a great way to transport myself back to my mindset from when I wrote the post. It’s easy to see progress in my understanding of things as well as in my writing. It’s interesting to note what I thought super important to include in the post <em>then</em> that I consider totally obvious <em>now</em><sup id="fnref:5" role="doc-noteref"><a href="#fn:5" class="footnote">3</a></sup>. It’s interesting to relearn what I’ve forgotten. It’s reassuring to realize that my terrible jokes were just as terrible as they are now.</p>

<p>One of my favorite posts to reread is <a href="https://manishearth.github.io/blog/2016/03/05/exploring-zero-knowledge-proofs/">this really long one on generalized zero knowledge proofs</a>. It’s the longest post I’ve written so far<sup id="fnref:6" role="doc-noteref"><a href="#fn:6" class="footnote">4</a></sup>, and it’s on a topic I don’t deal with often — cryptography. Not only does it help put me back in a mindset for thinking about cryptography, it’s about something super interesting but also complicated enough that rereading the post is like learning it all over again.</p>

<h2 id="it-lets-me-exercise-a-different-headspace">It lets me exercise a different headspace!</h2>

<p>I like programming a lot, but if programming was <em>all</em> I did, I’d get tired pretty quickly. When I was a student learning physics I’d often contribute to open source in my spare time, but now I write code full time so I’m less inclined to do it in my free time<sup id="fnref:8" role="doc-noteref"><a href="#fn:8" class="footnote">5</a></sup>.</p>

<p>But I still sometimes feel like doing programmery things in my spare time just … not programming.</p>

<p>Turns out that blogging doesn’t tire me out the same way! I’m sure that if I spent the whole day writing I’d not want to write when I go home, but I don’t spend the whole day writing, so it’s all good. It’s refreshing to sit down to write a blog post and discover a fresh reserve of energy. I’m not sure if this is the right term, but I usually call this “using a different headspace”.</p>

<p>I’ve also started using this to plan my work, I mix up the kinds of headspace I’m employing for various tasks so that I feel energetic throughout the day.</p>

<p>This is also why I really enjoy mentoring — mentoring often requires the same effort from me as fixing it myself, but it’s a different headspace I’m employing so it’s less tiring.</p>

<h2 id="blogging-lets-me-be-lazy">Blogging lets me be lazy!</h2>

<p>I often find myself explaining things often. I like helping folks and explaining things, but I’m also lazy<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">6</a></sup>, so writing stuff down really makes stuff easy for me! If folks ask me a question I can give a quick answer and then go “if you want to learn more, I’ve written about it here!”. If folks are asking a question a lot, there’s probably something missing in the documentation or learning materials about it. Some things can be fixed upstream in documentation, but other things — like <a href="https://manishearth.github.io/blog/2017/05/14/mentally-modelling-modules/">“how should I reason about modules in Rust?”</a> deserve to be tackled as a separate problem and addressed with their own post.</p>

<p>(Yes, this post is in this category!)</p>

<h2 id="its-okay-if-folks-have-written-about-it-before">It’s okay if folks have written about it before!</h2>

<p>A common question I’ve gotten is “Well I can write about X but … there are a lot of other posts out there about it, should I still?”</p>

<p>Yes!!</p>

<p>People think differently, people learn differently, and people come from different backgrounds. Existing posts may be useful for some folks but less useful for others.</p>

<p>My personal rule of thumb is that if it took <em>me</em> some effort to understand something after reading about it, that’s something worth writing about, so it’s easier to understand for others like me encountering the subject.</p>

<p>One of my favorite bloggers, <a href="https://jvns.ca/">Julia Evans</a> very often writes posts explaining computer concepts. Most of the times these have been explained before in other blog posts or manuals. But that doesn’t matter — her posts are <em>different</em>, and they’re <em>amazing</em>. They’re upbeat, fun to read, and often get me excited to learn more about things I knew about but never really looked at closely before.</p>

<h2 id="i-kinda-feel-its-my-duty-to">I kinda feel it’s my duty to?</h2>

<p>There’s a quote by Toni Morrison I quite enjoy:</p>

<blockquote>
  <p>I tell my students, ‘When you get these jobs that you have been so brilliantly trained for, just remember that your real job is that if you are free, you need to free somebody else. If you have some power, then your job is to empower somebody else. This is not just a grab-bag candy game.</p>
</blockquote>

<p>I enjoy it so much I <a href="https://manishearth.github.io/rustfest-slides/#/13">concluded my talk at RustFest Kyiv with it</a>!</p>

<p>I have the privilege of having time to do things like blogging and mentoring. Given that, I feel that it really is my duty to share what I know as much as possible; to help others attempting to tread the path I’m treading; and to battle against tribal knowledge.</p>

<p>When it comes to programming I’m mostly “self-taught”. But when I say that, I really mean that I wasn’t taught in a traditional way by other humans — I learned things by trying stuff out and <em>reading what others had written</em>. I didn’t learn Rust by taking <code>rustc</code> and pretending to be a fuzzer and just trying random nonsense till stuff made sense, I went through the tutorial (and <em>then</em> started exploring by trying random stuff). I didn’t figure out cool algorithms by discovering them from first principles, I picked them up from books and blog posts. I’m “self-taught” because I’ve been in charge of my learning process, but I’ve definitely relied on the work of other people throughout this process.</p>

<p>This means that for me, personally, knowledge-sharing is especially important. If I had to spend time figuring something out, I should make it easier for the next people to try<sup id="fnref:10" role="doc-noteref"><a href="#fn:10" class="footnote">7</a></sup>.</p>

<p>(All this said, I probably don’t blog as much as I <em>should</em>)</p>

<h2 id="you-should-blog-too">You should blog too!</h2>

<p>I wish everyone wrote more. I know not everyone has the time/privilege to do this, but if you do, I urge you to start!</p>

<p>I feel like tips on <em>how</em> to blog would fill up an entire other blog post, but Julia Evans has <a href="https://jvns.ca/blog/2016/05/22/how-do-you-write-blog-posts//">multiple</a> <a href="https://jvns.ca/blog/2017/03/20/blogging-principles/">posts</a> on this that I strongly recommend. Feel free to ask me for review on posts!</p>

<p>As for the technicalities of setting up a blog, my colleague Emily recently <a href="https://www.emilykager.com/writing/2018/07/27/myo-website.html">wrote a great post about doing this with Jekyll</a>. This blog uses <a href="http://octopress.org">Octopress</a> which is similar to set up.</p>

<p><em>Thanks to <a href="https://twitter.com/arshia__">Arshia</a>, <a href="https://twitter.com/QuietMisdreavus">QuietMisdreavus</a>, and <a href="https://twitter.com/myrrlyn">Alex</a> for reviewing drafts of this blog post.</em></p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:11" role="doc-endnote">
      <p>Who needs to <a href="https://www.ralfj.de/blog/2017/06/09/mutexguard-sync.html">look for unsoundness with rigorous formal verification</a> when you have <code>grep</code>? <a href="#fnref:11" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>Incidentally, I find there’s a similar dynamic when it comes to forum discussions vs hashing things out one-on-one, it’s way harder to get anywhere with forum discussions because they’re one-many and you have to put in that much more work to empathize with everyone else and also phrase things in a way that is resilient to accidental misinterpretation. <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:5" role="doc-endnote">
      <p>This is especially important as I get more and more “used” to subjects I’m familiar with – it’s easy to lose the ability to explain things when I think half of it is obvious. <a href="#fnref:5" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:6" role="doc-endnote">
      <p>This is probably the <em>real</em> reason I love rereading it — I like being verbose and would nest parentheses and footnotes if society let me <a href="#fnref:6" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:8" role="doc-endnote">
      <p>I also am in general less inclined to do technical things in my free time and have a better work-life balance, glad that worked out! <a href="#fnref:8" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:1" role="doc-endnote">
      <p>See blog title <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:10" role="doc-endnote">
      <p>One of my former title ideas for this post was “Knowledge is Theft”, riffing off of this concept, but I felt that was a bit too tongue-in-cheek. <a href="#fnref:10" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2018/06/05/the-future-of-clippy-the-rust-linter/">The Future of Clippy</a></h1>
    
    
      <p class="meta">
        





        
      </p>
    
  </header>


  <div class="entry-content"><p>We’ve recently been making lots of progress on future plans for <a href="https://github.com/rust-lang-nursery/rust-clippy">clippy</a> and I
thought I’d post an update.</p>

<p>For some background, Clippy is the linter for Rust. We have more than 250 lints, and
are steadily growing.</p>

<h2 id="clippy-and-nightly">Clippy and Nightly</h2>

<p>Sadly, Clippy has been nightly-only for a very long time. The reason behind this is
that to perform its analyses it hooks into the compiler so that it doesn’t have to
reimplement half the compiler’s info to get things like type information. But
these are internal APIs and as such will never stabilize, so Clippy needs to be
used with nightly Rust.</p>

<p>We’re hoping this will change soon! The plan is that Clippy will eventually
be distributed by Rustup, so something like <code>rustup component add clippy</code> will
get you the clippy binary.</p>

<p>The first steps are <a href="https://github.com/rust-lang/rust/pull/51122">happening</a>, we’re planning on setting it up so that when it compiles
Rustup will be able to fetch a clippy component (however this won’t be the recommended way
to use clippy until we figure out the workflow here, so sit tight!)</p>

<p>Eventually, clippy will probably block nightlies<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">1</a></sup>; and after a bunch of cycles of letting that
work itself out, hopefully clippy will be available with the stable compiler. There’s a lot of
stuff that needs to be figured out, and we want to do this in a way that minimally impacts
compiler development, so this may move in fits and starts.</p>

<h2 id="lint-audit">Lint audit</h2>

<p>A couple months ago <a href="https://github.com/oli-obk">Oliver</a> and I<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote">2</a></sup> did a <a href="https://github.com/rust-lang-nursery/rust-clippy/pull/2579">lint audit</a> in Clippy. Previously,
clippy lints were classified as simply “clippy”, “clippy_pedantic”, and “restriction”.
“restriction” was for allow-by-default lints for things which are generally not a problem but may
be something you specifically want to forbid based on the situation, and “pedantic”
was for all the lints which were allow-by-default for other reasons.</p>

<p>Usually these reasons included stuff like “somewhat controversial lint”, “lint is very buggy”,
or for lints which are actually exceedingly pedantic and may only be wanted by folks
who very seriously prefer their code to be <em>perfect</em>.</p>

<p>We had a lot of buggy lints, and these categories weren’t as helpful. People use clippy
for different reasons. Some folks only care about clippy catching bugs, whereas others want
its help enforcing the general “Rust Style”.</p>

<p>So we came up with a better division of lints:</p>

<ul>
  <li>Correctness (Deny): Probable bugs, e.g. calling <code>.clone()</code> on <code>&amp;&amp;T</code>, which clones the (<code>Copy</code>) reference and not the actual type</li>
  <li>Style (Warn): Style issues; where the fix usually doesn’t semantically change the code. For example, having a method named <code>into_foo()</code> that doesn’t take <code>self</code> by-move</li>
  <li>Complexity (Warn): For detecting unnecessary code complexities and helping simplify them. For example, replacing <code>.filter(..).next()</code> with <code>.find(..)</code></li>
  <li>Perf (Warn): Detecting potential performance footguns, like using <code>Box&lt;Vec&lt;T&gt;&gt;</code> or calling <code>.or(foo())</code> instead of <code>or_else(foo)</code>.</li>
  <li>Pedantic (Allow): Controversial or exceedingly pedantic lints</li>
  <li>Nursery (Allow): For lints which are buggy or need more work</li>
  <li>Cargo (Allow): Lints about your Cargo setup</li>
  <li>Restriction (Allow): Lints for things which are not usually a problem, but may be something specific situations may dictate disallowing.</li>
</ul>

<p>and applied it to the codebase. You can see the results on our <a href="https://rust-lang-nursery.github.io/rust-clippy/master/index.html">lint list</a></p>

<p>Some lints could belong in more than one group, and we picked the best one in that case. Feedback welcome!</p>

<h2 id="clippy-10">Clippy 1.0</h2>

<p>In the run up to making Clippy a rustup component we’d like to do a 1.0 release of Clippy. This involves an RFC,
and pinning down an idea of stability.</p>

<p>The general plan we have right now is to have the same idea of lint stability as rustc; essentially
we do not guarantee stability under <code>#[deny(lintname)]</code>. This is mostly fine since <code>deny</code> only affects
the current crate (dependencies have their lints capped) so at most you’ll be forced to slap on an <code>allow</code>
somewhere after a rustup.</p>

<p>With specifics, this means that we’ll never remove lints. We may recategorize them, or “deprecate” them
(which makes the lint do nothing, but keeps the name around so that <code>#[allow(lintname)]</code> doesn’t break the build
aside from emitting a warning).</p>

<p>We’ll also not change what individual lints do fundamentally. The kinds of changes you can expect are:</p>

<ul>
  <li>Entirely new lints</li>
  <li>Fixing false positives (a lint may no longer lint in a buggy case)</li>
  <li>Fixing false negatives (A case where the lint <em>should</em> be linting but doesn’t is fixed)</li>
  <li>Bugfixes (When the lint panics or does something otherwise totally broken)</li>
</ul>

<p>When fixing false negatives this will usually be fixing things that can be understood as comfortably within the
scope of the lint as documented/named</p>

<p>I’ll be posting an RFC soonish that both contains this general plan of stability, as well as a list of the current
lint categorization for folks to discuss.</p>

<hr />

<p>Anyway, thought I’d just post a general update on everything, since stuff’s changing quickly.</p>

<p>There’s still time for stable or even just reliably rustuppable nightly clippy to happen but the path to it is pretty clear now!</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>As in, if clippy is broken there will not be a nightly that day. Rustfmt and RLS work this way right now AIUI. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>Okay, mostly Oliver <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2018/04/12/down-a-rusty-rabbit-hole/">Down a Rusty Rabbit Hole</a></h1>
    
    
      <p class="meta">
        





        
      </p>
    
  </header>


  <div class="entry-content"><p>Last week I fell down a rather interesting rabbit hole in Rust, which was basically
me discovering a series of quirks of the Rust compiler/language, each one leading to the
next when I asked “why?”.</p>

<p>It started when someone asked why autogenerated <code>Debug</code> impls use argument names like <code>__arg_0</code>
which start with a double underscore.</p>

<p>This happened to be <a href="https://github.com/rust-lang/rust/pull/32294">my fault</a>. The reason <a href="https://github.com/rust-lang/rust/pull/32251#issuecomment-197481726">we used a double underscore</a> was that
while a single underscore tells rustc not to warn about a possibly-unused variable, there’s an off-
by-default clippy lint that warns about variables that start with a single underscore that are used,
which can be silenced with a double underscore. Now, the correct fix here is to make the lint ignore
derive/macros (which I believe we did as well), but at the time we needed to add an underscore
anyway so a double underscore didn’t seem worse.</p>

<p>Except of course, this double underscore appears in the docs. Oops.</p>

<p>Ideally the rustc derive infrastructure would have a way of specifying the argument name to use so
that we can at least have descriptive things here, but that’s a bit more work (I’m willing to mentor
this work though!). So I thought I’d fix this by at least removing the double underscore, and making
the unused lint ignore <code>#[derive()]</code> output.</p>

<p>While going through the code to look for underscores I also discovered a hygiene issue. The following code
throws a bunch of very weird type errors:</p>

<pre><code class="language-rust">pub const __cmp: u8 = 1;

#[derive(PartialOrd, PartialEq)]
pub enum Foo {
    A(u8), B(u8)
}
</code></pre>

<p>(<a href="https://play.rust-lang.org/?gist=2352b6a2192f38caba70bc2b1fa889e7&amp;version=stable">playpen</a>)</p>

<pre><code>error[E0308]: mismatched types
 --&gt; src/main.rs:6:7
  |
6 |     A(u8), B(u8)
  |       ^^^ expected enum `std::option::Option`, found u8
  |
  = note: expected type `std::option::Option&lt;std::cmp::Ordering&gt;`
             found type `u8`
.....
</code></pre>

<p>This is because the generated code for PartialOrd contains the following:</p>

<pre><code class="language-rust">match foo.cmp(bar) {
    Some(Ordering::Equal) =&gt; .....,
    __cmp =&gt; __cmp,
}
</code></pre>

<p><code>__cmp</code> can both be a binding to a wildcard pattern match as well as a match against a constant
named <code>__cmp</code>, and in the presence of such a constant it resolves to the constant, causing
type errors.</p>

<p>One way to fix this is to bind <code>foo.cmp(bar)</code> to some temporary variable <code>x</code> and use that directly in
a <code>_ =&gt; x</code> branch.</p>

<p>I thought I could be clever and try <code>cmp @ _ =&gt; cmp</code> instead. <code>match</code> supports syntax where you can
do <code>foo @ &lt;pattern&gt;</code>, where <code>foo</code> is bound to the entire matched variable. The <code>cmp</code> here is unambiguously
a binding; it cannot be a pattern. So no conflicting with the <code>const</code>, problem solved!</p>

<p>So I made <a href="https://github.com/rust-lang/rust/pull/49676">a PR for both removing the underscores and also fixing this</a>. The change for <code>__cmp</code>
is no longer in that PR, but you can find it <a href="https://github.com/Manishearth/rust/commit/partial-cmp-hygiene">here</a>.</p>

<p>Except I hit a problem. With that PR, the following still breaks:</p>

<pre><code class="language-rust">pub const cmp: u8 = 1;

#[derive(PartialOrd, PartialEq)]
pub enum Foo {
    A(u8), B(u8)
}
</code></pre>

<p>throwing a slightly cryptic error:</p>

<pre><code>error[E0530]: match bindings cannot shadow constants
 --&gt; test.rs:9:7
  |
4 | pub const cmp: u8 = 1;
  | ---------------------- a constant `cmp` is defined here
...
9 |     B(u8)
  |       ^^^ cannot be named the same as a constant
</code></pre>

<p>You can see a reduced version of this error in the following code:</p>

<pre><code class="language-rust">pub const cmp : u8 = 1;

fn main() {
    match 1 {
        cmp @ _ =&gt; ()
    }
}
</code></pre>

<p>(<a href="https://play.rust-lang.org/?gist=feebbc048b47c286d5720b9926c6925e&amp;version=stable">playpen</a>)</p>

<p>Huh. Wat. Why? <code>cmp @ _</code> seems to be pretty unambiguous, what’s wrong with it shadowing a constant?</p>

<p>Turns out bindings cannot shadow constants at all, for a <a href="https://github.com/rust-lang/rust/issues/33118#issuecomment-233962221">rather subtle reason</a>:</p>

<pre><code class="language-rust">const A: u8 = ...; // A_const
let A @ _ = ...; // A_let
match .. {
    A =&gt; ...; // A_match
}
</code></pre>

<p>What happens here is that constants and variables occupy the same namespace. So <code>A_let</code> shadows
<code>A_const</code> here, and when we attempt to <code>match</code>, <code>A_match</code> is resolved to <code>A_let</code> and rejected (since
you can’t match against a variable), and <code>A_match</code> falls back to resolving as a fresh binding
pattern, instead of resolving to a pattern that matches against <code>A_const</code>.</p>

<p>This is kinda weird, so we disallow shadowing constants with variables. This is rarely a problem
because variables are lowercase and constants are uppercase. We could <em>technically</em> allow this
language-wise, but it’s hard on the implementation (and irrelevant in practice) so we don’t.</p>

<hr />

<p>So I dropped that fix. The temporary local variable approach is broken as well since
you can also name a constant the same as the local variable and have a clash (so again, you
need the underscores to avoid surprises).</p>

<p>But then I realized that we had an issue with removing the underscores from <code>__arg_0</code> as well.</p>

<p>The following code is also broken:</p>

<pre><code class="language-rust">pub const __arg_0: u8 = 1;

#[derive(Debug)]
struct Foo(u8);
</code></pre>

<p>(<a href="https://play.rust-lang.org/?gist=6e10fd8de1123c6f6f695c891e879f70&amp;version=stable">playpen</a>)</p>

<pre><code>error[E0308]: mismatched types
 --&gt; src/main.rs:3:10
  |
3 | #[derive(Debug)]
  |          ^^^^^ expected mutable reference, found u8
  |
  = note: expected type `&amp;mut std::fmt::Formatter&lt;'_&gt;`
             found type `u8`
</code></pre>

<p>You can see a reduced version of this error in the following code:</p>

<pre><code class="language-rust">pub const __arg_0: u8 = 1;

fn foo(__arg_0: bool) {}
</code></pre>

<pre><code>error[E0308]: mismatched types
 --&gt; src/main.rs:3:8
  |
3 | fn foo(__arg_0: bool) {}
  |        ^^^^^^^ expected bool, found u8
</code></pre>

<p>(<a href="https://play.rust-lang.org/?gist=2cf2c8b3520d5b343de1b76f80ea3fe7&amp;version=stable">playpen</a>)</p>

<p>This breakage is not an issue with the current code because of the double underscores – there’s a
very low chance someone will create a constant that is both lowercase and starts with a double
underscore. But it’s a problem when I remove the underscores since that chance shoots up.</p>

<p>Anyway, this failure is even weirder. Why are we attempting to match against the constant in the
first place? <code>fn</code> argument patterns<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">1</a></sup> are irrefutable, i.e. all possible values of the type should match
the argument. For example, <code>fn foo(Some(foo): Option&lt;u8&gt;) {}</code> will fail to compile with
“refutable pattern in function argument: <code>None</code> not covered”.</p>

<p>There’s no point trying to match against constants here; because even if we find a constant it will be rejected
later. Instead, we can unambiguously resolve identifiers as new bindings, yes?</p>

<p>Right?</p>

<p>Firm in my belief, <a href="https://github.com/rust-lang/rust/issues/49680">I filed an issue</a>.</p>

<p>I was wrong, it’s <a href="https://github.com/rust-lang/rust/issues/49680#issuecomment-379029404">not going to always be rejected later</a>. With zero-sized types this
can totally still work:</p>

<pre><code class="language-rust">struct S;

const C: S = S;

fn main() {
    let C = S;
}
</code></pre>

<p>Here because <code>S</code> has only one state, matching against a constant of the type is still irrefutable.</p>

<p>I argued that this doesn’t matter – since the type has a single value, it doesn’t matter whether we resolved to
a new binding or the constant; the value and semantics are the same.</p>

<p>This is true.</p>

<p>Except.</p>

<p><a href="https://github.com/rust-lang/rust/issues/49680#issuecomment-379032842">Except for when destructors come in</a>.</p>

<p>It was at this point that my table found itself in the perplexing state of being upside-down.</p>

<p>This is still really fine, zero-sized-constants-with-destructors is a pretty rare thing in Rust
and I don’t really see folks <em>relying</em> on this behavior.</p>

<p>However I later realized that this entire detour was pointless because even if we fix this, we end up
with a way for bindings to shadow constants. Which … which we already realized isn’t allowed by the
compiler till we fix some bugs.</p>

<p>Damn.</p>

<hr />

<p>The <em>actual</em> fix to the macro stuff is to use hygenic generated variable names, which the current
infrastructure supports. I plan to make a PR for this eventually.</p>

<p>But it was a very interesting dive into the nuances of pattern matching in Rust.</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>Yes, function arguments in Rust are patterns. You can totally do things like <code>(a, b): (u8, u8)</code> in function arguments (like you can do in <code>let</code>) <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2018/02/15/picking-apart-the-crashing-ios-string/">Picking Apart the Crashing iOS String</a></h1>
    
    
      <p class="meta">
        





        
      </p>
    
  </header>


  <div class="entry-content"><p>So there’s <a href="https://www.theverge.com/2018/2/15/17015654/apple-iphone-crash-ios-11-bug-imessage">yet another iOS text crash</a>, where just looking at a particular string crashes
iOS. Basically, if you put this string in any system text box (and other places), it crashes that
process. I’ve been testing it by copy-pasting characters into Spotlight so I don’t end up crashing
my browser.</p>

<p>The original sequence is U+0C1C U+0C4D U+0C1E U+200C U+0C3E, which is a sequence of Telugu
characters: the consonant ja (జ), a virama ( ్ ), the consonant nya (ఞ), a zero-width non-joiner, and
the vowel aa ( ా).</p>

<p>I was pretty interested in what made this sequence “special”, and started investigating.</p>

<p>So first when looking into this, I thought that the &lt;ja, virama, nya&gt; sequence was the culprit.
That sequence forms a special ligature in many Indic scripts (ज्ञ in Devanagari) which is often
considered a letter of its own. However, the ligature for Telugu doesn’t seem very “special”.</p>

<p>Also, from some experimentation, this bug seemed to occur for <em>any</em> pair of Telugu consonants with
a vowel, as long as the vowel is not   ై (ai). Huh.</p>

<p>The ZWNJ must be doing something weird, then. &lt;consonant, virama, consonant, vowel&gt; is a
pretty common sequence in any Indic script; but ZWNJ before a vowel isn’t very useful for most
scripts (except for Bengali and Oriya, but I’ll get to that).</p>

<p>And then I saw that <a href="https://twitter.com/FakeUnicode/status/963300865762254848">there was a sequence in Bengali</a> that also crashed.</p>

<p>The sequence is U+09B8 U+09CD U+09B0 U+200C U+09C1, which is the consonant “so” (স), a virama ( ্ ),
the consonant “ro” (র), a ZWNJ, and vowel u (  ু).</p>

<p>Before we get too into this, let’s first take a little detour to learn how Indic scripts work:</p>

<h2 id="indic-scripts-and-consonant-clusters">Indic scripts and consonant clusters</h2>

<p>Indic scripts are <em>abugidas</em>; which means that their “letters” are consonants, which you
can attach diacritics to to change the vowel. By default, consonants have a base vowel.
So, for example, क is “kuh” (kə, often transcribed as “ka”), but I can change the vowel to make it के
(the “ka” in “okay”) का (“kaa”, like “car”).</p>

<p>Usually, the default vowel is the ə sound, though not always (in Bengali it’s more of an o sound).</p>

<p>Because of the “default” vowel, you need a way to combine consonants. For example, if you wished to
write the word “ski”, you can’t write it as स + की (sa + ki = “saki”), you must write it as स्की.
What’s happened here is that the स got its vowel “killed”, and got tacked on to the की to form a
consonant cluster ligature.</p>

<p>You can <em>also</em> write this as स्‌की . That little tail you see on the स is known as a “virama”;
it basically means “remove this vowel”. Explicit viramas are sometimes used when there’s no easy way
to form a ligature, e.g. in ङ्‌ठ because there is no simple way to ligatureify ङ into ठ. Some scripts
also <em>prefer</em> explicit viramas, e.g. “ski” in Malayalam is written as സ്കീ, where the little crescent
is the explicit virama.</p>

<p>In unicode, the virama character is always used to form a consonant cluster. So स्की was written as
&lt;स,  ्, क,  ी&gt;, or &lt;sa, virama, ka, i&gt;. If the font supports the cluster, it will show up
as a ligature, otherwise it will use an explicit virama.</p>

<p>For Devanagari and Bengali, <em>usually</em>, in a consonant cluster the first consonant is munged a bit and the second consonant stays intact.
There are exceptions – sometimes they’ll form an entirely new glyph (क + ष = क्ष), and sometimes both
glyphs will change (ड + ड = ड्ड, द + म = द्म, द + ब = द्ब). Those last ones should look like this in conjunct form:</p>

<p><img class="center" src="/images/post/unicode-crash/conjuncts.png" width="200" /></p>

<h2 id="investigating-the-bengali-case">Investigating the Bengali case</h2>

<p>Now, interestingly, unlike the Telugu crash, the Bengali crash seemed to only occur when the second
consonant is র (“ro”). However, I can trigger it for any choice of the first consonant or vowel, except
when the vowel is  ো (o) or  ৌ (au).</p>

<p>Now, র is an interesting consonant in some Indic scripts, including Devanagari. In Devanagari,
it looks like र (“ra”). However, it does all kinds of things when forming a cluster. If you’re having it
precede another consonant in a cluster, it forms a little feather-like stroke, like in र्क (rka). In Marathi,
that stroke can also look like a tusk, as in र्‍क. As a suffix consonant, it can provide a little
“extra leg”, as in क्र (kra). For letters without a vertical stroke, like ठ (tha), it does this caret-like thing,
ठ्र (thra).</p>

<p>Basically, while most consonants retain some of their form when put inside a cluster, र does not. And
a more special thing about र is that this happens even when र is the <em>second</em> consonant in a cluster – as I mentioned
before, for most consonant clusters the second consonant stays intact. While there are exceptions, they are usually
specific to the cluster; it is only र for which this happens for all clusters.</p>

<p>It’s similar in Bengali, র as the second consonant adds a tentacle-like thing on the existing consonant. For example,
প + র (po + ro) gives প্র (pro).</p>

<p>But it’s not just র that does this in Bengali, the consonant “jo” does as well. প + য (po + jo) forms প্য (pjo),
and the য is transformed into a wavy line called a “jophola”.</p>

<p>So I tried it with য  — , and it turns out that the Bengali crash occurs for  য as well!
So the general Bengali case is &lt;consonant, virama, র OR য, ZWNJ, vowel&gt;, where the vowel is not   ো or  ৌ.</p>

<h2 id="suffix-joining-consonants">Suffix-joining consonants</h2>

<p>So we’re getting close, here. At least for Bengali, it occurs when the second consonant is such that it often
combines with the first consonant without modifying its form much.</p>

<p>In fact, this is the case for Telugu as well! Consonant clusters in Telugu are usually formed by preserving the
original consonant, and tacking the second consonant on below!</p>

<p>For example, the original crashy string contains the cluster జ + ఞ, which looks like జ్ఞ. The first letter isn’t
really modified, but the second is.</p>

<p>From this, we can guess that it will also occur for Devanagari with र. Indeed it does! U+0915 U+094D U+0930 U+200C U+093E, that is,
&lt;क,  ्, र, zwnj,  ा&gt; (&lt; ka, virama, ra, zwnj, aa &gt;) is one such crashing sequence.</p>

<p>But this isn’t really the whole story, is it? For example, the crash does occur for “kro” + zwnj + vowel in Bengali,
and in “kro” (ক্র = ক + র = ko + ro) the resultant cluster involves the munging of both the prefix and suffix. But
the crash doesn’t occur for द्ब or ड्ड. It seems to be specific to the letter, not the nature of the cluster.</p>

<p>Digging deeper, the reason is that for many fonts (presumably the ones in use), these consonants
form “suffix joining consonants”<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">1</a></sup> (a term I made up) when preceded by a virama. This seems to
correspond to the <a href="https://docs.microsoft.com/en-us/typography/opentype/spec/features_pt#tag-pstf"><code>pstf</code> OpenType feature</a>, as well as <a href="https://docs.microsoft.com/en-us/typography/opentype/spec/features_uz#vatu"><code>vatu</code></a>.</p>

<p>For example, the sequence virama + क gives   ्क, i.e. it renders a virama with a placeholder followed by a क.</p>

<p>But, for र, virama + र renders  ्र, which for me looks like this:</p>

<p><img class="center" src="/images/post/unicode-crash/virama-ra.png" width="200" /></p>

<p>In fact, this is the case for the other consonants as well. For me,  ्र  ্র  ্য  ్ఞ  ్క
(Devanagari virama-ra, Bengali virama-ro, Bengali virama-jo, Telugu virama-nya, Telugu virama-ka)
all render as “suffix joining consonants”:</p>

<p><img class="center" src="/images/post/unicode-crash/virama-consonant.png" width="200" /></p>

<p>(This is true for all Telugu consonants, not just the ones listed).</p>

<p>An interesting bit is that the crash does not occur for &lt;र, virama, र, zwnj, vowel&gt;, because र-virama-र
uses the prefix-joining form of the first र (र्र). The same occurs for র with itself or ৰ or য. Because the virama
is “stickier” to the left in these cases, it doesn’t cause a crash. (h/t <a href="https://github.com/hackbunny">hackbunny</a> for discovering this
using a <a href="https://github.com/hackbunny/viramarama">script</a> to enumerate all cases).</p>

<p>Kannada <em>also</em> has “suffix joining consonants”, but for some reason I cannot trigger the crash with it. Ya in Gurmukhi
is also suffix-joining.</p>

<h2 id="the-zwnj">The ZWNJ</h2>

<p>The ZWNJ is curious. The crash doesn’t happen without it, but as I mentioned before a ZWNJ before a vowel
doesn’t really <em>do</em> anything for most Indic scripts. In Indic scripts, a ZWNJ can be used to explicitly force a
virama if used after the virama (I used it to write स्‌की in this post), however that’s not how it’s being used here.</p>

<p>In Bengali and Oriya specifically, a ZWNJ can be used to force a different vowel form when used before a vowel
(e.g. রু vs র‌ু), however this bug seems to apply to vowels for which there is only one form, and this bug
also applies to other scripts where this isn’t the case anyway.</p>

<p>The exception vowels are interesting. They’re basically all vowels that are made up of <em>two</em> glyph components. Philippe Verdy
points out:</p>

<blockquote>
  <p>And why this bug does not occur with some vowels is because these are vowels in two parts,
that are first decomposed into two separate glyphs reordered in the buffer of glyphs, while
other vowels do not need this prior mapping and keep their initial direct mapping from their
codepoints in fonts, which means that this has to do to the way the ZWNJ looks for the glyphs
of the vowels in the glyphs buffer and not in the initial codepoints buffer: there’s some desynchronization,
and more probably an uninitialized data field (for the lookup made in handling ZWNJ) if no vowel decomposition was done
(the same data field is correctly initialized when it is the first consonnant which takes an alternate form before
a virama, like in most Indic consonnant clusters, because the a glyph buffer is created.</p>
</blockquote>

<h2 id="generalizing">Generalizing</h2>

<p>So, ultimately, the full set of cases that cause the crash are:</p>

<p>Any sequence <code>&lt;consonant1, virama, consonant2, ZWNJ, vowel&gt;</code> in Devanagari, Bengali, and Telugu, where:</p>

<ul>
  <li><code>consonant2</code> is suffix-joining (<code>pstf</code>/<code>vatu</code>) – i.e. र, র, য, ৰ, and all Telugu consonants</li>
  <li><code>consonant1</code> is not a reph-forming letter like र/র (or a variant, like ৰ)</li>
  <li><code>vowel</code> does not have two glyph components, i.e. it is not   ై,   ো, or   ৌ</li>
</ul>

<p>This leaves one question open:</p>

<p>Why doesn’t it apply to Kannada? Or, for that matter, Khmer, which has a similar virama-like thing called a “coeng”?</p>

<h2 id="are-these-valid-strings">Are these valid strings?</h2>

<p>A recurring question I’m getting is if these strings are valid in the language, or unicode gibberish
like Zalgo text. Breaking it down:</p>

<ul>
  <li>All of the <em>rendered</em> glyphs are valid. The original Telugu one is the root of the word for
“knowledge” (and I’ve taken to calling this bug “forbidden knowledge” for that reason).</li>
  <li>In Telugu and Devanagari, there is no functional use of the ZWNJ as used before a vowel. It
should not be there, and one would not expect it in typical text.</li>
  <li>In Bengali (also Oriya), putting a ZWNJ before some vowels prevents them from ligatureifying, and this is
mentioned in the Unicode spec. However, it seems rare for native speakers to use this.</li>
  <li>In all of these scripts, putting a ZWNJ after viramas can be used to force an explicit virama
over a ligature. That is not the position ZWNJ is used here, but it gives a hint that this
might have been a mistype. Doing this is <em>also</em> rare at least for Devanagari (and I believe
for the other two scripts as well)</li>
  <li>Android has an explicit key for ZWNJ on its keyboards for these languages<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote">2</a></sup>, right next to the spacebar. iOS has this as
well on the long-press of the virama key. <em>Very</em> easy to mistype, at least for Android.</li>
</ul>

<p>So while the crashing strings are usually invalid, and when not, very rare, they are easy enough to mistype.</p>

<p>An example by <a href="https://twitter.com/FakeUnicode">@FakeUnicode</a> was the string “For/k” (or “Foŕk”, if accents were easier to type). A
slash isn’t something you’d normally type there, and the produced string is gibberish, but it’s easy enough to type
by accident.</p>

<p>Except of course that the mistake in “For/k”/”Foŕk” is visually obvious and would be fixed; this
isn’t the case for most of the crashing strings.</p>

<h2 id="conclusion">Conclusion</h2>

<p>I don’t really have <em>one</em> guess as to what’s going on here – I’d love to see what people think – but my current
guess is that the “affinity” of the virama to the left instead of the right confuses the algorithm that handles ZWNJs after
viramas into thinking the ZWNJ applies to the virama (it doesn’t, there’s a consonant in between), and this leads to some numbers
not matching up and causing a buffer overflow or something. Philippe’s diagnosis of the vowel situation matches up with this.</p>

<p>An interesting thing is that I can cause this crash to happen more reliably in browsers by clicking on the string.</p>

<p>Additionally, <em>sometimes</em> it actually renders in spotlight for a split second before crashing; which
means that either the crash isn’t deterministic, or it occurs in some process <em>after</em> rendering. I’m
not sure what to think of either. Looking at the backtraces, the crash seems to occur in different
places, so it’s likely that it’s memory corruption that gets uncovered later.</p>

<p>I’d love to hear if folks have further insight into this.</p>

<p>Update: Philippe on the Unicode mailing list has <a href="https://www.unicode.org/mail-arch/unicode-ml/y2018-m02/0103.html">an interesting theory</a></p>

<p><small>Yes, I could attach a debugger to the crashing process and investigate that instead, but that’s no fun 😂</small></p>
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>Philippe Verdy points out that these may be called “phala forms” at least for Bengali <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>I don’t think the Android keyboard <em>needs</em> this key; the keyboard seems very much a dump of “what does this unicode block let us do”, and includes things like Sindhi-specific or Kashmiri-specific characters for the Marathi keyboard as well as <em>extremely</em> archaic characters, whilst neglecting more common things like the eyelash reph (which doesn’t have its own code point but is a special unicode sequence; native speakers should not be expected to be aware of this sequence). <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2018/02/01/a-rough-proposal-for-sum-types-in-go/">A Rough Proposal for Sum Types in Go</a></h1>
    
    
      <p class="meta">
        





        
      </p>
    
  </header>


  <div class="entry-content"><p>Sum types are pretty cool. Just like how a struct is basically “This contains one of these <em>and</em> one of these”,
a sum type is “This contains one of these <em>or</em> one of these”.</p>

<p>So for example, the following sum type in Rust:</p>

<pre><code class="language-rust">enum Foo {
    Stringy(String),
    Numerical(u32)
}
</code></pre>

<p>or Swift:</p>

<pre><code class="language-swift">enum Foo {
    case stringy(String),
    case numerical(Int)
}
</code></pre>

<p>would be one where it’s either <code>Foo::Stringy</code> (<code>Foo::stringy</code> for swift), containing a <code>String</code>,
<em>or</em> <code>Foo::Numerical</code>, containing an integer.</p>

<p>This can be pretty useful. For example, messages between threads are often of a “this or that or that or that”
form.</p>

<p>The nice thing is, matching (switching) on these enums is usually <em>exhaustive</em> – you must list all
the cases (or include a default arm) for your code to compile. This leads to a useful component
of type safety – if you add a message to your message passing system, you’ll know where to update it.</p>

<p>Go doesn’t have these. Go <em>does</em> have interfaces, which are dynamically dispatched. The drawback here
is that you do not get the exhaustiveness condition, and consumers of your library can even add further
cases. (And, of course, dynamic dispatch can be slow). You <em>can</em> get exhaustiveness in Go with <a href="https://github.com/haya14busa/gosum">external tools</a>,
but it’s preferable to have such things in the language IMO.</p>

<p>Many years ago when I was learning Go I wrote a <a href="http://inpursuitoflaziness.blogspot.in/2015/02/thoughts-of-rustacean-learning-go.html">blog post</a> about what I liked and disliked
as a Rustacean learning Go. Since then, I’ve spent a lot more time with Go, and I’ve learned to like each Go design decision that I initially
disliked, <em>except</em> for the lack of sum types. Most of my issues arose from “trying to program Rust in Go”,
i.e. using idioms that are natural to Rust (or other languages I’d used previously). Once I got used to the
programming style, I realized that aside from the lack of sum types I really didn’t find much missing
from the language. Perhaps improvements to error handling.</p>

<p>Now, my intention here isn’t really to sell sum types. They’re somewhat controversial for Go, and
there are good arguments on both sides. You can see one discussion on this topic <a href="https://github.com/golang/go/issues/19412">here</a>.
If I were to make a more concrete proposal I’d probably try to motivate this in much more depth. But even
I’m not very <em>strongly</em> of the opinion that Go needs sum types; I have a slight preference for it.</p>

<p>Instead, I’m going to try and sketch this proposal for sum types that has been floating around my
mind for a while. I end up mentioning it often and it’s nice to have something to link to. Overall,
I think this “fits well” with the existing Go language design.</p>

<h2 id="the-proposal">The proposal</h2>

<p>The essence is pretty straightforward: Extend interfaces to allow for “closed interfaces”. These are
interfaces that are only implemented for a small list of types.</p>

<p>Writing the <code>Foo</code> sum type above would be:</p>

<pre><code class="language-go">type Foo interface {
    SomeFunction()
    OtherFunction()
    for string, int
}
</code></pre>

<p>It doesn’t even need to have functions defined on it.</p>

<p>The interface functions can only be called if you have an interface object; they are not directly available
on variant types without explicitly casting (<code>Foo("...").SomeFunction()</code>).</p>

<p>(I’m not strongly for the <code>for</code> keyword syntax, it’s just a suggestion. The core idea is that
you define an interface and you define the types it closes over. Somehow.)</p>

<p>A better example would be an interface for a message-passing system for Raft:</p>

<pre><code class="language-go">type VoteRequest struct {
    CandidateId uint
    Term uint
    // ...
}

type VoteResponse struct {
    Term uint
    VoteGranted bool
    VoterId uint
}

type AppendRequest struct {
    //...
}

type AppendResponse struct {
    //...
}
// ...
type RaftMessage interface {
    for VoteRequest, VoteResponse, AppendRequest, AppendResponse
}
</code></pre>

<p>Now, you use type switches for dealing with these:</p>

<pre><code class="language-go">switch value := msg.(type) {
    case VoteRequest:
        if value.Term &lt;= me.Term {
            me.reject_vote(value.CandidateId)
        } else {
            me.accept_vote(value.CandidateId, value.Term)
        }
    case VoteResponse: // ...
    case AppendRequest: // ...
    case AppendResponse: // ...
}
</code></pre>

<p>There is no need for the default case, unless you wish to leave one or more of the cases out.</p>

<p>Ideally, these could be implemented as inline structs instead of using dynamic dispatch. I’m not sure
what this entails for the GC design, but I’d love to hear thoughts on this.</p>

<p>We also make it possible to add methods to closed interfaces. This is in the spirit of
<a href="https://github.com/golang/go/issues/16254">this proposal</a>, where you allow</p>

<pre><code class="language-go">func (message RaftMessage) Process(me Me) error {
    // message handling logic
}
</code></pre>

<p>for closed interfaces.</p>

<p>This aligns more with how sum types are written and used in other languages; instead of assuming
that each method will be a <code>switch</code> on the variant, you can write arbitrary code that <em>may</em> <code>switch</code>
on the type but it can also just call other methods. This is really nice because you can write
methods in <em>both</em> ways – if it’s a “responsibility of the inner type” kind of method, require it in
the interface and delegate it to the individual types. If it’s a “responsibility of the interface”
method, write it as a method on the interface as a whole. I kind of wish Rust had this, because in Rust
you sometimes end up writing things like:</p>

<pre><code class="language-rust">match foo {
    Foo::Stringy(s) =&gt; s.process(),
    Foo::Numerical(n) =&gt; n.process(),
    // ...
}
</code></pre>

<p>Yes, this would work better as a trait, but then you lose some niceties of Rust enums. With this
proposal Go can have it both ways.</p>

<hr />

<p>Anyway, thoughts? This is a really rough proposal, and I’m not sure how receptive other Gophers will be
to this, nor how complex its implementation would be. I don’t really intend to submit this as a formal proposal,
but if someone else wants to they are more than welcome to build on this idea.</p>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2018/01/10/whats-tokio-and-async-io-all-about/">What Are Tokio and Async IO All About?</a></h1>
    
    
      <p class="meta">
        





        
      </p>
    
  </header>


  <div class="entry-content"><p>The Rust community lately has been focusing a lot on “async I/O” through the <a href="https://github.com/tokio-rs/">tokio</a>
project. This is pretty great!</p>

<p>But for many in the community who haven’t worked with web servers and related things it’s pretty
confusing as to what we’re trying to achieve there. When this stuff was being discussed around 1.0,
I was pretty lost as well, having never worked with this stuff before.</p>

<p>What’s all this Async I/O business about? What are coroutines? Lightweight threads? Futures? How
does this all fit together?</p>

<h2 id="what-problem-are-we-trying-to-solve">What problem are we trying to solve?</h2>

<p>One of Rust’s key features is “fearless concurrency”. But the kind of concurrency required for handling a
large amount of I/O bound tasks – the kind of concurrency found in Go, Elixir, Erlang – is absent
from Rust.</p>

<p>Let’s say you want to build something like a web service. It’s going to be handling thousands of
requests at any point in time (known as the “<a href="https://en.wikipedia.org/wiki/C10k_problem">c10k</a> problem”). In general, the problem we’re
considering is having a huge number of I/O bound (usually network I/O) tasks.</p>

<p>“Handling N things at once” is best done by using threads. But … <em>thousands</em> of threads? That
sounds a bit much. Threads can be pretty expensive: Each thread needs to allocate a large stack,
setting up a thread involves a bunch of syscalls, and context switching is expensive.</p>

<p>Of course, thousands of threads <em>all doing work</em> at once is not going to work anyway. You only
have a fixed number of cores, and at any one time only one thread will be running on a core.</p>

<p>But for cases like web servers, most of these threads won’t be doing work. They’ll be waiting on the
network. Most of these threads will either be listening for a request, or waiting for their response
to get sent.</p>

<p>With regular threads, when you perform a blocking I/O operation, the syscall returns control
to the kernel, which won’t yield control back, because the I/O operation is probably not finished.
Instead, it will use this as an opportunity to swap in a different thread, and will swap the original
thread back when its I/O operation is finished (i.e. it’s “unblocked”). Without Tokio and friends,
this is how you would handle such things in Rust. Spawn a million threads; let the OS deal with
scheduling based on I/O.</p>

<p>But, as we already discovered, threads don’t scale well for things like this<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">1</a></sup>.</p>

<p>We need “lighter” threads.</p>

<h2 id="lightweight-threading">Lightweight threading</h2>

<p>I think the best way to understand lightweight threading is to forget about Rust for a moment
and look at a language that does this well, Go.</p>

<p>Instead of using OS threads, Go has lightweight threads, called “goroutines”. You spawn these with the <code>go</code>
keyword. A web server might do something like this:</p>

<pre><code class="language-go">listener, err = net.Listen(...)
// handle err
for {
    conn, err := listener.Accept()
    // handle err

    // spawn goroutine:
    go handler(conn)
}
</code></pre>

<p>This is a loop which waits for new TCP connections, and spawns a goroutine with the connection
and the function <code>handler</code>. Each connection will be a new goroutine, and the goroutine will shut down
when <code>handler</code> finishes. In the meantime, the main loop continues executing, because it’s running in
a different goroutine.</p>

<p>So if these aren’t “real” (operating system) threads, what’s going on?</p>

<p>A goroutine is an example of a “lightweight” thread. The operating system doesn’t know about these,
it sees N threads owned by the Go runtime, and the Go runtime maps M goroutines onto them<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote">2</a></sup>, swapping
goroutines in and out much like the operating system scheduler. It’s able to do this because
Go code is already interruptible for the GC to be able to run, so the scheduler can always ask goroutines
to stop. The scheduler is also aware of I/O, so when a goroutine is waiting on I/O it yields to the scheduler.</p>

<p>Essentialy, a compiled Go function will have a bunch of points scattered throughout it where it
tells the scheduler and GC “take over if you want” (and also “I’m waiting on stuff, please take
over”).</p>

<p>When a goroutine is swapped on an OS thread, some registers will be saved, and
the program counter will switch to the new goroutine.</p>

<p>But what about its stack? OS threads have a large stack with them, and you kinda need a stack for functions
and stuff to work.</p>

<p>What Go used to do was segmented stacks. The reason a thread needs a large stack is that most
programming languages, including C, expect the stack to be contiguous, and stacks can’t just be
“reallocated” like we do with growable buffers since we expect stack data to stay put so that
pointers to stack data to continue to work. So we reserve all the stack we think we’ll ever need
(~8MB), and hope we don’t need more.</p>

<p>But the expectation of stacks being contiguous isn’t strictly necessary. In Go, stacks are made of tiny
chunks. When a function is called, it checks if there’s enough space on the stack for it to run, and if not,
allocates a new chunk of stack and runs on it. So if you have thousands of threads doing a small amount of work,
they’ll all get thousands of tiny stacks and it will be fine.</p>

<p>These days, Go actually does something different; it <a href="https://blog.cloudflare.com/how-stacks-are-handled-in-go/">copies stacks</a>. I mentioned that stacks can’t
just be “reallocated” we expect stack data to stay put. But that’s not necessarily true —
because Go has a GC it knows what all the pointers are <em>anyway</em>, and it can rewrite pointers to
stack data on demand.</p>

<p>Either way, Go’s rich runtime lets it handle this stuff well. Goroutines are super cheap, and you can spawn
thousands without your computer having problems.</p>

<p>Rust <em>used</em> to support lightweight/”green” threads (I believe it used segmented stacks). However, Rust cares
a lot about not paying for things you don’t use, and this imposes a penalty on all your code even if you
aren’t using green threads, and it was removed pre-1.0.</p>

<h2 id="async-io">Async I/O</h2>

<p>A core building block of this is Async I/O. As mentioned in the previous section,
with regular blocking I/O, the moment you request I/O your thread will not be allowed to run
(“blocked”) until the operation is done. This is perfect when working with OS threads (the OS
scheduler does all the work for you!), but if you have lightweight threads you instead want to
replace the lightweight thread running on the OS thread with a different one.</p>

<p>Instead, you use non-blocking I/O, where the thread queues a request for I/O with the OS and continues
execution. The I/O request is executed at some later point by the kernel. The thread then needs to ask the
OS “Is this I/O request ready yet?” before looking at the result of the I/O.</p>

<p>Of course, repeatedly asking the OS if it’s done can be tedious and consume resources. This is why
there are system calls like <a href="https://en.wikipedia.org/wiki/Epoll"><code>epoll</code></a>. Here, you can bundle together a bunch of unfinished I/O requests,
and then ask the OS to wake up your thread when <em>any</em> of these completes. So you can have a scheduler
thread (a real thread) that swaps out lightweight threads that are waiting on I/O, and when there’s nothing
else happening it can itself go to sleep with an <code>epoll</code> call until the OS wakes it up (when one of the I/O
requests completes).</p>

<p>(The exact mechanism involved here is probably more complex)</p>

<p>So, bringing this to Rust, Rust has the <a href="https://github.com/carllerche/mio">mio</a> library, which is a platform-agnostic
wrapper around non-blocking I/O and tools like epoll/kqueue/etc. It’s a building block; and while
those used to directly using <code>epoll</code> in C may find it helpful, it doesn’t provide a nice programming
model like Go does. But we can get there.</p>

<h2 id="futures">Futures</h2>

<p>These are another building block. A <a href="https://docs.rs/futures/0.1.17/futures/future/trait.Future.html"><code>Future</code></a> is the promise of eventually having a value
(in fact, in Javascript these are called <code>Promise</code>s).</p>

<p>So for example, you can ask to listen on a network socket, and get a <code>Future</code> back  (actually, a
<code>Stream</code>, which is like a future but for a sequence of values). This <code>Future</code> won’t contain the
response <em>yet</em>, but will know when it’s ready. You can <code>wait()</code> on a <code>Future</code>, which will block
until you have a result, and you can also <code>poll()</code> it, asking it if it’s done yet (it will give you
the result if it is).</p>

<p>Futures can also be chained, so you can do stuff like <code>future.then(|result| process(result))</code>.
The closure passed to <code>then</code> itself can produce another future, so you can chain together
things like I/O operations. With chained futures, <code>poll()</code> is how you make progress; each time
you call it it will move on to the next future provided the existing one is ready.</p>

<p>This is a pretty good abstraction over things like non-blocking I/O.</p>

<p>Chaining futures works much like chaining iterators. Each <code>and_then</code> (or whatever combinator)
call returns a struct wrapping around the inner future, which may contain an additional closure.
Closures themselves carry their references and data with them, so this really ends up being
very similar to a tiny stack!</p>

<h2 id="-tokio-">🗼 Tokio 🗼</h2>

<p>Tokio’s essentially a nice wrapper around mio that uses futures. Tokio has a core
event loop, and you feed it closures that return futures. What it will do is
run all the closures you feed it, use mio to efficiently figure out which futures
are ready to make a step<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote">3</a></sup>, and make progress on them (by calling <code>poll()</code>).</p>

<p>This actually is already pretty similar to what Go was doing, at a conceptual level.
You have to manually set up the Tokio event loop (the “scheduler”), but once you do
you can feed it tasks which intermittently do I/O, and the event loop takes
care of swapping over to a new task when one is blocked on I/O. A crucial difference is
that Tokio is single threaded, whereas the Go scheduler can use multiple OS threads
for execution. However, you can offload CPU-critical tasks onto other OS threads and
use channels to coordinate so this isn’t that big a deal.</p>

<p>While at a conceptual level this is beginning to shape up to be similar to what we had for Go, code-wise this doesn’t look so pretty. For the following Go code:</p>

<pre><code class="language-go">// error handling ignored for simplicity

func foo(...) ReturnType {
    data := doIo()
    result := compute(data)
    moreData = doMoreIo(result)
    moreResult := moreCompute(data)
    // ...
    return someFinalResult
}
</code></pre>

<p>The Rust code will look something like</p>

<pre><code class="language-rust">// error handling ignored for simplicity

fn foo(...) -&gt; Future&lt;ReturnType, ErrorType&gt; {
    do_io().and_then(|data| do_more_io(compute(data)))
          .and_then(|more_data| do_even_more_io(more_compute(more_data)))
    // ......
}
</code></pre>

<p>Not pretty. <a href="https://docs.rs/futures/0.1.25/futures/future/fn.loop_fn.html#examples">The code gets worse if you introduce branches and loops</a>. The problem is that in Go we
got the interruption points for free, but in Rust we have to encode this by chaining up combinators
into a kind of state machine. Ew.</p>

<h2 id="generators-and-asyncawait">Generators and async/await</h2>

<p>This is where generators (also called coroutines) come in.</p>

<p><a href="https://doc.rust-lang.org/nightly/unstable-book/language-features/generators.html">Generators</a> are an experimental feature in Rust. Here’s an example:</p>

<pre><code class="language-rust">let mut generator = || {
    let i = 0;
    loop {
        yield i;
        i += 1;
    }
};
assert_eq!(generator.resume(), GeneratorState::Yielded(0));
assert_eq!(generator.resume(), GeneratorState::Yielded(1));
assert_eq!(generator.resume(), GeneratorState::Yielded(2));
</code></pre>

<p>Functions are things which execute a task and return once. On the other hand, generators
return multiple times; they pause execution to “yield” some data, and can be resumed
at which point they will run until the next yield. While my example doesn’t show this, generators
can also finish executing like regular functions.</p>

<p>Closures in Rust are
<a href="http://huonw.github.io/blog/2015/05/finding-closure-in-rust/">sugar for a struct containing captured data, plus an implementation of one of the <code>Fn</code> traits to make it callable</a>.</p>

<p>Generators are similar, except they implement the <code>Generator</code> trait<sup id="fnref:5" role="doc-noteref"><a href="#fn:5" class="footnote">4</a></sup>, and usually store an enum representing various states.</p>

<p>The <a href="https://doc.rust-lang.org/nightly/unstable-book/language-features/generators.html#generators-as-state-machines">unstable book</a> has some examples on what the generator state machine enum will look like.</p>

<p>This is much closer to what we were looking for! Now our code can look like this:</p>

<pre><code class="language-rust">fn foo(...) -&gt; Future&lt;ReturnType, ErrorType&gt; {
    let generator = || {
        let mut future = do_io();
        let data;
        loop {
            // poll the future, yielding each time it fails,
            // but if it succeeds then move on
            match future.poll() {
                Ok(Async::Ready(d)) =&gt; { data = d; break },
                Ok(Async::NotReady(d)) =&gt; (),
                Err(..) =&gt; ...
            };
            yield future.polling_info();
        }
        let result = compute(data);
        // do the same thing for `doMoreIo()`, etc
    }

    futurify(generator)
}
</code></pre>

<p>where <code>futurify</code> is a function that takes a generator and returns a future which on
each <code>poll</code> call will <code>resume()</code> the generator, and return <code>NotReady</code> until the generator
finishes executing.</p>

<p>But wait, this is even <em>more</em> ugly! What was the point of converting our relatively
clean callback-chaining code into this mess?</p>

<p>Well, if you look at it, this code now looks <em>linear</em>. We’ve converted our callback
code to the same linear flow as the Go code, however it has this weird loop-yield boilerplate
and the <code>futurify</code> function and is overall not very neat.</p>

<p>And that’s where <a href="https://github.com/alexcrichton/futures-await">futures-await</a> comes in. <code>futures-await</code> is a procedural macro that
does the last-mile work of packaging away this boilerplate. It essentially lets you write
the above function as</p>

<pre><code class="language-rust">#[async]
fn foo(...) -&gt; Result&lt;ReturnType, ErrorType&gt; {
    let data = await!(do_io());
    let result = compute(data);
    let more_data = await!(do_more_io());
    // ....
</code></pre>

<p>Nice and clean. Almost as clean as the Go code, just that we have explicit <code>await!()</code> calls. These
await calls are basically providing the same function as the interruption points that Go code
gets implicitly.</p>

<p>And, of course, since it’s using a generator under the hood, you can loop and branch and do whatever
else you want as normal, and the code will still be clean.</p>

<h2 id="tying-it-together">Tying it together</h2>

<p>So, in Rust, futures can be chained together to provide a lightweight stack-like system. With async/await,
you can neatly write these future chains, and <code>await</code> provides explicit interruption points on each I/O operation.
Tokio provides an event loop “scheduler” abstraction, which you can feed async functions to, and under the hood it
uses mio to abstract over low level non-blocking I/O primitives.</p>

<p>These are components which can be used independently — you can use tokio with futures without
using async/await. You can use async/await without using Tokio. For example, I think this would be
useful for Servo’s networking stack. It doesn’t need to do <em>much</em> parallel I/O (not at the order
of thousands of threads), so it can just use multiplexed OS threads. However, we’d still want
to pool threads and pipeline data well, and async/await would help here.</p>

<p>Put together, all these components get something almost as clean as the Go stuff, with a little more
explicit boilerplate. Because generators (and thus async/await) play nice with the borrow checker
(they’re just enum state machines under the hood), Rust’s safety guarantees are all still in play,
and we get to have “fearless concurrency” for programs having a huge quantity of I/O bound tasks!</p>

<p><em>Thanks to Arshia Mufti, Steve Klabnik, Zaki Manian, and Kyle Huey for reviewing drafts of this post</em></p>
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>Note that this isn’t necessarily true for <em>all</em> network server applications. For example, Apache uses OS threads. OS threads are often the best tool for the job. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>Lightweight threading is also often called M:N threading (also “green threading”) <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>In general future combinators aren’t really aware of tokio or even I/O, so there’s no easy way to ask a combinator “hey, what I/O operation are you waiting for?”. Instead, with Tokio you use special I/O primitives that still provide futures but also register themselves with the scheduler in thread local state. This way when a future is waiting for I/O, Tokio can check what the recentmost I/O operation was, and associate it with that future so that it can wake up that future again when <code>epoll</code> tells it that that I/O operation is ready. (<em>Edit Dec 2018: This has changed, futures now have a built in <code>Waker</code> concept that handles passing things up the stack</em>) <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:5" role="doc-endnote">
      <p>The <code>Generator</code> trait has a <code>resume()</code> function which you can call multiple times, and each time it will return any yielded data or tell you that the generator has finished running. <a href="#fnref:5" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/posts/2">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
<h1> About Me </h1>
<div id="about">
    I'm a self-taught programmer with interests in programming languages, online communities, human languages, Rust, and physics, to name a few. <br><br>

    I'm currently on the Rust core team, and I work at Google on <a href="https://github.com/unicode-org/icu4x">ICU4X</a>.
</div>
<div id="doodads">
 <a href="http://twitter.com/Manishearth" style="white-space:normal">   <img style="border:none;box-shadow:none" src="/images/twitter.png" width="30px"></a>
 <a href="http://github.com/Manishearth" style="white-space:normal">   <img style="border:none;box-shadow:none"  src="/images/github.png" width="30px"></a>
</div>
</section>
<section>
<!-- <iframe scrolling="no" style="border: 0; height: 58px; width: 208px; overflow: hidden;" src="https://se-flair.appspot.com/751483b5-3bd0-467a-b3aa-f0bb8ac3887d/"></iframe> -->
</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2021/02/22/integrating-rust-and-c-plus-plus-in-firefox/">Integrating Rust and C++ in Firefox</a>
      </li>
    
      <li class="post">
        <a href="/blog/2019/10/09/on-voting-systems/">On Voting Systems</a>
      </li>
    
      <li class="post">
        <a href="/blog/2019/02/04/rust-governance-scaling-empathy/">Rust Governance: Scaling Empathy</a>
      </li>
    
      <li class="post">
        <a href="/blog/2018/09/11/converting-a-webgl-application-to-webvr/">Converting a WebGL Application to WebVR</a>
      </li>
    
      <li class="post">
        <a href="/blog/2018/08/26/why-i-enjoy-blogging/">Why I Enjoy Blogging</a>
      </li>
    
  </ul>
</section>

  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2021 - Manish Goregaokar - Licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/">CC BY SA 4.0</a> - 
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
