
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>In Pursuit of Laziness</title>
  <meta name="author" content="Manish Goregaokar">

  
  <meta name="description" content="The other day Steve wanted git alchemy done on the Rust repo. Specifically, he wanted the reference and nomicon moved out into
their own repositories &hellip;">
  
  <!-- Tweaked https://harimenon.com/blog/2013/02/23/twitter-cards-for-octopress-blogs/ -->
  
      <meta property="twitter:card" content="summary">
      <meta property="twitter:site" content="Manishearth">
      <meta property="twitter:url" content="http://manishearth.github.io">
      <meta property="twitter:title" content="In Pursuit of Laziness">
      <meta property="twitter:description" content="The other day Steve wanted git alchemy done on the Rust repo. Specifically, he wanted the reference and nomicon moved out into
their own repositories, preserving history. Both situations had some &hellip;">
      <meta name="twitter:image" content="http://manishearth.github.io/images/me.png" />
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://manishearth.github.io/posts/3/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/stylesheets/data-table.css" media="screen, projection" rel="stylesheet" type="text/css" />
  <link href="/stylesheets/custom.css" media="screen, projection" rel="stylesheet" type="text/css" />
  <link href="/atom.xml" rel="alternate" title="In Pursuit of Laziness" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="/javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <script src="/javascripts/manish.js" type="text/javascript"></script>
  <!--- MathJax Configuration -->
  
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-62537162-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">In Pursuit of Laziness</a></h1>
  
    <h2>Manish Goregaokar's blog</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="sitesearch" value="manishearth.github.io">
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2017/03/05/understanding-git-filter-branch/">Understanding Git Filter-branch and the Git Storage Model</a></h1>
    
    
      <p class="meta">
        





        
      </p>
    
  </header>


  <div class="entry-content"><p>The other day <a href="http://twitter.com/steveklabnik">Steve</a> wanted git alchemy done on the Rust repo.</p>

<p>Specifically, he wanted the reference and nomicon moved out into
their <a href="https://github.com/rust-lang-nursery/reference">own</a> <a href="https://github.com/rust-lang-nursery/nomicon">repositories</a>, preserving history. Both situations had some interesting
quirks, the reference has lived in <code>src/doc/reference/*</code> and <code>src/doc/reference.md</code>,
and the nomicon has lived in <code>src/doc/nomicon</code>, <code>src/doc/tarpl</code>, and at the top level
in a separate git root.</p>

<p>As you can guess from the title of this post, the correct tool for this job is <code>git filter-branch</code>.
<a href="https://twitter.com/indygreg">My colleague Greg</a> calls it “the swiss-army knife of Git history rewriting”.</p>

<p>I had some fun with filter-branch that day, thought I’d finally write an accessible tutorial for it. A lot
of folks treat filter-branch like rebase, but it isn’t, and this crucial difference can lead to many
false starts. It certainly did for me back when I first learned it.</p>

<p>This kind of ties into the common bit of pedantry about the nature of a commit I keep seeing pop up:</p>

<blockquote>
  <p><a href="https://twitter.com/ManishEarth/status/837203953926352896">Git commits appear to be diffs, but they’re actually file copies, but they’re actually ACTUALLY diffs.</a></p>
</blockquote>

<h2 id="so-what-is-a-git-commit">So what is a git commit?</h2>

<p>Generally we interact with git commits via <code>git show</code> or by looking at commits on
a git GUI / web UI. Here, we see diffs. It’s natural to think of a commit as a diff,
it’s the model that makes the most sense for the most common ways of interacting
with commits. It also makes some sense from an implementation point of view, diffs
seem like an efficient way of storing things.</p>

<p>It turns out that the “real” model is not this, it’s actually that each commit
is a snapshot of the whole repo state at the time.</p>

<p>But actually, it isn’t, the underlying implementation does make use of deltas
in packfiles and some other tricks like copy-on-write forking.</p>

<p>Ultimately, arguing about the “real” mental model is mostly pedantry. There are
multiple ways of looking at a commit. The documentation tends to implicitly think
of them as “full copies of the entire file tree”, which is where most
of the confusion about <code>filter-branch</code> comes from. But often it’s important
to picture them as diffs, too.</p>

<p>Understanding the implementation can be helpful, especially when you break the
repository whilst doing crazy things (I do this often). I’ve explained how it works
in a later section, it’s not really a prerequisite for understanding filter-branch,
but it’s interesting.</p>

<h2 id="how-do-i-rewrite-history-with-git-rebase">How do I rewrite history with <code>git rebase</code>?</h2>

<p>This is where some of the confusion around <code>filter-branch</code> stems from. Folks have worked with
<code>rebase</code>, and they think <code>filter-branch</code> is a generalized version of this. They’re actually quite
different.</p>

<p>For those of you who haven’t worked with <code>git rebase</code>, it’s a pretty useful way of rewriting
history, and is probably what you should use when you want to rewrite history, especially for
maintaining clean git history in an unmerged under-review branch.</p>

<p>Rebase does a whole bunch of things. Its core task is, given the current branch and a branch that
you want to “rebase onto”, it will take all commits unique to your branch, and apply them in order
to the new one. Here, “apply” means “apply the diff of the commit, attempting to resolve any conflicts”.
At times, it may ask you to manually resolve the conflicts, using the same tooling
you use for conflicts during <code>git merge</code>.</p>

<p>Rebase is much more powerful than that, though. <code>git rebase -i</code> will open up “interactive rebase”,
which will show you the commits that are going to be rebased. In this interface, you can reorder
commits, mark them for edits (wherein the rebase will stop at that commit and let you <code>git commit
--amend</code> changes into it), and even “squash” commits which lets you mark a commit to be absorbed
into the previous one. This is rather useful for when you’re working on a feature and want to keep
your commits neat, but also want to make fixup patches to older commits. <a href="https://blog.filippo.io/git-fixup-amending-an-older-commit/">Filippo’s <code>git fixup</code> alias</a>
packages this particular task into a single git command. Changing <code>EDITOR=true</code> into
<code>EDITOR=: GIT_SEQUENCE_EDITOR=:</code> will make it not even open the editor for confirmation
and try to do the whole thing automatically.</p>

<p><code>git rebase -x some_command</code> is also pretty neat, lets you run a shell command on each step during a rebase.</p>

<p>In this model, you are fundamentally thinking of commits as diffs. When you move around
commits in the interactive rebase editor, you’re moving around diffs. When you mark things
for squashing, you’re basically merging diffs. The whole process is about taking a set of
diffs and applying them to a different “base commit”.</p>

<p><img class="center" src="/images/post/memes/diffs-everywhere.jpg" width="400" /></p>

<h2 id="how-do-i-rewrite-history-with-git-filter-branch">How do I rewrite history with <code>git filter-branch</code>?</h2>

<p><code>filter-branch</code> does <em>not</em> work with diffs. You’re working with the “snapshot” model
of commits here, where each commit is a snapshot of the tree, and rewriting these commits.</p>

<p>What <code>git filter-branch</code> will do is for each commit in the specified branch, apply filters to the
snapshot, and create a new commit. The new commit’s parent will be the filtered version of the old
commit’s parent. So it creates a parallel commit DAG.</p>

<p>Because the filters apply on the snapshots instead of the diffs, there’s no chance for this to cause
conflicts like in git rebase. In git rebase, if I have one commit that makes changes to a file, and
I change the previous commit to just remove the area of the file that was changed, I’d have a conflict
and git would ask me to figure out how the changes are supposed to be applied.</p>

<p>In git-filter-branch, if I do this, it will just power through. Unless you explicitly write
your filters to refer to previous commits, the new commit is created in isolation, so it doesn’t
worry about changes to the previous commits. If you had indeed edited the previous commit,
the new commit will appear to undo those changes and apply its own on top of that.</p>

<p><code>filter-branch</code> is generally for operations you want to apply pervasively to a repository. If
you just want to tweak a few commits, it won’t work, since future commits will appear to undo
your changes. <code>git rebase</code> is for when you want to tweak a few commits.</p>

<p>So, how do you use it?</p>

<p>The basic syntax is <code>git filter-branch &lt;filters&gt; branch_name</code>. You can use <code>HEAD</code> or <code>@</code>
to refer to the current branch instead of explicitly typing <code>branch_name</code>.</p>

<p>A very simple and useful filter is the subdirectory filter. It makes a given subdirectory
the repository root. You use it via <code>git filter-branch --subdirectory-filter name_of_subdir @</code>.
This is useful for extracting the history of a folder into its own repository.</p>

<p>Another useful filter is the tree filter, you can use it to do things like moving around, creating,
or removing files. For example, if you want to move <code>README.md</code> to <code>README</code> in the entire history,
you’d do something like <code>git filter-branch --tree-filter 'mv README.md README' @</code> (you can also
achieve this much faster with some manual work and <code>rebase</code>). The tree filter will work by checking
out each commit (in a separate temporary folder), running your filter on the working directory,
adding any changes to the index (no need to <code>git add</code> yourself), and committing the new index.</p>

<p>The <code>--prune-empty</code> argument is useful here, as it removes commits which are now empty due to the
rewrite.</p>

<p>Because it is checking out each commit, this filter is quite slow. When I initially was trying to
do Steve’s task on the rust repo, I wrote a long tree filter and it was taking forever.</p>

<p>The faster version is the index filter. However, this is a bit trickier to work with (which is why I
tend to use a tree filter if I can get away with it). What this does is operate on the index,
directly.</p>

<p>The “index” is basically where things go when you <code>git add</code> them. Running <code>git add</code> will create
temporary objects for the added file, and modify the WIP index (directory tree) to include a
reference to the new file or change an existing file reference to the new one. When you commit, this
index is packaged up into a commit and stored as an object. (More on how these objects work in a
later section)</p>

<p>Now, since this deals with files that are already stored as objects, git doesn’t need to unwrap
these objects and create a working directory to operate on them. So, with <code>--index-filter</code>, you
can operate on these in a much faster way. However, since you don’t have a working directory,
stuff like adding and moving files can be trickier. You often have to use <code>git update-index</code>
to make this work.</p>

<p>However, a useful index filter is one which just scrubs a file (or files) from history:</p>

<pre><code class="language-sh">$ git filter-branch --index-filter 'git rm --cached --ignore-unmatch filename' HEAD
</code></pre>

<p>The <code>--ignore-unmatch</code> makes the command still succeed if the file doesn’t exist. <code>filter-branch</code>
will fail if one of the filters fails. In general I tend to write fallible filters like
<code>command1 1&gt;&amp;2 2&gt;/dev/null ; command2 1&gt;&amp;2 2&gt;/dev/null ; true</code>, which makes it always succeed
and also ignores any stdout/stderr output (which tends to make the progress screen fill up fast).</p>

<p>The <code>--cached</code> argument on <code>git rm</code> makes it operate only on the index, not the working directory.
This is great, because we don’t <em>have</em> a working directory right now.</p>

<p>I rarely use <code>git update-index</code> so I’m not really going to try and explain how it can be used here.
But if you need to do more complex operations in an index filter, that’s the way to go.</p>

<p>There are many other filters, like <code>--commit-filter</code> (lets you discard a commit entirely),
<code>--msg-filter</code> (rewriting commit messages), and <code>--env-filter</code> (changing things like author metadata
or other env vars). You can see a complete list with examples <a href="https://git-scm.com/docs/git-filter-branch">in the docs</a></p>

<h2 id="how-did-i-perform-the-rewrites-on-the-reference-and-nomicon">How did I perform the rewrites on the reference and nomicon?</h2>

<p>For the Rust Reference, basically I had to extract the history of <code>src/doc/reference.md</code>,
AND <code>src/doc/reference/*</code> (<code>reference.md</code> was split up into <code>reference/*.md</code> recently) into
its own commit. This is an easy tree filter to write, but tree filters take forever.</p>

<p>Instead of trying my luck with an index filter, I decided to just make it so that the
tree filter would be faster. I first extracted <code>src/doc/</code>:</p>

<pre><code class="language-sh">$ git filter-branch -f --prune-empty --subdirectory-filter src/doc @
</code></pre>

<p>Now I had a branch that contained only the history of <code>src/doc</code>, with the root directory moved to
<code>doc</code>. This is a much smaller repo than the entirety of Rust.</p>

<p>Now, I moved <code>reference.md</code> into <code>reference/</code>:</p>

<pre><code class="language-sh">$ git filter-branch -f --prune-empty --tree-filter 'mkdir -p reference; mv reference.md reference 1&gt;/dev/null 2&gt;/dev/null; true' @
</code></pre>

<p>As mentioned before, the <code>/dev/null</code> and <code>true</code> bits are because the mv command will fail in some cases
(when reference.md doesn’t exist), and I want it to just continue without complaining when that happens.
I only care about moving instances of that file, if that file doesn’t exist there it’s still okay.</p>

<p>Now, everything I cared about was within <code>reference</code>. The next step was simple:</p>

<pre><code class="language-sh">$ git filter-branch -f --prune-empty --subdirectory-filter reference @
</code></pre>

<p>The whole process took maybe 10 minutes to run, most of the time being spent by the second command.
The final result can be found <a href="https://github.com/rust-lang-nursery/reference">here</a>.</p>

<p>For the nomicon, the task was easier. In the case of the nomicon, it has always resided in
<code>src/doc/nomicon</code>, <code>src/doc/tarpl</code>, or at the root. This last bit is interesting, when
<a href="http://twitter.com/Gankro/">Alexis</a> was working on the nomicon, he started off by hacking on it in a separate repo, but
then within that repo moved it to <code>src/doc/tarpl</code>, and performed a merge commit with rustc. There’s
no inherent restriction in Git that all merges must have a common ancestor, and you can do stuff
like this. I was <a href="https://twitter.com/ManishEarth/status/837441118753062912">quite surprised</a> when I saw this, since it’s pretty uncommon in general,
but really, many projects of that size will have stuff like this. Servo and html5ever do too, and usually
it’s when a large project is merged into it after being developed on the side.</p>

<p>This sounds complicated to work with, but it wasn’t that hard. I took the same subdirectory-filtere’d
doc directory branch used for the reference. Then, I renamed <code>tarpl/</code> to <code>nomicon/</code> via a tree filter,
and ran another subdirectory filter:</p>

<pre><code class="language-sh">$ git filter-branch -f --prune-empty --tree-filter 'mv tarpl nomicon 1&gt;/dev/null 2&gt;/dev/null; true' @
$ git filter-branch -f --prune-empty --subdirectory-filter nomicon @
</code></pre>

<p>Now, I had the whole history of the nomicon in the root dir. Except for the commits made by Alexis
before his frankenmerge, because these got removed in the first subdirectory filter (the commits
were operating outside of <code>src/doc</code>, even though their contents eventually got moved there).</p>

<p>But, at this stage, I already had a branch with the nomicon at the root. Alexis’ original commits
were also operating on the root directory. I can just rebase here, and the diffs of my commits will
cleanly apply!</p>

<p>I found the commit (<a href="https://github.com/rust-lang/rust/commit/a54e64b3c41103c4f6ab840d8ddd3a56ec6b5da8"><code>a54e64</code></a>) where everything was moved to <code>tarpl/</code>, and took its parent
(<a href="https://github.com/rust-lang/rust/commit/c7919f2d9835578321bf7556ad1a01fa42e8a7e8"><code>c7919f</code></a>). Then, I just ran <code>git rebase --root c7919f</code>, and everything cleanly rebased.
As expected, because I had a history going back to the first child of <a href="https://github.com/rust-lang/rust/commit/a54e64b3c41103c4f6ab840d8ddd3a56ec6b5da8"><code>a54e64</code></a> with files
moved, and <a href="https://github.com/rust-lang/rust/commit/a54e64b3c41103c4f6ab840d8ddd3a56ec6b5da8"><code>a54e64</code></a> itself only moved files, so the diffs should cleanly apply.</p>

<p>The final result can be found <a href="https://github.com/rust-lang-nursery/nomicon">here</a>.</p>

<h2 id="appendix-how-are-commits-actually-stored">Appendix: How are commits actually stored?</h2>

<p>The way the actual implementation of a commit works is that each file being stored is hashed and
stored in a compressed format, indexed by the hash. A directory (“tree”) will be a list of hashes, one for
each file/directory inside it, alongside the filenames and other metadata. This list will be hashed
and used everywhere else to refer to the directory.</p>

<p>A commit will reference the “tree” object for the root directory via its hash.</p>

<p>Now, if you make a commit changing some files, most of the files will be unchanged. So will most of
the directories. So the commits can share the objects for the unchanged files/directories, reducing
their size. This is basically a copy-on-write model. Furthermore, there’s a second optimization
called a “packfile”, wherein instead of storing a file git will store a delta (a diff) and a
reference to the file the diff must be applied to.</p>

<p>We can see this at work using <code>git cat-file</code>. <code>cat-file</code> lets you view objects in
the “git filesystem”, which is basically a bunch of hash-indexed objects stored in
<code>.git/objects</code>. You can view them directly by traversing that directory (they’re
organized as a trie), but <code>cat-file -p</code> will let you pretty-print their contents
since they’re stored in a binary format.</p>

<p>I’m working with <a href="https://github.com/rust-lang/book">the repo for the Rust Book</a>,
playing with commit <a href="4822f2baa69c849e4fa3b85204f219a16bde2f42"><code>4822f2</code></a>. It’s a commit that changes
just one file (<code>second-edition/src/ch15-01-box.md </code>), perfect.</p>

<pre><code class="language-sh">$ git show 4822f2baa69c849e4fa3b85204f219a16bde2f42
commit 4822f2baa69c849e4fa3b85204f219a16bde2f42
Author: Jake Goulding &lt;...&gt;
Date:   Fri Mar 3 14:07:24 2017 -0500

    Reorder sentence about a generic cons list.

diff --git a/second-edition/src/ch15-01-box.md b/second-edition/src/ch15-01-box.md
index 14c5533..29d8793 100644
--- a/second-edition/src/ch15-01-box.md
+++ b/second-edition/src/ch15-01-box.md
(diff omitted)

$ git cat-file -p 4822f2baa69c849e4fa3b85204f219a16bde2f42

tree ec7cd2821d4bcbafe08f3eca6ea60487bfdc1b52
parent 24cd100e061bb11c3f7f3219467d6d644c50d811
author Jake Goulding &lt;...&gt; 1488568044 -0500
committer GitHub &lt;noreply@github.com&gt; 1488568044 -0500

Reorder sentence about a generic cons list.
</code></pre>

<p>This tells us that the commit is a thing with some author information, a pointer to
a parent, a commit message, and a “tree”. What’s this tree?</p>

<pre><code class="language-sh">$ git cat-file -p ec7cd2821d4bcbafe08f3eca6ea60487bfdc1b52
100644 blob 4cab1f4d267628ab5f4f7c14b1b64a9d4b032409    .gitattributes
040000 tree e1dcc1c754d72450b03542b2106fcb67c78805ff    .github
100644 blob 4c699f440ac134c577cb6f67b04ec5b93c652440    .gitignore
100644 blob e86d887d84a839417c960faf877c9057a8dc6823    .travis.yml
100644 blob 7990f2738876fc0fbc2ca30f5f91e91745b0b8eb    README.md
040000 tree 17b33cb52a5abb67ff678a03e7ed88cf9f163c69    ci
040000 tree 0ffd2c1238345c1b0e99af6c1c618eee4a0bab58    first-edition
100644 blob 5d1d2bb79e1521b28dd1b8ff67f9b04f38d83620    index.md
040000 tree b7160f7d05d5b5bfe28bad029b1b490e310cff22    redirects
040000 tree d5672dd9ef15adcd1527813df757847d745e299a    second-edition
</code></pre>

<p>This is just a directory! You can see that each entry has a hash. We can use
<code>git cat-file -p</code> to view each one. Looking at a <code>tree</code> object will just give
us a subdirectory, but the <code>blob</code>s will show us actual files!</p>

<pre><code class="language-sh">$ git cat-file -p 7990f2738876fc0fbc2ca30f5f91e91745b0b8eb # Show README
# The Rust Programming Language

[![Build Status](https://travis-ci.org/rust-lang/book.svg?branch=master)](https://travis-ci.org/rust-lang/book)

To read this book online, visit [rust-lang.github.io/book/][html].

(rest of file omitted)
</code></pre>

<p>So how does this share objects? Let’s look at the previous commit:</p>

<pre><code class="language-sh">$ git cat-file -p 4822f2baa69c849e4fa3b85204f219a16bde2f42^ # `^` means "parent"
tree d219be3c5010f64960ddb609a849fc42a01ad31b
parent 21c063868f9d7fb0fa488b6f1124262f055d275b
author steveklabnik &lt;...&gt; 1488567224 -0500
committer steveklabnik &lt;...&gt; 1488567239 -0500

mdbook needs to be on the PATH for deploy

$ git cat-file -p d219be3c5010f64960ddb609a849fc42a01ad31b # the tree
100644 blob 4cab1f4d267628ab5f4f7c14b1b64a9d4b032409    .gitattributes
040000 tree e1dcc1c754d72450b03542b2106fcb67c78805ff    .github
100644 blob 4c699f440ac134c577cb6f67b04ec5b93c652440    .gitignore
100644 blob e86d887d84a839417c960faf877c9057a8dc6823    .travis.yml
100644 blob 7990f2738876fc0fbc2ca30f5f91e91745b0b8eb    README.md
040000 tree 17b33cb52a5abb67ff678a03e7ed88cf9f163c69    ci
040000 tree 0ffd2c1238345c1b0e99af6c1c618eee4a0bab58    first-edition
100644 blob 5d1d2bb79e1521b28dd1b8ff67f9b04f38d83620    index.md
040000 tree b7160f7d05d5b5bfe28bad029b1b490e310cff22    redirects
040000 tree d48b2e06970cf3a6ae65655c340922ae69723989    second-edition
</code></pre>

<p>If you look closely, all of these hashes are the same, <em>except</em> for the hash for <code>second-edition</code>.
For the hashes which are the same, these objects are being shared across commits. The differing hash
is <code>d5672d</code> in the newer commit, and <code>d48b2e</code> in the older one.</p>

<p>Let’s look at the objects:</p>

<pre><code class="language-sh">$ git cat-file -p d5672d
100644 blob 82dc67a6b08f0eb62420e4da3b3aa9c0dc10911a    CONTRIBUTING.md
100644 blob 5cd51aa43f05416996c4ef055df5d6eb58fbe737    Cargo.lock
100644 blob 7ab2575fa5bf4abf6eaf767c72347580c9f769dd    Cargo.toml
100644 blob 96e9f0458b55a4047927de5bf04ceda89d772b2b    LICENSE-APACHE
100644 blob 5a56e6e8ed1909b4e4800aa8d2a0e7033ab4babe    LICENSE-MIT
100644 blob be1135fc6d28eca53959c7fc9ae191523e4bc96f    book.json
100644 blob 1400454f36840e916a7d7028d987c42fcb31b4db    dictionary.txt
100644 blob 5103c84d034d6e8a0e4b6090453ad2cdcde21537    doc-to-md.sh
040000 tree 6715d1d4c97e3d17a088922f687b8d9ffacb5953    dot
100644 blob f9e045c4c1824520534270a2643ebe68311503b8    nostarch.sh
040000 tree f8d9a9452b4bbaeba256b95d40b303cd5fb20a64    nostarch
100644 blob 0a2d16852c11355ef9d8758a304b812633dcf03c    spellcheck.sh
040000 tree 3f8db396566716299330cdd5f569fb0a0c4615dd    src
100644 blob 56677811f451084de7c3a2478587a09486209b14    style-guide.md
040000 tree 7601821a2ff38906332082671ea23e4074464dd2    tools

$ git cat-file -p d48b2e
100644 blob 82dc67a6b08f0eb62420e4da3b3aa9c0dc10911a    CONTRIBUTING.md
100644 blob 5cd51aa43f05416996c4ef055df5d6eb58fbe737    Cargo.lock
100644 blob 7ab2575fa5bf4abf6eaf767c72347580c9f769dd    Cargo.toml
100644 blob 96e9f0458b55a4047927de5bf04ceda89d772b2b    LICENSE-APACHE
100644 blob 5a56e6e8ed1909b4e4800aa8d2a0e7033ab4babe    LICENSE-MIT
100644 blob be1135fc6d28eca53959c7fc9ae191523e4bc96f    book.json
100644 blob 1400454f36840e916a7d7028d987c42fcb31b4db    dictionary.txt
100644 blob 5103c84d034d6e8a0e4b6090453ad2cdcde21537    doc-to-md.sh
040000 tree 6715d1d4c97e3d17a088922f687b8d9ffacb5953    dot
100644 blob f9e045c4c1824520534270a2643ebe68311503b8    nostarch.sh
040000 tree f8d9a9452b4bbaeba256b95d40b303cd5fb20a64    nostarch
100644 blob 0a2d16852c11355ef9d8758a304b812633dcf03c    spellcheck.sh
040000 tree f9fc05a6ff78b8211f4df931ed5e32c937aba66c    src
100644 blob 56677811f451084de7c3a2478587a09486209b14    style-guide.md
040000 tree 7601821a2ff38906332082671ea23e4074464dd2    tools
</code></pre>

<p>Again, these are the same, except for that of <code>src</code>. <code>src</code> has a <em>lot</em> of files in it,
which will clutter this post, so I’ll run a diff on the outputs of <code>cat-file</code>:</p>

<pre><code class="language-udiff">$ diff -U5 &lt;(g cat-file -p f9fc05a6ff78b8211f4df931ed5e32c937aba66c) &lt;(g cat-file -p 3f8db396566716299330cdd5f569fb0a0c4615dd)
--- /dev/fd/63  2017-03-05 11:58:22.000000000 -0800
+++ /dev/fd/62  2017-03-05 11:58:22.000000000 -0800
@@ -63,11 +63,11 @@
 100644 blob ff6b8f8cd44f624e1239c47edda59560cdf491ae   ch14-02-publishing-to-crates-io.md
 100644 blob c53ef854a74b6c9fbd915be1bf824c6e78439c42   ch14-03-cargo-workspaces.md
 100644 blob 3fb59f9cc85b6b81994e83a34d542871a260a8f0   ch14-04-installing-binaries.md
 100644 blob e1cd1ca779fdf202af433108a8af6eda317f2717   ch14-05-extending-cargo.md
 100644 blob 3173cc508484cc447ebe42a024eac7d9e6c2ddcd   ch15-00-smart-pointers.md
-100644 blob 14c5533bb3b604c6e6274db278d1e7129f78d55d   ch15-01-box.md
+100644 blob 29d87933d6832374b87d98aa5588e09e0c1a4991   ch15-01-box.md
 100644 blob 47b35ed489d63ce6a885289fec01b7b16ba1afea   ch15-02-deref.md
 100644 blob 2d20c55cc8605c0c899bc4867adc6b6ea1f5c902   ch15-03-drop.md
 100644 blob 8e3fcf4e83fe1ce985a7c0b479b8b16701765aaf   ch15-04-rc.md
 100644 blob a4ade4ae8bf5296d79ed51d69506e71a83f9f489   ch15-05-interior-mutability.md
 100644 blob 3a4db5616c4f5baeb95d04ea40c6747e60181684   ch15-06-reference-cycles.md
</code></pre>

<p>As you can see, only the file that was changed in the commit has a new blob stored.
If you view <code>14c553</code> and <code>29d879</code> you’ll get the pre- and post- commit versions
of the file respectively.</p>

<p>So basically, each commit stores a tree of references to objects, often sharing nodes
with other commits.</p>

<p>I haven’t had the opportunity to work with packfiles much, but they’re an
additional optimization on top of this. <a href="https://codewords.recurse.com/issues/three/unpacking-git-packfiles">Aditya’s post</a> is a good
intro to these.</p>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2017/03/04/what-are-sum-product-and-pi-types/">What Are Sum, Product, and Pi Types?</a></h1>
    
    
      <p class="meta">
        





        
      </p>
    
  </header>


  <div class="entry-content"><p><em>See also: <a href="https://tonyarcieri.com/a-quick-tour-of-rusts-type-system-part-1-sum-types-a-k-a-tagged-unions">Tony’s post on the same topic</a></em></p>

<p>You often hear people saying “Language X<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">1</a></sup> has sum types” or “I wish language X had sum types”<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote">2</a></sup>,
or “Sum types are cool”.</p>

<p>Much like fezzes and bow ties, sum types are indeed cool.</p>

<p><img class="center" src="/images/post/memes/sum-types-are-cool.jpg" width="400" /></p>

<p>These days, I’ve also seen people asking about “Pi types”, because of <a href="https://github.com/ticki/rfcs/blob/pi-types-2/text/0000-pi-types.md">this Rust RFC</a>.</p>

<p>But what does “sum type” mean? And why is it called that? And what, in the name of sanity, is
a Pi type?</p>

<p>Before I start, I’ll mention that while I will be covering some type theory to explain the names
“sum” and “product”, you don’t need to understand these names to use these things! Far too often
do people have trouble understanding relatively straightforward concepts in languages because
they have confusing names with confusing mathematical backgrounds<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote">3</a></sup>.</p>

<h2 id="so-whats-a-sum-type-the-no-type-theory-version">So what’s a sum type? (the no-type-theory version)</h2>

<p>In it’s essence, a sum type is basically an “or” type. Let’s first look at structs.</p>

<pre><code class="language-rust">struct Foo {
    x: bool,
    y: String,
}
</code></pre>

<p><code>Foo</code> is a <code>bool</code> AND a <code>String</code>. You need one of each to make one.
This is an “and” type, or a “product” type (I’ll explain the name later).</p>

<p>So what would an “or” type be? It would be one where the value can be a
<code>bool</code> OR a <code>String</code>. You can achieve this with C++ with a union:</p>

<pre><code class="language-cpp">union Foo {
    bool x;
    string y;
}

foo.x = true; // set it to a bool
foo.y = "blah"; // set it to a string
</code></pre>

<p>However, this isn’t <em>exactly</em> right, since the value doesn’t store the information
of which variant it is. You could store <code>false</code> and the reader wouldn’t know
if you had stored an empty <code>string</code> or a <code>false</code> <code>bool</code>.</p>

<p>There’s a pattern called “tagged union” (or “discriminated union”) in C++ which bridges this gap.</p>

<pre><code class="language-cpp">union FooUnion {
    bool x;
    string y;
}

enum FooTag {
    BOOL, STRING
}

struct Foo {
    FooUnion data;
    FooTag tag;
}

// set it to a bool
foo.data.x = true;
foo.tag = BOOL;

// set it to a string
foo.data.y = "blah";
foo.tag = STRING;
</code></pre>

<p>Here, you manually set the tag when setting the value. C++ also has <code>std::variant</code> (or
<code>boost::variant</code>) that encapsulates this pattern with a better API.</p>

<p>While I’m calling these “or” types here, the technical term for such types is “sum” types.
Other languages have built-in sum types.</p>

<p>Rust has them and calls them “enums”. These are a more generalized version of the
enums you see in other languages.</p>

<pre><code class="language-rust">enum Foo {
    Str(String),
    Bool(bool)
}

let foo = Foo::Bool(true);

// "pattern matching"
match foo {
    Str(s) =&gt; /* do something with string `s` */,
    Bool(b) =&gt; /* do something with bool `b` */,
}
</code></pre>

<p>Swift is similar, and also calls them enums</p>
<pre><code class="language-swift">enum Foo {
    case str(String)
    case boolean(bool)
}

let foo = Foo.boolean(true);
switch foo {
    case .str(let s):
        // do something with string `s`
    case .boolean(let b):
        // do something with boolean `b`
}
</code></pre>

<p>You can fake these in Go using interfaces, as well. Typescript has built-in
unions which can be typechecked without any special effort, but you need
to add a tag (like in C++) to pattern match on them.</p>

<p>Of course, Haskell has them:</p>

<pre><code class="language-haskell">data Foo = B Bool | S String

-- define a function
doThing :: Foo -&gt; SomeReturnType
doThing (B b) = -- do something with boolean b
doThing (S s) = -- do something with string s

-- call it
doThing (S "blah")
doThing (B True)
</code></pre>

<p>One of the very common things that languages with sum types do is express nullability
as a sum type;</p>

<pre><code class="language-rust">// an Option is either "something", containing a type, or "nothing"
enum Option&lt;T&gt; {
    Some(T),
    None
}

let x = Some("hello");
match x {
    Some(s) =&gt; println!("{}", s),
    None =&gt; println!("no string for you"),
}
</code></pre>

<p>Generally, these languages have “pattern matching”, which is like a <code>switch</code>
statement on steroids. It lets you match on and destructure all kinds of things,
sum types being one of them. Usually, these are “exhaustive”, which means that
you are forced to handle all possible cases. In Rust, if you remove that <code>None</code>
branch, the program won’t compile. So you’re forced to deal with the none case,
<em>somehow</em>.</p>

<p>In general sum types are a pretty neat and powerful tool. Languages with them built-in
tend to make heavy use of them, almost as much as they use structs.</p>

<h2 id="why-do-we-call-it-a-sum-type">Why do we call it a sum type?</h2>

<p><em>Here be (type theory) <a href="https://en.wikipedia.org/wiki/Compilers:_Principles,_Techniques,_and_Tools">dragons</a></em></p>

<p>Let’s step back a bit and figure out what a type is.</p>

<p>It’s really a restriction on the values allowed. It can have things like methods and whatnot
dangling off it, but that’s not so important here.</p>

<p>In other words, it’s like<sup id="fnref:10" role="doc-noteref"><a href="#fn:10" class="footnote">4</a></sup> a <a href="https://en.wikipedia.org/wiki/Set_(mathematics)">set</a>. A boolean is the set &lt;div class='bogus-wrapper'&gt;<notextile>\\(\\\{\mathtt{true}, \mathtt{false}\\\}\\)</notextile>&lt;/div&gt;. An 8-bit unsigned integer
(<code>u8</code> in Rust) is the set &lt;div class='bogus-wrapper'&gt;<notextile>\\(\\\{0, 1, 2, 3, .... 254, 255\\\}\\)</notextile>&lt;/div&gt;. A string is a set with
infinite elements, containing all possible valid strings<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" class="footnote">5</a></sup>.</p>

<p>What’s a struct? A struct with two fields contains every possible combination of elements from the two sets.</p>

<pre><code class="language-rust">struct Foo {
    x: bool,
    y: u8,
}
</code></pre>

<p>The set of possible values of <code>Foo</code> is</p>

<div class="bogus-wrapper"><notextile>\\[\\{(\mathtt{x}, \mathtt{y}): \mathtt{x} \in \mathtt{bool}, \mathtt y \in \mathtt{u8}\\}\\]</notextile></div>

<p>(Read as “The set of all &lt;div class='bogus-wrapper'&gt;<notextile>\\((\mathtt{x}, \mathtt{y})\\)</notextile>&lt;/div&gt; where &lt;div class='bogus-wrapper'&gt;<notextile>\\(\tt x\\)</notextile>&lt;/div&gt; is in &lt;div class='bogus-wrapper'&gt;<notextile>\\(\mathtt{bool}\\)</notextile>&lt;/div&gt; and &lt;div class='bogus-wrapper'&gt;<notextile>\\(\tt y\\)</notextile>&lt;/div&gt; is in &lt;div class='bogus-wrapper'&gt;<notextile>\\(\mathtt{u8}\\)</notextile>&lt;/div&gt;”)</p>

<p>This is called a <em>Cartesian product</em>, and is often represented as &lt;div class='bogus-wrapper'&gt;<notextile>\\(\tt Foo = bool \times u8\\)</notextile>&lt;/div&gt;.
An easy way to view this as a product is to count the possible values: The number of possible values
of <code>Foo</code> is the number of possible values of <code>bool</code> (2) <em>times</em> the number of possible values of <code>u8</code> (256).</p>

<p>A general struct would be a “product” of the types of each field, so something like</p>

<pre><code class="language-rust">struct Bar {
    x: bool,
    y: u8,
    z: bool,
    w: String
}
</code></pre>

<p>is &lt;div class='bogus-wrapper'&gt;<notextile>\\(\mathtt{Bar = bool \times u8 \times bool \times String}\\)</notextile>&lt;/div&gt;</p>

<p>This is why structs are called “product types”<sup id="fnref:7" role="doc-noteref"><a href="#fn:7" class="footnote">6</a></sup>.</p>

<p>You can probably guess what comes next – Rust/Swift enums are “sum types”, because they are the
<em>sum</em> of the two sets.</p>

<pre><code class="language-rust">enum Foo {
    Bool(bool),
    Integer(u8),
}
</code></pre>

<p>is a set of all values which are valid booleans, <em>and</em> all values which are valid integers. This
is a sum of sets, &lt;div class='bogus-wrapper'&gt;<notextile>\\(\tt Foo = bool + u8\\)</notextile>&lt;/div&gt;. More accurately, it’s a <em>disjoint union</em>, where if the input
sets have overlap, the overlap is “discriminated” out.</p>

<p>An example of this being a disjoint union is:</p>

<pre><code class="language-rust">enum Bar {
    Bool1(bool),
    Bool2(bool),
    Integer(u8).
}
</code></pre>

<p>This is not &lt;div class='bogus-wrapper'&gt;<notextile>\\(\tt Bar = bool + bool + u8\\)</notextile>&lt;/div&gt;, because &lt;div class='bogus-wrapper'&gt;<notextile>\\(\tt bool + bool = bool\\)</notextile>&lt;/div&gt;, (regular set addition doesn’t duplicate the overlap).</p>

<p>Instead, it’s something like</p>

<div class="bogus-wrapper"><notextile>\\[\tt Bar = bool + otherbool + u8\\]</notextile></div>

<p>where &lt;div class='bogus-wrapper'&gt;<notextile>\\(\tt otherbool\\)</notextile>&lt;/div&gt; is also a set &lt;div class='bogus-wrapper'&gt;<notextile>\\(\tt \\\{true, false\\\}\\)</notextile>&lt;/div&gt;,
except that these elements are <em>different</em> from those in &lt;div class='bogus-wrapper'&gt;<notextile>\\(\tt bool\\)</notextile>&lt;/div&gt;. You can look at it as if</p>

<div class="bogus-wrapper"><notextile>\\[\tt otherbool = \\{true_2, false_2\\}\\]</notextile></div>

<p>so that</p>

<div class="bogus-wrapper"><notextile>\\[\mathtt{bool + otherbool} = \\{\mathtt{true, false, true_2, false_2}\\}\\]</notextile></div>

<p>For sum types, the number of possible values is the sum of the number of possible values of
each of its component types.</p>

<p>So, Rust/Swift enums are “sum types”.</p>

<p>You may often notice the terminology “algebraic datatypes” (ADT) being used, usually that’s just
talking about sum and product types together – a language with ADTs will have both.</p>

<p>In fact, you can even have <em>exponential</em> types! The notation A^B in set theory does mean something,
it’s the set of all possible mappings from &lt;div class='bogus-wrapper'&gt;<notextile>\\(B\\)</notextile>&lt;/div&gt; to &lt;div class='bogus-wrapper'&gt;<notextile>\\(A\\)</notextile>&lt;/div&gt;. The number of elements is &lt;div class='bogus-wrapper'&gt;<notextile>\\({N_A}^{N_B}\\)</notextile>&lt;/div&gt;. So
basically, the type of a function (which is a mapping) is an “exponential” type. You can also view it as
an iterated product type, a function from type <code>B</code> to <code>A</code> is really a struct like this:</p>

<pre><code class="language-rust">// the type
fn my_func(b: B) -&gt; A;

// is conceptually (each possible my_func can be written as an instance of)

struct my_func {
    b1: A, // value for first element in B
    b2: A, // value for second element in B
    b3: A,
    // ... 
}
</code></pre>

<p>given a value of the input <code>b</code>, the function will find the right field of <code>my_func</code> and return
the mapping. Since a struct is a product type, this is</p>

<div class="bogus-wrapper"><notextile>\\[\mathtt{A}^{N_\mathtt{B}} = \tt A \times A \times A \times \dots\\]</notextile></div>

<p>making it an exponential type.</p>

<p><a href="https://web.archive.org/web/20190706084116/https://strictlypositive.org/diff.pdf">You can even take <em>derivatives</em> of types!</a> (h/t Sam Tobin-Hochstadt for pointing this out to me)</p>

<h2 id="what-in-the-name-of-sanity-is-a-pi-type">What, in the name of sanity, is a Pi type?</h2>

<p><img class="center" src="/images/post/memes/what-in-the-name-of-sanity.jpg" width="400" /></p>

<p>It’s essentially a form of dependent type. A dependent type is when your type
can depend on a value. An example of this is integer generics, where you
can do things like <code>Array&lt;bool, 5&gt;</code>, or <code>template&lt;unsigned int N, typename T&gt; Array&lt;T, N&gt; ...</code> (in C++).</p>

<p>Note that the type signature contains a <em>type</em> dependent on an integer, being generic over multiple
different array lengths.</p>

<p>The name comes from how a constructor for these types would look:</p>

<pre><code class="language-rust">// create an array of booleans from a given integer
// I made up this syntax, this is _not_ from the Rust Pi type RFC
fn make_array(x: u8) -&gt; Array&lt;bool, x&gt; {
    // ...
}

// or
// (the proposed rust syntax)
fn make_array&lt;const x: u8&gt;() -&gt; Array&lt;bool, x&gt; {
   // ... 
}
</code></pre>

<p>What’s the type of <code>make_array</code> here? It’s a function which can accept any integer
and return a different type in each case. You can view it as a set of functions,
where each function corresponds to a different integer input. It’s basically:</p>

<pre><code class="language-rust">struct make_array {
    make_array_0: fn() -&gt; Array&lt;bool, 0&gt;,
    make_array_1: fn() -&gt; Array&lt;bool, 1&gt;,
    make_array_2: fn() -&gt; Array&lt;bool, 2&gt;,
    make_array_3: fn() -&gt; Array&lt;bool, 3&gt;,
    make_array_4: fn() -&gt; Array&lt;bool, 4&gt;,
    make_array_5: fn() -&gt; Array&lt;bool, 5&gt;,
    // ... 
}
</code></pre>

<p>Given an input, the function chooses the right child function here, and calls it.</p>

<p>This is a struct, or a product type! But it’s a product of an infinite number of types<sup id="fnref:5" role="doc-noteref"><a href="#fn:5" class="footnote">7</a></sup>.</p>

<p>We can look at it as</p>

<div class="bogus-wrapper"><notextile>\\[\\texttt{make_array} = \prod\limits_{x = 0}^\infty\left( \texttt{fn()} \mathtt\to \texttt{Array&lt;bool, x&gt;}\right)\\]</notextile></div>

<p>The usage of the &lt;div class='bogus-wrapper'&gt;<notextile>\\(\Pi\\)</notextile>&lt;/div&gt; symbol to denote an iterative product gives this the name “Pi type”.</p>

<p>In languages with lazy evaluation (like Haskell), there is no difference between having a function
that can give you a value, and actually having the value. So, the type of <code>make_array</code> is the type
of <code>Array&lt;bool, N&gt;</code> itself in languages with lazy evaluation.</p>

<p>There’s also a notion of a “sigma” type, which is basically</p>

<div class="bogus-wrapper"><notextile>\\[\sum\limits_{x = 0}^\infty \left(\texttt{fn()} \mathtt\to \texttt{Array&lt;bool, x&gt;}\right)\\]</notextile></div>

<p>With the Pi type, we had “for all N we can
construct an array”, with the sigma type we have “there exists some N for which we can construct this array”.
As you can expect, this type can be expressed with a possibly-infinite enum, and instances of this type
are basically instances of <code>Array&lt;bool, N&gt;</code> for some specific <code>N</code> where the <code>N</code> is only known at runtime.
(much like how regular sum types are instances of one amongst multiple types, where the exact type
is only known at runtime). <code>Vec&lt;bool&gt;</code> is conceptually similar to the sigma type <code>Array&lt;bool, ?&gt;</code>,
as is <code>&amp;[bool]</code>.</p>

<h2 id="wrapping-up">Wrapping up</h2>

<p>Types are sets, and we can do set-theory things on them to make cooler types.</p>

<p>Let’s try to avoid using confusing terminology, however. If Rust <em>does</em> get “pi types”,
let’s just call them “dependent types” or “const generics” :)</p>

<p><em>Thanks to Zaki, Avi Weinstock, Corey Richardson, and Peter Atashian for reviewing drafts of this post.</em></p>
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>Rust, Swift, <em>sort of</em> Typescript, and all the functional languages who had it before it was cool. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>Lookin’ at you, Go. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>Moooooooooooooooonads <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:10" role="doc-endnote">
      <p>Types are not exactly sets due to some differences, but for the purposes of this post we can think of them like sets. <a href="#fnref:10" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:4" role="doc-endnote">
      <p>Though you can argue that strings often have their length bounded by the pointer size of the platform, so it’s still a finite set. <a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:7" role="doc-endnote">
      <p>This even holds for zero-sized types, for more examples, check out <a href="http://chris-taylor.github.io/blog/2013/02/10/the-algebra-of-algebraic-data-types/">this blog post</a> <a href="#fnref:7" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:5" role="doc-endnote">
      <p>Like with strings, in practice this would probably be bounded by the integer type chosen <a href="#fnref:5" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2017/03/02/mitigating-underhandedness-fuzzing-your-code/">Mitigating Underhandedness: Fuzzing Your Code</a></h1>
    
    
      <p class="meta">
        





        
      </p>
    
  </header>


  <div class="entry-content"><p><em>This may be part of a collaborative blog post series about underhanded Rust code. Or it may not. I invite you to write your own posts about underhanded code to make it so!</em></p>

<p>The <a href="https://underhanded.rs/blog/2017/02/28/extending-submission-deadline.en-US.html">submission deadline for the Underhanded Rust competition has been extended</a>, so
let’s talk more about how to keep your code working and free from bugs/underhandedness!</p>

<p><a href="http://manishearth.github.io/blog/2017/01/21/mitigating-underhandedness-clippy/">Previously, we talked about Clippy</a>.</p>

<p>Now, really, underhanded bugs are just another form of bug. And how do we find bugs? We test!</p>

<p>We write unit tests. We run the code under Valgrind, ASan, MSan, UBSan, TSan, and any other sanitizer
we can get our hands on. Tests tests tests. More tests. Tests.</p>

<p>But, there’s a problem here. You need to write <em>test cases</em> to make this work. These are inputs
fed to your code after which you check whatever invariants your code has. There’s
no guarantee that the test cases you write will exercise all the code paths in your
program. This applies for sanitizers too, sanitizers are limited to testing the code paths
that your test cases hit.</p>

<p>Of course, you can use code coverage tools to ensure that all these code paths will be hit.
However, there’s a conflict here – your code will have many code paths that are
<em>not supposed to be hit ever</em>. Things like redundant bounds checks, null checks, etc.
In Rust programs such code paths generally use panics.</p>

<p>Now, these code paths are never <em>supposed</em> to be hit, so they’ll never show up in your
code coverage. But you don’t have a guarantee that they can never be hit, short
of formally verifying your program. The only solution here is writing more test cases.</p>

<p>Aside from that, even ignoring those code paths, you still need to manually write
test cases for everything. For each possible code path in your code, if you want to
be sure.</p>

<p>Who wants to manually write a million test cases?</p>

<p><img class="center" src="/images/post/memes/aint-nobody.jpg" width="400" /></p>

<p><img class="center" src="/images/post/memes/that-would-be-great.jpg" width="400" /></p>

<p>Enter fuzzing. What fuzzing will do is feed your program random inputs, carefully watching the
codepaths being taken, and try to massage the inputs so that new, interesting (usually crashy)
codepaths are taken. You write tests for the fuzzer such that they can accept arbitrary input, and
the fuzzer will find cases where they crash or panic.</p>

<p>One of the most popular fuzzers out there is <a href="http://lcamtuf.coredump.cx/afl/">AFL</a>, which takes a binary and feeds it random
input. Rust <a href="https://github.com/rust-fuzz/afl.rs">has a library that you can use for running AFL</a>, however it currently needs
to be run via a Docker image or needs a recompilation of rustc, since it adds a custom LLVM pass.
We’re working on making this step unnecessary.</p>

<p>However, as of a few weeks ago, we now have bindings for <a href="http://llvm.org/docs/LibFuzzer.html">libFuzzer</a>, which uses existing
instrumentation options built in to LLVM itself! libFuzzer works a bit differently; instead
of giving it a binary, you write a function in a special way and give it a library containing
that function, which it turns into a fuzzer binary. This is faster, since the fuzzer lives
inside the binary itself and it doesn’t need to execute a new program each time.</p>

<p>Using libFuzzer in Rust is easy. Install <a href="https://github.com/rust-fuzz/cargo-fuzz"><code>cargo-fuzz</code></a>:</p>

<pre><code class="language-sh">$ cargo install cargo-fuzz
</code></pre>

<p>Now, within your crate, initialize the fuzz setup:</p>

<pre><code class="language-sh">$ cargo fuzz init
</code></pre>

<p>This will create a fuzzing crate in <code>fuzz/</code>, with a single “fuzz target”, <code>fuzzer_script_1</code>.
You can add more such targets with <code>cargo fuzz add name_of_target</code>. Fuzz targets are small libraries
with a single function in them; the function that will be called over and over again by the fuzzer.
It is up to you to fill in the body of this function, such that the program will crash or panic
if and only if something goes wrong.</p>

<p>For example, for the <code>unicode-segmentation</code> crate, <a href="https://github.com/Manishearth/unicode-segmentation/blob/99b3636ef6b4d96c05644403c1c2eccba2c5f5db/fuzz/fuzzers/equality.rs">one of the fuzz targets I wrote</a> just
takes the string, splits it by grapheme and word boundaries, recombines it, and then asserts that
the new string is the same.</p>

<pre><code class="language-rust">pub extern fn go(data: &amp;[u8]) {
    // we only deal with unicode input
    // bail early, *without panicking* if the input isn't utf8
    if let Ok(s) = str::from_utf8(data) {
        // split into graphemes, recollect
        let result = UnicodeSegmentation::graphemes(s, true).flat_map(|s| s.chars()).collect::&lt;String&gt;();
        // recollected string should be the same as the input, panic if not
        assert_eq!(s, result);

        // split into words, recollect
        let result = s.split_word_bounds().flat_map(|s| s.chars()).collect::&lt;String&gt;();
        // recollected string should be the same as the input, panic if not
        assert_eq!(s, result);
    }
}
</code></pre>

<p>The other targets ensure that the forward and reverse word/grapheme
iterators produce the same results. They all take the byte slice input, attempt to convert to UTF8
(silently failing  – NOT panicking – if not possible), and then use the string as an input
testcase.</p>

<p>Now, these targets will panic if the test fails, and the fuzzer will try and force that panic to
happen. But also, these targets put together exercise most of the API surface of the crate, so
the fuzzer may also find panics (or even segmentation faults!) in the crate itself. For example,
the <a href="https://github.com/servo/rust-url/blob/3e5541e51e02d8acb10a6ea8ab174ba1bc23ce41/fuzz/fuzzers/parse.rs#L10">fuzz target for rust-url</a> doesn’t itself assert; all it does is try to parse the given
string. The fuzzer will try to get the URL parser to panic.</p>

<p>To run a fuzz script:</p>

<pre><code class="language-sh">$ cargo fuzz run fuzzer_script_1
</code></pre>

<p>This will start the fuzzer, running until it finds a crash or panic. It may also
find other things like inputs which make the code abnormally slow.</p>

<p>Fuzzing can find some interesting bugs. For example, the unicode-segmentation
fuzzers found <a href="https://github.com/unicode-rs/unicode-segmentation/issues/19">this bug</a>, where an emoji followed by <em>two</em> skin tone modifiers
isn’t handled correctly. We’d probably never have been able to come up with this testcase on our
own. But the fuzzer could find it!</p>

<p>The Rust Cap’n Proto crate ran cargo-fuzz and found <a href="https://dwrensha.github.io/capnproto-rust/2017/02/27/cargo-fuzz.html">a whole ton of bugs</a>. There
are more such examples <a href="https://github.com/rust-fuzz/cargo-fuzz#trophy-case">in the trophy case</a> (be sure to add any of your own findings
to the trophy case, too!)</p>

<p>cargo-fuzz is relatively new, so the API and behavior may still be tweaked a bit before 1.0.
But you can start taking it for a spin now, and finding bugs!</p>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2017/02/26/clarifying-misconceptions-about-shattered/">Clarifying Misconceptions About SHAttered</a></h1>
    
    
      <p class="meta">
        





        
      </p>
    
  </header>


  <div class="entry-content"><p>This week Google published a <a href="https://shattered.io/">SHA-1 collision</a>.</p>

<p>There’s a lot of confusion about the implications of this. A lot of this is due to differences of
opinion on what exactly constitutes a “new” collision. I <a href="https://twitter.com/ManishEarth/status/835557328308969472">tweeted about this</a>. The webpage
for the attack itself is misleading, saying that the answer to “Who is capable of mounting this attack?”
is people with Google-esque resources. This depends on what exactly you mean by “this attack”.</p>

<p>So I’m seeing a lot of “oh well just another anti-milestone for SHA, doesn’t affect anyone since its
still quite expensive to exploit” reactions, as well as the opposite “aaaaa everything is on fire”
reaction. Both are wrong. It has practical implications for you even if you are certain that you
won’t attract the ire of an entity with a lot of computational power. None of these implications,
however, are likely to be disastrous.</p>

<p>TLDR: Now <em>anyone</em>, without needing Google-esque resources,
can generate two colliding PDFs with arbitrary visual content in each.</p>

<p>(In fact, there’s already <a href="http://alf.nu/SHA1">a PDF collision-generator</a> up where
you can upload two images and get a PDF with collisions in it)</p>

<h2 id="okay-back-up-a-bit-whats-a-hash-whats-sha-1">Okay, back up a bit. What’s a hash? What’s SHA-1?</h2>

<p>I explained this a bit in my older post about <a href="http://manishearth.github.io/blog/2016/03/05/exploring-zero-knowledge-proofs/">zero-knowledge-proofs</a>.</p>

<p>In essence, a hash function takes some data (usually of arbitrary size), and produces a value called
a <em>hash</em> (usually of fixed size). The function has some additional properties:</p>

<ul>
  <li>In almost all cases, a small perturbation in the input will lead to a large perturbation in the hash</li>
  <li>Given an input and its hash, it is computationally hard to find an alternate input producing the same hash</li>
  <li>It’s also hard to just find two inputs that has to the same value, though this is usually easier than the previous one</li>
</ul>

<p>when two inputs hash to the same value, this is called a collision. As mentioned, is easier to find
<em>a</em> collision, over finding a colliding alternate input for a known input.</p>

<p>SHA-1 is one such hash function. It’s been known for a while that it’s insecure, and the industry has
largely moved off of it, but it’s still used, so it can still be a problem.</p>

<h2 id="what-did-the-researchers-do">What did the researchers do?</h2>

<p>They found a hash collision for SHA-1. In essence, they found two strings, <code>A</code> and <code>B</code>, where
<code>SHA1(A) == SHA1(B)</code>.</p>

<p><em>However</em>, given the way SHA-1 works, this means that you can generate infinitely many other
such pairs of strings. And given the nature of the exact <code>A</code> and <code>B</code> they created, it is possible
to use this to create arbitrary colliding PDFs.</p>

<p>Basically, SHA-1 (and many other hash functions), operate on “blocks”. These are fixed-size chunks
of data, where the size is a property of the hash function. For SHA1 this is 512 bits.</p>

<p>The function starts off with an “initial” built-in hash. It takes the first block of your data and
this hash, and does some computation with the two to produce a new hash, which is its state after
the first block.</p>

<p>It will then take this hash and the second block, and run the same computations to produce
a newer hash, which is its state after the second block. This is repeated till all blocks have
been processed, and the final state is the result of the function.</p>

<p>There’s an important thing to notice here. At each block, the only inputs are the block itself and the
hash of the string up to that block.</p>

<p>This means, if <code>A</code> and <code>B</code> are of a size that is a multiple of the block size, and <code>SHA1(A) == SHA1(B)</code>,
then <code>SHA1(A + C) == SHA1(B + C)</code>. This is because, when the hash function reaches <code>C</code>, the state will
be the same due to the hash collision, and after this point the next input blocks are identical in
both cases, so the final hash will be the same.</p>

<p>Now, while you might consider <code>A+C, B+C</code> to be the “same collision” as <code>A, B</code>, the implications
of this are different than just “there is now one known pair of inputs that collide”, since everyone
now has the ability to generate new colliding inputs by appending an arbitrary string to <code>A</code> and <code>B</code>.</p>

<p>Of course, these new collisions have the restriction that the strings will always start with <code>A</code> or
<code>B</code> and the suffixes will be identical. If you want to break this restriction, you will
have to devote expensive resources to finding a new collision, like Google did.</p>

<h2 id="how-does-this-let-us-generate-arbitrary-colliding-pdfs">How does this let us generate arbitrary colliding PDFs?</h2>

<p>So this exploit actually uses features of the JPEG format to work. It was done in
a PDF format since JPEGs often get compressed when sent around the Internet. However,
since both A and B start a partial PDF document, they can only be used to generate colliding
PDFs, not JPEGs.</p>

<p>I’m going to first sketch out a simplified example of what this is doing, using a hypothetical
pseudocode-y file format. The researchers found a collision between the strings:</p>

<ul>
  <li>A: <code>&lt;header data&gt; COMMENT(&lt;nonce for A&gt;) DISPLAY IMAGE 1</code></li>
  <li>B: <code>&lt;header data&gt; COMMENT(&lt;nonce for B&gt;) DISPLAY IMAGE 2</code></li>
</ul>

<p>Here, <code>&lt;header data&gt;</code> is whatever is necessary to make the format work, and the “nonce”s are
strings that make <code>A</code> and <code>B</code> have the same hash. Finding these nonces is where
the computational power is required, since you basically have to brute-force a solution.</p>

<p>Now, to both these strings, they append a suffix C: <code>IMAGE 1(&lt;data for image 1&gt;) IMAGE 2(&lt;data for image 2&gt;)</code>.
This creates two complete documents. Both of the documents contain both images, but each one is instructed
to display a different one. Note that since <code>SHA1(A) == SHA1(B)</code>, <code>SHA1(A + C) = SHA1(B + C)</code>, so these
final documents have the same hash.</p>

<p>The contents of <code>C</code> don’t affect the collision at all. So, we can insert any two images in <code>C</code>, to create
our own personal pair of colliding PDFs.</p>

<p>The actual technique used is similar to this, and it relies on JPEG comment fields. They have found
a collision between two strings that look like:</p>

<pre><code class="language-text">pdf header data                       | String A
begin embedded image                  |  
    jpg header data                   |
    declare jpg comment of length N   |
    random nonce of length N          | (comment ends here) 
                                     ---
    image 1, length L                 | String C
    jpg EOF byte (2 bytes)            |
    image 2                           |
end embedded image                    |

and

pdf header data                       | String B
begin embedded image                  |
    jpg header data                   |
    declare jpg comment of length M   |
    random nonce of length M-L-2      |
                                     ---
    image 1, length L                 | String C
    jpg EOF marker (2 bytes)          | (comment ends here)
    image 2                           |
end embedded image                    |
</code></pre>

<p>By playing with the nonces, they managed to generate a collision between <code>A</code> and <code>B</code>. In the first
pdf, the embedded image has a comment containing only the nonce. Once the JPEG reader gets past that
comment, it sees the first image, displays it, and then sees the end-of-file marker and decides to
stop. Since the PDF format doesn’t try to interpret the image itself, the PDF format won’t be
boggled by the fact that there’s some extra garbage data after the JPEG EOF marker. It
simply takes all the data between the “begin embedded image” and “end embedded image” blocks,
and passes it to the JPEG decoder. The JPEG decoder itself stops after it sees the end of file
marker, and doesn’t get to the extra data for the second image.</p>

<p>In the second pdf, the jpg comment is longer, and subsumes the first image (as well as the EOF marker)
Thus, the JPEG decoder directly gets to the second image, which it displays.</p>

<p>Since the actual images are not part of the original collision (A and B), you can substitute any pair
of jpeg images there, with some length restrictions.</p>

<h2 id="what-are-the-implications">What are the implications?</h2>

<p>This does mean that you should not trust the integrity of a PDF when all you have
to go on is its SHA-1 hash. Use a better hash. <em>Anyone can generate these colliding PDFs
now.</em></p>

<p>Fortunately, since all such PDFs will have the same prefix A or B, you can detect when
such a deception is being carried out.</p>

<p>Don’t check colliding PDFs into SVN. <a href="https://bugs.webkit.org/show_bug.cgi?id=168774#c27">Things break</a>.</p>

<p>In some cases it is possible to use the PDF collision in other formats. For example,
<a href="https://mobile.twitter.com/arw/status/834883944898125824">it can be used to create colliding HTML documents</a>. I think it can be used to colide
ZIP files too.</p>

<p>Outside the world of complex file formats, little has changed. It’s still a bad idea to use SHA-1.
It’s still possible for people to generate entirely new collisions like Google did, though this
needs a lot of resources. It’s possible that someone with resources has already generated such a
“universal-key collision” for some other file format<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">1</a></sup> and will use it on you, but this was
equally possible before Google published their attack.</p>

<p>This does not make it easier to collide with arbitrary hashes – if someone else
has uploaded a document with a hash, and you trust them to not be playing any tricks,
an attacker won’t be able to generate a colliding document for this without immense
resources. The attack only works when the attacker has control over the initial document;
e.g. in a bait-and-switch-like attack where the attacker uploads document A, you read and verify it
and broadcast your trust in document A with hash <code>SHA(A)</code>, and then the attacker switches it with
document B.</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>Google’s specific collision was designed to be a “universal key”, since A and B are designed to have the image-switching mechanism built into it. Some other collision may not be like this; it could just be a collision of two images (or whatever) with no such switching mechanism. It takes about the same effort to do either of these, however, so if you have a file format that can be exploited to create a switching mechanism, it would always make more sense to build one into any collision you look for. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2017/01/21/mitigating-underhandedness-clippy/">Mitigating Underhandedness: Clippy!</a></h1>
    
    
      <p class="meta">
        





        
      </p>
    
  </header>


  <div class="entry-content"><p><em>This may be part of a collaborative blog post series about underhanded Rust code. Or it may not. I invite you to write your own posts about underhanded code to make it so!</em></p>

<p>Last month we opened up <a href="https://underhanded.rs/blog/2016/12/15/underhanded-rust.en-US.html">The Underhanded Rust competition</a>. This contest is about
writing seemingly-innocuous malicious code; code that is deliberately written to do some harm,
but will pass a typical code review.</p>

<p>It is inspired by the <a href="http://www.underhanded-c.org">Underhanded C</a> contest. Most of the underhanded C submissions have to do
with hidden buffer overflows, pointer arithmetic fails, or misuse of C macros; and these problems
largely don’t occur in Rust programs. However, the ability to layer abstractions on each other does
open up new avenues to introducing underhandedness by relying on sufficiently confusing abstraction
sandwiches. There are probably other interesting avenues. Overall, I’m pretty excited to see what
kind of underhandedness folks come up with!</p>

<p>Of course, underhandedness is not just about fun and games; we should be hardening our code against
this kind of thing. Even if you trust your fellow programmers. Even if <em>you</em> are the sole programmer and you trust yourself.
After all, <a href="https://github.com/Gankro/thesis/blob/master/thesis.pdf">you can’t spell Trust without Rust</a>; and Rust is indeed about trust. Specifically,
Rust is about trusting <em>nobody</em>. Not even yourself.</p>

<p><img src="/images/post/memes/trust-nobody.jpg" width="300" /></p>

<p>Rust protects you from your own mistakes when it comes to memory management. But we
should be worried about other kinds of mistakes, too. Many of the techniques used in underhanded
programming involve sleights of hand that could just as well be introduced in the code by accident, causing bugs.
Not memory safety bugs (in Rust), but still, bugs. The existence of these sleights of hand is great for
that very common situation
<a href="https://underhanded.rs/blog/2016/12/15/underhanded-rust.en-US.html#prize">when you are feeling severely under-plushied and must win a competition to replenish your supply</a>
but we really don’t want these creeping into real-world code, either by accident or intentionally.</p>

<hr />

<p>Allow me to take a moment out of your busy underhanded-submission-writing schedules to talk to you about
our Lord and Savior <a href="http://github.com/manishearth/rust-clippy/">Clippy</a>.</p>

<p>Clippy is for those of you who have become desensitized to the constant whining of the Rust compiler
and need a higher dosage of whininess to be kept on their toes. Clippy is for those perfectionists
amongst you who want to know every minute thing wrong with their code so that they can fix it.
But really, Clippy is for everyone.</p>

<p>Clippy is simply a large repository of lints. As of the time of writing this post, there are
<a href="https://github.com/manishearth/rust-clippy/#lints">183 lints</a> in it, though not all of them are enabled by default. These use the regular Rust lint
system so you can pick and choose the ones you need via <code>#[allow(lint_name)]</code> and
<code>#[warn(lint_name)]</code>. These lints cover a wide range of functions:</p>

<ul>
  <li>Improving readability of the code (though <a href="https://github.com/rust-lang-nursery/rustfmt/">rustfmt</a> is the main tool you should use for this)</li>
  <li>Helping make the code more compact by reducing unnecessary things (my absolute favorite is <a href="https://github.com/Manishearth/rust-clippy/wiki#needless_lifetimes">needless_lifetimes</a>)</li>
  <li>Helping make the code more idiomatic</li>
  <li>Making sure you don’t do things that you’re not supposed to</li>
  <li>Catching mistakes and cases where the code may not work as expected</li>
</ul>

<p>The last two really are the ones which help with underhanded code. Just to give an example,
we have lints like:</p>

<ul>
  <li><a href="https://github.com/Manishearth/rust-clippy/wiki#cmp_nan">cmp_nan</a>, which disallows things like <code>x == NaN</code></li>
  <li><a href="https://github.com/Manishearth/rust-clippy/wiki#clone_double_ref">clone_double_ref</a>, which disallows calling <code>.clone()</code> on double-references (<code>&amp;&amp;T</code>), since that’s a straightforward copy and you probably meant to do something like <code>(*x).clone()</code></li>
  <li></li>
  <li><a href="https://github.com/Manishearth/rust-clippy/wiki#match_same_arms">match_same_arms</a>, which checks for identical match arm bodies (strong indication of a typo)</li>
  <li><a href="https://github.com/Manishearth/rust-clippy/wiki#suspicious_assignment_formatting">suspicious_assignment_formatting</a>, which checks for possible typos with the <code>+=</code> and <code>-=</code> operators</li>
  <li><a href="https://github.com/Manishearth/rust-clippy/wiki#unused_io_amount">unused_io_amount</a>, which ensures that you don’t forget that some I/O APIs may not write all bytes in the span of a single call</li>
</ul>

<p>These catch many of the gotchas that might crop up in Rust code. In fact,
I based <a href="https://www.reddit.com/r/rust/comments/3hb0wm/underhanded_rust_contest/cu5yuhr/">my solution of an older, more informal Underhanded Rust contest</a> on one of these.</p>

<h2 id="usage">Usage</h2>

<p>Clippy is still nightly-only. We hook straight into the compiler’s guts to obtain
the information we need, and like most internal compiler APIs, this is completely unstable. This
does mean that you usually need a latest or near-latest nightly for clippy to work, and there will
be times when it won’t compile while we’re working to update it.</p>

<p>There is a plan to ship clippy as an optional component of rustc releases, which will fix all of
these issues (yay!).</p>

<p>But, for now, you can use clippy via:</p>

<pre><code class="language-sh">rustup install nightly
# +nightly not necessary if nightly is your default toolchain
cargo +nightly install clippy
# in your project folder
cargo +nightly clippy
</code></pre>

<p>If you’re going to be making it part of the development procedures of a crate
you maintain, you can also <a href="https://github.com/manishearth/rust-clippy/#optional-dependency">make it an optional dependency</a>.</p>

<p>If you’re on windows, there’s currently a rustup/cargo <a href="https://github.com/rust-lang-nursery/rustup.rs/issues/876">bug</a> where you may have to add
the rustc libs path in your <code>PATH</code> for <code>cargo clippy</code> to work.</p>

<p>There’s an experimental project called <a href="https://github.com/killercup/rustfix">rustfix</a> which can automatically apply suggestions from
clippy and rustc to your code. This may help in clippy-izing a large codebase, but it may
also eat your code and/or laundry, so beware.</p>

<h2 id="contributing">Contributing</h2>

<p>There’s a <em>lot</em> of work that can be done on clippy. A hundred and eighty lints is just
a start, there are <a href="https://github.com/manishearth/rust-clippy/issues">hundreds more lint ideas filed on the issue tracker</a>. We’re
willing to mentor anyone who wants to get involved; and have
<a href="https://github.com/manishearth/rust-clippy/issues?q=is%3Aissue+is%3Aopen+label%3AE-easy">specially tagged “easy” issues</a> for folks new to compiler internals. In general,
contributing to clippy is a great way to gain an understanding of compiler internals
if you want to contribute to the compiler itself.</p>

<p>If you don’t want to write code for clippy, you can also run it on random crates,
open pull requests with fixes, and file bugs on clippy for any false positives that appear.</p>

<p>There are more tips about contributing in <a href="https://github.com/Manishearth/rust-clippy/blob/master/CONTRIBUTING.md">our CONTRIBUTING.md</a>.</p>

<hr />

<p>I hope this helps reduce mistakes and underhandedness in your code!</p>

<p>..unless you’re writing code for the Underhanded Rust competition. In that case, underhand away!</p>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2017/01/15/breaking-our-latin-1-assumptions/">Breaking Our Latin-1 Assumptions</a></h1>
    
    
      <p class="meta">
        





        
      </p>
    
  </header>


  <div class="entry-content"><p>So in my <a href="http://manishearth.github.io/blog/2017/01/14/stop-ascribing-meaning-to-unicode-code-points">previous post</a> I explored a specific (wrong) assumption that programmers
tend to make about the nature of code points and text.</p>

<p>I was asked multiple times about other assumptions we tend to make. There are a lot. Most
Latin-based scripts are simple, but most programmers spend their time dealing with Latin
text so these complexities never come up.</p>

<p>I thought it would be useful to share my personal list of
<a href="https://twitter.com/ManishEarth/status/810582690906931200">scripts that break our Latin-1 assumptions</a>. This is a list I mentally check against
whenever I am attempting to reason about text. I check if I’m making any assumptions that
break in these scripts. <em>Most</em> of these concepts are independent of Unicode; so any program
would have to deal with this regardless of encoding.</p>

<p>I again recommend going through <a href="https://eev.ee/blog/2015/09/12/dark-corners-of-unicode/">eevee’s post</a>, since it covers many related issues.
<a href="https://github.com/jagracey/Awesome-Unicode">Awesome-Unicode</a> also has a lot of random tidbits about Unicode.</p>

<p>Anyway, here’s the list. Note that a lot of the concepts here exist in scripts other than the
ones listed, these are just the scripts <em>I</em> use for comparing.</p>

<h2 id="arabic--hebrew">Arabic / Hebrew</h2>

<p>Both Arabic and Hebrew are RTL scripts; they read right-to-left. This may even affect how
a page is laid out, see the <a href="https://he.wikipedia.org/wiki/%D7%A2%D7%9E%D7%95%D7%93_%D7%A8%D7%90%D7%A9%D7%99">Hebrew Wikipedia</a>.</p>

<p>They both have a concept of letters changing how they look depending on where they are in the word.
Hebrew has the “sofit” letters, which use separate code points. For example, Kaf (כ) should be typed
as ך at the end of a word. Greek has something similar with the sigma.</p>

<p>In Arabic, the letters can have up to four different forms, depending on whether they start a word,
end a word, are inside a word, or are used by themselves. These forms can look very different. They
don’t use separate code points for this; however. You can see a list of these forms <a href="https://en.wikipedia.org/wiki/Arabic_alphabet#Table_of_basic_letters">here</a></p>

<p>Arabic can get pretty tricky – the characters have to join up; and in cursive fonts (like those for Nastaliq),
you get a lot of complex ligatures.</p>

<p>As I mentioned in the last post, U+FDFD (﷽), a ligature representing the Basamala,
is also a character that breaks a lot of assumptions.</p>

<h2 id="indic-scripts">Indic scripts</h2>

<p>Indic scripts are <em>abugidas</em>, where you have consonants with vowel modifiers. For example, क is
“kə”, where the upside down “e” is a schwa, something like an “uh” vowel sound. You can change the
vowel by adding a diacritic (e.g <code>ा</code>); getting things like का (“kaa”) को (“koh”) कू (“koo”).</p>

<p>You can also mash together consonants to create consonant clusters. The “virama” is a vowel-killer
symbol that removes the inherent schwa vowel. So, <code>क</code> + <code>्</code> becomes <code>क्</code>. This sound itself is
unpronounceable since क is a stop consonant (vowel-killed consonants can be pronounced for nasal and some other
consonants though), but you can combine it with another consonant, as <code>क्</code> + <code>र</code> (“rə”), to get <code>क्र</code>
(“krə”). Consonants can be strung up infinitely, and you can stick one or more vowel diacritics
after that. Usually, you won’t see more than two consonants in a cluster, but larger ones are not
uncommon in Sanskrit (or when writing down some onomatopoeia). They may not get rendered as single
glyphs, depending on the font.</p>

<p>One thing that crops up is that there’s no unambiguous concept of a letter here. There
is a concept of an “akshara”, which basically includes the vowel diacritics, and
depending on who you talk to may also include consonant clusters. Often things are
clusters an akshara depending on whether they’re drawn with an explicit virama
or form a single glyph.</p>

<p>In general the nature of the virama as a two-way combining character in Unicode is pretty new.</p>

<h2 id="hangul">Hangul</h2>

<p>Korean does its own fun thing when it comes to conjoining characters. Hangul has a concept
of a “syllable block”, which is basically a letter. It’s made up of a leading consonant,
medial vowel, and an optional tail consonant. 각 is an example of
such a syllable block, and it can be typed as ᄀ + ᅡ + ᆨ. It can
also be typed as 각, which is a “precomposed form” (and a single code point).</p>

<p>These characters are examples of combining characters with very specific combining rules. Unlike
accents or other diacritics, these combining characters will combine with the surrounding characters
only when the surrounding characters form an L-V-T or L-V syllable block.</p>

<p>As I mentioned in my previous post, apparently syllable blocks with more (adjacent) Ls, Vs, and Ts are
also valid and used in Old Korean, so the grapheme segmentation algorithm in Unicode considers
“ᄀᄀᄀ각ᆨᆨ” to be a single grapheme (<a href="http://www.unicode.org/reports/tr29/#Hangul_Syllable_Boundary_Determination">it explicitly mentions this</a>).
I’m not aware of any fonts which render these as a single syllable block, or if that’s even
a valid thing to do.</p>

<h2 id="han-scripts">Han scripts</h2>

<p>So Chinese (Hanzi), Japanese (Kanji<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">1</a></sup>), Korean (Hanja<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote">2</a></sup>), and Vietnamese (Hán tự, along with Chữ
Nôm <sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote">3</a></sup>) all share glyphs, collectively called “Han characters” (or CJK characters<sup id="fnref:7" role="doc-noteref"><a href="#fn:7" class="footnote">4</a></sup>). These
languages at some point in their history borrowed the Chinese writing system, and made their own
changes to it to tailor to their needs.</p>

<p>Now, the Han characters are ideographs. This is not a phonetic script; individual characters
represent words. The word/idea they represent is not always consistent across languages. The
pronounciation is usually different too. Sometimes, the glyph is drawn slightly differently based on
the language used. There are around 80,000 Han ideographs in Unicode right now.</p>

<p>The concept of ideographs itself breaks some of our Latin-1 assumptions. For example, how
do you define Levenshtein edit distance for text using Han ideographs? The straight answer is that
you can’t, though if you step back and decide <em>why</em> you need edit distance you might be able
to find a workaround. For example, if you need it to detect typos, the user’s input method
may help. If it’s based on pinyin or bopomofo, you might be able to reverse-convert to the
phonetic script, apply edit distance in that space, and convert back. Or not. I only maintain
an idle curiosity in these scripts and don’t actually use them, so I’m not sure how well this would
work.</p>

<p>The concept of halfwidth character is a quirk that breaks some assumptions.</p>

<p>In the space of Unicode in particular, all of these scripts are represented by a single set of
ideographs. This is known as “Han unification”. This is a pretty controversial issue, but the
end result is that rendering may sometimes be dependent on the language of the text, which
e.g. in HTML you set with a <code>&lt;span lang=whatever&gt;</code>. <a href="https://en.wikipedia.org/wiki/Han_unification#Examples_of_language-dependent_glyphs">The wiki page</a> has some examples of
encoding-dependent characters.</p>

<p>Unicode also has a concept of variation selector, which is a code point that can be used to
select between variations for a code point that has multiple ways of being drawn. These
do get used in Han scripts.</p>

<p>While this doesn’t affect rendering, Unicode, as a system for <em>describing</em> text,
also has a concept of interlinear annotation characters. These are used to represent
<a href="https://en.wikipedia.org/wiki/Ruby_character">furigana / ruby</a>. Fonts don’t render this, but it’s useful if you want to represent
text that uses ruby. Similarly, there are <a href="https://en.wikipedia.org/wiki/Chinese_character_description_languages#Ideographic_Description_Sequences">ideographic description sequences</a> which
can be used to “build up” glyphs from smaller ones when the glyph can’t be encoded in
Unicode. These, too, are not to be rendered, but can be used when you want to describe
the existence of a character like <a href="https://en.wikipedia.org/wiki/Biangbiang_noodles#Chinese_character_for_bi.C3.A1ng">biáng</a>. These are not things a programmer
needs to worry about; I just find them interesting and couldn’t resist mentioning them :)</p>

<p>Japanese speakers haven’t completely moved to Unicode; there are a lot of things out there
using Shift-JIS, and IIRC there are valid reasons for that (perhaps Han unification?). This
is another thing you may have to consider.</p>

<p>Finally, these scripts are often written <em>vertically</em>, top-down. <a href="https://en.wikipedia.org/wiki/Mongolian_script">Mongolian</a>, while
not being a Han script, is written vertically sideways, which is pretty unique. The
CSS <a href="https://drafts.csswg.org/css-writing-modes/">writing modes</a> spec introduces various concepts related to this, though that’s mostly in the
context of the Web.</p>

<h2 id="thai--khmer--burmese--lao">Thai / Khmer / Burmese / Lao</h2>

<p>These scripts don’t use spaces to split words. Instead, they have rules for what kinds of sequences
of characters start and end a word. This can be determined programmatically, however IIRC the
Unicode spec does not attempt to deal with this. There are libraries you can use here instead.</p>

<h2 id="latin-scripts-themselves">Latin scripts themselves!</h2>

<p>Turkish is a latin-based script. But it has a quirk: The uppercase of “i” is
a dotted “İ”, and the lowercase of “I” is “ı”. If doing case-based operations, try to use
a Unicode-aware library, and try to provide the locale if possible.</p>

<p>Also, not all code points have a single-codepoint uppercase version. The eszett (ß) capitalizes
to “SS”. There’s also the “capital” eszett ẞ, but its usage seems to vary and I’m not exactly
sure how it interacts here.</p>

<p>While Latin-1 uses precomposed characters, Unicode also introduces ways to specify the same
characters via combining diacritics. Treating these the same involves using the normalization
algorithms (NFC/NFD).</p>

<h2 id="emoji">Emoji</h2>

<p>Well, not a script<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" class="footnote">5</a></sup>. But emoji is weird enough that it breaks many of our assumptions. The
scripts above cover most of these, but it’s sometimes easier to think of them
in the context of emoji.</p>

<p>The main thing with emoji is that you can use a zero-width-joiner character to glue emoji together.</p>

<p>For example, the family emoji 👩‍👩‍👧‍👦 (may not render for you) is made by using the woman/man/girl/boy
emoji and gluing them together with ZWJs. You can see its decomposition in <a href="https://r12a.github.io/uniview/?charlist=%F0%9F%91%A9%E2%80%8D%F0%9F%91%A9%E2%80%8D%F0%9F%91%A7%E2%80%8D%F0%9F%91%A6">uniview</a>.</p>

<p>There are more sequences like this, which you can see in the <a href="http://unicode.org/Public/emoji/4.0/emoji-zwj-sequences.txt">emoji-zwj-sequences</a> file. For
example, MAN + ZWJ + COOK will give a male cook emoji (font support is sketchy).
Similarly, SWIMMER + ZWJ + FEMALE SIGN is a female swimmer. You have both sequences of
the form “gendered person + zwj + thing”, and “emoji containing human + zwj + gender”,
IIRC due to legacy issues<sup id="fnref:5" role="doc-noteref"><a href="#fn:5" class="footnote">6</a></sup></p>

<p>There are also <a href="http://www.unicode.org/reports/tr51/#Diversity">modifier characters</a> that let you change the skin tone of an emoji that
contains a human (or human body part, like the hand-gesture emojis) in it.</p>

<p>Finally, the flag emoji are pretty special snowflakes. For example, 🇪🇸 is the Spanish
flag. It’s made up of <a href="https://r12a.github.io/uniview/?charlist=%F0%9F%87%AA%F0%9F%87%B8">two regional indicator characters for “E” and “S”</a>.</p>

<p>Unicode didn’t want to deal with adding new flags each time a new country or territory pops up. Nor
did they want to get into the tricky business of determining what a country <em>is</em>, for example
when dealing with disputed territories. So instead, they just defined these regional indicator
symbols. Fonts are supposed to take pairs of RI symbols<sup id="fnref:6" role="doc-noteref"><a href="#fn:6" class="footnote">7</a></sup> and map the country code to a flag.
This mapping is up to them, so it’s totally valid for a font to render a regional indicator
pair “E” + “S” as something other than the flag of Spain. On some Chinese systems, for example,
the flag for Taiwan (🇹🇼) may not render.</p>

<hr />

<p>I hightly recommend comparing against this relatively small list of scripts the next time you
are writing code that does heavy manipulation of user-provided strings.</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>Supplemented (but not replaced) by the Hiragana and Katakana phonetic scripts. In widespread use. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>Replaced by Hangul in modern usage <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>Replaced by chữ quốc ngữ in modern usage, which is based on the Latin alphabet <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:7" role="doc-endnote">
      <p>“CJK” (Chinese-Japanese-Korean) is probably more accurate here, though it probably should include “V” for Vietnamese too. Not all of these ideographs come from Han; the other scripts invented some of their own. See: Kokuji, Gukja, Chữ Nôm. <a href="#fnref:7" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:4" role="doc-endnote">
      <p>Back in <em>my</em> day we painstakingly typed actual real words on numeric phone keypads, while trudging to 🏫 in three feet of ❄️️, and it was uphill both ways, and we weren’t even <em>allowed</em> 📱s in 🏫. Get off my lawn! <a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:5" role="doc-endnote">
      <p>We previously had individual code points for professions and stuff and they decided to switch over to using existing object emoji with combiners instead of inventing new profession emoji all the time <a href="#fnref:5" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:6" role="doc-endnote">
      <p>676 countries should be enough for anybody <a href="#fnref:6" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2017/01/14/stop-ascribing-meaning-to-unicode-code-points/">Let's Stop Ascribing Meaning to Code Points</a></h1>
    
    
      <p class="meta">
        





        
      </p>
    
  </header>


  <div class="entry-content"><p><em>Update: This post got a sequel, <a href="http://manishearth.github.io/blog/2017/01/15/breaking-our-latin-1-assumptions/">Breaking our latin-1 assumptions</a>.</em></p>

<p>I’ve seen misconceptions about Unicode crop up regularly in posts discussing it. One very common
misconception I’ve seen is that <em>code points have cross-language intrinsic meaning</em>.</p>

<p>It usually comes up when people are comparing UTF8 and UTF32. Folks start implying that code points
<em>mean</em> something, and that O(1) indexing or slicing at code point boundaries is a useful operation.
I’ve also seen this assumption manifest itself in actual programs which make incorrect assumptions
about the nature of code points and mess things up when fed non-Latin text.</p>

<p>If you like reading about unicode, you might also want to go through <a href="https://eev.ee/blog/2015/09/12/dark-corners-of-unicode/">Eevee’s article</a>
on the dark corners of unicode. Great read!</p>

<h2 id="encodings">Encodings</h2>

<p>So, anyway, we have some popular encodings for Unicode. UTF8 encodes 7-bit code points as a single
byte, 11-bit code points as two bytes, 16-bit code points as 3 bytes, and 21-bit code points as four
bytes. UTF-16 encodes the first three in two bytes, and the last one as four bytes (logically, a
pair of two-byte code units). UTF-32 encodes all code points as 4-byte code units. UTF-16 is mostly
a “worst of both worlds” compromise at this point, and the main programming language I can think of
that uses it (and exposes it in this form) is Javascript, and that too in a broken way.</p>

<p>The nice thing about UTF8 is that it saves space. Of course, that is subjective and dependent on
the script you use most commonly, for example my first name is 12 bytes in UTF-8 but only 4
in ISCII (or a hypothetical unicode-based encoding that swapped the Devanagri Unicode block with
the ASCII block). It also uses more space over the very non-hypothetical UTF-16 encoding if you
tend to use code points in the U+0800 - U+FFFF range. It always uses less space than UTF-32 however.</p>

<p>A commonly touted disadvantage of UTF-8 is that string indexing is <code>O(n)</code>. Because code points take
up a variable number of bytes, you won’t know where the 5th codepoint is until you scan the string
and look for it. UTF-32 doesn’t have this problem; it’s always <code>4 * index</code> bytes away.</p>

<p>The problem here is that indexing by code point shouldn’t be an operation you ever need!</p>

<h2 id="indexing-by-code-point">Indexing by code point</h2>

<p>The main time you want to be able to index by code point is if you’re implementing algorithms
defined in the unicode spec that operate on unicode strings (casefolding, segmentation, NFD/NFC).
Most if not all of these algorithms operate on whole strings, so implementing them
as an iteration pass is usually necessary anyway, so you don’t lose anything if you can’t
do arbitrary code point indexing.</p>

<p>But for application logic, dealing with code points doesn’t really make sense. This is because
code points have no intrinsic meaning. They are not “characters”. I’m using scare quotes here
because a “character” isn’t a well-defined concept either, but we’ll get to that later.</p>

<p>For example, “é” is two code points (<code>e</code> +<code> ́</code>), where one of them is a combining accent. My name,
“मनीष”, visually looks like three “characters”, but is four code points. The “नी” is made up of <code>न</code></p>
<ul>
  <li><code>ी</code>. My last name contains a “character” made up of three code points (and multiple two-code-point
“characters”). The flag emoji “🇺🇸” is also made of two code points, <code>🇺</code> + <code>🇸</code>.</li>
</ul>

<p>One false assumption that’s often made is that code points are a single column wide. They’re not.
They sometimes bunch up to form characters that fit in single “columns”. This is often dependent on
the font, and if your application relies on this, you should be querying the font. There are even
code points like U+FDFD (﷽) which are often rendered multiple columns wide. In fact, in my
<em>monospace</em> font in my text editor, that character is rendered <em>almost</em> 12 columns wide. Yes,
“almost”, subsequent characters get offset a tiny bit. I don’t know why.</p>

<p>Another false assumption is that editing actions (selection, backspace, cut, paste) operate on code
points. In both Chrome and Firefox, selection will often include multiple code points. All the
multi-code-point examples I gave above fall into this category. An interesting testcase for this is
the string “ᄀᄀᄀ각ᆨᆨ”, which will rarely if ever render as a single “character” but will be considered
as one for the purposes of selection, pretty much universally. I’ll get to why this is later.</p>

<p>Backspace can gobble multiple code points at once too, but the heuristics are different. The reason
behind this is that backspace needs to mirror the act of typing, and while typing sometimes
constructs multi-codepoint characters, backspace decomposes it piece by piece. In cases where a
multi-codepoint “character” <em>can</em> be logically decomposed (e.g. “letter + accent”), backspace will
decompose it, by removing the accent or whatever. But some multi-codepoint characters are not
“constructions” of general concepts that should be exposed to the user. For example, a user should
never need to know that the “🇺🇸” flag emoji is made of <code>🇺</code> + <code>🇸</code>, and hitting backspace on it should
delete both codepoints. Similarly, variation selectors and other such code points shouldn’t
be treated as their own unit when backspacing.</p>

<p>On my Mac most builtin apps (which I presume use the OSX UI toolkits) seem to use the same
heuristics that Firefox/Chrome use for selection for both selection and backspace. While the
treatment of code points in editing contexts is not consistent, it seems like applications
consistently do not consider code points as “editing units”.</p>

<p>Now, it is true that you often need <em>some</em> way to index a string. For example, if you have a large
document and need to represent a slice of it. This could be a user-selection, or something delimeted
by markup. Basically, you’ve already gone through the document and have a section you want to be
able to refer to later without copying it out.</p>

<p>However, you don’t need code point indexing here, byte
indexing works fine! UTF8 is designed so that you can check if you’re on a code point boundary even
if you just byte-index directly. It does this by restricting the kinds of bytes allowed. One-byte
code points never have the high bit set (ASCII). All other code points have the high bit set in each
byte. The first byte of multibyte codepoints always starts with a sequence that specifies the number
of bytes in the codepoint, and such sequences can’t be found in the lower-order bytes of any
multibyte codepoint. You can see this visually in the table <a href="https://en.wikipedia.org/wiki/UTF-8#Description">here</a>. The upshot of all this
is that you just need to check the current byte if you want to be sure you’re on a codepoint
boundary, and if you receive an arbitrarily byte-sliced string, you will not mistake it for
something else. It’s not possible to have a valid code point be a subslice of another, or form a
valid code point by subslicing a sequence of two different ones by cutting each in half.</p>

<p>So all you need to do is keep track of the byte indices, and use them for slicing it later.</p>

<p>All in all, it’s important to always remember that “code point” doesn’t have intrinsic meaning. If
you need to do a segmentation operation on a string, find out what <em>exactly</em> you’re looking for, and
what concept maps closest to that. It’s rare that “code point” is the concept you’re looking for.
In <em>most</em> cases, what you’re looking for instead is “grapheme cluster”.</p>

<h2 id="grapheme-clusters">Grapheme clusters</h2>

<p>The concept of a “character” is a nebulous one. Is “각” a single character, or
three? How about “नी”? Or “நி”? Or the “👨‍❤️‍👨” emoji<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">1</a></sup>? Or the “👨‍👨‍👧‍👧” family emoji<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote">2</a></sup>?
Different scripts have different concepts which may not clearly map to the Latin notion of “letter”
or our programmery notion of “character”.</p>

<p>Unicode itself gives the term <a href="http://unicode.org/glossary/#character">“character”</a> multiple incompatible meanings, and as
far as I know doesn’t use the term in any normative text.</p>

<p>Often, you need to deal with what is actually displayed to the user. A lot of terminal emulators do
this wrong, and end up messing up cursor placement. I used to use irssi-xmpp to keep my Facebook and
Gchat conversations in my IRC client, but I eventually stopped as I was increasingly chatting in
Marathi or Hindi and I prefer using the actual script over romanizing<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote">3</a></sup>, and it would just break
my terminal<sup id="fnref:5" role="doc-noteref"><a href="#fn:5" class="footnote">4</a></sup>. Also, they got rid of the XMPP bridge but I’d already cut down on it by then.</p>

<p>So sometimes, you need an API querying what the font is doing. Generally, when talking about the
actual rendered image, the term “glyph” or “glyph image” is used.</p>

<p>However, you can’t always query the font. Text itself exists independent of rendering, and sometimes
you need a rendering-agnostic way of segmenting it into “characters”.</p>

<p>For this, Unicode has a concept of <a href="http://unicode.org/glossary/#grapheme_cluster">“grapheme cluster”</a>. There’s also “extended grapheme
cluster” (EGC), which is basically an updated version of the concept. In this post, whenever
I use the term “grapheme cluster”, I am talking about EGCs.</p>

<p>The term is defined and explored in <a href="http://www.unicode.org/reports/tr29/#Grapheme_Cluster_Boundaries">UAX #29</a>. It starts by pinning down the still-nebulous
concept of “user-perceived character” (“a basic unit of a writing system for a language”),
and then declares the concept of a “grapheme cluster” to be an approximation to this notion
that we can determine programmatically.</p>

<p>A rough definition of grapheme cluster is a “horizontally segmentable unit of text”.</p>

<p>The spec goes into detail as to the exact algorithm that segments text at grapheme cluster
boundaries. All of the examples I gave in the first paragraph of this section are single grapheme
clusters. So is “ᄀᄀᄀ각ᆨᆨ” (or “ᄀᄀᄀ각ᆨᆨ”), which apparently is considered a
single syllable block in Hangul even though it is not of the typical form of leading consonant +
vowel + optional tail consonant, but is not something you’d see in modern Korean. The spec
explicitly talks of this case so it seems to be on purpose. I like this string because nothing I
know of renders it as a single glyph; so you can easily use it to tell if a particular segmentation-
aware operation uses grapheme clusters as segmentation. If you try and select it, in most browsers
you will be forced to select the whole thing, but backspace will delete the jamos one by one. For
the second string, backspace will decompose the core syllable block too (in the first string the
syllable block 각 is “precomposed” as a single code point, in the second one I
built it using combining jamos).</p>

<p>Basically, unless you have very specific requirements or are able to query the font, use an API that
segments strings into grapheme clusters wherever you need to deal with the notion of “character”.</p>

<h2 id="language-defaults">Language defaults</h2>

<p>Now, a lot of languages by default are now using Unicode-aware encodings. This is great. It gets rid
of the misconception that characters are one byte long.</p>

<p>But it doesn’t get rid of the misconception that user-perceived characters are one code point long.</p>

<p>There are only two languages I know of which handle this well: Swift and Perl 6. I don’t know much
about Perl 6’s thing so I can’t really comment on it, but I am really happy with what Swift does:</p>

<p>In Swift, the <code>Character</code> type is an extended grapheme cluster. This does mean that a
character itself is basically a string, since EGCs can be arbitrarily many code points long.</p>

<p>All the APIs by default deal with EGCs. The length of a string is the number of EGCs in it. They
are indexed by EGC. Iteration yields EGCs. The default comparison algorithm uses unicode
canonical equivalence, which I think is kind of neat. Of course, APIs that work with code
points are exposed too, you can iterate over the code points using <code>.unicodeScalars</code>.</p>

<p>The internal encoding itself is … weird (and as far as I can tell not publicly exposed), but as a
higher level language I think it’s fine to do things like that.</p>

<p>I strongly feel that languages should be moving in this direction, having defaults involving
grapheme clusters.</p>

<p>Rust, for example, gets a lot of things right – it has UTF-8 strings. It internally uses byte
indices in slices. Explicit slicing usually uses byte indices too, and will panic if out of bounds.
The non-O(1) methods are all explicit, since you will use an iterator to perform the operation (E.g.
<code>.chars().nth(5)</code>). This encourages people to <em>think</em> about the cost, and it also  encourages people
to coalesce the cost with nearby iterations – if you are going to do multiple <code>O(n)</code> things, do
them in a single iteration! Rust <code>char</code>s represent code points. <code>.char_indices()</code> is
a useful string iteration method that bridges the gap between byte indexing and code points.</p>

<p>However, while the documentation does mention grapheme clusters, the stdlib is not aware of the
concept of grapheme clusters at all. The default “fundamental” unit of the string in Rust is
a code point, and the operations revolve around that. If you want grapheme clusters, you
may use <a href="https://unicode-rs.github.io/unicode-segmentation/unicode_segmentation/trait.UnicodeSegmentation.html#tymethod.graphemes"><code>unicode-segmentation</code></a></p>

<p>Now, Rust is a systems programming language and it just wouldn’t do to have expensive grapheme
segmentation operations all over your string defaults. I’m very happy that the expensive <code>O(n)</code>
operations are all only possible with explicit acknowledgement of the cost. So I do think that going
the Swift route would be counterproductive for Rust. Not that it <em>can</em> anyway, due to backwards
compatibility :)</p>

<p>But I would prefer if the grapheme segmentation methods were in the stdlib (they used to be).
This is probably not something that will happen, though I should probably push for the unicode
crates being move into the nursery at least.</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>Emoji may not render as a single glyph depending on the font. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>While writing this paragraph I discovered that wrapping text that contains lots of family emoji hangs Sublime. Neat. <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>Part of the reason here is that I just find romanization confusing. There are some standardized ways to romanize which don’t get used much. My friends and I romanize one way, different from the standardizations. My family members romanize things a completely different way and it’s a bit hard to read. Then again, romanization <em>does</em> hide the fact that my spelling in Hindi is atrocious :) <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:5" role="doc-endnote">
      <p>It’s possible to make work. You need a good terminal emulator, with the right settings, the right settings in your env vars, the right settings in irssi, and the right settings in screen. I think my current setup works well with non-ascii text but I’m not sure what I did to make it happen. <a href="#fnref:5" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2017/01/11/rust-tidbits-what-is-a-lang-item/">Rust Tidbits: What Is a Lang Item?</a></h1>
    
    
      <p class="meta">
        





        
      </p>
    
  </header>


  <div class="entry-content"><p><em>Rust is not a simple language. As with any such language, it has many little tidbits of complexity
that most folks aren’t aware of. Many of these tidbits are ones which may not practically matter
much for everyday Rust programming, but are interesting to know. Others may be more useful. I’ve
found that a lot of these aren’t documented anywhere (not that they always should be), and sometimes
depend on knowledge of compiler internals or history. As a fan of programming trivia myself, I’ve
decided to try writing about these things whenever I come across them. “Tribal Knowledge” shouldn’t
be a thing in a programming community; and trivia is fun!</em></p>

<p>Previously in tidbits: <a href="http://manishearth.github.io/blog/2017/01/10/rust-tidbits-box-is-special/"><code>Box</code> is Special</a></p>

<p>Last time I talked about <code>Box&lt;T&gt;</code> and how it is a special snowflake. Corey <a href="https://www.reddit.com/r/rust/comments/5nb86x/rust_tidbits_box_is_special/dca4y6n/?utm_content=permalink&amp;utm_medium=front&amp;utm_source=reddit&amp;utm_name=rust">asked</a> that
I write more about lang items, which are basically all of the special snowflakes in the stdlib.</p>

<p>So what <em>is</em> a lang item? Lang items are a way for the stdlib (and libcore) to define types, traits,
functions, and other items which the compiler needs to know about.</p>

<p>For example, when you write <code>x + y</code>, the compiler will effectively desugar that into
<code>Add::add(x, y)</code><sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">1</a></sup>. How did it know what trait to call? Did it just insert a call to
<code>::core::Add::add</code> and hope the trait was defined there? This is what C++ does;
the Itanium ABI spec expects functions of certain names
to just <em>exist</em>, which the compiler is supposed to call in various cases. The
<code>__cxa_guard_*</code> functions from C++s deferred-initialization local statics (which
I’ve <a href="http://manishearth.github.io/blog/2015/06/26/adventures-in-systems-programming-c-plus-plus-local-statics/">explored in the past</a>) are an example of this. You’ll find that the spec is
full of similar <code>__cxa</code> functions. While the spec just expects certain types,
e.g. <code>std::type_traits</code> (“Type properties” § 20.10.4.3), to be magic and exist in certain locations,
the compilers seem to implement them using intrinsics like <code>__is_trivial&lt;T&gt;</code> which aren’t defined
in C++ code at all. So C++ compilers have a mix of solutions here, they partly insert calls
to known ABI functions, and they partly implement “special” types via intrinsics which
are detected and magicked when the compiler comes across them.</p>

<p>However, this is not Rust’s solution. It does not care what the <code>Add</code> trait is named or where it is
placed. Instead, it knew where the trait for addition was located because <a href="https://github.com/rust-lang/rust/blob/2782e8f8fcefdce77c5e0dd0846c15c4c5103d84/src/libcore/ops.rs#L243"><em>we told it</em></a>.
When you put <code>#[lang = "add"]</code> on a trait, the compiler knows to call <code>YourTrait::add(x, y)</code> when it
encounters the addition operator. Of course, usually the compiler will already have been told about
such a trait since libcore is usually the first library in the pipeline. If you want to actually use
this, you need to <em>replace libcore</em>.</p>

<p>Huh? You can’t do that, can you?</p>

<p>It’s not a big secret that you can compile rust without the stdlib using
<a href="https://doc.rust-lang.org/book/no-stdlib.html"><code>#![no_std]</code></a>. This is useful in cases when you are on an embedded system and can’t
rely on an allocator existing. It’s also useful for writing your own alternate stdlib, though
that’s not something folks do often. Of course, libstd itself <a href="https://github.com/rust-lang/rust/blob/2782e8f8fcefdce77c5e0dd0846c15c4c5103d84/src/libstd/lib.rs#L213-L214">uses <code>#![no_std]</code></a>,
because without it the compiler will happily inject an <code>extern crate std</code> while trying to compile
libstd and the universe will implode.</p>

<p>What’s less known is that you can do the same thing with libcore, via <code>#![no_core]</code>. And, of course,
libcore <a href="https://github.com/rust-lang/rust/blob/2782e8f8fcefdce77c5e0dd0846c15c4c5103d84/src/libcore/lib.rs#L65">uses it</a> to avoid the cyclic dependency. Unlike <code>#![no_std]</code>, <code>no_core</code> is
a nightly-only feature that we may never stabilize<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote">2</a></sup>. <code>#![no_core]</code> is something that’s basically
only to be used if you <em>are</em> libcore (or you are an alternate Rust stdlib/core implementation
trying to emulate it).</p>

<p>Still, it’s possible to write a working Rust binary in <code>no_core</code> mode:</p>

<pre><code class="language-rust">#![feature(no_core)]
#![feature(lang_items)]

// Look at me.
// Look at me.
// I'm the libcore now.
#![no_core]

// Tell the compiler to link to appropriate runtime libs
// (This way I don't have to specify `-l` flags explicitly)
#[cfg(target_os = "linux")]
#[link(name = "c")]
extern {}
#[cfg(target_os = "macos")]
#[link(name = "System")]
extern {}

// Compiler needs these to proceed
#[lang = "sized"]
pub trait Sized {}
#[lang = "copy"]
pub trait Copy {}

// `main` isn't the actual entry point, `start` is.
#[lang = "start"]
fn start(_main: *const u8, _argc: isize, _argv: *const *const u8) -&gt; isize {
    // we can't really do much in this benighted hellhole of
    // an environment without bringing in more libraries.
    // We can make syscalls, segfault, and set the exit code.
    // To be sure that this actually ran, let's set the exit code.
    42
}

// still need a main unless we want to use `#![no_main]`
// won't actually get called; `start()` is supposed to call it
fn main() {}
</code></pre>

<p>If you run this, the program will exit with exit code 42.</p>

<p>Note that this already adds two lang items. <code>Sized</code> and <code>Copy</code>. It’s usually worth
<a href="https://github.com/rust-lang/rust/blob/2782e8f8fcefdce77c5e0dd0846c15c4c5103d84/src/libcore/marker.rs#L88-L94">looking at the lang item in libcore</a> and copying it over unless you want to make
tweaks. Beware that tweaks may not always work; not only does the compiler expect the lang item
to exist, it expects it to make sense. There are properties of the lang item that it assumes
are true, and failure to provide an appropriate lang item may cause the compiler to assert
without a useful error message. In this case I do have a tweak, since
the original definition of <code>Copy</code> is <code>pub trait Copy: Clone {}</code>, but I know that this tweak
will work.</p>

<p>Lang items are usually only required when you do an operation which needs them. There are 72 non-
deprecated lang items and we only had to define three of them here. “start” is necessary to, well,
start executables, and <code>Copy</code>/<code>Sized</code> are very crucial to how the compiler reasons about types and
must exist.</p>

<p>But let’s try doing something that will trigger a lang item to be required:</p>

<pre><code class="language-rust">pub static X: u8 = 1;
</code></pre>

<p>Rust will immediately complain:</p>

<pre><code>$ rustc test.rs
error: requires `sync` lang_item
</code></pre>

<p>This is because Rust wants to enforce that types in statics (which can be accessed concurrently)
are safe when accessed concurrently, i.e., they implement <code>Sync</code>. We haven’t defined <code>Sync</code> yet,
so Rust doesn’t know how to enforce this restruction. The <code>Sync</code> trait is defined with the “sync”
lang item, so we need to do:</p>

<pre><code class="language-rust">pub static X: u8 = 1;

#[lang = "sync"]
pub unsafe trait Sync {}
unsafe impl Sync for u8 {}
</code></pre>

<p>Note that the trait doesn’t have to be called <code>Sync</code> here, any trait name would work. This
definition is also a slight <a href="https://github.com/rust-lang/rust/blob/2782e8f8fcefdce77c5e0dd0846c15c4c5103d84/src/libcore/marker.rs#L343-L351">departure from the one in the stdlib</a>, and in general you
should include the auto trait impl (instead of specifically using <code>unsafe impl Sync for u8 {}</code>)
since the compiler may assume it exists. Our code is small enough for this to not matter.</p>

<p>Alright, let’s try defining our own addition trait as before. First, let’s see
what happens if we try to add a struct when addition isn’t defined:</p>

<pre><code class="language-rust">struct Foo;
#[lang = "start"]
fn start(_main: *const u8, _argc: isize, _argv: *const *const u8) -&gt; isize {
    Foo + Foo
}
</code></pre>

<p>We get an error:</p>

<pre><code>$ rustc test.rs
error[E0369]: binary operation `+` cannot be applied to type `Foo`
  --&gt; test.rs:33:5
   |
33 |     Foo + Foo
   |     ^^^
   |
note: an implementation of `std::ops::Add` might be missing for `Foo`
  --&gt; test.rs:33:5
   |
33 |     Foo + Foo
   |     ^^^

error: aborting due to previous error
</code></pre>

<p>It is interesting to note that here the compiler <em>did</em> refer to <code>Add</code> by its path.
This is because the diagnostics in the compiler are free to assume that libcore
exists. However, the actual error just noted that it doesn’t know how to add two
<code>Foo</code>s. But we can tell it how!</p>

<pre><code class="language-rust">#[lang = "add"]
trait MyAdd&lt;RHS&gt; {
    type Output;
    fn add(self, other: RHS) -&gt; Self::Output;
}

impl MyAdd&lt;Foo&gt; for Foo {
    type Output = isize;
    fn add(self, other: Foo) -&gt; isize {
        return 42;
    }
}

struct Foo;
#[lang = "start"]
fn start(_main: *const u8, _argc: isize, _argv: *const *const u8) -&gt; isize {
    Foo + Foo
}
</code></pre>

<p>This will compile fine and the exit code of the program will be 42.</p>

<p>An interesting bit of behavior is what happens if we try to add two numbers. It will give us the
same kind of error, even though the addition of concrete primitives doesn’t
go through <code>Add::add</code> (Rust asks LLVM to generate an add instruction directly). However, any addition operation still checks if <code>Add::add</code> is implemented, even though it won’t get <em>used</em> in the case of a primitive. We can even verify this!</p>

<pre><code class="language-rust">#[lang = "add"]
trait MyAdd&lt;RHS&gt; {
    type Output;
    fn add(self, other: RHS) -&gt; Self::Output;
}

impl MyAdd&lt;isize&gt; for isize {
    type Output = isize;
    fn add(self, other: isize) -&gt; isize {
        self + other + 50
    }
}

struct Foo;
#[lang = "start"]
fn start(_main: *const u8, _argc: isize, _argv: *const *const u8) -&gt; isize {
    40 + 2
}
</code></pre>

<p>This will need to be compiled with <code>-C opt-level=2</code>, since numeric addition in debug mode panics on
wrap and we haven’t defined the <code>"panic"</code> lang item to teach the compiler <em>how</em> to panic.</p>

<p>It will exit with 42, not 92, since while the <code>Add</code> implementation is required for this to type
check, it doesn’t actually get used.</p>

<hr />

<p>So what lang items <em>are</em> there, and why are they lang items? There’s a <a href="https://github.com/rust-lang/rust/blob/1ca100d0428985f916eea153886762bed3909771/src/librustc/middle/lang_items.rs#L252-L363">big list</a> in the
compiler. Let’s go through them:</p>

<p>The <a href="https://github.com/rust-lang/rust/blob/1ca100d0428985f916eea153886762bed3909771/src/librustc/middle/lang_items.rs#L254-L272"><code>ImplItem</code> ones</a> (<a href="https://github.com/rust-lang/rust/blob/2782e8f8fcefdce77c5e0dd0846c15c4c5103d84/src/libstd_unicode/char.rs#L134-L135">core</a>) are used to mark implementations on
primitive types. <code>char</code> has some methods, and <em>someone</em> has to say <code>impl char</code> to define them. But
coherence only allows us to impl methods on types defined in our own crate, and <code>char</code> isn’t defined
… in any crate, so how do we add methods to it? <code>#[lang = "char"]</code> provides an escape hatch;
applying that to <code>impl char</code> will allow you to break the coherence rules and add methods,
<a href="https://github.com/rust-lang/rust/blob/2782e8f8fcefdce77c5e0dd0846c15c4c5103d84/src/libstd_unicode/char.rs#L134-L135">as is done in the standard library</a>. Since lang items can only be defined once, only
a single crate gets the honor of adding methods to <code>char</code>, so we don’t have any of the issues that
arise from sidestepping coherence.</p>

<p>There are a bunch for the <a href="https://github.com/rust-lang/rust/blob/1ca100d0428985f916eea153886762bed3909771/src/librustc/middle/lang_items.rs#L274-L278">marker traits</a> (<a href="https://github.com/rust-lang/rust/blob/408c2f7827be838aadcd05bd041dab94388af35d/src/libcore/marker.rs#L41-L356">core</a>):</p>

<ul>
  <li><code>Send</code> is a lang item because you are allowed to use it in a <code>+</code> bound in a trait object (<code>Box&lt;SomeTrait+Send+Sync&gt;</code>), and the compiler caches it aggressively</li>
  <li><code>Sync</code> is a lang item for the same reasons as <code>Send</code>, but also because the compiler needs to enforce its implementation on types used in statics</li>
  <li><code>Copy</code> is fundamental to classifying values and reasoning about moves/etc, so it needs to be a lang item</li>
  <li><code>Sized</code> is also fundamental to reasoning about which values may exist on the stack. It is also magically included as a bound on generic parameters unless excluded with <code>?Sized</code></li>
  <li><a href="https://doc.rust-lang.org/nightly/std/marker/trait.Unsize.html"><code>Unsize</code></a> is implemented automatically on types using a specific set of rules (<a href="https://doc.rust-lang.org/nomicon/coercions.html">listed in the nomicon</a>). Unlike <code>Send</code> and <code>Sync</code>, this mechanism for autoimplementation is tailored for the use case of <code>Unsize</code> and can’t be reused on user-defined marker traits.</li>
</ul>

<p><a href="https://github.com/rust-lang/rust/blob/1ca100d0428985f916eea153886762bed3909771/src/librustc/middle/lang_items.rs#L280"><code>Drop</code> is a lang item</a> (<a href="https://github.com/rust-lang/rust/blob/408c2f7827be838aadcd05bd041dab94388af35d/src/libcore/ops.rs#L174-L197">core</a>) because the compiler needs to know which types have destructors, and how to call
these destructors.</p>

<p><a href="https://doc.rust-lang.org/nightly/std/ops/trait.CoerceUnsized.html"><code>CoerceUnsized</code></a> <a href="https://github.com/rust-lang/rust/blob/1ca100d0428985f916eea153886762bed3909771/src/librustc/middle/lang_items.rs#L282">is a lang item</a>
(<a href="https://github.com/rust-lang/rust/blob/408c2f7827be838aadcd05bd041dab94388af35d/src/libcore/ops.rs#L2743-L2746">core</a>) because the compiler is allowed to perform
<a href="https://github.com/rust-lang/rfcs/blob/master/text/0982-dst-coercion.md">DST coercions</a> (<a href="https://doc.rust-lang.org/nomicon/coercions.html">nomicon</a>) when it is implemented.</p>

<p><a href="https://github.com/rust-lang/rust/blob/1ca100d0428985f916eea153886762bed3909771/src/librustc/middle/lang_items.rs#L284-L307">All of the builtin operators</a> (also <a href="https://github.com/rust-lang/rust/blob/1ca100d0428985f916eea153886762bed3909771/src/librustc/middle/lang_items.rs#L311-L312"><code>Deref</code></a>
and <a href="https://github.com/rust-lang/rust/blob/1ca100d0428985f916eea153886762bed3909771/src/librustc/middle/lang_items.rs#L318-L319"><code>PartialEq</code>/<code>PartialOrd</code></a>, which are listed later in the file) (<a href="https://github.com/rust-lang/rust/blob/408c2f7827be838aadcd05bd041dab94388af35d/src/libcore/ops.rs#L243-L2035">core</a>)
are lang items because the compiler needs to know what trait to require (and call)
when it comes across such an operation.</p>

<p><a href="http://doc.rust-lang.org/std/cell/struct.UnsafeCell.html"><code>UnsafeCell</code></a> <a href="https://github.com/rust-lang/rust/blob/1ca100d0428985f916eea153886762bed3909771/src/librustc/middle/lang_items.rs#L309">is a lang item</a>
(<a href="https://github.com/rust-lang/rust/blob/408c2f7827be838aadcd05bd041dab94388af35d/src/libcore/cell.rs#L1065-L1069">core</a>) because it has very special semantics; it prevents
certain optimizations. Specifically, Rust is allowed to reorder reads/writes to <code>&amp;mut foo</code> with the
assumption that the local variable holding the reference is the only alias allowed to read from
or write to the data, and it is allowed to reorder reads from <code>&amp;foo</code> assuming that no other alias
writes to it. We tell LLVM that these types are <code>noalias</code>. <code>UnsafeCell&lt;T&gt;</code> turns this optimization
off, allowing writes to <code>&amp;UnsafeCell&lt;T&gt;</code> references. This is used in the implementation of interior
mutability types like <code>Cell&lt;T&gt;</code>, <code>RefCell&lt;T&gt;</code>, and <code>Mutex&lt;T&gt;</code>.</p>

<p>The <a href="https://github.com/rust-lang/rust/blob/1ca100d0428985f916eea153886762bed3909771/src/librustc/middle/lang_items.rs#L314-L316"><code>Fn</code> traits</a> (<a href="https://github.com/rust-lang/rust/blob/408c2f7827be838aadcd05bd041dab94388af35d/src/libcore/ops.rs#L2556-L2659">core</a>) are used in dispatching function calls,
and can be specified with special syntax sugar, so they need to be lang items. They also
get autoimplemented on closures.</p>

<p><a href="https://github.com/rust-lang/rust/blob/1ca100d0428985f916eea153886762bed3909771/src/librustc/middle/lang_items.rs#L321">The <code>"str_eq"</code> lang item</a> is outdated. It <em>used</em> to specify how to check the equality
of a string value against a literal string pattern in a <code>match</code> (<code>match</code> uses structural equality,
not <code>PartialEq::eq</code>), however I believe this behavior is now hardcoded in the compiler.</p>

<p><a href="https://github.com/rust-lang/rust/blob/1ca100d0428985f916eea153886762bed3909771/src/librustc/middle/lang_items.rs#L332-L334">The panic-related lang items</a> (<a href="https://github.com/rust-lang/rust/blob/408c2f7827be838aadcd05bd041dab94388af35d/src/libcore/panicking.rs#L39-L58">core</a>) exist because rustc itself
inserts panics in a few places. The first one, <code>"panic"</code>, is used for integer overflow panics in debug mode, and
<code>"panic_bounds_check"</code> is used for out of bounds indexing panics on slices. The last one,
<code>"panic_fmt"</code> hooks into a function defined later in libstd.</p>

<p>The <a href="https://github.com/rust-lang/rust/blob/1ca100d0428985f916eea153886762bed3909771/src/librustc/middle/lang_items.rs#L336-L337"><code>"exchange_malloc"</code> and <code>"box_free"</code></a> (<a href="https://github.com/rust-lang/rust/blob/408c2f7827be838aadcd05bd041dab94388af35d/src/liballoc/heap.rs#L129-L152">alloc</a>) are for
telling the compiler which functions to call in case it needs to do a <code>malloc()</code> or <code>free()</code>. These
are used when constructing <code>Box&lt;T&gt;</code> via placement <code>box</code> syntax and when moving out of a deref of a
box.</p>

<p><a href="https://github.com/rust-lang/rust/blob/1ca100d0428985f916eea153886762bed3909771/src/librustc/middle/lang_items.rs#L338"><code>"strdup_uniq"</code></a> seemed to be used in the past for moving string literals to the heap,
but is no longer used.</p>

<p>We’ve already seen <a href="https://github.com/rust-lang/rust/blob/1ca100d0428985f916eea153886762bed3909771/src/librustc/middle/lang_items.rs#L340">the start lang item</a> (<a href="https://github.com/rust-lang/rust/blob/1ca100d0428985f916eea153886762bed3909771/src/libstd/rt.rs#L31-L67">std</a>) being used in our
minimal example program. This function is basically where you find Rust’s “runtime”: it gets called
with a pointer to main and the command line arguments, it sets up the “runtime”, calls main, and
tears down anything it needs to. Rust has a C-like minimal runtime, so
<a href="https://github.com/rust-lang/rust/blob/1ca100d0428985f916eea153886762bed3909771/src/libstd/rt.rs#L31-L67">the actual libstd definition</a> doesn’t do much.
But you theoretically could stick a very heavy runtime initialization routine here.</p>

<p>The <a href="https://github.com/rust-lang/rust/blob/1ca100d0428985f916eea153886762bed3909771/src/librustc/middle/lang_items.rs#L342-L344">exception handling lang items</a> (<a href="https://github.com/rust-lang/rust/blob/408c2f7827be838aadcd05bd041dab94388af35d/src/libpanic_unwind/seh.rs">panic_unwind</a>, in multiple
platform-specific modules) specify various bits of the exception handling behavior. These hooks are
called during various steps of unwinding: <code>eh_personality</code> is called when determining whether
or not to stop at a stack frame or unwind up to the next one. <code>eh_unwind_resume</code> is the routine
called when the unwinding code wishes to resume unwinding after calling destructors in a landing
pad. <code>msvc_try_filter</code> defines some parameter that MSVC needs in its unwinding code. I don’t
understand it, and apparently, <a href="https://github.com/rust-lang/rust/blob/408c2f7827be838aadcd05bd041dab94388af35d/src/libpanic_unwind/seh.rs#L232">neither does the person who wrote it</a>.</p>

<p>The <a href="https://github.com/rust-lang/rust/blob/1ca100d0428985f916eea153886762bed3909771/src/librustc/middle/lang_items.rs#L346"><code>"owned_box"</code></a> (<a href="https://github.com/rust-lang/rust/blob/408c2f7827be838aadcd05bd041dab94388af35d/src/liballoc/boxed.rs#L105-L107">alloc</a>) lang item tells the compiler which type is
the <code>Box</code> type. In my previous post I covered how <code>Box</code> is special; this lang item is how the
compiler finds impls on <code>Box</code> and knows what the type is. Unlike the other primitives, <code>Box</code> doesn’t
actually have a type name (like <code>bool</code>) that can be used if you’re writing libcore or libstd. This
lang item gives <code>Box</code> a type name that can be used to refer to it. (It also defines some,
but not all, of the semantics of <code>Box&lt;T&gt;</code>)</p>

<p>The <a href="https://github.com/rust-lang/rust/blob/1ca100d0428985f916eea153886762bed3909771/src/librustc/middle/lang_items.rs#L348"><code>"phantom_data"</code></a> (<a href="https://github.com/rust-lang/rust/blob/2782e8f8fcefdce77c5e0dd0846c15c4c5103d84/src/libcore/marker.rs#L544-L546">core</a>) type itself is allowed to have
an unused type parameter, and it can be used to help fix the variance and drop behavior
of a generic type. More on this in <a href="https://doc.rust-lang.org/nomicon/phantom-data.html">the nomicon</a>.</p>

<p>The <a href="https://github.com/rust-lang/rust/blob/1ca100d0428985f916eea153886762bed3909771/src/librustc/middle/lang_items.rs#L360"><code>"non_zero"</code></a> lang item (<a href="https://github.com/rust-lang/rust/blob/2782e8f8fcefdce77c5e0dd0846c15c4c5103d84/src/libcore/nonzero.rs#L38-L42">core</a>) marks the <code>NonZero&lt;T&gt;</code> type,
a type which is guaranteed to never contain a bit pattern of only zeroes. This is used inside things
like <code>Rc&lt;T&gt;</code> and <code>Box&lt;T&gt;</code> – we know that the pointers in these can/should never be null, so they
contain a <code>NonZero&lt;*const T&gt;</code>. When used inside an enum like <code>Option&lt;Rc&lt;T&gt;&gt;</code>, the discriminant
(the “tag” value that distinguishes between <code>Some</code> and <code>None</code>) is no longer necessary, since
we can mark the <code>None</code> case as the case where the bits occupied by <code>NonZero</code> in the <code>Some</code> case
are zero. Beware, this optimization also applies to C-like enums that don’t have a variant
corresponding to a discriminant value of zero (unless they are <code>#[repr(C)]</code>)</p>

<p>There are also a bunch of deprecated lang items there. For example, <code>NoCopy</code> used to be a struct
that could be dropped within a type to make it not implement <code>Copy</code>; in the past <code>Copy</code>
implementations were automatic like <code>Send</code> and <code>Sync</code> are today. <code>NoCopy</code> was the way to opt out.
There also used to be <code>NoSend</code> and <code>NoSync</code>. <code>CovariantType</code>/<code>CovariantLifetime</code>/etc were the
predecessors of <code>PhantomData</code>; they could be used to specify variance relations of a type with its
type or lifetime parameters, but you can now do this with providing the right <code>PhantomData</code>, e.g.
<code>InvariantType&lt;T&gt;</code> is now <code>PhantomData&lt;Cell&lt;T&gt;&gt;</code>.
The <a href="https://doc.rust-lang.org/nomicon/subtyping.html">nomicon</a> has more on variance. I don’t know why these lang items haven’t been
removed (they don’t work anymore anyway); the only consumer of them is libcore so “deprecating” them
seems unnecessary. It’s probably an oversight.</p>

<p>Interestingly, <code>Iterator</code> and <code>IntoIterator</code> are <em>not</em> lang items, even though they are used in <code>for</code>
loops. Instead, the compiler inserts hardcoded calls to <code>::std::iter::IntoIterator::into_iter</code> and
<code>::std::iter::Iterator::next</code>, and a hardcoded reference to <code>::std::option::Option</code> (The paths use
<code>core</code> in <code>no_std</code> mode). This is probably because the compiler desugars <code>for</code> loops before type
resolution is done, so withut this, libcore would not be able to use for loops since the compiler
wouldn’t know what calls to insert in place of the loops while compiling.</p>

<hr />

<p>Basically, whenever the compiler needs to use special treatment with an item – whether it be
dispatching calls to functions and trait methods in various situations, conferring special semantics
to types/traits, or requiring traits to be implemented, the type will be defined in the standard
library (libstd, libcore, or one of the crates behind the libstd façade), and marked as a lang item.</p>

<p>Some of the lang items are useful/necessary when working without libstd. Most only come into play if
you want to replace libcore, which is a pretty niche thing to do, and knowing about them is rarely
useful outside of the realm of compiler hacking.</p>

<p>But, like with the <code>Box&lt;T&gt;</code> madness, I still find this quite interesting, even if it isn’t generally
useful!</p>
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>Though as we learned in the previous post, when <code>x</code> and <code>y</code> are known numeric types it will bypass the trait and directly generate an add instruction in LLVM <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>To be clear, I’m not aware of any plans to eventually stabilize this. It’s something that could happen. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2017/01/10/rust-tidbits-box-is-special/">Rust Tidbits: Box Is Special</a></h1>
    
    
      <p class="meta">
        





        
      </p>
    
  </header>


  <div class="entry-content"><p>Rust is not a simple language. As with any such language, it has many little tidbits of complexity
that most folks aren’t aware of. Many of these tidbits are ones which may not practically matter
much for everyday Rust programming, but are interesting to know. Others may be more useful. I’ve
found that a lot of these aren’t documented anywhere (not that they always should be), and sometimes
depend on knowledge of compiler internals or history. As a fan of programming trivia myself, I’ve
decided to try writing about these things whenever I come across them. “Tribal Knowledge” shouldn’t
be a thing in a programming community; and trivia is fun!</p>

<hr />

<p>So. <code>Box&lt;T&gt;</code>. Your favorite heap allocation type that nobody uses<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">1</a></sup>.</p>

<p>I was discussing some stuff on the rfcs repo when
<a href="https://github.com/rust-lang/rfcs/issues/1850#issuecomment-271766300">@burdges realized that <code>Box&lt;T&gt;</code> has a funky <code>Deref</code> impl</a>.</p>

<p>Let’s <a href="https://github.com/rust-lang/rust/blob/e4fee525e04838dabc82beed5ae1a06051be53fd/src/liballoc/boxed.rs#L502">look at it</a>:</p>

<pre><code class="language-rust">#[stable(feature = "rust1", since = "1.0.0")]
impl&lt;T: ?Sized&gt; Deref for Box&lt;T&gt; {
    type Target = T;

    fn deref(&amp;self) -&gt; &amp;T {
        &amp;**self
    }
}

#[stable(feature = "rust1", since = "1.0.0")]
impl&lt;T: ?Sized&gt; DerefMut for Box&lt;T&gt; {
    fn deref_mut(&amp;mut self) -&gt; &amp;mut T {
        &amp;mut **self
    }
}
</code></pre>

<p>Wait, what? <em>Squints</em></p>

<pre><code class="language-rust">    fn deref(&amp;self) -&gt; &amp;T {
        &amp;**self
    }
</code></pre>

<p><em>The call is coming from inside the house!</em></p>

<p>In case you didn’t realize it, this deref impl returns <code>&amp;**self</code> – since <code>self</code>
is an <code>&amp;Box&lt;T&gt;</code>, dereferencing it once will provide a <code>Box&lt;T&gt;</code>, and the second dereference
will dereference the box to provide a <code>T</code>. We then wrap it in a reference and return it.</p>

<p>But wait, we are <em>defining</em> how a <code>Box&lt;T&gt;</code> is to be dereferenced (that’s what <code>Deref::deref</code> is
for!), such a definition cannot itself dereference a <code>Box&lt;T&gt;</code>! That’s infinite recursion.</p>

<p>And indeed. For any other type such a <code>deref</code> impl would recurse infinitely. If you run
<a href="https://play.rust-lang.org/?gist=9c8a02336c6816e57c83de39c103ca06&amp;version=stable&amp;backtrace=0">this code</a>:</p>

<pre><code class="language-rust">use std::ops::Deref;

struct LolBox&lt;T&gt;(T);

impl&lt;T&gt; Deref for LolBox&lt;T&gt; {
    type Target = T;
    fn deref(&amp;self) -&gt; &amp;T {
        &amp;**self
    }
}
</code></pre>

<p>the compiler will warn you:</p>

<pre><code class="language-text">warning: function cannot return without recurring, #[warn(unconditional_recursion)] on by default
 --&gt; &lt;anon&gt;:7:5
  |
7 |     fn deref(&amp;self) -&gt; &amp;T {
  |     ^
  |
note: recursive call site
 --&gt; &lt;anon&gt;:8:10
  |
8 |         &amp;**self
  |          ^^^^^^
  = help: a `loop` may express intention better if this is on purpose
</code></pre>

<p>Actually trying to dereference the type will lead to a stack overflow.</p>

<p>Clearly something is fishy here. This deref impl is similar to <a href="https://github.com/rust-lang/rust/blob/52c03d1d619fd25c961bc9de59bcc942b660d5db/src/libcore/ops.rs#L2460">the deref impl for <code>&amp;T</code></a>,
or the <a href="https://github.com/rust-lang/rust/blob/52c03d1d619fd25c961bc9de59bcc942b660d5db/src/libcore/ops.rs#L263"><code>Add</code> impl for number types</a>, or any other of the implementations of operators on
primitive types. For example we literally
<a href="https://github.com/rust-lang/rust/blob/52c03d1d619fd25c961bc9de59bcc942b660d5db/src/libcore/ops.rs#L263">define <code>Add</code> on two integers to be their addition</a>. The reason these impls need to exist
is so that people can still call <code>Add::add</code> if they need to in generic code and be able to pass
integers to things with an <code>Add</code> bound. But the compiler knows how to use builtin operators on
numbers and dereference borrowed references without these impls. But those are primitive types
which are defined in the compiler, while <code>Box&lt;T&gt;</code> is just a regular smart pointer struct, right?</p>

<p>Turns out, <code>Box&lt;T&gt;</code> is special. It, too, is somewhat of a primitive type.</p>

<p>This is partly due to historical accident.</p>

<p>To understand this, we must look back to Ye Olde days of pre-1.0 Rust (ca 2014). Back in these days,
we had none of this newfangled “stability” business. The compiler broke your code every two weeks.
Of course, you wouldn’t <em>know</em> that because the compiler would usually crash before it could tell
you that your code was broken! Sigils roamed the lands freely, and cargo was but a newborn child
which was destined to eventually end the tyranny of Makefiles. People were largely happy knowing
that their closures were safely boxed and their threads sufficiently green.</p>

<p>Back in these days, we didn’t have <code>Box&lt;T&gt;</code>, <code>Vec&lt;T&gt;</code>, or <code>String</code>. We had <code>~T</code>, <code>~[T]</code>, and <code>~str</code>.
The second two are <em>not</em> equivalent to <code>Box&lt;[T]&gt;</code> and <code>Box&lt;str&gt;</code>, even though they may look like it,
they are both growable containers like <code>Vec&lt;T&gt;</code> and <code>String</code>. <code>~</code> conceptually meant “owned”, though
IMO that caused more confusion than it was worth.</p>

<p>You created a box using the <code>~</code> operator, e.g. <code>let x = ~1;</code>. It could be dereferenced with the <code>*</code>
operator, and autoderef worked much like it does today.</p>

<p>As a “primitive” type; like all primitive types, <code>~T</code> was special. The compiler knew things about
it. The compiler knew how to dereference it without an explicit <code>Deref</code> impl. In fact, the <code>Deref</code>
traits <a href="https://github.com/rust-lang/rust/pull/12491">came into existence</a> much after <code>~T</code> did. <code>~T</code> never got an explicit <code>Deref</code> impl,
though it probably should have.</p>

<p>Eventually, there was a move to remove sigils from the language. The box constructor <code>~foo</code> was
superseded by <a href="https://github.com/rust-lang/rust/pull/11055/">placement <code>box</code> syntax</a>, which still exists in Rust nightly<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote">2</a></sup>. Then, the
<a href="https://github.com/rust-lang/rust/pull/13904"><code>~T</code> type became <code>Box&lt;T&gt;</code></a>. (<code>~[T]</code> and <code>~str</code> would also be removed, though <code>~str</code> took
a very confusing detour with <code>StrBuf</code> first).</p>

<p>However, <code>Box&lt;T&gt;</code> was still special. It no longer needed special syntax to be referred to or
constructed, but it was still internally a special type. It didn’t even have a <code>Deref</code> impl yet,
that came <a href="https://github.com/rust-lang/rust/pull/20052">six months later</a>, and it was implemented as <code>&amp;**self</code>, exactly the same
as it is today.</p>

<p>But why does it <em>have</em> to be special now? Rust had all the features it needed (allocations,
ownership, overloadable deref) to implement <code>Box&lt;T&gt;</code> in pure rust in the stdlib as if it
were a regular type.</p>

<p>Turns out that Rust didn’t. You see, because <code>Box&lt;T&gt;</code> and before it <code>~T</code> were special, their
dereference semantics were implemented in a different part of the code. And, these semantics were
not the same as the ones for <code>DerefImm</code> and <code>DerefMut</code>, which were created for use with other smart
pointers. I don’t know if the possibility of being used for <code>~T</code> was considered when
<code>DerefImm</code>/<code>DerefMut</code> were being implemented, or if it was a simple oversight, but <code>Box&lt;T&gt;</code> has
three pieces of behavior that could not be replicated in pure Rust at the time:</p>

<ul>
  <li><code>box foo</code> in a pattern would destructure a box into its contents. It’s somewhat the opposite of <code>ref</code></li>
  <li><code>box foo()</code> performed placement box, so the result of <code>foo()</code> could be directly written to a preallocated box, reducing extraneous copies</li>
  <li>You could <em>move out of deref</em> with <code>Box&lt;T&gt;</code></li>
</ul>

<p>The third one is the one that really gets to us here<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" class="footnote">3</a></sup>.
For a <em>regular</em> type, <code>*foo</code> will produce a temporary that must be immediately borrowed or copied.
You cannot do <code>let x = *y</code> for a non-<code>Copy</code> type. This dereference operation will call
<code>DerefMut::deref_mut</code> or <code>Deref::deref</code> based on how it gets borrowed. With <code>Box&lt;T&gt;</code>, you can do
this:</p>

<pre><code class="language-rust">let x = Box::new(vec![1,2,3,4]);
let y = *x; // moves the vec out into `y`, then deallocates the box
            // but does not call a destructor on the vec
</code></pre>

<p>For any other type, such an operation will produce a “cannot move out of a borrow” error.</p>

<p>This operation is colloquially called <code>DerefMove</code>, and there has been <a href="https://github.com/rust-lang/rfcs/pull/178/files?short_path=6f69a99#diff-6f69a990502a98c2eeb172d87269005d">an rfc</a> in the
past for making it into a trait. I suspect that the <code>DerefMove</code> semantics could even have been
removed from <code>Box&lt;T&gt;</code> before 1.0 (I don’t find it <em>necessary</em>), but people had better things to do,
like fixing the million other rough edges of the language that can’t be touched after backwards
compatibility is a thing.</p>

<p>So now we’re stuck with it. The current status is that <code>Box&lt;T&gt;</code> is <em>still</em> a special type in the
compiler. By “special type” I don’t just mean that the compiler treats it a bit differently (this is
true for any lang item), I mean that it literally is treated as
<a href="http://manishearth.github.io/rust-internals-docs/rustc/ty/enum.TypeVariants.html#TyBox.v">a completely new kind of type</a>, not as a struct the way it has been defined in liballoc.
There’s a TON of cruft in the compiler related to this type, much of which can be removed, but some
of which can’t. If we ever do get <code>DerefMove</code>, we should probably try removing it all again. After
writing this post I’m half-convinced to try and implement an internal-use-only <code>DerefMove</code> and try
cleaning up the code myself.</p>

<p>Most of this isn’t really useful to know unless you actually come across a case where you can make
use of <code>DerefMove</code> semantics, or if you work on the compiler. But it certainly is interesting!</p>

<p>Next post: <a href="http://manishearth.github.io/blog/2017/01/11/rust-tidbits-what-is-a-lang-item/">What is a lang item?</a></p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>Seriously though, does anyone use it much? I’ve only seen it getting used for boxed DSTs (trait objects and boxed slices), which themselves are pretty rare, for sending heap types over FFI, recursive types (rare), and random special cases. I find this pretty interesting given that other languages are much more liberal with non-refcounted single-element allocation. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>It will probably eventually be replaced or made equivalent to the <code>&lt;-</code> syntax before stabilizing <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:4" role="doc-endnote">
      <p>It’s easier to special case the first two, much like how <code>for</code> loops are aware of the iterator trait without the iterator trait being extremely special cased <a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/12/02/reflections-on-rusting-trust/">Reflections on Rusting Trust</a></h1>
    
    
      <p class="meta">
        





        
      </p>
    
  </header>


  <div class="entry-content"><p>The Rust compiler is written in Rust. This is overall a pretty common practice in compiler
development. This usually means that the process of building the compiler involves downloading a
(typically) older version of the compiler.</p>

<p>This also means that the compiler is vulnerable to what is colloquially known as the “Trusting
Trust” attack, an attack described in <a href="https://www.ece.cmu.edu/~ganger/712.fall02/papers/p761-thompson.pdf">Ken Thompson’s acceptance speech for the 1983 Turing Award</a>.
This kind of thing fascinates me, so I decided to try writing one myself. It’s stuff like this which
started my interest in compilers, and I hope this post can help get others interested the same way.</p>

<p>To be clear, this isn’t an indictment of Rust’s security. Quite a few languages out there have
popular self-hosted compilers (C, C++, Haskell, Scala, D, Go) and are vulnerable to this attack. For
this attack to have any effect, one needs to be able to uniformly distribute this compiler, and
there are roughly equivalent ways of doing the same level of damage with that kind of access.</p>

<p>If you already know what a trusting trust attack is, you can skip the next section. If you just want
to see the code, it’s in the <a href="https://github.com/Manishearth/rust/tree/rusting-trust">trusting-trust branch</a> on my Rust fork, specifically
<a href="https://github.com/Manishearth/rust/blob/rusting-trust/src/librustc_driver/driver.rs#L541">this code</a>.</p>

<h2 id="the-attack">The attack</h2>

<p>The essence of the attack is this:</p>

<p>An attacker can conceivably change a compiler such that it can detect a particular kind of application and
make malicious changes to it. The example given in the talk was the UNIX <code>login</code> program — the attacker
can tweak a compiler so as to detect that it is compiling the <code>login</code> program, and compile in a
backdoor that lets it unconditionally accept a special password (created by the attacker) for any
user, thereby giving the attacker access to all accounts on all systems that have <code>login</code> compiled
by their modified compiler.</p>

<p>However, this change would be detected in the source. If it was not included in the source, this
change would disappear in the next release of the compiler, or when someone else compiles the
compiler from source. Avoiding this attack is easily done by compiling your own compilers and not
downloading untrusted binaries. This is good advice in general regarding untrusted binaries, and it
equally applies here.</p>

<p>To counter this, the attacker can go one step further. If they can tweak the compiler so as to
backdoor <code>login</code>, they could also tweak the compiler so as to backdoor itself. The attacker needs to
modify the compiler with a backdoor which detects when it is compiling the same compiler, and
introduces <em>itself</em> into the compiler that it is compiling. On top of this it can also introduce
backdoors into <code>login</code> or whatever other program the attacker is interested in.</p>

<p>Now, in this case, even if the backdoor is removed from the source, <em>every compiler compiled using
this backdoored compiler will be similarly backdoored</em>. So if this backdoored compiler somehow
starts getting distributed, it will spread itself as it is used to compile more copies of itself
(e.g. newer versions, etc). And it will be virtually undetectable — since the source doesn’t
need to be modified for it to work; just the non-human-readable binary.</p>

<p>Of course, there are ways to protect against this. Ultimately, before a compiler for language X
existed, that compiler had to be written in some other language Y. If you can track the sources back
to that point you can bootstrap a working compiler from scratch and keep compiling newer compiler
versions till you reach the present. This raises the question of whether or not Y’s compiler is
backdoored. While it sounds pretty unlikely that such a backdoor could be so robust as to work on
two different compilers and stay put throughout the history of X, you can of course trace back Y
back to other languages and so on till you find a compiler in assembly that you can verify<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">1</a></sup>.</p>

<h2 id="backdooring-rust">Backdooring Rust</h2>

<p>Alright, so I want to backdoor my compiler. I first have to decide when in the pipeline the code
that insert backdoors executes. The Rust compiler operates by taking source code, parsing it into a
syntax tree (AST), transforming it into some intermediate representations (HIR and MIR), and feeding
it to LLVM in the form of LLVM IR, after which LLVM does its thing and creates binaries. A backdoor
can be inserted at any point in this stage. To me, it seems like it’s easier to insert one into the
AST, because it’s easier to obtain AST from source, and this is important as we’ll see soon. It also
makes this attack less practically viable<sup id="fnref:5" role="doc-noteref"><a href="#fn:5" class="footnote">2</a></sup>, which is nice since this is just a fun exercise and I
don’t actually want to backdoor the compiler.</p>

<p>So the moment the compiler finishes parsing, my code will modify the AST to insert a backdoor.</p>

<p>First, I’ll try to write a simpler backdoor; one which doesn’t affect the compiler but instead
affects some programs. I shall write a backdoor that replaces occurrences of the string “hello world”
with “जगाला नमस्कार”, a rough translation of the same in my native language.</p>

<p>Now, in rustc, the <code>rustc_driver</code> crate is where the whole process of compiling is coordinated. In particular,
<a href="https://github.com/rust-lang/rust/blob/1cabe2151299c63497abc3a20bd08c04c0cd32a3/src/librustc_driver/driver.rs#L546"><code>phase_2_configure_and_expand</code></a> is run right after parsing (which is <a href="https://github.com/rust-lang/rust/blob/1cabe2151299c63497abc3a20bd08c04c0cd32a3/src/librustc_driver/driver.rs#L485">phase 1</a>). Perfect.
Within that function, the <code>krate</code> variable contains the parsed AST for the crate<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote">3</a></sup>, and we need to modify that.</p>

<p>In this case, there’s already machinery in <a href="http://manishearth.github.io/rust-internals-docs/syntax/fold/"><code>syntax::fold</code></a> for mutating ASTs based on patterns. A
<a href="http://manishearth.github.io/rust-internals-docs/syntax/fold/trait.Folder.html"><code>Folder</code></a> basically has the ability to walk the AST, producing a mirror AST, with modifications. For
each kind of node, you get to specify a function which will produce a node to be used in its place.
Most such functions will default to no-op (returning the same node).</p>

<p>So I write the following <code>Folder</code>:</p>

<pre><code class="language-rust">// Understanding the minute details of this code isn't important; it is a bit complex
// since the API used here isn't meant to be used this way. Focus on the comments.

mod trust {
    use syntax::fold::*;
    use syntax::ast::*;
    use syntax::parse::token::InternedString;
    use syntax::ptr::P;
    struct TrustFolder;

    // The trait contains default impls which we override for specific cases
    impl Folder for TrustFolder {
        // every time we come across an expression, run this function
        // on it and replace it with the produced expression in the tree
        fn fold_expr(&amp;mut self, expr: P&lt;Expr&gt;) -&gt; P&lt;Expr&gt; {
            // The peculiar `.map` pattern needs to be used here
            // because of the way AST nodes are stored in immutable
            // `P&lt;T&gt;` pointers. The AST is not typically mutated.
            expr.map(|mut expr| {
                match expr.node {
                    ExprKind::Lit(ref mut l) =&gt; {
                        *l = l.clone().map(|mut l| {
                            // look for string literals
                            if let LitKind::Str(ref mut s, _) = l.node {
                                // replace their contents
                                if s == "hello world" {
                                    *s = InternedString::new("जगाला नमस्कार");
                                }
                            }
                            l
                        })
                    }
                    _ =&gt; ()
                }
                // recurse down expression with the default fold
                noop_fold_expr(expr, self)
            })
        }
        fn fold_mac(&amp;mut self, mac: Mac) -&gt; Mac {
            // Folders are not typically supposed to operate on pre-macro-expansion ASTs
            // and will by default panic here. We must explicitly specify otherwise.
            noop_fold_mac(mac, self)
        }
    }

    // our entry point
    pub fn fold_crate(krate: Crate) -&gt; Crate {
        // make a folder, fold the crate with it
        TrustFolder.fold_crate(krate)
    }
}
</code></pre>

<p>I invoke it by calling <code>let krate = trust::fold_crate(krate);</code> as the first line of <code>phase_2_configure_and_expand</code>.</p>

<p>I create a stage 1 build<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote">4</a></sup> of rustc (<code>make rustc-stage1</code>). I’ve already set up <code>rustup</code> to have a “stage1” toolchain
pointing to this folder (<code>rustup toolchain link stage1 /path/to/rust/target_triple/stage1</code>), so I can easily test this new compiler:</p>

<pre><code class="language-rust">// test.rs
fn main() {
    let x = "hello world";
    println!("{}", x);
}
</code></pre>

<pre><code class="language-sh">$ rustup run stage1 rustc test.rs
$ ./test
जगाला नमस्कार
</code></pre>

<p>Note that I had the string on a separate line instead of directly doing <code>println!("hello world")</code>.
This is because our backdoor isn’t perfect; it applies to the <em>pre-expansion</em> AST. In this AST,
<code>println!</code> is stored as a macro and the <code>"hello world"</code> is part of the macro token tree; and has not
yet been turned into an expression. Our folder ignores it. It is not too hard to perform this same attack
post-expansion, however.</p>

<p>So far, so good. We have a compiler that tweaks “hello world” strings. Now, let’s see if we can get
it to miscompile itself. This means that our compiler, when compiling a pristine Rust source tree,
should produce a compiler that is similarly backdoored (with the <code>trust</code> module and the
<code>trust::fold_crate()</code> call).</p>

<p>We need to tweak our folder so that it does two things:</p>

<ul>
  <li>Inserts the <code>let krate = trust::fold_crate(krate);</code> statement in the appropriate function (<code>phase_2_configure_and_expand</code>) when compiling a pristine Rust source tree</li>
  <li>Inserts the <code>trust</code> module</li>
</ul>

<p>The former is relatively easy. We need to construct an AST for that statement (can be done by
invoking the parser again and extracting the node). The latter is where it gets tricky. We can
encode instructions for outputting the AST of the <code>trust</code> module, but these instructions themselves
are within the same module, so the instructions for outputting <em>these</em> instructions need to be
included, and so on. This clearly isn’t viable.</p>

<p>However, there’s a way around this. It’s a common trick used in writing <a href="https://en.wikipedia.org/wiki/Quine_(computing)">quines</a>, which face similar
issues. The idea is to put the entire block of code in a string. We then construct the code for the
module by doing something like</p>

<pre><code class="language-rust">mod trust {
    static SELF_STRING: &amp;'static str = "/* stringified contents of this module except for this line */";
    // ..
    fn fold_mod(..) {
        // ..
        // this produces a string that is the same as the code for the module containing it
        // SELF_STRING is used twice, once to produce the string literal for SELF_STRING, and
        // once to produce the code for the module
        let code_for_module = "mod trust { static SELF_STRING: &amp;'static str = \"" + SELF_STRING + "\";" + SELF_STRING + "}";
        insert_into_crate(code_for_module);
        // ..
    }
    // ..
}
</code></pre>

<p>With the code of the module entered in, this will look something like</p>

<pre><code class="language-rust">mod trust {
    static SELF_STRING: &amp;'static str = "
        // .. 
        fn fold_mod(..) {
            // ..
            // this produces a string that is the same as the code for the module containing it
            // SELF_STRING is used twice, once to produce the string literal for SELF_STRING, and
            // once to produce the code for the module
            let code_for_module = \"mod trust { static SELF_STRING: &amp;'static str = \\\"\" + SELF_STRING + \"\\\";\" + SELF_STRING + \"}\";
            insert_into_crate(code_for_module);
            // ..
        }
        // ..
    ";

    // ..
    fn fold_mod(..) {
        // ..
        // this produces a string that is the same as the code for the module containing it
        // SELF_STRING is used twice, once to produce the string literal for SELF_STRING, and
        // once to produce the code for the module
        let code_for_module = "mod trust { static SELF_STRING: &amp;'static str = \"" + SELF_STRING + "\";" + SELF_STRING + "}";
        insert_into_crate(code_for_module);
        // ..
    }
    // ..
}
</code></pre>

<p>So you have a string containing the contents of the module, except for itself. You build the code
for the module by using the string twice – once to construct the code for the declaration of the
string, and once to construct the code for the rest of the module. Now, by parsing this, you’ll get
the original AST!</p>

<p>Let’s try this step by step. Let’s first see if injecting an arbitrary string (<code>use foo::bar::blah</code>)
works, without worrying about this cyclical quineyness:</p>

<pre><code class="language-rust">mod trust {
    // dummy string just to see if it gets injected
    // inserting the full code of this module has some practical concerns
    // about escaping which I'll address later
    static SELF_STRING: &amp;'static str = "use foo::bar::blah;";
    use syntax::fold::*;
    use syntax::ast::*;
    use syntax::parse::parse_crate_from_source_str;
    use syntax::parse::token::InternedString;
    use syntax::ptr::P;
    use syntax::util::move_map::MoveMap;
    use rustc::session::Session;

    struct TrustFolder&lt;'a&gt; {
        // we need the session to be able to parse things. No biggie.
        sess: &amp;'a Session,
    }

    impl&lt;'a&gt; Folder for TrustFolder&lt;'a&gt; {
        fn fold_expr(&amp;mut self, expr: P&lt;Expr&gt;) -&gt; P&lt;Expr&gt; {
            expr.map(|mut expr| {
                match expr.node {
                    ExprKind::Lit(ref mut l) =&gt; {
                        *l = l.clone().map(|mut l| {
                            if let LitKind::Str(ref mut s, _) = l.node {
                                if s == "hello world" {
                                    *s = InternedString::new("जगाला नमस्कार");
                                }
                            }
                            l
                        })
                    }
                    _ =&gt; ()
                }
                noop_fold_expr(expr, self)
            })
        }
        fn fold_mod(&amp;mut self, m: Mod) -&gt; Mod {
            // move_flat_map takes a vector, constructs a new one by operating
            // on each element by-move. Again, needed because of `P&lt;T&gt;`
            let new_items = m.items.move_flat_map(|item| {
                // we want to modify this function, and give it a sibling from SELF_STRING
                if item.ident.name.as_str() == "phase_2_configure_and_expand" {
                    // parse SELF_STRING
                    let new_crate = parse_crate_from_source_str("trust".into(),
                                                                SELF_STRING.into(),
                                                                &amp;self.sess.parse_sess).unwrap();
                    // extract the first item contained in it, which is the use statement
                    let inner_item = new_crate.module.items[0].clone();

                    // move_flat_map needs an iterator of items to insert
                    vec![inner_item, item].into_iter()
                } else {
                    vec![item].into_iter()
                }
            });
            let m = Mod {
                inner: m.inner,
                items: new_items,
            };
            noop_fold_mod(m, self)
        }
        fn fold_mac(&amp;mut self, _mac: Mac) -&gt; Mac {
            noop_fold_mac(_mac, self)
        }
    }

    pub fn fold_crate(krate: Crate, sess: &amp;Session) -&gt; Crate {
        let mut folder = TrustFolder {sess: sess};
        folder.fold_crate(krate)
    }
}
</code></pre>

<p>We also change the original call in <code>phase_2_configure_and_expand</code> to <code>let krate = trust::fold_crate(krate, sess);</code></p>

<p>Compiling with <code>make rustc-stage2</code> (we now want the backdoored stage1 compiler to try and compile
the same sources and fudge the <code>phase_2_configure_and_expand</code> function the second time around), gets us this error:</p>

<pre><code>rustc: x86_64-apple-darwin/stage1/lib/rustlib/x86_64-apple-darwin/lib/librustc_driver
error[E0432]: unresolved import `foo::bar::blah`
 --&gt; trust:1:5
  |
1 | use foo::bar::blah;
  |     ^^^^^^^^^^^^^^ Maybe a missing `extern crate foo;`?

error: aborting due to previous error
</code></pre>

<p>This is exactly what we expected! We inserted the code <code>use foo::bar::blah;</code>, which isn’t going to
resolve, and thus got a failure when compiling the crate the second time around.</p>

<p>Let’s add the code for the quineyness and for inserting the <code>fold_crate</code> call:</p>

<pre><code class="language-rust">fn fold_mod(&amp;mut self, m: Mod) -&gt; Mod {
    let new_items = m.items.move_flat_map(|item| {
        // look for the phase_2_configure_and_expand function
        if item.ident.name.as_str() == "phase_2_configure_and_expand" {
            // construct the code for the module contents as described earlier
            let code_for_module = r###"mod trust { static SELF_STRING: &amp;'static str = r##"###.to_string() + r###"##""### + SELF_STRING + r###""##"### + r###"##;"### + SELF_STRING + "}";
            // Parse it into an AST by creating a crate only containing that code
            let new_crate = parse_crate_from_source_str("trust".into(),
                                                        code_for_module,
                                                        &amp;self.sess.parse_sess).unwrap();
            // extract the AST of the contained module
            let inner_mod = new_crate.module.items[0].clone();

            // now to insert the fold_crate() call
            let item = item.map(|mut i| {
                if let ItemKind::Fn(.., ref mut block) = i.node {
                    *block = block.clone().map(|mut b| {
                        // create a temporary crate just containing a fold_crate call
                        let new_crate = parse_crate_from_source_str("trust".into(),
                                                                    "fn trust() {let krate = trust::fold_crate(krate, sess);}".into(),
                                                                    &amp;self.sess.parse_sess).unwrap();
                        // extract the AST from the parsed temporary crate, shove it in here
                        if let ItemKind::Fn(.., ref blk) = new_crate.module.items[0].node {
                            b.stmts.insert(0, blk.stmts[0].clone());
                        }
                        b
                    });
                }
                i
            });
            // yield both the created module and the modified function to move_flat_map
            vec![inner_mod, item].into_iter()
        } else {
            vec![item].into_iter()
        }
    });
    let m = Mod {
        inner: m.inner,
        items: new_items,
    };
    noop_fold_mod(m, self)
}
</code></pre>

<p>The <code>#</code>s let us specify “raw strings” in Rust, where I can freely include other quotation marks
without needing to escape things. For a string starting with <code>n</code> pound symbols, we can have raw
strings with up to <code>n - 1</code> pound symbols inside it. The <code>SELF_STRING</code> is declared with four pound
symbols, and the code in the trust module only uses raw strings with three pound symbols. Since the
code needs to generate the declaration of <code>SELF_STRING</code> (with four pound symbols), we manually
concatenate extra pound symbols on – a 4-pound-symbol raw string will not be valid within a three-
pound-symbol raw string since the parser will try to end the string early. So we don’t ever directly
type a sequence of four consecutive pound symbols in the code, and instead construct it by
concatenating two pairs of pound symbols.</p>

<p>Ultimately, the <code>code_for_module</code> declaration really does the same as:</p>

<pre><code class="language-rust">let code_for_module = "mod trust { static SELF_STRING: &amp;'static str = \"" + SELF_STRING + "\";" + SELF_STRING + "}";
</code></pre>

<p>conceptually, but also ensures that things stay escaped. I could get similar results by calling into
a function that takes a string and inserts literal backslashes at the appropriate points.</p>

<p>To update <code>SELF_STRING</code>, we just need to include all the code inside the <code>trust</code> module after the
declaration of <code>SELF_STRING</code> itself inside the string. I won’t include this inline since it’s big,
but <a href="https://github.com/Manishearth/rust/blob/rusting-trust/src/librustc_driver/driver.rs#L541">this is what it looks like in the end</a>.</p>

<p>If we try compiling this code to stage 2 after updating <code>SELF_STRING</code>, we will get errors about
duplicate <code>trust</code> modules, which makes sense because we’re actually already compiling an already-
backdoored version of the Rust source code. While we could set up two Rust builds, the easiest way
to verify if our attack is working is to just use <code>#[cfg(stage0)]</code> on the trust module and the
<code>fold_crate</code> call<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" class="footnote">5</a></sup>. These will only get included during “stage 0” (when it compiles the stage 1
compiler<sup id="fnref:7" role="doc-noteref"><a href="#fn:7" class="footnote">6</a></sup>), and not when it compiles the stage 2 compiler, so if the stage 2 compiler still
backdoors executables, we’re done.</p>

<p>On building the stage 2 (<code>make rustc-stage2</code>) compiler,</p>

<pre><code class="language-sh">$ rustup run stage2 rustc test.rs
$ ./test
जगाला नमस्कार
</code></pre>

<p>I was also able to make it work with a separate clone of Rust:</p>

<pre><code class="language-sh">$ cd /path/to/new/clone
# Tell rustup to use our backdoored stage1 compiler whenever rustc is invoked
# from anywhere inside this folder.
$ rustup override set stage1 # Works with stage 2 as well.

# with --enable-local-rust, instead of the downloaded stage 0 compiler compiling
# stage 0 internal libraries (like libsyntax), the libraries from the local Rust get used. Hence we
# need to check out a git commit close to our changes. This commit is the parent of our changes,
# and is bound to work
$ git checkout bfa709a38a8c607e1c13ee5635fbfd1940eb18b1

# This will make it call `rustc` instead of downloading its own compiler.
# We already overrode rustc to be our backdoored compiler for this folder
# using rustup
$ ./configure --enable-local-rust
# build it!
$ make rustc-stage1
# Tell rustup about the new toolchain
$ rustup toolchain link other-stage1 /path/to/new/clone/target_dir/stage1
$ rustup run other-stage1 rustc test.rs
$ ./test
जगाला नमस्कार
</code></pre>

<p>Thus, a pristine copy of the rustc source has built a compiler infected with the backdoor.</p>

<hr />

<p>So we now have a working trusting trust attack in Rust. What can we do with it? Hopefully nothing!
This particular attack isn’t very robust, and while that can be improved upon, building a practical
and resilient trusting trust attack that won’t get noticed is a bit trickier.</p>

<p>We in the Rust community should be working on ways to prevent such attacks from being successful, though.</p>

<p>A couple of things we could do are:</p>

<ul>
  <li>Work on an alternate Rust compiler (in Rust or otherwise). For a pair of self-hosted compilers, there’s a technique called <a href="http://www.acsa-admin.org/countering-trusting-trust-through-diverse-double-compiling/">“Diverse Double-Compiling”</a> wherein you choose an arbitrary sequence of compilers (something like “<code>gcc</code> followed by 3x <code>clang</code> followed by <code>gcc</code>” followed by <code>clang</code>), and compile each compiler with the output of the previous one. Difficulty of writing a backdoor that can survive this process grows exponentially.</li>
  <li>Try compiling rustc from its ocaml roots, and package up the process into a shell script so that you have reproducible trustworthy rustc builds.</li>
  <li>Make rustc builds deterministic, which means that a known-trustworthy rustc build can be compared against a suspect one to figure out if it has been tampered with.</li>
</ul>

<p>Overall trusting trust attacks aren’t that pressing a concern since there are many other ways to get
approximately equivalent access with the same threat model. Having the ability to insert any
backdoor into distributed binaries is bad enough, and should be protected against regardless of
whether or not the backdoor is a self-propagating one. If someone had access to the distribution or
build servers, for example, they could as easily insert a backdoor into the <em>server</em>, or place a key
so that they can reupload tampered binaries when they want. Now, cleaning up after these attacks is
easier than trusting trust, but ultimately this is like comparing being at the epicenter of Little
Boy or the Tsar Bomba – one is worse, but you’re atomized regardless, and your mitigation plan
shouldn’t need to change.</p>

<p>But it’s certainly an interesting attack, and should be something we should at least be thinking
about.</p>

<p><em>Thanks to Josh Matthews, Nika Layzell, Diane Hosfelt, Eevee, and Yehuda Katz for reviewing drafts of this post.</em></p>

<p><small>Discuss: <a href="https://news.ycombinator.com/item?id=13091941">HN</a>, <a href="https://www.reddit.com/r/rust/comments/5g5hib/reflections_on_rusting_trust/">Reddit</a></small></p>
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>Of course, <em>this</em> raises the question of whether or not your assembler/OS/loader/processor is backdoored. Ultimately, you have to trust <em>someone</em>, which was partly the point of Thompson’s talk. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:5" role="doc-endnote">
      <p>The AST turns up in the metadata/debuginfo/error messages, can be inspected from the command line, and in general is very far upstream and affects a number of things (all the other stages in the pipeline). You could write code to strip it out from these during inspection and only have it turn up in the binary, but that is much harder. <a href="#fnref:5" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>The local variable is called <code>krate</code> because <code>crate</code> is a keyword <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>Stage 1 takes the downloaded (older) rust compiler and compiles the sources from it. The stage 2 compiler is build when the stage 1 compiler (which is a “new” compiler) is used to compile the sources again. <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:4" role="doc-endnote">
      <p>Using it on the <code>fold_crate</code> call requires enabling the “attributes on statements” feature, but that’s no big deal – we’re only using the cfgs to be able to test easily; this feature won’t actually be required if we use our stage1 compiler to compile a clean clone of the sources. <a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:7" role="doc-endnote">
      <p>The numbering of the stages is a bit confusing. During “stage 0” (<code>cfg(stage0)</code>), the stage 1 compiler is <em>built</em>. Since you are building the stage 1 compiler, the make invocation is <code>make rustc-stage1</code>. Similarly, during stage 1, the stage 2 compiler is built, and the invocation is <code>make rustc-stage2</code> but you use <code>#[cfg(stage1)]</code> in the code. <a href="#fnref:7" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/posts/4">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/posts/2">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
<h1> About Me </h1>
<div id="about">
    I'm a self-taught programmer with interests in programming languages, online communities, human languages, Rust, and physics, to name a few. <br><br>

    I'm currently on the Rust core team, and I work at Google on <a href="https://github.com/unicode-org/icu4x">ICU4X</a>.
</div>
<div id="doodads">
 <a href="http://twitter.com/Manishearth" style="white-space:normal">   <img style="border:none;box-shadow:none" src="/images/twitter.png" width="30px"></a>
 <a href="http://github.com/Manishearth" style="white-space:normal">   <img style="border:none;box-shadow:none"  src="/images/github.png" width="30px"></a>
</div>
</section>
<section>
<!-- <iframe scrolling="no" style="border: 0; height: 58px; width: 208px; overflow: hidden;" src="https://se-flair.appspot.com/751483b5-3bd0-467a-b3aa-f0bb8ac3887d/"></iframe> -->
</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2019/10/09/on-voting-systems/">On Voting Systems</a>
      </li>
    
      <li class="post">
        <a href="/blog/2019/02/04/rust-governance-scaling-empathy/">Rust Governance: Scaling Empathy</a>
      </li>
    
      <li class="post">
        <a href="/blog/2018/09/11/converting-a-webgl-application-to-webvr/">Converting a WebGL Application to WebVR</a>
      </li>
    
      <li class="post">
        <a href="/blog/2018/08/26/why-i-enjoy-blogging/">Why I Enjoy Blogging</a>
      </li>
    
      <li class="post">
        <a href="/blog/2018/06/05/the-future-of-clippy-the-rust-linter/">The Future of Clippy</a>
      </li>
    
  </ul>
</section>

  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2021 - Manish Goregaokar - Licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/">CC BY SA 4.0</a> - 
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
