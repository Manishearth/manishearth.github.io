<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[In Pursuit of Laziness]]></title>
  <link href="http://manishearth.github.io/atom.xml" rel="self"/>
  <link href="http://manishearth.github.io/"/>
  <updated>2021-02-16T06:42:45+00:00</updated>
  <id>http://manishearth.github.io/</id>
  <author>
    <name><![CDATA[Manish Goregaokar]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[On Voting Systems]]></title>
    <link href="http://manishearth.github.io/blog/2019/10/09/on-voting-systems/"/>
    <updated>2019-10-09T00:00:00+00:00</updated>
    <id>http://manishearth.github.io/blog/2019/10/09/on-voting-systems</id>
    <content type="html"><![CDATA[<p>Election season is starting up again, and as with many other topics I’m seeing a lot of overconfident takes from people in tech wanting to “solve” how voting works with naïve techy solutions. Hell, <a href="https://cointelegraph.com/news/andrew-yang-wants-to-make-us-elections-fraud-proof-using-blockchain">even a presidential candidate seems to have proposed an extremely uninformed plan for “fixing” voting using blockchain technology</a>.</p>

<p>Last year I wrote <a href="https://twitter.com/ManishEarth/status/1056255900095340545">a thread on Twitter</a> covering some of the essential properties good voting systems uphold as well as how they prevent fraud. It was through the lens of Alameda County’s voting system, where I’ve volunteered as a poll worker in the past (and intend to do again). I’ve been meaning to write down the contents of that thread in blog form for a while, and now seemed like a good opportunity to do it.</p>

<p>I’ll be explaining more about most of these properties later, but ideally, a good voting system should uphold:</p>

<ul>
  <li>Secret ballot: Nobody, not even you, can verify who you voted for after you’re out of the polling place, to prevent vote-buying and coercion.</li>
  <li>Auditable paper trail: We should be able to audit the election. Paper trails are usually the most robust way to enable effective audits.</li>
  <li>Obviousness: It should be relatively obvious what individuals should be doing when they need to mark their ballots. A system that you can easily “mess up” with is a bad system.</li>
  <li>Accessibility: It should not exclude individuals with disabilities from being able to vote.</li>
</ul>

<h2 id="how-voting-works-in-alameda-county">How voting works in Alameda County</h2>

<p>I’ll first go over how voting in my county works. The system isn’t perfect, but it’s pretty good, and it’s a good springboard for understanding how voting systems in general can work. There’s a <a href="https://www.acvote.org/acvote-assets/04_resources/PDFs/pwmanuals/06042019/Guide-FINAL-june.pdf">poll worker guide</a> you can refer to if you’re really interested in all the specifics.</p>

<p>Broadly speaking, there are four ways to vote:</p>

<ul>
  <li>By mail</li>
  <li>In person at certain government offices, before election day (“early voting”)</li>
  <li>In person on election day at a polling place</li>
  <li>Provisionally, in person on election day at a polling place</li>
</ul>

<p>Voting by mail is pretty straightforward: When you register you can choose to vote by mail (or you can choose to do so online after the fact). You get a ballot in the mail, along with a special envelope. You fill in the ballot at your leisure, stick it in the envelope, write your name/address on the envelope, sign it, and mail it back. There are also convenient ballot dropboxes all over the place in case you’re a millenial like me and don’t want to figure out how to buy stamps<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">1</a></sup>.</p>

<p>If you’re voting by mail you can also show up at any polling place on the day of the election and drop off your ballots in a sealed bin. At the polling place I helped run roughly half of the people coming in were just there to drop off their vote by mail ballots!</p>

<p>Voting by mail is by far the easiest option here. Sadly not all counties support it<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote">2</a></sup>. In some states <a href="https://en.wikipedia.org/wiki/Vote-by-mail_in_Oregon">this is even the <em>default</em> option</a>.</p>

<p>As I understand it, voting in person at designated government offices<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote">3</a></sup> is pretty much the same as voting in person at a polling place, it’s just run by government employees instead of volunteers and open for a few weeks before election day.</p>

<figure class="caption-wrapper center" style="width: 400px"><img class="caption" src="http://manishearth.github.io/images/post/polls/bling.jpeg" width="400" /><figcaption class="caption-text"><p>Poll workers are given some neat bling to wear</p>
</figcaption></figure>

<h3 id="in-person-voting">In person voting</h3>

<p>If you’ve chosen to vote in person, you are supposed to turn up at your assigned polling place (you get your assignment in the mail along with other voter info booklets).</p>

<p>There’s a copy of the list of people assigned to the polling place posted outside, and another with the poll workers inside. When you tell your name to the poll workers, they cross your name off the list, and you have to sign your name next to it<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" class="footnote">4</a></sup>.</p>

<ul>
  <li>If your name isn’t on the list, the poll workers will try and find your assigned precinct and inform you that you can go there instead, but you can still choose to vote provisionally at the existing precinct.</li>
  <li>If your name isn’t on the list of all voters (perhaps you registered very late, or were unable to register), you can also vote provisionally.</li>
  <li>If your name is on the list but marked as voting-by-mail (and you want to vote in person), you can vote normally only if you surrender your mail ballot (which poll workers will mark as spoiled and put in a separate pouch).</li>
  <li>If you lost/didn’t receive your ballot, you can always vote provisionally.</li>
</ul>

<p>When you are voting normally, signing your name on the list fraudulently is illegal.</p>

<p>If it is your first time voting, you need to show some form of ID, but it doesn’t need to be photo ID and <a href="https://en.wikipedia.org/wiki/Help_America_Vote_Act#Voter_identification">even a utility bill is fine</a>.</p>

<p>Once you’re done signing, you’ll be given your ballot cards and a privacy sleeve folder so you can carry your filled ballots around. Because this is California and there are tons of local and state measures, we had 4 (!!) ballot cards, six sides to fill in<sup id="fnref:5" role="doc-noteref"><a href="#fn:5" class="footnote">5</a></sup>. Usually a poll worker will also detach the ballot stubs in front of you and hand them to you to keep. You can use these to check the status (but not the contents!) of your ballot online.</p>

<p>You take your cards to a voting booth, fill them in, and come back. A poll worker will then help you feed your ballot cards into a scanner machine. This machine will reject cards with any problems — which you can fix, rerequesting new ballot cards if necessary, but you then have to spoil and return the old ballot card.</p>

<p>The machine keeps an externally-visible tally of the number of ballots submitted, and an internal tally of all the votes made, ignoring write-ins. It also internally stores ballot cards in one of two bins (depending on write-ins). These bins are verified to be empty when polls open, and are inaccessible till polls close.</p>

<p>It’s important to note that the scanner is not a load-bearing component of the system: It could be replaced with a locked bin with a slot, and the system would still work. The scanner enables one to get <em>preliminary</em> results for the precinct, and provides a way to double-check results.</p>

<p>And that’s it! You’ll be given an I Voted sticker, and you can go home!</p>

<figure class="caption-wrapper center" style="width: 400px"><img class="caption" src="http://manishearth.github.io/images/post/polls/stickers.png" width="400" /><figcaption class="caption-text"><p>Some “I Voted!” stickers in Spanish</p>
</figcaption></figure>

<h3 id="using-a-voting-machine">Using a voting machine</h3>

<p>In case you think you will have trouble filling out a ballot card in pen (e.g. if your vision is heavily impared), there’s an alternate way to vote that doesn’t involve a pen. Instead, we have a machine which has a touchscreen and an audio unit, which prompts the voter for their selection for each ballot item on the touchscreen or audio unit. When they’re done, the machine will print out a “receipt” listing their choices inside a sealed box with a glass window, so they can verify that their vote was recorded correctly<sup id="fnref:6" role="doc-noteref"><a href="#fn:6" class="footnote">6</a></sup>. Once they’re done the sealed box will scroll the “receipt” out of view so that the next voter can’t see it.</p>

<p>The sealed box is called a <a href="https://en.wikipedia.org/wiki/Voter-verified_paper_audit_trail">Voter-Verified Paper Trail</a> box: the election runners no longer need to trust the machine’s internal memory, they can trust the paper trail inside the box (which, while produced by a potentially-untrustworthy machine, was verified by the voters), and the machine’s internal memory is simply a way to double-check (and get fast preliminary results).</p>

<h3 id="provisional-voting">Provisional voting</h3>

<p>There are many, many situations in which you may not be able to vote normally. Perhaps you showed up at the wrong precinct but don’t have time to go to the right one. Perhaps you were signed up for vote-by-mail but didn’t receive (or lost) your ballot. Perhaps you recently moved into the county and weren’t able to register in time. Perhaps you were a first-time in-person voter and didn’t have some form of ID.</p>

<p>In such a case you can always vote provisionally. The beauty of this system is that it removes most liability from poll workers: we don’t have any reason to turn people away from the polls, all we can do is refuse to let people vote normally (and instead vote provisionally) in the case of any inconsistencies. This is not to say that malicious poll workers <em>can’t</em> turn people away; it’s illegal but it happens. But well-meaning poll workers cannot, by accident, disenfranchise a voter because we are always allowed to give them a provisional ballot, and that’s an easy rule to follow.</p>

<p>With provisional voting, the voters are given the same ballot cards, but they’re also given an envelope with a form on it. This envelope is equivalent to a voter registration form, (re)registering them in their appropriate county/district<sup id="fnref:7" role="doc-noteref"><a href="#fn:7" class="footnote">7</a></sup>. They vote on the ballot cards normally, but instead of submitting the ballots to the scanner, they put them in the envelope, which goes into a sealed bin<sup id="fnref:8" role="doc-noteref"><a href="#fn:8" class="footnote">8</a></sup>. You’re also given a number you can call to check the status of your ballot.</p>

<p>When you vote provisionally, the registrar of voters will manually process your envelope, remaking your ballot on the right set of cards if necessary, and feeding them into a scanner machine.</p>

<h3 id="integrity-checks">Integrity checks</h3>

<p>Underlying this system is a bevy of integrity checks. There’s an intricate seal system, with numbered seals of varying colors. Some are to be added and never removed, some are to be removed after checking the number, some are never supposed to be touched, some are added at the beginning of the day and removed at the end of the day.</p>

<p>For example, during setup we check that the bins in the scanner are empty, and seal it with a numbered seal. This number is noted down on a form, along with some numbers from the scanner/touchscreen display. The first person to vote is asked to verify all this, and signs the form along with the poll workers.</p>

<p>Election officials drop in multiple times during the day, and may check these numbers. At the end of the day, the numbers of all seals used, and any physical seals that were removed are sent back along with all the ballots.</p>

<p>Various ballot counts are also kept track of. We keep track of the number of provisional ballots, the number of submitted regular ballots (also kept track by the scanner), the number of ballot cards used, and the number of unused ballots left over. Everything needs to match up at the end of the day, and all unused ballots are sent back. These counts are also noted down.</p>

<p>Poll watchers are allowed to be around for most of this, though I think they’re not allowed to <em>touch</em> anything. I think poll watchers are also allowed to be around when the actual ballots are being counted by election officials.</p>

<h3 id="immediate-local-results">Immediate local results</h3>

<p>As mentioned before, the scanner isn’t a crucial part of the system, but if it happens to be working it can be used to get immediate local results. At the end of the day, the scanner prints out a bunch of stuff, including vote totals for races which got more than N votes (N=20, IIRC), so you get immediate results for your precinct. This printout is supposed to be taped to the polling place doors for everyone to see, and presumably the registrar of voters uses the copy submitted to them to publish quick preliminary results.</p>

<p>Using paper ballots doesn’t mean that we have to give up all the benefits of computers doing some of the work for us! We can still use computers to get fast results, without relying on them for the integrity of the system.</p>

<figure class="caption-wrapper center" style="width: 400px"><img class="caption" src="http://manishearth.github.io/images/post/polls/totals.jpeg" width="400" /><figcaption class="caption-text"><p>Vote totals posted outside. Our ballots are big and have lots of races on them; so the list of vote totals is absolutely ginormous.</p>
</figcaption></figure>

<h2 id="properties-of-this-voting-system">Properties of this voting system</h2>

<p>This system has some crucial properties.</p>

<h3 id="secret-ballot">Secret ballot</h3>

<p>It’s well known that nobody is supposed to be able to see who you voted for. But a crucial part of this system is that, once you submit your ballots, <em>you</em> can’t see who you voted for either. Of course, you probably can <em>remember</em>, but you have no <em>proof</em>. On the face of it this sounds like a bad property — wouldn’t it be nicer if people could verify that their vote was counted correctly?</p>

<p>The problem is that if <em>I</em> can verify that my vote was counted correctly, someone else can coerce me into doing this in front of them to ensure I voted a certain way. Any system that gives me the ability to verify my vote gives people who have power over me (or just people who want to buy my vote) the same ability.</p>

<p>Provisional voting doesn’t quite have this property, but it’s supposed to be for edge cases. Vote by mail trades off some of this property for convenience; people can now see who you voted for while you’re voting (and the people you live with can fradulently vote on your behalf, too).</p>

<h3 id="conservation-of-ballots-auditable-paper-trail">Conservation of ballots (Auditable paper trail)</h3>

<p>The total number of ballots in the system is roughly conserved and kept track of. If you’re registered to vote by mail, you cannot request a normal ballot without surrendering your vote by mail ballot and envelope (which we mark as spoiled and put in a separate pouch). If you re-request a ballot card because you made a mistake, the old card needs to be similarly spoiled and put away separately. It’s one set of ballot cards per voter, and almost all potential aberrations in this property result in a provisional vote<sup id="fnref:9" role="doc-noteref"><a href="#fn:9" class="footnote">9</a></sup>. Even provisional votes are converted to normal ballot cards in the end.</p>

<p>Eventually, there will be a giant roomful of ballots that cannot be traced back to their individual voters, but it can still be traced back to the <em>entirety</em> of the voters — it’s hard to put a ballot into the system without a corresponding voter. This is perfect — the ballots can be hand-counted, but they can’t be individually corellated with their respective voters.</p>

<p>You don’t even need to recount the entire set of ballots to perform an audit, <a href="https://risklimitingaudits.org/">risk limiting audits</a> are quite effective and much more efficient to carry out.</p>

<h3 id="paper-ballots">Paper ballots</h3>

<p>The fact that they can (and should) be hand counted is itself an important property. Hand counting of ballots can be independently verified in ways that can’t be done for software. Despite not being able to trace a ballot back to its voter, there still is a paper trail of integrity for the ballots as a bulk unit.</p>

<p>This property leads to [software independance]: while we may use software in the process, it’s not possible for a bug in the software to cause an undetectable error in the final vote counts.</p>

<figure class="caption-wrapper center" style="width: 500px"><img class="caption" src="http://manishearth.github.io/images/post/polls/totals-zoom.png" width="500" /><figcaption class="caption-text"><p>Specific vote totals for the top races</p>
</figcaption></figure>

<h3 id="obviousness">Obviousness</h3>

<p>Figuring out what to do in the voting booth isn’t hard. You’re allowed to request assistance, but you’ll rarely have to. There are systems (like the scanner’s error checking) that are designed to ensure you don’t mess up, but the system is quite sound even without them; they just provide an additional buffer.</p>

<p>Compare this with <a href="https://www.texastribune.org/2018/11/01/texas-straight-ticket-voting-problems-old-machines/">the problems some Texas voting machines had last midterm</a>. The machines were somewhat buggy, but, crucially, there was an opaque right and wrong way to use them, and some voters accidentally used it the wrong way, and then didn’t check the final page before submitting. This kind of thing should never happen in a good voting system.</p>

<p>It’s really important that the system is intuitive and hard to make mistakes in.</p>

<h2 id="fraud-prevention">Fraud prevention</h2>

<p>So, how is this robust against fraud?</p>

<p>Firstly, voter fraud isn’t a major problem in the US, and it’s often used as an excuse to propagate voter suppression tactics, which <em>are</em> a major problem here.</p>

<p>But even then, we probably want our system to be robust against fraud.</p>

<p>Let’s see how an individual might thwart this system. They could vote multiple times, under assumed identites. This doesn’t scale well and isn’t really worth it: to influence an election you’d need to do this many times, or have many individuals do it a couple times, and the chance of getting caught (e.g., the people who you are voting as may come by and try to vote later, throwing up a flag) and investigated scales exponentially with the number of votes. That’s not worth it at all.</p>

<p>Maybe poll workers could do something malicious. Poll worker manipulation would largely exist in the form of submitting extra ballots. But that’s hard because the ballot counts need to match the list of voters. So you have the same problem as individual voters committing fraud: if the actual voter shows up, they’ll notice. Poll workers <em>could</em> wait till the end of the day to do this, but then to make any kind of difference you’d have to do a bulk scan of ballots, and that’s very noticeable. Poll workers would have to collude to make anything like this work, and poll watchers (and government staff) may be present.</p>

<p>Poll workers can also <em>discard</em> ballots to influence an election. But you can’t do this in front of the voters, and the receptacles with non-defaced ballots are all sealed so you can’t do this when nobody is watching without having to re-seal (which means you need a new numbered seal, which the election office will notice). The scanner’s inner receptacle is opened at the end of the day but you can’t tamper with that without messing up the various counts.</p>

<p>Election officials have access to giant piles of ballots and could mess with things there, but I suspect poll watchers are present during the ballot sorting and counting process, and again, it’s hard to tamper with anything without messing up the various counts.</p>

<p>Overall, this system is pretty robust. It’s important to note that fraud prevention is achieved by more social means, not technical means: there are seals, counts, and various properties of the system, but no computers involved in any crucial roles.</p>

<h2 id="techy-solutions-for-voting">Techy solutions for voting</h2>

<p>In general, amongst the three properties of “secret ballot”, “obviousness”, and “auditable paper trail”, computer-based voting systems almost always fail at one, and usually fail at two.</p>

<p>A lot of naïve tech solutions for voting are explicitly designed to not have the secret ballot property: they are instead designed specifically to let voters check that what their vote was counted as after the election. As mentioned earlier, this is a problem for vote-buying and coercion.</p>

<p>It’s theoretically possible to have a system where you can ensure your ballot, specifically, was correctly counted after the election, without losing the secret ballot property: <a href="https://en.wikipedia.org/wiki/ThreeBallot">ThreeBallot</a> is a cool example of such a system, though it fails the “obviousness” property.</p>

<p>Most systems end up not having an auditable paper trail since they rely on machines to record votes. This is vulnerable to bugs in the machine: you end up having to trust the output of the machine. Buggy/vulnerable voting machines are so common that every year at DEFCON <a href="https://media.defcon.org/DEF%20CON%2027/voting-village-report-defcon27.pdf">people get together to hack the latest voting machines, and typically succeed</a>.</p>

<p>Voting machines can still produce a paper trail: Voter-Verified Paper Trail systems partially succeed in doing this. They’re not as good with maintaining the “conservation of ballots” property that makes tampering much harder, and they’re not as good on the “obviousness” part since people need to check the VVPAT box for what their vote was recorded as.</p>

<p>Ballot-Marking devices are a bit better at this: These still produce paper ballots, it’s just that the ballot is marked by the machine on your behalf. There’s still a bit of an “obviousness” fail in that people may not double check the marked ballot, but at least there’s a nice paper trail with ballot conservation! Of course, these only work if the produced ballot is easily human-readable.</p>

<p>It’s not <em>impossible</em> to design good voting systems that rely on technology, but it’s hard to maintain the same properties you can with paper ballots. If you want to try, please keep the properties listed above in mind.</p>

<h3 id="blockchain">Blockchain?</h3>

<p>Every now and then people will suggest using blockchains for voting. This is a pretty large design space, but …. most of these proposals are <em>extremely</em> naïve and achieve very little.</p>

<p>For one, most of them are of the category that lose the “secret ballot” property, instead producing some kind of identifier you’re able to check in some published blockchain. This lets you see what your vote was after the election, and as I’ve covered already that’s not a good thing.</p>

<p>Even if this process only lets you verify that your vote was counted (but not what it was), it typically involves some understanding of cryptography to spot-check the validity of the machine output (e.g. you need to verify that some hash is the hash of your actual vote or something). This fails the obviousness property.</p>

<p>Blockchains don’t really bring much to the table here. They’re decent for byzantine fault tolerance in a space without a central authority, but elections <em>do</em> have some form of central authority and we’re not getting rid of that. The anonymity properties of blockchains can usually be achieved without blockchains for things like elections.</p>

<p>There are some kinds of cryptography that can be useful for auditability — zero knowledge proofs and homomorphic encryption come to mind — but you don’t need blockchains to use these, and using these still requires some form of technology as a key part of the voting system and this makes other properties of the system harder to achieve.</p>

<h2 id="become-a-poll-worker">Become a poll worker!</h2>

<p>It’s still a bit early for the next election, but I highly recommend you volunteer to be a poll worker for your county if you can!</p>

<p>It’s really fun, you get to learn about the inner workings of voting systems, and you get to meet a lot of people!</p>

<figure class="caption-wrapper center" style="width: 700px"><img class="caption" src="http://manishearth.github.io/images/post/polls/nancy.jpeg" width="700" /><figcaption class="caption-text">
<p>We had a cool kid come in and <a href="https://twitter.com/ManishEarth/status/1060052694772011008">more or less do this</a> at one point</p>

</figcaption></figure>

<p><em>Thanks to Nika Layzell, Sunjay Varma, Jane Lusby, and Arshia Mufti for providing feedback on drafts of this blog post.</em></p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>Last year they required postage, but I they’ve changed that with <a href="https://www.sos.ca.gov/administration/news-releases-and-advisories/2019/no-stamp-no-problem-all-vote-mail-ballots-now-come-prepaid-postage-return-envelopes/">a law</a> this year. Yay! <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>Ostensibly because of fears of voter fraud, but they’re largely unfounded — in practice this just reduces turnout <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>I think for Alameda county the only such office is the Registrar of Voters in Oakland <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:4" role="doc-endnote">
      <p>The crossing-off and signing lists are different, but this isn’t too important. <a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:5" role="doc-endnote">
      <p>I remember one particularly curmudgeonly voter loudly grumbling about all the propositions as they were voting. One doesn’t “vote” in California, one fills out social studies homework. <a href="#fnref:5" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:6" role="doc-endnote">
      <p>I don’t quite recall how the verifiability works for people using the audio unit, they may be allowed to ask someone else to verify for them? <a href="#fnref:6" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:7" role="doc-endnote">
      <p>If you vote in a different precinct, or worse, a different county, the ballot cards may not contain all the same races, so voting provisionally from the wrong district means that you only get to vote for the races common to both ballot cards. <a href="#fnref:7" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:8" role="doc-endnote">
      <p>It’s imperative that these do not go into the scanner (since that operation cannot be undone), and to prevent this poll workers are instructed to not give provisional voters a secrecy sleeve as the envelope acts as a secrecy sleeve. Whoever is supervising the scanner will only allow people with secrecy sleeves to slip their ballots into the scanner. <a href="#fnref:8" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:9" role="doc-endnote">
      <p>The exception is using the touchscreen machine, where you get to vote without using up a ballot card on voting day. However, tallies for the machine are kept separately, and I think these too are eventually turned into normal ballot cards. <a href="#fnref:9" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Rust Governance: Scaling Empathy]]></title>
    <link href="http://manishearth.github.io/blog/2019/02/04/rust-governance-scaling-empathy/"/>
    <updated>2019-02-04T00:00:00+00:00</updated>
    <id>http://manishearth.github.io/blog/2019/02/04/rust-governance-scaling-empathy</id>
    <content type="html"><![CDATA[<p>There’s been a lot of talk about improving Rust’s governance model lately. As we decompress from last year’s hectic edition work, we’re slowly starting to look at all the bits of <a href="https://twitter.com/ManishEarth/status/1073088515041198080">debt</a> we accumulated, and <a href="https://boats.gitlab.io/blog/post/rust-2019/">organizational debt</a> is high on that list.</p>

<p>I’ve been talking in private with people about a bunch of these things for quite a while now, and I felt it worthwhile to write down as much of my thoughts as I can before the Rust All Hands in Berlin this week.</p>

<p>In the interest of brevity<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">1</a></sup> I’m going to assume the reader is roughly familiar with most of the stuff that’s happened with the Rust community in the past few years. I’m probably going to omit concrete examples of incidents, both to avoid mischaracterizing individual actions (as with most such analyses, I wish to talk in more general terms about trends), and also just because it would take me forever to write this if I were to supply all the layers of context. If you feel something is inaccurate, please let me know.</p>

<p>This blog post is probably going to reach the eyes of non-Rust-community members. You’re welcome to read it, but please accept my apologies in advance if it doesn’t make any sense. This is something that I initially planned to circulate as a private post (writing for a general audience is <em>hard</em>), but I felt this would be more widely useful. However due to time constraints I haven’t had time to edit it to make it acceptable to a wider audience.</p>

<h2 id="the-symptoms">The symptoms</h2>

<p>Before I actually get into it, I’d like to carefully delineate <em>what</em> the problem is that I’m talking about. Or more accurately, the <em>symptoms</em> I am talking about — as I’ll explain soon I feel like these are not the actual problem but symptoms of a more general problem.</p>

<p>Basically, as time has gone by our decisionmaking process has become more and more arduous, both for community members and the teams. Folks have to deal with:</p>

<ul>
  <li>The same arguments getting brought up over and over again</li>
  <li>Accusations of bad faith</li>
  <li>Derailing</li>
  <li>Not feeling heard</li>
  <li>Just getting exhausted by all the stuff that’s going on</li>
</ul>

<p>The RFC process is the primary exhibitor of these symptoms, but semi-official consensus-building threads on https://internals.rust-lang.org have similar problems.</p>

<p>Aaron <a href="http://aturon.github.io/2018/05/25/listening-part-1/">has written some extremely empathetic blog posts</a> about a bunch of these problems, starting with concrete examples and ending with a takeaway of a bunch of values for us to apply as well as thoughts on what our next steps can be. I highly recommend you read them if you haven’t already.</p>

<p>Fundamentally I consider our problems to be social problems, not technical ones. In my opinion, technical solutions like changing the discussion forum format may be necessary but are not sufficient for fixing this.</p>

<h2 id="the-scaling-problem">The scaling problem</h2>

<p>I contend that all of these issues are symptoms of an underlying <em>scaling issue</em>, but also a failure of how our moderation works.</p>

<p>The scaling issue is somewhat straightforward. Such forum discussions are inherently N-to-N discussions. When you leave a comment, you’re leaving a comment for <em>everyone</em> to read and interpret, and this is hard to get right. It’s <em>much</em> easier to have one-on-one discussions because it’s easy to build a shared vocabulary and avoid misunderstandings. Any misunderstandings can often be quickly detected and corrected.</p>

<p>I find that most unpleasant technical arguments stem from an unenumerated mismatch of assumptions, or sometimes what I call a mismatch of axioms (i.e. when there is fundamental conflict between core beliefs). A mismatch of assumptions, if identified, can be resolved, leading to an amicable conclusion. Mismatches of axioms are harder to resolve, however recognizing them can take most of the vitriol out of an argument, because both parties will <em>understand</em> each other, even if they don’t <em>agree</em>. In such situations the end result may leave one or both parties <em>unhappy</em>, but rarely <em>angry</em>. (It’s also not necessary that axiom mismatches leave people unhappy, embracing <a href="http://aturon.github.io/2018/06/02/listening-part-2/#pluralism-and-positive-sums">positive sum thinking</a> helps us come to mutually beneficial conclusions)</p>

<p>All of these mismatches are easy to identify in one-on-one discussions, because it’s easy to switch gears to the meta discussion for a bit.</p>

<p>One-on-one discussions are pleasant. They foster empathy.</p>

<p>N-to-N discussions are <em>not</em>. It’s harder to converge on this shared vocabulary amongst N other people. It’s harder to identify these mismatches, partly because it’s hard to switch into the meta-mode of a discussion at all, but also because there’s a lot going on. It’s harder to build empathy.</p>

<p>As we’ve grown, discussion complexity has grown quadratically, and we’re not really attempting to relinearize them.</p>

<h3 id="hanabi-and-parallel-universes">Hanabi and parallel universes</h3>

<p>I quite enjoy the game of <a href="https://en.wikipedia.org/wiki/Hanabi_(card_game)">Hanabi</a>. It’s a game of information and trust, and I find it extremely fun, especially with the right group.</p>

<p>Hanabi is a cooperative game. You can see everyone’s cards (or tiles) but your own, and information-sharing is severely restricted. The goal is to play the right cards in the right order to collectively win. The gimmick is to share additional information through the side-channel of <em>the choice of move you make</em>.</p>

<p>A very common occurrence in this game is that people start making plans in their mind. You typically have a decent understanding of what information everyone has, and you can use this to make predictions as to what everyone’s moves will be. With this in mind, you can attempt to “set up” situations where the game progresses rapidly in a short period of time. This is somewhat necessary for the game to work, but a common pitfall is for these plans to be <em>extremely</em> elaborate, leading to frustration as the game doesn’t actually play out as planned.</p>

<p>The core issue behind this is forgetting that you actually <em>can’t</em> see the entire game state, since your own cards are hidden. It’s not just <em>you</em> who has plans — everyone does! And each of those plans is incomplete since they’re missing a piece of the picture, just as you are.</p>

<p>In Hanabi it’s very easy to forget that you’re missing a piece of the picture — in competitive card games you mostly can’t see the game state since everyone else’s cards are hidden. But in Hanabi you can see <em>most</em> of the cards and it’s easy to forget that your own four cards are hidden from you.</p>

<p>So what ends up happening is that due to incomplete information, everyone is operating in their own little parallel universe, occasionally getting frustrated when it becomes clear that other players are not operating in the same universe. As long as you recognize the existence of these parallel universes beforehand you’re fine, but if you don’t you will be frustrated.</p>

<p>This is largely true of N-to-N discussions as well. Because most of what’s being said makes sense to an individual in a particular way, it’s very easy for them to forget that other people may not share your assumptions and thus may be on a different page. Every time someone leaves a comment, different people may interpret it differently, “forking” the common understanding of the state of the discussion into multiple parallel universes. Eventually there are enough parallel universes that everyone’s talking past each other.</p>

<p>One thing I often prefer doing in such cases is to have a one on one discussion with people who disagree with me — typically the shared understanding that is the end result of such discussions is super useful and can be brought back to the discussion as something that all participants interpret the same way. I’m not consistent in doing this — in the midst of a heated argument it’s easy to get too wrapped up in the argument to think about getting results and I’ve certainly had my time arguing instead of resolving — but overall whenever I’ve chosen to do this it’s been a useful policy.</p>

<p>This is a good example of how relinearization and communication can help move N-to-N discussions along. Operating in different parallel universes is kind of the <em>point</em> of Hanabi, but it’s not the point of having a technical discussion.</p>

<h2 id="the-moderation-problem">The moderation problem</h2>

<p>In a technical discussion, broadly speaking, I find that there are three kinds of comments disagreeing with you:</p>

<ul>
  <li>Constructive: Comments which disagree with you constructively. We’re glad these exist, disagreement can hurt but is necessary for us to collaboratively reach the best outcomes.</li>
  <li>Disruptive: Comments which may be written in good faith but end up being disruptive. For example, this includes people who don’t read enough of the discussion and end up rehashing the same points. It also includes taking discussions off topic. These kinds of things are problematic but not covered by the code of conduct.</li>
  <li>Abrasive: Comments which are rude/abrasive. These are covered by the code of conduct. The mod team tries to handle these.</li>
</ul>

<p>(For a long time I and <a href="http://twitter.com/aaron_turon/">Aaron</a> had a shared vocabulary of “Type A, B, C” for these, mostly because I’m often unimaginative when it comes to such things, thanks to <a href="https://github.com/mark-simulacrum">Mark</a> for coming up with, better, descriptive titles)</p>

<p>Note that while I’m talking about “disruptive” comments it’s not a judgement on the <em>intent</em> of the participants, but rather a judgement on the harm it has caused.</p>

<p>The second category – disruptive comments – are the thing we’re currently unable to handle well. They snowball pretty badly too — as more and more of these collect, more and more people get frustrated and in turn leave comments that cause further disruption. As the discussion progresses into more and more “parallel universes” it also just becomes <em>easier</em> for a comment to be disruptive.</p>

<p>The Rust moderation team operates mostly passively, we simply don’t have the scale<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote">2</a></sup> to watch for and nip these things in the bud. Active moderation requires a degree of involvement we cannot provide. So while the best response would be to work with participants and resolve issues early as we see them crop up, we typically get pulled in at a point where some participants are already causing harm, and our response has to be more severe. It’s a bit of a catch-22: it’s not exactly our job to deal with this stuff<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote">3</a></sup>, but by the time it <em>becomes</em> our job (or even, by the time we <em>notice</em>), most acceptable actions for us to take are extremely suboptimal. The problem with passive moderation is that it’s largely reactive — it’s harder to proactively nudge the discussion in the right direction when you don’t even <em>notice</em> what’s going on until it’s too late. This is largely okay for dealing with bad-faith actors (the main goal of the mod team); it’s hard to <em>prevent</em> someone from deciding to harass someone else. But for dealing with disruptive buildups, we kind of need something different.</p>

<h2 id="participation-guidelines">Participation guidelines</h2>

<p>Part of the solution here is recognizing that spaces for official discussion are <em>different</em> from community hangout spaces. Our code of conduct attempts to handle abrasive behavior, which can disrupt discussions anywhere, but the comments that can disrupt consensusbuilding official discussions aren’t really covered. Nor are the repercussions of code of conduct violations really <em>appropriate</em> for such disruptive comments anyway.</p>

<p>A proposal I’ve circulated in the past is to have a notion of participation guidelines. Discussions in team spaces (RFCs, pre-RFCs, discord/zulip/IRC channels during team meetings) follow a set of rules set forth by the individual teams. It might be worth having a base set of participation guidelines defined by the core team. Something like the following is a very rough strawman:</p>

<ul>
  <li>Don’t have irrelevant discussions during team meetings on Discord/IRC/Zulip</li>
  <li>Don’t take threads off topic</li>
  <li>Don’t rehash discussions</li>
</ul>

<p>We ask people to read these before participating, but also breaking these rules isn’t considered serious, it just triggers a conversation (and maybe the hiding/deletion of a comment). If someone repeatedly breaks these rules they may be asked to not participate in a given thread anymore. The primary goal here is to empower team members to better deal with disruptive comments by giving them a formalized framework. Having codified rules helps team members confidently deal with such situations without having to worry as much about drawing direct ire from affected community members.</p>

<p>A base participation guidelines document can also be a value statement, not just a set of rules but also set of values. These values can be things like:</p>

<ul>
  <li>“We explicitly value high empathy interactions”</li>
  <li>“How everyone is feeling is everyone’s business”</li>
</ul>

<p>(h/t <a href="http://twitter.com/adam_n_p/">Adam</a> for the articulate wording here)</p>

<p>Having such words written somewhere — both the high level values we expect people to hold, and the individual behaviors we expect people to exhibit (or not exhibit) — is really valuable in and of itself, even if not enforced. The value of such documents is not that everyone reads them before participating — most don’t — but they serve as a good starting point for people interested in learning how to best conduct themselves, as well as an easy place to point people to where they’re having trouble doing so.</p>

<p>On its own, I find that this is a powerful framework but may not achieve the goal of improving the situation. I recently realized that this actually couples really well with a <em>different</em> idea I’ve been talking about for quite a while now, the idea of having facilitators:</p>

<h2 id="facilitators">Facilitators</h2>

<p>A common conflict I see occurring is that in many cases it’s a team’s job to think about and opine on a technical decision, but it’s also the team’s job to shepherd the discussion for that decision. This often works out great, but it also leads to people just feeling unheard. It kinda hurts when someone who has just strongly disagreed with you goes on to summarize the state of the discussion in a way that you feel you’ve been unfairly represented. The natural response to that for most people isn’t to work with that person and try to be properly represented, it’s to just get angry, leading to less empathy over time.</p>

<p>By design, Rust team members are <em>partisan</em>. The teams exist to build well-informed, carefully crafted opinions, and present them to the community. They also exist to make final decisions based on the results of a consensusbuilding discussion, which can involve picking sides. This is fine, there is always going to be some degree of partisanship amongst decisionmakers, or decisions would not get made.</p>

<p>Having team members also facilitate discussions is somewhat at odds with all of this. Furthermore, I feel like they don’t have enough bandwidth to do this well anyway. Some teams do have a concept of “sheriffs”, but this is more of an onramp to full team membership and the role of a sheriff is largely the same as the role of a team member, just without a binding vote.</p>

<p>I feel like it would be useful to have a group of (per-team?) <em>facilitators</em> to help with this. Facilitators are people who are interested in seeing progress happening, and largely don’t have <em>much</em> of an opinion on a given discussion, or are able to set aside this opinion in the interest of moving a discussion forward. They operate largely at the meta level of the discussion. Actions they may take are:</p>

<ul>
  <li>Summarizing the discussion every now and then</li>
  <li>Calling out one sided discussions</li>
  <li>Encouraging one-on-one tangents to be discussed elsewhere (perhaps creating a space for them, like an issue)</li>
  <li>Calling out specific people to do a thing that helps move the discussion forward. For example, something like “hey @Manishearth, I noticed you’ve been vocal in <a href="https://github.com/mystor/slag">arguing that Rust should switch to whitespace-sensitive syntax</a>, could you summarize all the arguments made by people on your side?” would help.</li>
  <li>Reinforcing positive behavior</li>
  <li>Occasionally pinging participants privately to help them improve their comments</li>
  <li>Attempting to identify the root cause of a disagreement, or empowering people to work together to identify this. This one is important but tricky. I’ve often enjoyed doing it — noticing the core axiomatic disagreement at play and spelling it out is a great feeling. But I’ve also found that it’s incredibly hard to do when you’re emotionally involved, and I’ve often needed a nudge from someone else to get there.</li>
</ul>

<p>At a high level, the job of the facilitators is to:</p>

<ul>
  <li>help foster empathy between participants</li>
  <li>help linearize complex discussions</li>
  <li>nudge towards cooperative behavior, away from adversarial behavior. Get people playing not to win, but to win-win.</li>
</ul>

<p>It’s important to note that facilitators don’t make decisions — the team does. In fact, they almost completely avoid making technical points, they instead keep their comments largely at the meta level, perhaps occasionally making factual corrections.</p>

<p>The teams <em>could</em> do most of this themselves<sup id="fnref:5" role="doc-noteref"><a href="#fn:5" class="footnote">4</a></sup>, but as I’ve mentioned before it’s harder for others to not perceive all of your actions as partisan when some of them are. Furthermore, it can come off as patronizing at times.</p>

<p>This is also something the moderation team could do, however it’s <em>much</em> harder to scale the moderation team this way. Given that the moderation team deals with harassment and stuff like that, we need to be careful about how we build it up. On the other hand facilitating discussions is largely a public task, and the stakes aren’t as high: screwups can get noticed, and they don’t cause much harm. As a fundamentally <em>proactive</em> moderation effort, most actions taken will be to nudge things in a positive direction; getting this wrong usually just means that the status quo is maintained, not that harm is caused. Also, from talking to people it seems that while very few people want to be involved in moderating Rust, this notion of <em>facilitating</em> sounds much more fun and rewarding (I’d love to hear from people who would like to help).</p>

<p>And to me, this pairs really well with the idea of participation guidelines: teams can write down how they want discussions to take place on their venues, and facilitators can help ensure this works out. It’s good to look at the participation guidelines less as a set of rules and more as an aspiration for how we conduct ourselves, with the facilitators as a means to achieving that goal.</p>

<p>There are a lot of specifics we can twiddle with this proposal. For example, we can have a per-team group of appointed facilitators (with no overlap with the team), and for a given discussion one facilitator is picked (if they don’t have time or feel like they have strong opinions, try someone else). But there’s also no strong need for there to be such a group, facilitators can be picked as a discussion is starting, too. I don’t expect <em>most</em> discussions to need facilitators, so this is mostly reserved for discussions we expect will get heated, or discussions that have started to get heated. I’m not really going to spend time analysing these specifics; I have opinions but I’d rather have us figure out if we want to do something like this and how before getting into the weeds.</p>

<h2 id="prospective-outcomes">Prospective outcomes</h2>

<p>The real goal here is to bootstrap better empathy within the community. In an ideal world we don’t need facilitators, instead everyone is able to facilitate well. The explicitly non-partisan nature of facilitators is <em>useful</em>, but if everyone was able to operate in this manner it would largely be unnecessary. But as with any organization, being able to horizontally scale specific skills is really tricky without specialization.</p>

<p>I suspect that in the process of building up such a team of facilitators, we will also end up building a set of resources that can help others learn to act the same way, and eventually overall improve how empathetic our community is.</p>

<p>The concept of facilitators directly addresses the moderation problem, but it also handles the scaling problem pretty well! Facilitators are key in re-linearizing the n-to-n discussions, bringing the “parallel universes” together again. This should overall help people (especially team members) who are feeling overwhelmed by all the things that are going on.</p>

<p>This also helps with concerns people have that they’re not getting heard, as facilitators are basically posed as allies on all sides of the argument; people whose primary goal is to <em>help communication happen</em>.</p>

<hr />

<p>Overall what I’ve proposed here isn’t a fully-formed idea; but it’s the seed of one. There are a lot of interesting bits to discuss and build upon. I’m hoping through this post we might push forward some of the discussions about governance — both by providing a strawman idea, as well as by providing a perspective on the problem that I hope is useful.</p>

<p>I’m really interested to hear what people think!</p>

<p><em>Thanks to <a href="http://twitter.com/aaron_turon/">Aaron</a>, <a href="https://twitter.com/ag_dubs">Ashley</a>, <a href="http://twitter.com/adam_n_p/">Adam</a>, <a href="https://twitter.com/cmrx64/">Corey</a>, <a href="http://twitter.com/arshia__">Arshia</a>, <a href="https://twitter.com/mgattozzi">Michael</a>, <a href="https://twitter.com/sunjay03">Sunjay</a>, <a href="http://twitter.com/fitzgen/">Nick</a> and other people I’ve probably forgotten for having been part of these discussions with me over the last few years, helping me refine my thoughts</em></p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>I am way too verbose for “brief” to be an accurate description of anything I write, but might as well <em>try</em>. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>Scaling the moderation team properly is another piece of this puzzle that I’m working on; we’ve made some progress recently. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>I helped draft <a href="https://www.rust-lang.org/policies/code-of-conduct#moderation">our moderation policy</a>, so this is a somewhat a lack of foresight on my part, but as I’ll explain later it’s suboptimal for the mod team to be dealing with this anyway. <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:5" role="doc-endnote">
      <p>In particular, I feel like Aaron has done an <em>excellent</em> and consistent job of facilitating discussions this way in many cases. <a href="#fnref:5" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Converting a WebGL Application to WebVR]]></title>
    <link href="http://manishearth.github.io/blog/2018/09/11/converting-a-webgl-application-to-webvr/"/>
    <updated>2018-09-11T00:00:00+00:00</updated>
    <id>http://manishearth.github.io/blog/2018/09/11/converting-a-webgl-application-to-webvr</id>
    <content type="html"><![CDATA[<p>I wrote a post for Mozilla Hacks on converting WebGL applications to WebVR,
<a href="https://hacks.mozilla.org/2018/09/converting-a-webgl-application-to-webvr/">you can read it there</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Why I Enjoy Blogging]]></title>
    <link href="http://manishearth.github.io/blog/2018/08/26/why-i-enjoy-blogging/"/>
    <updated>2018-08-26T00:00:00+00:00</updated>
    <id>http://manishearth.github.io/blog/2018/08/26/why-i-enjoy-blogging</id>
    <content type="html"><![CDATA[<p><em>See also: <a href="https://myrrlyn.net/blog/misc/to-all-the-posts-ive-blogged-before">Alex’s version of this blog post</a></em></p>

<p>I started this blog three years ago, moving from my <a href="http://inpursuitoflaziness.blogspot.com/">older blog</a>, hoping to written about programming, math, physics, books, and miscellenia. I’ve not quite written about everything I wanted to, but I’ve been very very happy with the experience of blogging. <code>wc</code> says I’ve written almost 75k words, which is mind-boggling to me!</p>

<p>I often get asked by others — usually trying to decide if they should start blogging — what it’s like. I also often try to convince friends to blog by enumerating why I think it’s awesome. Might as well write it down so that it’s generally useful for everyone! 😃</p>

<h2 id="blogging-helps-cement-my-understanding-of-things">Blogging helps cement my understanding of things!</h2>

<p>I’ve often noticed that I’ll start blogging about something I <em>think</em> I understand, and it turns out that my understanding of the subject was somewhat nebulous. Turns out it’s pretty easy to convince ourselves that we understand something.</p>

<p>The act of writing stuff down helps cement my own understanding — words are usually not as nebulous as thoughts so I’m forced to figure out little details.</p>

<p>I recall when I wrote my post on <a href="https://manishearth.github.io/blog/2015/05/30/how-rust-achieves-thread-safety/">how Rust’s thread safety guarantees work</a>, I <em>thought</em> I understood <code>Send</code> and <code>Sync</code> in Rust. I understood what they did, but I didn’t have a clear mental model for them. I obtained this mental model through the process of writing the post; to be able to explain it to others I had to first explain it to myself.</p>

<p>I point out this post in particular because this was both one of the first posts for me where I’d noticed this, and, more importantly, my more concrete mental model led to me <a href="https://github.com/rust-lang/rust/issues/25894">finding a soundness bug in Rust’s standard library</a>. When I was thinking about my mental model I realized “an impl that looks like this should never exist”,
so I grepped the source code and found one<sup id="fnref:11" role="doc-noteref"><a href="#fn:11" class="footnote">1</a></sup>.</p>

<p>I’ve even noticed a difference between one-on-one explaining and explaining things through blog posts. I <em>love</em> explaining things one-on-one, it’s much easier to tailor the explanation to the other person’s background,
as well as what they’re actually asking for help with. Plus, it’s interactive. A <em>lot</em> of my posts are of the “okay I get this question a lot I’m going to write down the answer so I don’t have to repeat myself” kind and I’ve found that I’ve often learned things from these despite having talked about the thing in the article contents multiple times.</p>

<p>I guess it’s basically that blogging is inherently one-many — you’re trying to explain to a whole group of people with varied backgrounds — which means you need to cover all your bases<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote">2</a></sup> and explain everything together instead of the minimum necessary.</p>

<h2 id="its-really-fun-to-revisit-old-posts">It’s really fun to revisit old posts!</h2>

<p>Okay, I’ll admit that I never really write blog posts with this in mind. But when I <em>do</em> reread them, I’m usually quite thankful I wrote them!</p>

<p>I’m a fan of rereading in general, I’ve reread most of my favorite books tens of times; I make a yearly pilgrimage to <a href="https://mickens.seas.harvard.edu/wisdom-james-mickens">James Mickens’ website</a>; I reread many of my favorite posts and articles on the internet; and I often reread my <em>own</em> posts from the past.</p>

<p>Sometimes I’ll do it because I want a refresher in a topic. Sometimes I’ll do it because I’m bored. Whatever the reason, it’s always been a useful and fun thing to do.</p>

<p>Rereading old posts is a great way to transport myself back to my mindset from when I wrote the post. It’s easy to see progress in my understanding of things as well as in my writing. It’s interesting to note what I thought super important to include in the post <em>then</em> that I consider totally obvious <em>now</em><sup id="fnref:5" role="doc-noteref"><a href="#fn:5" class="footnote">3</a></sup>. It’s interesting to relearn what I’ve forgotten. It’s reassuring to realize that my terrible jokes were just as terrible as they are now.</p>

<p>One of my favorite posts to reread is <a href="https://manishearth.github.io/blog/2016/03/05/exploring-zero-knowledge-proofs/">this really long one on generalized zero knowledge proofs</a>. It’s the longest post I’ve written so far<sup id="fnref:6" role="doc-noteref"><a href="#fn:6" class="footnote">4</a></sup>, and it’s on a topic I don’t deal with often — cryptography. Not only does it help put me back in a mindset for thinking about cryptography, it’s about something super interesting but also complicated enough that rereading the post is like learning it all over again.</p>

<h2 id="it-lets-me-exercise-a-different-headspace">It lets me exercise a different headspace!</h2>

<p>I like programming a lot, but if programming was <em>all</em> I did, I’d get tired pretty quickly. When I was a student learning physics I’d often contribute to open source in my spare time, but now I write code full time so I’m less inclined to do it in my free time<sup id="fnref:8" role="doc-noteref"><a href="#fn:8" class="footnote">5</a></sup>.</p>

<p>But I still sometimes feel like doing programmery things in my spare time just … not programming.</p>

<p>Turns out that blogging doesn’t tire me out the same way! I’m sure that if I spent the whole day writing I’d not want to write when I go home, but I don’t spend the whole day writing, so it’s all good. It’s refreshing to sit down to write a blog post and discover a fresh reserve of energy. I’m not sure if this is the right term, but I usually call this “using a different headspace”.</p>

<p>I’ve also started using this to plan my work, I mix up the kinds of headspace I’m employing for various tasks so that I feel energetic throughout the day.</p>

<p>This is also why I really enjoy mentoring — mentoring often requires the same effort from me as fixing it myself, but it’s a different headspace I’m employing so it’s less tiring.</p>

<h2 id="blogging-lets-me-be-lazy">Blogging lets me be lazy!</h2>

<p>I often find myself explaining things often. I like helping folks and explaining things, but I’m also lazy<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">6</a></sup>, so writing stuff down really makes stuff easy for me! If folks ask me a question I can give a quick answer and then go “if you want to learn more, I’ve written about it here!”. If folks are asking a question a lot, there’s probably something missing in the documentation or learning materials about it. Some things can be fixed upstream in documentation, but other things — like <a href="https://manishearth.github.io/blog/2017/05/14/mentally-modelling-modules/">“how should I reason about modules in Rust?”</a> deserve to be tackled as a separate problem and addressed with their own post.</p>

<p>(Yes, this post is in this category!)</p>

<h2 id="its-okay-if-folks-have-written-about-it-before">It’s okay if folks have written about it before!</h2>

<p>A common question I’ve gotten is “Well I can write about X but … there are a lot of other posts out there about it, should I still?”</p>

<p>Yes!!</p>

<p>People think differently, people learn differently, and people come from different backgrounds. Existing posts may be useful for some folks but less useful for others.</p>

<p>My personal rule of thumb is that if it took <em>me</em> some effort to understand something after reading about it, that’s something worth writing about, so it’s easier to understand for others like me encountering the subject.</p>

<p>One of my favorite bloggers, <a href="https://jvns.ca/">Julia Evans</a> very often writes posts explaining computer concepts. Most of the times these have been explained before in other blog posts or manuals. But that doesn’t matter — her posts are <em>different</em>, and they’re <em>amazing</em>. They’re upbeat, fun to read, and often get me excited to learn more about things I knew about but never really looked at closely before.</p>

<h2 id="i-kinda-feel-its-my-duty-to">I kinda feel it’s my duty to?</h2>

<p>There’s a quote by Toni Morrison I quite enjoy:</p>

<blockquote>
  <p>I tell my students, ‘When you get these jobs that you have been so brilliantly trained for, just remember that your real job is that if you are free, you need to free somebody else. If you have some power, then your job is to empower somebody else. This is not just a grab-bag candy game.</p>
</blockquote>

<p>I enjoy it so much I <a href="https://manishearth.github.io/rustfest-slides/#/13">concluded my talk at RustFest Kyiv with it</a>!</p>

<p>I have the privilege of having time to do things like blogging and mentoring. Given that, I feel that it really is my duty to share what I know as much as possible; to help others attempting to tread the path I’m treading; and to battle against tribal knowledge.</p>

<p>When it comes to programming I’m mostly “self-taught”. But when I say that, I really mean that I wasn’t taught in a traditional way by other humans — I learned things by trying stuff out and <em>reading what others had written</em>. I didn’t learn Rust by taking <code>rustc</code> and pretending to be a fuzzer and just trying random nonsense till stuff made sense, I went through the tutorial (and <em>then</em> started exploring by trying random stuff). I didn’t figure out cool algorithms by discovering them from first principles, I picked them up from books and blog posts. I’m “self-taught” because I’ve been in charge of my learning process, but I’ve definitely relied on the work of other people throughout this process.</p>

<p>This means that for me, personally, knowledge-sharing is especially important. If I had to spend time figuring something out, I should make it easier for the next people to try<sup id="fnref:10" role="doc-noteref"><a href="#fn:10" class="footnote">7</a></sup>.</p>

<p>(All this said, I probably don’t blog as much as I <em>should</em>)</p>

<h2 id="you-should-blog-too">You should blog too!</h2>

<p>I wish everyone wrote more. I know not everyone has the time/privilege to do this, but if you do, I urge you to start!</p>

<p>I feel like tips on <em>how</em> to blog would fill up an entire other blog post, but Julia Evans has <a href="https://jvns.ca/blog/2016/05/22/how-do-you-write-blog-posts//">multiple</a> <a href="https://jvns.ca/blog/2017/03/20/blogging-principles/">posts</a> on this that I strongly recommend. Feel free to ask me for review on posts!</p>

<p>As for the technicalities of setting up a blog, my colleague Emily recently <a href="https://www.emilykager.com/writing/2018/07/27/myo-website.html">wrote a great post about doing this with Jekyll</a>. This blog uses <a href="http://octopress.org">Octopress</a> which is similar to set up.</p>

<p><em>Thanks to <a href="https://twitter.com/arshia__">Arshia</a>, <a href="https://twitter.com/QuietMisdreavus">QuietMisdreavus</a>, and <a href="https://twitter.com/myrrlyn">Alex</a> for reviewing drafts of this blog post.</em></p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:11" role="doc-endnote">
      <p>Who needs to <a href="https://www.ralfj.de/blog/2017/06/09/mutexguard-sync.html">look for unsoundness with rigorous formal verification</a> when you have <code>grep</code>? <a href="#fnref:11" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>Incidentally, I find there’s a similar dynamic when it comes to forum discussions vs hashing things out one-on-one, it’s way harder to get anywhere with forum discussions because they’re one-many and you have to put in that much more work to empathize with everyone else and also phrase things in a way that is resilient to accidental misinterpretation. <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:5" role="doc-endnote">
      <p>This is especially important as I get more and more “used” to subjects I’m familiar with – it’s easy to lose the ability to explain things when I think half of it is obvious. <a href="#fnref:5" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:6" role="doc-endnote">
      <p>This is probably the <em>real</em> reason I love rereading it — I like being verbose and would nest parentheses and footnotes if society let me <a href="#fnref:6" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:8" role="doc-endnote">
      <p>I also am in general less inclined to do technical things in my free time and have a better work-life balance, glad that worked out! <a href="#fnref:8" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:1" role="doc-endnote">
      <p>See blog title <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:10" role="doc-endnote">
      <p>One of my former title ideas for this post was “Knowledge is Theft”, riffing off of this concept, but I felt that was a bit too tongue-in-cheek. <a href="#fnref:10" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Future of Clippy]]></title>
    <link href="http://manishearth.github.io/blog/2018/06/05/the-future-of-clippy-the-rust-linter/"/>
    <updated>2018-06-05T00:00:00+00:00</updated>
    <id>http://manishearth.github.io/blog/2018/06/05/the-future-of-clippy-the-rust-linter</id>
    <content type="html"><![CDATA[<p>We’ve recently been making lots of progress on future plans for <a href="https://github.com/rust-lang-nursery/rust-clippy">clippy</a> and I
thought I’d post an update.</p>

<p>For some background, Clippy is the linter for Rust. We have more than 250 lints, and
are steadily growing.</p>

<h2 id="clippy-and-nightly">Clippy and Nightly</h2>

<p>Sadly, Clippy has been nightly-only for a very long time. The reason behind this is
that to perform its analyses it hooks into the compiler so that it doesn’t have to
reimplement half the compiler’s info to get things like type information. But
these are internal APIs and as such will never stabilize, so Clippy needs to be
used with nightly Rust.</p>

<p>We’re hoping this will change soon! The plan is that Clippy will eventually
be distributed by Rustup, so something like <code>rustup component add clippy</code> will
get you the clippy binary.</p>

<p>The first steps are <a href="https://github.com/rust-lang/rust/pull/51122">happening</a>, we’re planning on setting it up so that when it compiles
Rustup will be able to fetch a clippy component (however this won’t be the recommended way
to use clippy until we figure out the workflow here, so sit tight!)</p>

<p>Eventually, clippy will probably block nightlies<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">1</a></sup>; and after a bunch of cycles of letting that
work itself out, hopefully clippy will be available with the stable compiler. There’s a lot of
stuff that needs to be figured out, and we want to do this in a way that minimally impacts
compiler development, so this may move in fits and starts.</p>

<h2 id="lint-audit">Lint audit</h2>

<p>A couple months ago <a href="https://github.com/oli-obk">Oliver</a> and I<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote">2</a></sup> did a <a href="https://github.com/rust-lang-nursery/rust-clippy/pull/2579">lint audit</a> in Clippy. Previously,
clippy lints were classified as simply “clippy”, “clippy_pedantic”, and “restriction”.
“restriction” was for allow-by-default lints for things which are generally not a problem but may
be something you specifically want to forbid based on the situation, and “pedantic”
was for all the lints which were allow-by-default for other reasons.</p>

<p>Usually these reasons included stuff like “somewhat controversial lint”, “lint is very buggy”,
or for lints which are actually exceedingly pedantic and may only be wanted by folks
who very seriously prefer their code to be <em>perfect</em>.</p>

<p>We had a lot of buggy lints, and these categories weren’t as helpful. People use clippy
for different reasons. Some folks only care about clippy catching bugs, whereas others want
its help enforcing the general “Rust Style”.</p>

<p>So we came up with a better division of lints:</p>

<ul>
  <li>Correctness (Deny): Probable bugs, e.g. calling <code>.clone()</code> on <code>&amp;&amp;T</code>, which clones the (<code>Copy</code>) reference and not the actual type</li>
  <li>Style (Warn): Style issues; where the fix usually doesn’t semantically change the code. For example, having a method named <code>into_foo()</code> that doesn’t take <code>self</code> by-move</li>
  <li>Complexity (Warn): For detecting unnecessary code complexities and helping simplify them. For example, replacing <code>.filter(..).next()</code> with <code>.find(..)</code></li>
  <li>Perf (Warn): Detecting potential performance footguns, like using <code>Box&lt;Vec&lt;T&gt;&gt;</code> or calling <code>.or(foo())</code> instead of <code>or_else(foo)</code>.</li>
  <li>Pedantic (Allow): Controversial or exceedingly pedantic lints</li>
  <li>Nursery (Allow): For lints which are buggy or need more work</li>
  <li>Cargo (Allow): Lints about your Cargo setup</li>
  <li>Restriction (Allow): Lints for things which are not usually a problem, but may be something specific situations may dictate disallowing.</li>
</ul>

<p>and applied it to the codebase. You can see the results on our <a href="https://rust-lang-nursery.github.io/rust-clippy/master/index.html">lint list</a></p>

<p>Some lints could belong in more than one group, and we picked the best one in that case. Feedback welcome!</p>

<h2 id="clippy-10">Clippy 1.0</h2>

<p>In the run up to making Clippy a rustup component we’d like to do a 1.0 release of Clippy. This involves an RFC,
and pinning down an idea of stability.</p>

<p>The general plan we have right now is to have the same idea of lint stability as rustc; essentially
we do not guarantee stability under <code>#[deny(lintname)]</code>. This is mostly fine since <code>deny</code> only affects
the current crate (dependencies have their lints capped) so at most you’ll be forced to slap on an <code>allow</code>
somewhere after a rustup.</p>

<p>With specifics, this means that we’ll never remove lints. We may recategorize them, or “deprecate” them
(which makes the lint do nothing, but keeps the name around so that <code>#[allow(lintname)]</code> doesn’t break the build
aside from emitting a warning).</p>

<p>We’ll also not change what individual lints do fundamentally. The kinds of changes you can expect are:</p>

<ul>
  <li>Entirely new lints</li>
  <li>Fixing false positives (a lint may no longer lint in a buggy case)</li>
  <li>Fixing false negatives (A case where the lint <em>should</em> be linting but doesn’t is fixed)</li>
  <li>Bugfixes (When the lint panics or does something otherwise totally broken)</li>
</ul>

<p>When fixing false negatives this will usually be fixing things that can be understood as comfortably within the
scope of the lint as documented/named</p>

<p>I’ll be posting an RFC soonish that both contains this general plan of stability, as well as a list of the current
lint categorization for folks to discuss.</p>

<hr />

<p>Anyway, thought I’d just post a general update on everything, since stuff’s changing quickly.</p>

<p>There’s still time for stable or even just reliably rustuppable nightly clippy to happen but the path to it is pretty clear now!</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>As in, if clippy is broken there will not be a nightly that day. Rustfmt and RLS work this way right now AIUI. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>Okay, mostly Oliver <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Down a Rusty Rabbit Hole]]></title>
    <link href="http://manishearth.github.io/blog/2018/04/12/down-a-rusty-rabbit-hole/"/>
    <updated>2018-04-12T00:00:00+00:00</updated>
    <id>http://manishearth.github.io/blog/2018/04/12/down-a-rusty-rabbit-hole</id>
    <content type="html"><![CDATA[<p>Last week I fell down a rather interesting rabbit hole in Rust, which was basically
me discovering a series of quirks of the Rust compiler/language, each one leading to the
next when I asked “why?”.</p>

<p>It started when someone asked why autogenerated <code>Debug</code> impls use argument names like <code>__arg_0</code>
which start with a double underscore.</p>

<p>This happened to be <a href="https://github.com/rust-lang/rust/pull/32294">my fault</a>. The reason <a href="https://github.com/rust-lang/rust/pull/32251#issuecomment-197481726">we used a double underscore</a> was that
while a single underscore tells rustc not to warn about a possibly-unused variable, there’s an off-
by-default clippy lint that warns about variables that start with a single underscore that are used,
which can be silenced with a double underscore. Now, the correct fix here is to make the lint ignore
derive/macros (which I believe we did as well), but at the time we needed to add an underscore
anyway so a double underscore didn’t seem worse.</p>

<p>Except of course, this double underscore appears in the docs. Oops.</p>

<p>Ideally the rustc derive infrastructure would have a way of specifying the argument name to use so
that we can at least have descriptive things here, but that’s a bit more work (I’m willing to mentor
this work though!). So I thought I’d fix this by at least removing the double underscore, and making
the unused lint ignore <code>#[derive()]</code> output.</p>

<p>While going through the code to look for underscores I also discovered a hygiene issue. The following code
throws a bunch of very weird type errors:</p>

<pre><code class="language-rust">pub const __cmp: u8 = 1;

#[derive(PartialOrd, PartialEq)]
pub enum Foo {
    A(u8), B(u8)
}
</code></pre>

<p>(<a href="https://play.rust-lang.org/?gist=2352b6a2192f38caba70bc2b1fa889e7&amp;version=stable">playpen</a>)</p>

<pre><code>error[E0308]: mismatched types
 --&gt; src/main.rs:6:7
  |
6 |     A(u8), B(u8)
  |       ^^^ expected enum `std::option::Option`, found u8
  |
  = note: expected type `std::option::Option&lt;std::cmp::Ordering&gt;`
             found type `u8`
.....
</code></pre>

<p>This is because the generated code for PartialOrd contains the following:</p>

<pre><code class="language-rust">match foo.cmp(bar) {
    Some(Ordering::Equal) =&gt; .....,
    __cmp =&gt; __cmp,
}
</code></pre>

<p><code>__cmp</code> can both be a binding to a wildcard pattern match as well as a match against a constant
named <code>__cmp</code>, and in the presence of such a constant it resolves to the constant, causing
type errors.</p>

<p>One way to fix this is to bind <code>foo.cmp(bar)</code> to some temporary variable <code>x</code> and use that directly in
a <code>_ =&gt; x</code> branch.</p>

<p>I thought I could be clever and try <code>cmp @ _ =&gt; cmp</code> instead. <code>match</code> supports syntax where you can
do <code>foo @ &lt;pattern&gt;</code>, where <code>foo</code> is bound to the entire matched variable. The <code>cmp</code> here is unambiguously
a binding; it cannot be a pattern. So no conflicting with the <code>const</code>, problem solved!</p>

<p>So I made <a href="https://github.com/rust-lang/rust/pull/49676">a PR for both removing the underscores and also fixing this</a>. The change for <code>__cmp</code>
is no longer in that PR, but you can find it <a href="https://github.com/Manishearth/rust/commit/partial-cmp-hygiene">here</a>.</p>

<p>Except I hit a problem. With that PR, the following still breaks:</p>

<pre><code class="language-rust">pub const cmp: u8 = 1;

#[derive(PartialOrd, PartialEq)]
pub enum Foo {
    A(u8), B(u8)
}
</code></pre>

<p>throwing a slightly cryptic error:</p>

<pre><code>error[E0530]: match bindings cannot shadow constants
 --&gt; test.rs:9:7
  |
4 | pub const cmp: u8 = 1;
  | ---------------------- a constant `cmp` is defined here
...
9 |     B(u8)
  |       ^^^ cannot be named the same as a constant
</code></pre>

<p>You can see a reduced version of this error in the following code:</p>

<pre><code class="language-rust">pub const cmp : u8 = 1;

fn main() {
    match 1 {
        cmp @ _ =&gt; ()
    }
}
</code></pre>

<p>(<a href="https://play.rust-lang.org/?gist=feebbc048b47c286d5720b9926c6925e&amp;version=stable">playpen</a>)</p>

<p>Huh. Wat. Why? <code>cmp @ _</code> seems to be pretty unambiguous, what’s wrong with it shadowing a constant?</p>

<p>Turns out bindings cannot shadow constants at all, for a <a href="https://github.com/rust-lang/rust/issues/33118#issuecomment-233962221">rather subtle reason</a>:</p>

<pre><code class="language-rust">const A: u8 = ...; // A_const
let A @ _ = ...; // A_let
match .. {
    A =&gt; ...; // A_match
}
</code></pre>

<p>What happens here is that constants and variables occupy the same namespace. So <code>A_let</code> shadows
<code>A_const</code> here, and when we attempt to <code>match</code>, <code>A_match</code> is resolved to <code>A_let</code> and rejected (since
you can’t match against a variable), and <code>A_match</code> falls back to resolving as a fresh binding
pattern, instead of resolving to a pattern that matches against <code>A_const</code>.</p>

<p>This is kinda weird, so we disallow shadowing constants with variables. This is rarely a problem
because variables are lowercase and constants are uppercase. We could <em>technically</em> allow this
language-wise, but it’s hard on the implementation (and irrelevant in practice) so we don’t.</p>

<hr />

<p>So I dropped that fix. The temporary local variable approach is broken as well since
you can also name a constant the same as the local variable and have a clash (so again, you
need the underscores to avoid surprises).</p>

<p>But then I realized that we had an issue with removing the underscores from <code>__arg_0</code> as well.</p>

<p>The following code is also broken:</p>

<pre><code class="language-rust">pub const __arg_0: u8 = 1;

#[derive(Debug)]
struct Foo(u8);
</code></pre>

<p>(<a href="https://play.rust-lang.org/?gist=6e10fd8de1123c6f6f695c891e879f70&amp;version=stable">playpen</a>)</p>

<pre><code>error[E0308]: mismatched types
 --&gt; src/main.rs:3:10
  |
3 | #[derive(Debug)]
  |          ^^^^^ expected mutable reference, found u8
  |
  = note: expected type `&amp;mut std::fmt::Formatter&lt;'_&gt;`
             found type `u8`
</code></pre>

<p>You can see a reduced version of this error in the following code:</p>

<pre><code class="language-rust">pub const __arg_0: u8 = 1;

fn foo(__arg_0: bool) {}
</code></pre>

<pre><code>error[E0308]: mismatched types
 --&gt; src/main.rs:3:8
  |
3 | fn foo(__arg_0: bool) {}
  |        ^^^^^^^ expected bool, found u8
</code></pre>

<p>(<a href="https://play.rust-lang.org/?gist=2cf2c8b3520d5b343de1b76f80ea3fe7&amp;version=stable">playpen</a>)</p>

<p>This breakage is not an issue with the current code because of the double underscores – there’s a
very low chance someone will create a constant that is both lowercase and starts with a double
underscore. But it’s a problem when I remove the underscores since that chance shoots up.</p>

<p>Anyway, this failure is even weirder. Why are we attempting to match against the constant in the
first place? <code>fn</code> argument patterns<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">1</a></sup> are irrefutable, i.e. all possible values of the type should match
the argument. For example, <code>fn foo(Some(foo): Option&lt;u8&gt;) {}</code> will fail to compile with
“refutable pattern in function argument: <code>None</code> not covered”.</p>

<p>There’s no point trying to match against constants here; because even if we find a constant it will be rejected
later. Instead, we can unambiguously resolve identifiers as new bindings, yes?</p>

<p>Right?</p>

<p>Firm in my belief, <a href="https://github.com/rust-lang/rust/issues/49680">I filed an issue</a>.</p>

<p>I was wrong, it’s <a href="https://github.com/rust-lang/rust/issues/49680#issuecomment-379029404">not going to always be rejected later</a>. With zero-sized types this
can totally still work:</p>

<pre><code class="language-rust">struct S;

const C: S = S;

fn main() {
    let C = S;
}
</code></pre>

<p>Here because <code>S</code> has only one state, matching against a constant of the type is still irrefutable.</p>

<p>I argued that this doesn’t matter – since the type has a single value, it doesn’t matter whether we resolved to
a new binding or the constant; the value and semantics are the same.</p>

<p>This is true.</p>

<p>Except.</p>

<p><a href="https://github.com/rust-lang/rust/issues/49680#issuecomment-379032842">Except for when destructors come in</a>.</p>

<p>It was at this point that my table found itself in the perplexing state of being upside-down.</p>

<p>This is still really fine, zero-sized-constants-with-destructors is a pretty rare thing in Rust
and I don’t really see folks <em>relying</em> on this behavior.</p>

<p>However I later realized that this entire detour was pointless because even if we fix this, we end up
with a way for bindings to shadow constants. Which … which we already realized isn’t allowed by the
compiler till we fix some bugs.</p>

<p>Damn.</p>

<hr />

<p>The <em>actual</em> fix to the macro stuff is to use hygenic generated variable names, which the current
infrastructure supports. I plan to make a PR for this eventually.</p>

<p>But it was a very interesting dive into the nuances of pattern matching in Rust.</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>Yes, function arguments in Rust are patterns. You can totally do things like <code>(a, b): (u8, u8)</code> in function arguments (like you can do in <code>let</code>) <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Picking Apart the Crashing iOS String]]></title>
    <link href="http://manishearth.github.io/blog/2018/02/15/picking-apart-the-crashing-ios-string/"/>
    <updated>2018-02-15T00:00:00+00:00</updated>
    <id>http://manishearth.github.io/blog/2018/02/15/picking-apart-the-crashing-ios-string</id>
    <content type="html"><![CDATA[<p>So there’s <a href="https://www.theverge.com/2018/2/15/17015654/apple-iphone-crash-ios-11-bug-imessage">yet another iOS text crash</a>, where just looking at a particular string crashes
iOS. Basically, if you put this string in any system text box (and other places), it crashes that
process. I’ve been testing it by copy-pasting characters into Spotlight so I don’t end up crashing
my browser.</p>

<p>The original sequence is U+0C1C U+0C4D U+0C1E U+200C U+0C3E, which is a sequence of Telugu
characters: the consonant ja (జ), a virama ( ్ ), the consonant nya (ఞ), a zero-width non-joiner, and
the vowel aa ( ా).</p>

<p>I was pretty interested in what made this sequence “special”, and started investigating.</p>

<p>So first when looking into this, I thought that the &lt;ja, virama, nya&gt; sequence was the culprit.
That sequence forms a special ligature in many Indic scripts (ज्ञ in Devanagari) which is often
considered a letter of its own. However, the ligature for Telugu doesn’t seem very “special”.</p>

<p>Also, from some experimentation, this bug seemed to occur for <em>any</em> pair of Telugu consonants with
a vowel, as long as the vowel is not   ై (ai). Huh.</p>

<p>The ZWNJ must be doing something weird, then. &lt;consonant, virama, consonant, vowel&gt; is a
pretty common sequence in any Indic script; but ZWNJ before a vowel isn’t very useful for most
scripts (except for Bengali and Oriya, but I’ll get to that).</p>

<p>And then I saw that <a href="https://twitter.com/FakeUnicode/status/963300865762254848">there was a sequence in Bengali</a> that also crashed.</p>

<p>The sequence is U+09B8 U+09CD U+09B0 U+200C U+09C1, which is the consonant “so” (স), a virama ( ্ ),
the consonant “ro” (র), a ZWNJ, and vowel u (  ু).</p>

<p>Before we get too into this, let’s first take a little detour to learn how Indic scripts work:</p>

<h2 id="indic-scripts-and-consonant-clusters">Indic scripts and consonant clusters</h2>

<p>Indic scripts are <em>abugidas</em>; which means that their “letters” are consonants, which you
can attach diacritics to to change the vowel. By default, consonants have a base vowel.
So, for example, क is “kuh” (kə, often transcribed as “ka”), but I can change the vowel to make it के
(the “ka” in “okay”) का (“kaa”, like “car”).</p>

<p>Usually, the default vowel is the ə sound, though not always (in Bengali it’s more of an o sound).</p>

<p>Because of the “default” vowel, you need a way to combine consonants. For example, if you wished to
write the word “ski”, you can’t write it as स + की (sa + ki = “saki”), you must write it as स्की.
What’s happened here is that the स got its vowel “killed”, and got tacked on to the की to form a
consonant cluster ligature.</p>

<p>You can <em>also</em> write this as स्‌की . That little tail you see on the स is known as a “virama”;
it basically means “remove this vowel”. Explicit viramas are sometimes used when there’s no easy way
to form a ligature, e.g. in ङ्‌ठ because there is no simple way to ligatureify ङ into ठ. Some scripts
also <em>prefer</em> explicit viramas, e.g. “ski” in Malayalam is written as സ്കീ, where the little crescent
is the explicit virama.</p>

<p>In unicode, the virama character is always used to form a consonant cluster. So स्की was written as
&lt;स,  ्, क,  ी&gt;, or &lt;sa, virama, ka, i&gt;. If the font supports the cluster, it will show up
as a ligature, otherwise it will use an explicit virama.</p>

<p>For Devanagari and Bengali, <em>usually</em>, in a consonant cluster the first consonant is munged a bit and the second consonant stays intact.
There are exceptions – sometimes they’ll form an entirely new glyph (क + ष = क्ष), and sometimes both
glyphs will change (ड + ड = ड्ड, द + म = द्म, द + ब = द्ब). Those last ones should look like this in conjunct form:</p>

<p><img class="center" src="http://manishearth.github.io/images/post/unicode-crash/conjuncts.png" width="200" /></p>

<h2 id="investigating-the-bengali-case">Investigating the Bengali case</h2>

<p>Now, interestingly, unlike the Telugu crash, the Bengali crash seemed to only occur when the second
consonant is র (“ro”). However, I can trigger it for any choice of the first consonant or vowel, except
when the vowel is  ো (o) or  ৌ (au).</p>

<p>Now, র is an interesting consonant in some Indic scripts, including Devanagari. In Devanagari,
it looks like र (“ra”). However, it does all kinds of things when forming a cluster. If you’re having it
precede another consonant in a cluster, it forms a little feather-like stroke, like in र्क (rka). In Marathi,
that stroke can also look like a tusk, as in र्‍क. As a suffix consonant, it can provide a little
“extra leg”, as in क्र (kra). For letters without a vertical stroke, like ठ (tha), it does this caret-like thing,
ठ्र (thra).</p>

<p>Basically, while most consonants retain some of their form when put inside a cluster, र does not. And
a more special thing about र is that this happens even when र is the <em>second</em> consonant in a cluster – as I mentioned
before, for most consonant clusters the second consonant stays intact. While there are exceptions, they are usually
specific to the cluster; it is only र for which this happens for all clusters.</p>

<p>It’s similar in Bengali, র as the second consonant adds a tentacle-like thing on the existing consonant. For example,
প + র (po + ro) gives প্র (pro).</p>

<p>But it’s not just র that does this in Bengali, the consonant “jo” does as well. প + য (po + jo) forms প্য (pjo),
and the য is transformed into a wavy line called a “jophola”.</p>

<p>So I tried it with য  — , and it turns out that the Bengali crash occurs for  য as well!
So the general Bengali case is &lt;consonant, virama, র OR য, ZWNJ, vowel&gt;, where the vowel is not   ো or  ৌ.</p>

<h2 id="suffix-joining-consonants">Suffix-joining consonants</h2>

<p>So we’re getting close, here. At least for Bengali, it occurs when the second consonant is such that it often
combines with the first consonant without modifying its form much.</p>

<p>In fact, this is the case for Telugu as well! Consonant clusters in Telugu are usually formed by preserving the
original consonant, and tacking the second consonant on below!</p>

<p>For example, the original crashy string contains the cluster జ + ఞ, which looks like జ్ఞ. The first letter isn’t
really modified, but the second is.</p>

<p>From this, we can guess that it will also occur for Devanagari with र. Indeed it does! U+0915 U+094D U+0930 U+200C U+093E, that is,
&lt;क,  ्, र, zwnj,  ा&gt; (&lt; ka, virama, ra, zwnj, aa &gt;) is one such crashing sequence.</p>

<p>But this isn’t really the whole story, is it? For example, the crash does occur for “kro” + zwnj + vowel in Bengali,
and in “kro” (ক্র = ক + র = ko + ro) the resultant cluster involves the munging of both the prefix and suffix. But
the crash doesn’t occur for द्ब or ड्ड. It seems to be specific to the letter, not the nature of the cluster.</p>

<p>Digging deeper, the reason is that for many fonts (presumably the ones in use), these consonants
form “suffix joining consonants”<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">1</a></sup> (a term I made up) when preceded by a virama. This seems to
correspond to the <a href="https://docs.microsoft.com/en-us/typography/opentype/spec/features_pt#tag-pstf"><code>pstf</code> OpenType feature</a>, as well as <a href="https://docs.microsoft.com/en-us/typography/opentype/spec/features_uz#vatu"><code>vatu</code></a>.</p>

<p>For example, the sequence virama + क gives   ्क, i.e. it renders a virama with a placeholder followed by a क.</p>

<p>But, for र, virama + र renders  ्र, which for me looks like this:</p>

<p><img class="center" src="http://manishearth.github.io/images/post/unicode-crash/virama-ra.png" width="200" /></p>

<p>In fact, this is the case for the other consonants as well. For me,  ्र  ্র  ্য  ్ఞ  ్క
(Devanagari virama-ra, Bengali virama-ro, Bengali virama-jo, Telugu virama-nya, Telugu virama-ka)
all render as “suffix joining consonants”:</p>

<p><img class="center" src="http://manishearth.github.io/images/post/unicode-crash/virama-consonant.png" width="200" /></p>

<p>(This is true for all Telugu consonants, not just the ones listed).</p>

<p>An interesting bit is that the crash does not occur for &lt;र, virama, र, zwnj, vowel&gt;, because र-virama-र
uses the prefix-joining form of the first र (र्र). The same occurs for র with itself or ৰ or য. Because the virama
is “stickier” to the left in these cases, it doesn’t cause a crash. (h/t <a href="https://github.com/hackbunny">hackbunny</a> for discovering this
using a <a href="https://github.com/hackbunny/viramarama">script</a> to enumerate all cases).</p>

<p>Kannada <em>also</em> has “suffix joining consonants”, but for some reason I cannot trigger the crash with it. Ya in Gurmukhi
is also suffix-joining.</p>

<h2 id="the-zwnj">The ZWNJ</h2>

<p>The ZWNJ is curious. The crash doesn’t happen without it, but as I mentioned before a ZWNJ before a vowel
doesn’t really <em>do</em> anything for most Indic scripts. In Indic scripts, a ZWNJ can be used to explicitly force a
virama if used after the virama (I used it to write स्‌की in this post), however that’s not how it’s being used here.</p>

<p>In Bengali and Oriya specifically, a ZWNJ can be used to force a different vowel form when used before a vowel
(e.g. রু vs র‌ু), however this bug seems to apply to vowels for which there is only one form, and this bug
also applies to other scripts where this isn’t the case anyway.</p>

<p>The exception vowels are interesting. They’re basically all vowels that are made up of <em>two</em> glyph components. Philippe Verdy
points out:</p>

<blockquote>
  <p>And why this bug does not occur with some vowels is because these are vowels in two parts,
that are first decomposed into two separate glyphs reordered in the buffer of glyphs, while
other vowels do not need this prior mapping and keep their initial direct mapping from their
codepoints in fonts, which means that this has to do to the way the ZWNJ looks for the glyphs
of the vowels in the glyphs buffer and not in the initial codepoints buffer: there’s some desynchronization,
and more probably an uninitialized data field (for the lookup made in handling ZWNJ) if no vowel decomposition was done
(the same data field is correctly initialized when it is the first consonnant which takes an alternate form before
a virama, like in most Indic consonnant clusters, because the a glyph buffer is created.</p>
</blockquote>

<h2 id="generalizing">Generalizing</h2>

<p>So, ultimately, the full set of cases that cause the crash are:</p>

<p>Any sequence <code>&lt;consonant1, virama, consonant2, ZWNJ, vowel&gt;</code> in Devanagari, Bengali, and Telugu, where:</p>

<ul>
  <li><code>consonant2</code> is suffix-joining (<code>pstf</code>/<code>vatu</code>) – i.e. र, র, য, ৰ, and all Telugu consonants</li>
  <li><code>consonant1</code> is not a reph-forming letter like र/র (or a variant, like ৰ)</li>
  <li><code>vowel</code> does not have two glyph components, i.e. it is not   ై,   ো, or   ৌ</li>
</ul>

<p>This leaves one question open:</p>

<p>Why doesn’t it apply to Kannada? Or, for that matter, Khmer, which has a similar virama-like thing called a “coeng”?</p>

<h2 id="are-these-valid-strings">Are these valid strings?</h2>

<p>A recurring question I’m getting is if these strings are valid in the language, or unicode gibberish
like Zalgo text. Breaking it down:</p>

<ul>
  <li>All of the <em>rendered</em> glyphs are valid. The original Telugu one is the root of the word for
“knowledge” (and I’ve taken to calling this bug “forbidden knowledge” for that reason).</li>
  <li>In Telugu and Devanagari, there is no functional use of the ZWNJ as used before a vowel. It
should not be there, and one would not expect it in typical text.</li>
  <li>In Bengali (also Oriya), putting a ZWNJ before some vowels prevents them from ligatureifying, and this is
mentioned in the Unicode spec. However, it seems rare for native speakers to use this.</li>
  <li>In all of these scripts, putting a ZWNJ after viramas can be used to force an explicit virama
over a ligature. That is not the position ZWNJ is used here, but it gives a hint that this
might have been a mistype. Doing this is <em>also</em> rare at least for Devanagari (and I believe
for the other two scripts as well)</li>
  <li>Android has an explicit key for ZWNJ on its keyboards for these languages<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote">2</a></sup>, right next to the spacebar. iOS has this as
well on the long-press of the virama key. <em>Very</em> easy to mistype, at least for Android.</li>
</ul>

<p>So while the crashing strings are usually invalid, and when not, very rare, they are easy enough to mistype.</p>

<p>An example by <a href="https://twitter.com/FakeUnicode">@FakeUnicode</a> was the string “For/k” (or “Foŕk”, if accents were easier to type). A
slash isn’t something you’d normally type there, and the produced string is gibberish, but it’s easy enough to type
by accident.</p>

<p>Except of course that the mistake in “For/k”/”Foŕk” is visually obvious and would be fixed; this
isn’t the case for most of the crashing strings.</p>

<h2 id="conclusion">Conclusion</h2>

<p>I don’t really have <em>one</em> guess as to what’s going on here – I’d love to see what people think – but my current
guess is that the “affinity” of the virama to the left instead of the right confuses the algorithm that handles ZWNJs after
viramas into thinking the ZWNJ applies to the virama (it doesn’t, there’s a consonant in between), and this leads to some numbers
not matching up and causing a buffer overflow or something. Philippe’s diagnosis of the vowel situation matches up with this.</p>

<p>An interesting thing is that I can cause this crash to happen more reliably in browsers by clicking on the string.</p>

<p>Additionally, <em>sometimes</em> it actually renders in spotlight for a split second before crashing; which
means that either the crash isn’t deterministic, or it occurs in some process <em>after</em> rendering. I’m
not sure what to think of either. Looking at the backtraces, the crash seems to occur in different
places, so it’s likely that it’s memory corruption that gets uncovered later.</p>

<p>I’d love to hear if folks have further insight into this.</p>

<p>Update: Philippe on the Unicode mailing list has <a href="https://www.unicode.org/mail-arch/unicode-ml/y2018-m02/0103.html">an interesting theory</a></p>

<p><small>Yes, I could attach a debugger to the crashing process and investigate that instead, but that’s no fun 😂</small></p>
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>Philippe Verdy points out that these may be called “phala forms” at least for Bengali <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>I don’t think the Android keyboard <em>needs</em> this key; the keyboard seems very much a dump of “what does this unicode block let us do”, and includes things like Sindhi-specific or Kashmiri-specific characters for the Marathi keyboard as well as <em>extremely</em> archaic characters, whilst neglecting more common things like the eyelash reph (which doesn’t have its own code point but is a special unicode sequence; native speakers should not be expected to be aware of this sequence). <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A Rough Proposal for Sum Types in Go]]></title>
    <link href="http://manishearth.github.io/blog/2018/02/01/a-rough-proposal-for-sum-types-in-go/"/>
    <updated>2018-02-01T00:00:00+00:00</updated>
    <id>http://manishearth.github.io/blog/2018/02/01/a-rough-proposal-for-sum-types-in-go</id>
    <content type="html"><![CDATA[<p>Sum types are pretty cool. Just like how a struct is basically “This contains one of these <em>and</em> one of these”,
a sum type is “This contains one of these <em>or</em> one of these”.</p>

<p>So for example, the following sum type in Rust:</p>

<pre><code class="language-rust">enum Foo {
    Stringy(String),
    Numerical(u32)
}
</code></pre>

<p>or Swift:</p>

<pre><code class="language-swift">enum Foo {
    case stringy(String),
    case numerical(Int)
}
</code></pre>

<p>would be one where it’s either <code>Foo::Stringy</code> (<code>Foo::stringy</code> for swift), containing a <code>String</code>,
<em>or</em> <code>Foo::Numerical</code>, containing an integer.</p>

<p>This can be pretty useful. For example, messages between threads are often of a “this or that or that or that”
form.</p>

<p>The nice thing is, matching (switching) on these enums is usually <em>exhaustive</em> – you must list all
the cases (or include a default arm) for your code to compile. This leads to a useful component
of type safety – if you add a message to your message passing system, you’ll know where to update it.</p>

<p>Go doesn’t have these. Go <em>does</em> have interfaces, which are dynamically dispatched. The drawback here
is that you do not get the exhaustiveness condition, and consumers of your library can even add further
cases. (And, of course, dynamic dispatch can be slow). You <em>can</em> get exhaustiveness in Go with <a href="https://github.com/haya14busa/gosum">external tools</a>,
but it’s preferable to have such things in the language IMO.</p>

<p>Many years ago when I was learning Go I wrote a <a href="http://inpursuitoflaziness.blogspot.in/2015/02/thoughts-of-rustacean-learning-go.html">blog post</a> about what I liked and disliked
as a Rustacean learning Go. Since then, I’ve spent a lot more time with Go, and I’ve learned to like each Go design decision that I initially
disliked, <em>except</em> for the lack of sum types. Most of my issues arose from “trying to program Rust in Go”,
i.e. using idioms that are natural to Rust (or other languages I’d used previously). Once I got used to the
programming style, I realized that aside from the lack of sum types I really didn’t find much missing
from the language. Perhaps improvements to error handling.</p>

<p>Now, my intention here isn’t really to sell sum types. They’re somewhat controversial for Go, and
there are good arguments on both sides. You can see one discussion on this topic <a href="https://github.com/golang/go/issues/19412">here</a>.
If I were to make a more concrete proposal I’d probably try to motivate this in much more depth. But even
I’m not very <em>strongly</em> of the opinion that Go needs sum types; I have a slight preference for it.</p>

<p>Instead, I’m going to try and sketch this proposal for sum types that has been floating around my
mind for a while. I end up mentioning it often and it’s nice to have something to link to. Overall,
I think this “fits well” with the existing Go language design.</p>

<h2 id="the-proposal">The proposal</h2>

<p>The essence is pretty straightforward: Extend interfaces to allow for “closed interfaces”. These are
interfaces that are only implemented for a small list of types.</p>

<p>Writing the <code>Foo</code> sum type above would be:</p>

<pre><code class="language-go">type Foo interface {
    SomeFunction()
    OtherFunction()
    for string, int
}
</code></pre>

<p>It doesn’t even need to have functions defined on it.</p>

<p>The interface functions can only be called if you have an interface object; they are not directly available
on variant types without explicitly casting (<code>Foo("...").SomeFunction()</code>).</p>

<p>(I’m not strongly for the <code>for</code> keyword syntax, it’s just a suggestion. The core idea is that
you define an interface and you define the types it closes over. Somehow.)</p>

<p>A better example would be an interface for a message-passing system for Raft:</p>

<pre><code class="language-go">type VoteRequest struct {
    CandidateId uint
    Term uint
    // ...
}

type VoteResponse struct {
    Term uint
    VoteGranted bool
    VoterId uint
}

type AppendRequest struct {
    //...
}

type AppendResponse struct {
    //...
}
// ...
type RaftMessage interface {
    for VoteRequest, VoteResponse, AppendRequest, AppendResponse
}
</code></pre>

<p>Now, you use type switches for dealing with these:</p>

<pre><code class="language-go">switch value := msg.(type) {
    case VoteRequest:
        if value.Term &lt;= me.Term {
            me.reject_vote(value.CandidateId)
        } else {
            me.accept_vote(value.CandidateId, value.Term)
        }
    case VoteResponse: // ...
    case AppendRequest: // ...
    case AppendResponse: // ...
}
</code></pre>

<p>There is no need for the default case, unless you wish to leave one or more of the cases out.</p>

<p>Ideally, these could be implemented as inline structs instead of using dynamic dispatch. I’m not sure
what this entails for the GC design, but I’d love to hear thoughts on this.</p>

<p>We also make it possible to add methods to closed interfaces. This is in the spirit of
<a href="https://github.com/golang/go/issues/16254">this proposal</a>, where you allow</p>

<pre><code class="language-go">func (message RaftMessage) Process(me Me) error {
    // message handling logic
}
</code></pre>

<p>for closed interfaces.</p>

<p>This aligns more with how sum types are written and used in other languages; instead of assuming
that each method will be a <code>switch</code> on the variant, you can write arbitrary code that <em>may</em> <code>switch</code>
on the type but it can also just call other methods. This is really nice because you can write
methods in <em>both</em> ways – if it’s a “responsibility of the inner type” kind of method, require it in
the interface and delegate it to the individual types. If it’s a “responsibility of the interface”
method, write it as a method on the interface as a whole. I kind of wish Rust had this, because in Rust
you sometimes end up writing things like:</p>

<pre><code class="language-rust">match foo {
    Foo::Stringy(s) =&gt; s.process(),
    Foo::Numerical(n) =&gt; n.process(),
    // ...
}
</code></pre>

<p>Yes, this would work better as a trait, but then you lose some niceties of Rust enums. With this
proposal Go can have it both ways.</p>

<hr />

<p>Anyway, thoughts? This is a really rough proposal, and I’m not sure how receptive other Gophers will be
to this, nor how complex its implementation would be. I don’t really intend to submit this as a formal proposal,
but if someone else wants to they are more than welcome to build on this idea.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[What Are Tokio and Async IO All About?]]></title>
    <link href="http://manishearth.github.io/blog/2018/01/10/whats-tokio-and-async-io-all-about/"/>
    <updated>2018-01-10T00:00:00+00:00</updated>
    <id>http://manishearth.github.io/blog/2018/01/10/whats-tokio-and-async-io-all-about</id>
    <content type="html"><![CDATA[<p>The Rust community lately has been focusing a lot on “async I/O” through the <a href="https://github.com/tokio-rs/">tokio</a>
project. This is pretty great!</p>

<p>But for many in the community who haven’t worked with web servers and related things it’s pretty
confusing as to what we’re trying to achieve there. When this stuff was being discussed around 1.0,
I was pretty lost as well, having never worked with this stuff before.</p>

<p>What’s all this Async I/O business about? What are coroutines? Lightweight threads? Futures? How
does this all fit together?</p>

<h2 id="what-problem-are-we-trying-to-solve">What problem are we trying to solve?</h2>

<p>One of Rust’s key features is “fearless concurrency”. But the kind of concurrency required for handling a
large amount of I/O bound tasks – the kind of concurrency found in Go, Elixir, Erlang – is absent
from Rust.</p>

<p>Let’s say you want to build something like a web service. It’s going to be handling thousands of
requests at any point in time (known as the “<a href="https://en.wikipedia.org/wiki/C10k_problem">c10k</a> problem”). In general, the problem we’re
considering is having a huge number of I/O bound (usually network I/O) tasks.</p>

<p>“Handling N things at once” is best done by using threads. But … <em>thousands</em> of threads? That
sounds a bit much. Threads can be pretty expensive: Each thread needs to allocate a large stack,
setting up a thread involves a bunch of syscalls, and context switching is expensive.</p>

<p>Of course, thousands of threads <em>all doing work</em> at once is not going to work anyway. You only
have a fixed number of cores, and at any one time only one thread will be running on a core.</p>

<p>But for cases like web servers, most of these threads won’t be doing work. They’ll be waiting on the
network. Most of these threads will either be listening for a request, or waiting for their response
to get sent.</p>

<p>With regular threads, when you perform a blocking I/O operation, the syscall returns control
to the kernel, which won’t yield control back, because the I/O operation is probably not finished.
Instead, it will use this as an opportunity to swap in a different thread, and will swap the original
thread back when its I/O operation is finished (i.e. it’s “unblocked”). Without Tokio and friends,
this is how you would handle such things in Rust. Spawn a million threads; let the OS deal with
scheduling based on I/O.</p>

<p>But, as we already discovered, threads don’t scale well for things like this<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">1</a></sup>.</p>

<p>We need “lighter” threads.</p>

<h2 id="lightweight-threading">Lightweight threading</h2>

<p>I think the best way to understand lightweight threading is to forget about Rust for a moment
and look at a language that does this well, Go.</p>

<p>Instead of using OS threads, Go has lightweight threads, called “goroutines”. You spawn these with the <code>go</code>
keyword. A web server might do something like this:</p>

<pre><code class="language-go">listener, err = net.Listen(...)
// handle err
for {
    conn, err := listener.Accept()
    // handle err

    // spawn goroutine:
    go handler(conn)
}
</code></pre>

<p>This is a loop which waits for new TCP connections, and spawns a goroutine with the connection
and the function <code>handler</code>. Each connection will be a new goroutine, and the goroutine will shut down
when <code>handler</code> finishes. In the meantime, the main loop continues executing, because it’s running in
a different goroutine.</p>

<p>So if these aren’t “real” (operating system) threads, what’s going on?</p>

<p>A goroutine is an example of a “lightweight” thread. The operating system doesn’t know about these,
it sees N threads owned by the Go runtime, and the Go runtime maps M goroutines onto them<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote">2</a></sup>, swapping
goroutines in and out much like the operating system scheduler. It’s able to do this because
Go code is already interruptible for the GC to be able to run, so the scheduler can always ask goroutines
to stop. The scheduler is also aware of I/O, so when a goroutine is waiting on I/O it yields to the scheduler.</p>

<p>Essentialy, a compiled Go function will have a bunch of points scattered throughout it where it
tells the scheduler and GC “take over if you want” (and also “I’m waiting on stuff, please take
over”).</p>

<p>When a goroutine is swapped on an OS thread, some registers will be saved, and
the program counter will switch to the new goroutine.</p>

<p>But what about its stack? OS threads have a large stack with them, and you kinda need a stack for functions
and stuff to work.</p>

<p>What Go used to do was segmented stacks. The reason a thread needs a large stack is that most
programming languages, including C, expect the stack to be contiguous, and stacks can’t just be
“reallocated” like we do with growable buffers since we expect stack data to stay put so that
pointers to stack data to continue to work. So we reserve all the stack we think we’ll ever need
(~8MB), and hope we don’t need more.</p>

<p>But the expectation of stacks being contiguous isn’t strictly necessary. In Go, stacks are made of tiny
chunks. When a function is called, it checks if there’s enough space on the stack for it to run, and if not,
allocates a new chunk of stack and runs on it. So if you have thousands of threads doing a small amount of work,
they’ll all get thousands of tiny stacks and it will be fine.</p>

<p>These days, Go actually does something different; it <a href="https://blog.cloudflare.com/how-stacks-are-handled-in-go/">copies stacks</a>. I mentioned that stacks can’t
just be “reallocated” we expect stack data to stay put. But that’s not necessarily true —
because Go has a GC it knows what all the pointers are <em>anyway</em>, and it can rewrite pointers to
stack data on demand.</p>

<p>Either way, Go’s rich runtime lets it handle this stuff well. Goroutines are super cheap, and you can spawn
thousands without your computer having problems.</p>

<p>Rust <em>used</em> to support lightweight/”green” threads (I believe it used segmented stacks). However, Rust cares
a lot about not paying for things you don’t use, and this imposes a penalty on all your code even if you
aren’t using green threads, and it was removed pre-1.0.</p>

<h2 id="async-io">Async I/O</h2>

<p>A core building block of this is Async I/O. As mentioned in the previous section,
with regular blocking I/O, the moment you request I/O your thread will not be allowed to run
(“blocked”) until the operation is done. This is perfect when working with OS threads (the OS
scheduler does all the work for you!), but if you have lightweight threads you instead want to
replace the lightweight thread running on the OS thread with a different one.</p>

<p>Instead, you use non-blocking I/O, where the thread queues a request for I/O with the OS and continues
execution. The I/O request is executed at some later point by the kernel. The thread then needs to ask the
OS “Is this I/O request ready yet?” before looking at the result of the I/O.</p>

<p>Of course, repeatedly asking the OS if it’s done can be tedious and consume resources. This is why
there are system calls like <a href="https://en.wikipedia.org/wiki/Epoll"><code>epoll</code></a>. Here, you can bundle together a bunch of unfinished I/O requests,
and then ask the OS to wake up your thread when <em>any</em> of these completes. So you can have a scheduler
thread (a real thread) that swaps out lightweight threads that are waiting on I/O, and when there’s nothing
else happening it can itself go to sleep with an <code>epoll</code> call until the OS wakes it up (when one of the I/O
requests completes).</p>

<p>(The exact mechanism involved here is probably more complex)</p>

<p>So, bringing this to Rust, Rust has the <a href="https://github.com/carllerche/mio">mio</a> library, which is a platform-agnostic
wrapper around non-blocking I/O and tools like epoll/kqueue/etc. It’s a building block; and while
those used to directly using <code>epoll</code> in C may find it helpful, it doesn’t provide a nice programming
model like Go does. But we can get there.</p>

<h2 id="futures">Futures</h2>

<p>These are another building block. A <a href="https://docs.rs/futures/0.1.17/futures/future/trait.Future.html"><code>Future</code></a> is the promise of eventually having a value
(in fact, in Javascript these are called <code>Promise</code>s).</p>

<p>So for example, you can ask to listen on a network socket, and get a <code>Future</code> back  (actually, a
<code>Stream</code>, which is like a future but for a sequence of values). This <code>Future</code> won’t contain the
response <em>yet</em>, but will know when it’s ready. You can <code>wait()</code> on a <code>Future</code>, which will block
until you have a result, and you can also <code>poll()</code> it, asking it if it’s done yet (it will give you
the result if it is).</p>

<p>Futures can also be chained, so you can do stuff like <code>future.then(|result| process(result))</code>.
The closure passed to <code>then</code> itself can produce another future, so you can chain together
things like I/O operations. With chained futures, <code>poll()</code> is how you make progress; each time
you call it it will move on to the next future provided the existing one is ready.</p>

<p>This is a pretty good abstraction over things like non-blocking I/O.</p>

<p>Chaining futures works much like chaining iterators. Each <code>and_then</code> (or whatever combinator)
call returns a struct wrapping around the inner future, which may contain an additional closure.
Closures themselves carry their references and data with them, so this really ends up being
very similar to a tiny stack!</p>

<h2 id="-tokio-">🗼 Tokio 🗼</h2>

<p>Tokio’s essentially a nice wrapper around mio that uses futures. Tokio has a core
event loop, and you feed it closures that return futures. What it will do is
run all the closures you feed it, use mio to efficiently figure out which futures
are ready to make a step<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote">3</a></sup>, and make progress on them (by calling <code>poll()</code>).</p>

<p>This actually is already pretty similar to what Go was doing, at a conceptual level.
You have to manually set up the Tokio event loop (the “scheduler”), but once you do
you can feed it tasks which intermittently do I/O, and the event loop takes
care of swapping over to a new task when one is blocked on I/O. A crucial difference is
that Tokio is single threaded, whereas the Go scheduler can use multiple OS threads
for execution. However, you can offload CPU-critical tasks onto other OS threads and
use channels to coordinate so this isn’t that big a deal.</p>

<p>While at a conceptual level this is beginning to shape up to be similar to what we had for Go, code-wise this doesn’t look so pretty. For the following Go code:</p>

<pre><code class="language-go">// error handling ignored for simplicity

func foo(...) ReturnType {
    data := doIo()
    result := compute(data)
    moreData = doMoreIo(result)
    moreResult := moreCompute(data)
    // ...
    return someFinalResult
}
</code></pre>

<p>The Rust code will look something like</p>

<pre><code class="language-rust">// error handling ignored for simplicity

fn foo(...) -&gt; Future&lt;ReturnType, ErrorType&gt; {
    do_io().and_then(|data| do_more_io(compute(data)))
          .and_then(|more_data| do_even_more_io(more_compute(more_data)))
    // ......
}
</code></pre>

<p>Not pretty. <a href="https://docs.rs/futures/0.1.25/futures/future/fn.loop_fn.html#examples">The code gets worse if you introduce branches and loops</a>. The problem is that in Go we
got the interruption points for free, but in Rust we have to encode this by chaining up combinators
into a kind of state machine. Ew.</p>

<h2 id="generators-and-asyncawait">Generators and async/await</h2>

<p>This is where generators (also called coroutines) come in.</p>

<p><a href="https://doc.rust-lang.org/nightly/unstable-book/language-features/generators.html">Generators</a> are an experimental feature in Rust. Here’s an example:</p>

<pre><code class="language-rust">let mut generator = || {
    let i = 0;
    loop {
        yield i;
        i += 1;
    }
};
assert_eq!(generator.resume(), GeneratorState::Yielded(0));
assert_eq!(generator.resume(), GeneratorState::Yielded(1));
assert_eq!(generator.resume(), GeneratorState::Yielded(2));
</code></pre>

<p>Functions are things which execute a task and return once. On the other hand, generators
return multiple times; they pause execution to “yield” some data, and can be resumed
at which point they will run until the next yield. While my example doesn’t show this, generators
can also finish executing like regular functions.</p>

<p>Closures in Rust are
<a href="http://huonw.github.io/blog/2015/05/finding-closure-in-rust/">sugar for a struct containing captured data, plus an implementation of one of the <code>Fn</code> traits to make it callable</a>.</p>

<p>Generators are similar, except they implement the <code>Generator</code> trait<sup id="fnref:5" role="doc-noteref"><a href="#fn:5" class="footnote">4</a></sup>, and usually store an enum representing various states.</p>

<p>The <a href="https://doc.rust-lang.org/nightly/unstable-book/language-features/generators.html#generators-as-state-machines">unstable book</a> has some examples on what the generator state machine enum will look like.</p>

<p>This is much closer to what we were looking for! Now our code can look like this:</p>

<pre><code class="language-rust">fn foo(...) -&gt; Future&lt;ReturnType, ErrorType&gt; {
    let generator = || {
        let mut future = do_io();
        let data;
        loop {
            // poll the future, yielding each time it fails,
            // but if it succeeds then move on
            match future.poll() {
                Ok(Async::Ready(d)) =&gt; { data = d; break },
                Ok(Async::NotReady(d)) =&gt; (),
                Err(..) =&gt; ...
            };
            yield future.polling_info();
        }
        let result = compute(data);
        // do the same thing for `doMoreIo()`, etc
    }

    futurify(generator)
}
</code></pre>

<p>where <code>futurify</code> is a function that takes a generator and returns a future which on
each <code>poll</code> call will <code>resume()</code> the generator, and return <code>NotReady</code> until the generator
finishes executing.</p>

<p>But wait, this is even <em>more</em> ugly! What was the point of converting our relatively
clean callback-chaining code into this mess?</p>

<p>Well, if you look at it, this code now looks <em>linear</em>. We’ve converted our callback
code to the same linear flow as the Go code, however it has this weird loop-yield boilerplate
and the <code>futurify</code> function and is overall not very neat.</p>

<p>And that’s where <a href="https://github.com/alexcrichton/futures-await">futures-await</a> comes in. <code>futures-await</code> is a procedural macro that
does the last-mile work of packaging away this boilerplate. It essentially lets you write
the above function as</p>

<pre><code class="language-rust">#[async]
fn foo(...) -&gt; Result&lt;ReturnType, ErrorType&gt; {
    let data = await!(do_io());
    let result = compute(data);
    let more_data = await!(do_more_io());
    // ....
</code></pre>

<p>Nice and clean. Almost as clean as the Go code, just that we have explicit <code>await!()</code> calls. These
await calls are basically providing the same function as the interruption points that Go code
gets implicitly.</p>

<p>And, of course, since it’s using a generator under the hood, you can loop and branch and do whatever
else you want as normal, and the code will still be clean.</p>

<h2 id="tying-it-together">Tying it together</h2>

<p>So, in Rust, futures can be chained together to provide a lightweight stack-like system. With async/await,
you can neatly write these future chains, and <code>await</code> provides explicit interruption points on each I/O operation.
Tokio provides an event loop “scheduler” abstraction, which you can feed async functions to, and under the hood it
uses mio to abstract over low level non-blocking I/O primitives.</p>

<p>These are components which can be used independently — you can use tokio with futures without
using async/await. You can use async/await without using Tokio. For example, I think this would be
useful for Servo’s networking stack. It doesn’t need to do <em>much</em> parallel I/O (not at the order
of thousands of threads), so it can just use multiplexed OS threads. However, we’d still want
to pool threads and pipeline data well, and async/await would help here.</p>

<p>Put together, all these components get something almost as clean as the Go stuff, with a little more
explicit boilerplate. Because generators (and thus async/await) play nice with the borrow checker
(they’re just enum state machines under the hood), Rust’s safety guarantees are all still in play,
and we get to have “fearless concurrency” for programs having a huge quantity of I/O bound tasks!</p>

<p><em>Thanks to Arshia Mufti, Steve Klabnik, Zaki Manian, and Kyle Huey for reviewing drafts of this post</em></p>
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>Note that this isn’t necessarily true for <em>all</em> network server applications. For example, Apache uses OS threads. OS threads are often the best tool for the job. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>Lightweight threading is also often called M:N threading (also “green threading”) <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>In general future combinators aren’t really aware of tokio or even I/O, so there’s no easy way to ask a combinator “hey, what I/O operation are you waiting for?”. Instead, with Tokio you use special I/O primitives that still provide futures but also register themselves with the scheduler in thread local state. This way when a future is waiting for I/O, Tokio can check what the recentmost I/O operation was, and associate it with that future so that it can wake up that future again when <code>epoll</code> tells it that that I/O operation is ready. (<em>Edit Dec 2018: This has changed, futures now have a built in <code>Waker</code> concept that handles passing things up the stack</em>) <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:5" role="doc-endnote">
      <p>The <code>Generator</code> trait has a <code>resume()</code> function which you can call multiple times, and each time it will return any yielded data or tell you that the generator has finished running. <a href="#fnref:5" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Rust in 2018]]></title>
    <link href="http://manishearth.github.io/blog/2018/01/10/rust-in-2018/"/>
    <updated>2018-01-10T00:00:00+00:00</updated>
    <id>http://manishearth.github.io/blog/2018/01/10/rust-in-2018</id>
    <content type="html"><![CDATA[<p>A week ago <a href="https://blog.rust-lang.org/2018/01/03/new-years-rust-a-call-for-community-blogposts.html">we put out a call for blog posts for what folks think Rust should do in 2018</a>.</p>

<p>This is mine.</p>

<h2 id="overall-focus">Overall focus</h2>

<p>I think 2017 was a great year for Rust. Near the beginning of the year, after custom derive
and a bunch of things stabilized, I had a strong feeling that Rust was “complete”. Not really “finished”,
there’s still tons of stuff to improve, but this was the first time stable Rust was the language
I wanted it to be, and was something I could recommend for most kinds of work without reservations.</p>

<p>I think this is a good signal to wind down the frightening pace of new features Rust has been getting.
And that happened! We had the impl period, which took some time to focus on <em>getting things done</em> before
proposing new things. And Rust is feeling more polished than ever.</p>

<p>Like <a href="https://www.ncameron.org/blog/rust-2018/">Nick</a>, I feel like 2018 should be boring. I feel like we should focus on polishing what
we have, implementing all the things, and improving our approachability as a language.</p>

<p>Basically, I want to see this as an extended impl period.</p>

<p>This doesn’t mean I’m looking for a moratorium on RFCs, really. Hell, in the past few days I’ve posted
one pre-pre-RFC<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">1</a></sup>, one pre-RFC, and one RFC (from the pre-RFC). I’m mostly looking for <em>prioritizing</em> impl
work over designing new things, but still having <em>some</em> focus on design.</p>

<h2 id="language">Language</h2>

<p>I think Rust still has some “missing bits” which make it hard to justify for some use cases. Rust’s
async story is being fleshed out. We don’t yet have stable SIMD or stable inline ASM. The microcontroller
story is kinda iffy. RLS/clippy need nightly. I’d like to see these crystallize and stabilize this year.</p>

<p>I think this year we need to continue to take a critical look at Rust’s ergonomics. Last year the
ergonomics initiative was really good for Rust, and I’d like to see more of that. This is kind of at
odds with my “focus on polishing Rust” statement, but fixing ergonomics is not just new features. It’s
also about figuring out barriers in Rust, polishing mental models, improving docs/diagnostics, and in
general figuring out how to best present Rust’s features. Starting dialogues about confusing bits of
the language and figuring out the best mental model to present them with is something we should
continue doing. Sometimes this may need new features, indeed, but not always. We must continue
to take a critical look at how our language presents itself to newcomers.</p>

<h2 id="community">Community</h2>

<p>I’d like to see a stronger focus on mentoring. Mentoring on rustc, mentoring on major libraries, mentoring on
Rust tooling, mentoring everywhere. This includes not just the mentors, but the associated infrastructure –
contribution docs, sites like <a href="http://starters.servo.org/">servo-starters</a> and <a href="https://www.rustaceans.org/findwork">findwork</a>, and similar tooling.</p>

<p>I’m also hoping for more companies to invest back into Rust. This year <a href="http://buoyant.io/">Buoyant</a> became pretty well
known within the community, and many of their employees are paid to work on various important parts
of the Rust ecosystem. There are also multiple consulting groups that contribute to the ecosystem.
It’s nice to see that “paid to work on Rust” is no longer limited to Mozilla, and this is crucial
for the health of the language. I hope this trend continues.</p>

<p>Finally, I want to see more companies <em>talk</em> about Rust. Success stories are really nice to hear.
I’ve heard many amazing success stories this year, but a lot of them are things which can’t be shared.</p>

<h2 id="governance">Governance</h2>

<p>Last year we started seeing the limits of the RFC process. Large RFCs were stressful for both the RFC authors
and participating community members, and rather opaque for newer community members wishing to participate.
Alternative models have been discussed; I’d like to see more movement on this front.</p>

<p>I’d also like to grow the moderation team; it is currently rather small and doesn’t have the capacity to handle
incidents in a timely fashion.</p>

<h2 id="docs--learning">Docs / Learning</h2>

<p>I’d like to see a focus on improving Rust for folks who learn the language by <em>trying things</em> over reading books <sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote">2</a></sup> <sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote">3</a></sup>.</p>

<p>This means better diagnostics, better alternative resources like rustbyexample, etc. Improving mentorship helps here
as well.</p>

<p>Of course, I’d like to see our normal docs work continue to happen.</p>

<hr />

<p>I’m overall really excited for 2018. I think we’re doing great on most fronts so far, and if we
maintain the momentum we’ll have an even-more-awesome Rust by the end of this year!</p>
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>This isn’t a “pre rfc” because I’ve written it as a much looser sketch of the problem and a solution <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>There is literally no programming language I’ve personally learned through a book or formal teaching. I’ve often read books after I know a language because it’s fun and instructive, but it’s always started out as “learn extreme basics” followed by “look at existing code, tweak stuff, and write your own code”. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>Back in <em>my</em> day Rust didn’t have a book, just this tiny thing called “The Tutorial”. <em>grouches incessantly</em> <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Undefined vs Unsafe in Rust]]></title>
    <link href="http://manishearth.github.io/blog/2017/12/24/undefined-vs-unsafe-in-rust/"/>
    <updated>2017-12-24T00:00:00+00:00</updated>
    <id>http://manishearth.github.io/blog/2017/12/24/undefined-vs-unsafe-in-rust</id>
    <content type="html"><![CDATA[<p>Recently Julia Evans wrote an <a href="https://jvns.ca/blog/2017/12/23/segfault-debugging/">excellent post</a> about debugging a segfault in Rust. (Go read it, it’s good)</p>

<p>One thing it mentioned was</p>

<blockquote>
  <p>I think “undefined” and “unsafe” are considered to be synonyms.</p>
</blockquote>

<p>This is … incorrect. However, we in the Rust community have never really explicitly outlined the
distinction, so that confusion is on us! This blog post is an attempt to clarify the difference of
terminology as used within the Rust community. It’s a very useful but subtle distinction and I feel we’d be
able to talk about safety more expressively if this was well known.</p>

<h2 id="unsafe-means-two-things-in-rust-yay">Unsafe means two things in Rust, yay</h2>

<p>So, first off, the waters are a bit muddied by the fact that Rust uses <code>unsafe</code> to both mean “within
an <code>unsafe {}</code> block” and “something Bad is happening here”. It’s possible to have safe code
within an <code>unsafe</code> block; indeed this is the <em>primary function</em> of an <code>unsafe</code> block. Somewhat
counterintutively, the <code>unsafe</code> block’s purpose is to actually tell the compiler “I know you don’t
like this code but trust me, it’s safe!” (where “safe” is the negation of the <em>second</em> meaning of “unsafe”,
i.e. “something Bad is not happening here”).</p>

<p>Similarly, we use “safe code” to mean “code not using <code>unsafe{}</code> blocks” but also “code that is not unsafe”,
i.e. “code where nothing bad happens”.</p>

<p>This blog post is primarily about the “something bad is happening here” meaning of “unsafe”. When referring
to the other kind I’ll specifically say “code within <code>unsafe</code> blocks” or something like that.</p>

<h2 id="undefined-behavior">Undefined behavior</h2>

<p>In languages like C, C++, and Rust, undefined behavior is when you reach a point where
the compiler is allowed to do anything with your code. This is distinct from implementation-defined
behavior, where usually a given compiler/library will do a deterministic thing, however they have some
freedom from the spec in deciding what that thing is.</p>

<p>Undefined behavior can be pretty scary. This is usually because in practice it causes problems when
the compiler assumes “X won’t happen because it is undefined behavior”, and X ends up happening,
breaking the assumptions. In some cases this does nothing dangerous, but often the compiler will
end up doing wacky things to your code. Dereferencing a null pointer will <em>sometimes</em> cause segfaults
(which is the compiler generating code that actually dereferences the pointer, making the kernel
complain), but sometimes it will be optimized in a way that assumes it won’t and moves around code
such that you have major problems.</p>

<p>Undefined behavior is a global property, based on how your code is <em>used</em>. The following function
in C++ or Rust may or may not exhibit undefined behavior, based on how it gets used:</p>

<pre><code class="language-cpp">int deref(int* x) {
    return *x;
}
</code></pre>

<pre><code class="language-rust">// do not try this at home
fn deref(x: *mut u32) -&gt; u32 {
    unsafe { *x }
}
</code></pre>

<p>As long as you always call it with a valid pointer to an integer, there is no undefined behavior
involved.</p>

<p>But in either language, if you use it with some pointer conjured out of thin air (like <code>0x01</code>), that’s
probably undefined behavior.</p>

<p>As it stands, UB is a property of the entire program and its execution. Sometimes you may have snippets of code
that will always exhibit undefined behavior regardless of how they are called, but in general UB
is a global property.</p>

<h2 id="unsafe-behavior">Unsafe behavior</h2>

<p>Rust’s concept of “unsafe behavior” (I’m coining this term because “unsafety” and “unsafe code” can
be a bit confusing) is far more scoped. Here, <code>fn deref</code> <em>is</em> “unsafe”<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">1</a></sup>, even if you <em>always</em>
call it with a valid pointer. The reason it is still unsafe is because it’s possible to trigger UB by only
changing the “safe” caller code. I.e. “changes to code outside unsafe blocks can trigger UB if they include
calls to this function”.</p>

<p>Basically, in Rust a bit of code is “safe” if it cannot exhibit undefined behavior under all circumstances of
that code being used. The following code exhibits “safe behavior”:</p>

<pre><code class="language-rust">unsafe {
    let x = 1;
    let raw = &amp;x as *const u32;
    println!("{}", *raw);
}
</code></pre>

<p>We dereferenced a raw pointer, but we knew it was valid. Of course, actual <code>unsafe</code> blocks will
usually be “actually totally safe” for less obvious reasons, and part of this is because
<a href="https://doc.rust-lang.org/nomicon/working-with-unsafe.html#working-with-unsafe"><code>unsafe</code> blocks sometimes can pollute the entire module</a>.</p>

<p>Basically, “safe” in Rust is a more local property. Code isn’t safe just because you only use it in
a way that doesn’t trigger UB, it is safe because there is literally <em>no way to use it such that it
will do so</em>. No way to do so without using <code>unsafe</code> blocks, that is<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote">2</a></sup>.</p>

<p>This is a distinction that’s <em>possible</em> to draw in Rust because it gives us the ability
to compartmentalize safety. Trying to apply this definition to C++ is problematic; you can
ask “is <code>std::unique_ptr&lt;T&gt;</code> safe?”, but you can <em>always</em> use it within code in a way that you trigger
undefined behavior, because C++ does not have the tools for compartmentalizing safety. The distinction
between “code which doesn’t need to worry about safety” and “code which does need to worry about safety”
exists in Rust in the form of “code outside of <code>unsafe {}</code>” and “code within <code>unsafe {}</code>”, whereas in
C++ it’s a lot fuzzier and based on expectations (and documentation/the spec).</p>

<p>So C++’s <code>std::unique_ptr&lt;T&gt;</code> is “safe” in the sense that it does what you expect but
if you use it in a way counter to how it’s <em>supposed</em> to be used (constructing one from an invalid pointer, for example)
it can blow up. This is still a useful sense of safety, and is how one regularly reasons about safety in C++. However it’s not
the same sense of the term as used in Rust, which can be a bit more formal about what the expectations
actually are.</p>

<p>So <code>unsafe</code> in Rust is a strictly more general concept – all code exhibiting undefined behavior in Rust is also “unsafe”,
however not all “unsafe” code in Rust exhibits undefined behavior as written in the current program.</p>

<p>Rust furthermore attempts to guarantee that you will not trigger undefined behavior if you do not use <code>unsafe {}</code> blocks.
This of course depends on the correctness of the compiler (it has bugs) and of the libraries you use (they may also have bugs)
but this compartmentalization gets you most of the way there in having UB-free programs.</p>
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>Once again in we have a slight difference between an “<code>unsafe fn</code>”, i.e. a function that needs an <code>unsafe</code> block to call and probably is unsafe, and an “unsafe function”, a function that exhibits unsafe behavior. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>This caveat and the confusing dual-usage of the term “safe” lead to the rather tautological-sounding sentence “Safe Rust code is Rust code that cannot cause undefined behavior when used in safe Rust code” <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Font-size: An Unexpectedly Complex CSS Property]]></title>
    <link href="http://manishearth.github.io/blog/2017/08/10/font-size-an-unexpectedly-complex-css-property/"/>
    <updated>2017-08-10T00:00:00+00:00</updated>
    <id>http://manishearth.github.io/blog/2017/08/10/font-size-an-unexpectedly-complex-css-property</id>
    <content type="html"><![CDATA[<p><a href="https://developer.mozilla.org/en/docs/Web/CSS/font-size"><code>font-size</code></a> is the worst.</p>

<p>It’s a CSS property probably everyone who writes CSS has used at some point. It’s pretty ubiquitous.</p>

<p>And it’s <em>super</em> complicated.</p>

<p>“But it’s just a number”, you say. “How can that be complicated?”</p>

<p>I too felt that way one time. And then I worked on implementing it for <a href="https://wiki.mozilla.org/Quantum/Stylo">stylo</a>.</p>

<p>Stylo is the project to integrate <a href="http://github.com/servo/servo/">Servo</a>’s styling system into Firefox. The styling system handles
parsing CSS, determining which rules apply to which elements, running this through the cascade,
and eventually computing and assigning styles to individual elements in the tree. This happens not
only on page load, but also whenever various kinds of events (including DOM manipulation) occur,
and is a nontrivial portion of pageload and interaction times.</p>

<p>Servo is in <a href="https://rust-lang.org">Rust</a>, and makes use of Rust’s safe parallelism in many places, one of them being
styling. Stylo has the potential to bring these speedups into Firefox, along with the added safety
of the code being in a safer systems language.</p>

<p>Anyway, as far as the styling system is concerned, I believe that font-size is the most complex
property it has to handle. Some properties may be more complicated when it comes to layout or
rendering, but font-size is probably the most complex one in the department of styling.</p>

<p>I’m hoping this post can give an idea of how complex the Web can <em>get</em>, and also serve as documentation
for some of these complexities. I’ll also try to give an idea of how the styling system works throughout this post.</p>

<p>Alright. Let’s see what is so complex about font-size.</p>

<h2 id="the-basics">The basics</h2>

<p>The syntax of the property is pretty straightforward. You can specify it as:</p>

<ul>
  <li>A length (<code>12px</code>, <code>15pt</code>, <code>13em</code>, <code>4in</code>, <code>8rem</code>)</li>
  <li>A percentage (<code>50%</code>)</li>
  <li>A compound of the above, via a calc (<code>calc(12px + 4em + 20%)</code>)</li>
  <li>An absolute keyword (<code>medium</code>, <code>small</code>, <code>large</code>, <code>x-large</code>, etc)</li>
  <li>A relative keyword (<code>larger</code>, <code>smaller</code>)</li>
</ul>

<p>The first three are common amongst quite a few length-related properties. Nothing abnormal in the syntax.</p>

<p>The next two are interesting. Essentially, the absolute keywords map to various pixel values, and match
the result of <code>&lt;font size=foo&gt;</code> (e.g. <code>size=3</code> is the same as <code>font-size: medium</code>). The <em>actual</em> value they map to
is not straightforward, and I’ll get to that later in this post.</p>

<p>The relative keywords basically scale the size up or down. The mechanism of the scaling was also complex, however
this has changed. I’ll get to that too.</p>

<h2 id="em-and-rem-units">em and rem units</h2>

<p>First up: <code>em</code> units. One of the things you can specify in <em>any</em> length-based CSS property is a value with an <code>em</code> or <code>rem</code>
unit.</p>

<p><code>5em</code> means “5 times the <code>font-size</code> of the element this is applied to”. <code>5rem</code> means “5 times the font-size of the root element”</p>

<p>The implications of this are that font-size needs to be computed before all the other properties (well, not quite, but we’ll get to that!)
so that it is available during that time.</p>

<p>You can also use <code>em</code> units within <code>font-size</code> itself. In this case, it computed relative to the font-size of the <em>parent</em> element, since
you can’t use the font-size of the element to compute itself. (This is identical to using a percentage unit)</p>

<h2 id="minimum-font-size">Minimum font size</h2>

<p>Browsers let you set a “minimum” font size in their preferences, and text will not be scaled below it. It’s useful for those with
trouble seeing small text.</p>

<p>However, this doesn’t affect properties which depend on font-size via <code>em</code> units. So if you’re using a minimum font size,
<code>&lt;div style="font-size: 1px; height: 1em; background-color: red"&gt;</code> will have a very tiny height (which you’ll notice from the color),
but the text will be clamped to the minimum size.</p>

<p>What this effectively means is that you need to keep track of <em>two</em> separate computed font size values. There’s one value that
is used to actually determine the font size used for the text, and one value that is used whenever the style system needs to
know the font-size (e.g. to compute an <code>em</code> unit.)</p>

<p>This gets slightly more complicated when <a href="https://en.wikipedia.org/wiki/Ruby_character">ruby</a> is involved. In ideographic scripts (usually, Han
and Han-based scripts like Kanji or Hanja) it’s sometimes useful to have the pronunciation
of each character above it in a phonetic script, for the aid of readers without proficiency in that
script, and this is known as “ruby” (“furigana” in Japanese). Because these scripts are ideographic,
it’s not uncommon for learners to know the pronunciation of a word but have no idea how to write it.
An example would be <ruby><rb>日</rb><rt>に</rt><rb>本</rb><rt>ほん</rt></ruby>, which is 日本 (“nihon”,
i.e. “Japan”) in Kanji with ruby にほん in the phonetic Hiragana script above it.</p>

<p>As you can probably see, the phonetic ruby text is in a smaller font size (usually 50% of the font
size of the main text<sup id="fnref:5" role="doc-noteref"><a href="#fn:5" class="footnote">1</a></sup>). The minimum font-size support <em>respects</em> this, and ensures that if the ruby
is supposed to be <code>50%</code> of the size of the text, the minimum font size for the ruby is <code>50%</code> of the
original minimum font size. This avoids clamped text from looking like <ruby><rb>日</rb><rt style="font-size: 1em">に</rt><rb>本</rb><rt style="font-size: 1em">ほん</rt></ruby> (where both get set to
the same size), which is pretty ugly.</p>

<h2 id="text-zoom">Text zoom</h2>

<p>Firefox additionally lets you zoom text only when zooming. If you have trouble reading small things, it’s great to
be able to just blow up the text on the page without having the whole page get zoomed (which means you need to scroll
around a lot).</p>

<p>In this case, <code>em</code> units of other properties <em>do</em> get zoomed as well. After all, they’re supposed to be relative to the text’s font
size (and may have some relation to the text), so if that size has changed so should they.</p>

<p>(Of course, that argument could also apply to the min font size stuff. I don’t have an answer for why it doesn’t.)</p>

<p>This is actually pretty straightforward to implement. When computing absolute font sizes (including
keywords), zoom them if text zoom is on. For everything else continue as normal.</p>

<p>Text zoom is also disabled within <code>&lt;svg:text&gt;</code> elements, which leads to some trickiness here.</p>

<h2 id="interlude-how-the-style-system-works">Interlude: How the style system works</h2>

<p>Before I go ahead it’s probably worth giving a quick overview of how everything works.</p>

<p>The responsibiltiy of a style system is to take in CSS code and a DOM tree, and assign computed styles to each element.</p>

<p>There’s a distinction between “specified” and “computed” here. “specified” styles are in the format
you specify in CSS, whereas computed styles are those that get attached to the elements, sent to
layout, and inherited from. A given specified style may compute to different values when applied to
different elements.</p>

<p>So while you can <em>specify</em> <code>width: 5em</code>, it will compute to something like <code>width: 80px</code>. Computed values are usually a
cleaned up form of the specified value.</p>

<p>The style system will first parse the CSS, producing a bunch of rules usually containing declarations (a declaration is like <code>width: 20%;</code>; i.e. a property name and a specified value)</p>

<p>It then goes through the tree in top-down order (this is parallelized in Stylo), figuring out which declarations <em>apply</em> to each element
and in which order – some declarations have precedence over others. Then it will compute each relevant declaration against the element’s style (and parent style, among other bits of info),
and store this value in the element’s “computed style”.</p>

<p>There are a bunch of optimizations that Gecko and Servo do here to avoid duplicated work<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">2</a></sup>. There’s a
bloom filter for quickly checking if deep descendent selectors apply to a subtree. There’s a “rule
tree” that helps cache effort from determining applicable declarations. Computed styles are
reference counted and shared very often (since the default state is to inherit from the parent or
from the default style).</p>

<p>But ultimately, this is the gist of what happens.</p>

<h2 id="keyword-values">Keyword values</h2>

<p>Alright, this is where it gets complicated.</p>

<p>Remember when I said <code>font-size: medium</code> was a thing that mapped to a value?</p>

<p>So what does it map to?</p>

<p>Well, it turns out, it depends on the font family. For the following HTML:</p>

<pre><code class="language-html">&lt;span style="font: medium monospace"&gt;text&lt;/span&gt;
&lt;span style="font: medium sans-serif"&gt;text&lt;/span&gt;
</code></pre>

<p>you get (<a href="https://codepen.io/anon/pen/RZgxjw">codepen</a>)</p>

<div style="border: 1px solid black; display: inline-block; padding: 15px;">
<span style="font: medium monospace">text</span>
<span style="font: medium sans-serif">text</span>
</div>

<p>where the first one computes to a font-size of 13px, and the second one computes to a font-size of
16px. You can check this in the computed style pane of your devtools, or by using
<code>getComputedStyle()</code>.</p>

<p>I <em>think</em> the reason behind this is that monospace fonts tend to be wider, so the default font size (medium)
is scaled so that they have similar widths, and all other keyword font sizes get shifted as well. The final result is something like this:</p>

<p><img class="center" src="http://manishearth.github.io/images/post/font-size-table.png" width="600" /></p>

<p>Firefox and Servo have <a href="https://github.com/servo/servo/blob/d415617a5bbe65a73bd805808a7ac76f38a1861c/components/style/properties/longhand/font.mako.rs#L763-L774">a matrix</a> that helps derive the values for all the absolute
font-size keywords based on the “base size” (i.e. the computed of <code>font-size: medium</code>). Actually,
Firefox has <a href="http://searchfox.org/mozilla-central/rev/c329d562fb6c6218bdb79290faaf015467ef89e2/layout/style/nsRuleNode.cpp#3272-3341">three tables</a> to support some legacy use cases like quirks mode (Servo has
yet to add support for these tables). We query other parts of the browser for what the “base size”
is based on the language and font family.</p>

<p>Wait, but what does the language have to do with this anyway? How does the language impact font-size?</p>

<p>It turns out that the base size depends on the font family <em>and</em> the language, and you can configure this.</p>

<p>Both Firefox and Chrome (using an extension) actually let you tweak which fonts get used on a per-language basis,
<em>as well as the default (base) font-size</em>.</p>

<p>This is not as obscure as one might think. Default system fonts are often really ugly for non-Latin-
using scripts. I have a separate font installed that produces better-looking Devanagari ligatures.</p>

<p>Similarly, some scripts are just more intricate than Latin. My default font size for Devanagari is
set to 18 instead of 16. I’ve started learning Mandarin and I’ve set that font size to 18 as well. Hanzi glyphs
can get pretty complicated and I still struggle to learn (and later recognize) them. A larger font size is great for this.</p>

<p>Anyway, this doesn’t complicate things too much.  This does mean that the font family needs to be
computed before font-size, which already needs to be computed before most other properties. The
language, which can be set using a <code>lang</code> HTML attribute, is internally treated as a CSS property by
Firefox since it inherits, and it must be computed earlier as well.</p>

<p>Not too bad. So far.</p>

<p>Now here’s the kicker. This <em>dependence</em> on the language and family <em>inherits</em>.</p>

<p>Quick, what’s the font-size of the inner <code>div</code>?</p>

<pre><code class="language-html">&lt;div style="font-size: medium; font-family: sans-serif;"&gt; &lt;!-- base size 16 --&gt;
    font size is 16px
    &lt;div style="font-family: monospace"&gt; &lt;!-- base size 13 --&gt;
        font size is ??
    &lt;/div&gt;
&lt;/div&gt;
</code></pre>

<p>For a normal inherited CSS property<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote">3</a></sup>, if the parent has a computed value of <code>16px</code>,
and the child has no additional values specified, the child will inherit a value of <code>16px</code>.
<em>Where</em> the parent got that computed value from doesn’t matter.</p>

<p>Here, <code>font-size</code> “inherits” a value of <code>13px</code>. You can see this below (<a href="https://codepen.io/anon/pen/MvorQQ">codepen</a>):</p>

<div style="border: 1px solid black; display: inline-block; padding: 15px;">
<div style="font-size: medium; font-family: sans-serif;"> <!-- base size 16 -->
    font size is 16px
    <div style="font-family: monospace"> <!-- base size 13 -->
        font size is ??
    </div>
</div>
</div>

<p>Basically, if the computed value originated from a keyword, whenever the font family or language
change, font-size is recomputed from the original keyword with the new font family and language.</p>

<p>The reason this exists is because otherwise the differing font sizes wouldn’t work anyway! The default font size
is <code>medium</code>, so basically the root element gets a <code>font-size: medium</code> and all elements inherit from it. If you change
to monospace or a different language in the document you need the font-size recomputed.</p>

<p>But it doesn’t stop here. This even inherits <em>through relative units</em> (Not in IE).</p>

<pre><code class="language-html">&lt;div style="font-size: medium; font-family: sans-serif;"&gt; &lt;!-- base size 16 --&gt;
    font size is 16px
    &lt;div style="font-size: 0.9em"&gt; &lt;!-- could also be font-size: 50%--&gt;
        font size is 14.4px (16 * 0.9)
        &lt;div style="font-family: monospace"&gt; &lt;!-- base size 13 --&gt;
            font size is 11.7px! (13 * 0.9)
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
</code></pre>

<p>(<a href="https://codepen.io/anon/pen/oewpER">codepen</a>)</p>

<div style="border: 1px solid black; display: inline-block; padding: 15px;">
<div style="font-size: medium; font-family: sans-serif;"> <!-- base size 16 -->
    font size is 16px
    <div style="font-size: 0.9em"> <!-- could also be font-size: 90%-->
        font size is 14.4px (16 * 0.9)
        <div style="font-family: monospace"> <!-- base size 13 -->
            font size is 11.7px! (13 * 0.9)
        </div>
    </div>
</div>
</div>

<p>So we’re actually inheriting a font-size of <code>0.9*medium</code> when we inherit from the second div, not <code>14.4px</code>.</p>

<p>Another way of looking at it is whenever the font family or language changes, you should recompute the font-size as if the language and family <em>were always that way</em> up the tree.</p>

<p>Firefox code uses both of these strategies. The original Gecko style system handles this by actually
going back to the top of the tree and recalculating the font size as if the language/family were
different. I suspect this is inefficient, but the rule tree seems to be involved in making this slightly
more efficient</p>

<p>Servo, on the other hand, stores some extra data on the side when computing stuff, data which gets copied over to the child element. It basically
stores the equivalent of saying “Yes, this font was computed from a keyword. The keyword was <code>medium</code>, and after that we applied a factor of 0.9 to it.”<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote">4</a></sup></p>

<p>In both cases, this leads to a bunch of complexities in all the <em>other</em> font-size complexities, since they need to be carefully preserved through this.</p>

<p>In Servo, <em>most</em> of this gets handled <a href="https://github.com/servo/servo/blob/53c6f8ea8bf1002d0c99c067601fe070dcd6bcf1/components/style/properties/longhand/font.mako.rs#L964-L1061">via custom cascading functions for font-size</a>.</p>

<h2 id="largersmaller">Larger/smaller</h2>

<p>So I mentioned that <code>font-size: larger</code> and <code>smaller</code> scale the size, but didn’t mention by what fraction.</p>

<p>According <a href="https://drafts.csswg.org/css-fonts-3/#relative-size-value">to the spec</a>, if the font-size currently matches the value of an absolute keyword size (medium/large/etc),
you should pick the value of the next/previous keyword sizes respectively.</p>

<p>If it is <em>between</em> two, find the same point between the next/previous two sizes.</p>

<p>This, of course, must play well with the weird inheritance of keyword font sizes mentioned before. In Gecko’s model this isn’t too hard,
since Gecko recalculates things anyway. In Servo’s model we’d have to store a sequence of applications of <code>larger</code>/<code>smaller</code> and relative
units, instead of storing just a relative unit.</p>

<p>Additionally, when computing this during text-zoom, you have to unzoom before looking it up in the table, and then rezoom.</p>

<p>Overall, a bunch of complexity for not much gain — turns out only Gecko actually followed the spec here! All other browser engines
used simple ratios here.</p>

<p>So my fix here <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1361550">was simply to remove this behavior from Gecko</a>. That simplified things.</p>

<h2 id="mathml">MathML</h2>

<p>Firefox and Safari support MathML, a markup language for math. It doesn’t get used much on the Web these days, but it exists.</p>

<p>MathML has its own complexities when it comes to font-size. Specifically, <code>scriptminsize</code>, <code>scriptlevel</code>, and <code>scriptsizemultiplier</code>.</p>

<p>For example, in MathML, the text in the numerator or denominator of a fraction or the text of a superscript is 0.71 times the size of the text outside of it. This is because
the default <code>scriptsizemultiplier</code> for MathML elements is 0.71, and these specific elements all get a default scriptlevel of <code>+1</code>.</p>

<p>Basically, <code>scriptlevel=+1</code> means “multiply the font size by <code>scriptsizemultiplier</code>”, and
<code>scriptlevel=-1</code> is for dividing. This can be specified via a <code>scriptlevel</code> HTML attribute on an <code>mstyle</code> element. You can
similarly tweak the (inherited) multiplier via the <code>scriptsizemultiplier</code> HTML attribute, and the minimum size via <code>scriptminsize</code>.</p>

<p>So, for example:</p>

<pre><code class="language-html">&lt;math&gt;&lt;msup&gt;
    &lt;mi&gt;text&lt;/mi&gt;
    &lt;mn&gt;small superscript&lt;/mn&gt;
&lt;/msup&gt;&lt;/math&gt;&lt;br&gt;
&lt;math&gt;
    text
    &lt;mstyle scriptlevel=+1&gt;
        small
        &lt;mstyle scriptlevel=+1&gt;
            smaller
            &lt;mstyle scriptlevel=-1&gt;
                small again
            &lt;/mstyle&gt;
        &lt;/mstyle&gt;
    &lt;/mstyle&gt;
&lt;/math&gt;
</code></pre>

<p>will show as (you will need Firefox to see the rendered version, Safari supports MathML too but the support isn’t as good):</p>

<div style="border: 1px solid black; display: inline-block; padding: 15px;">
<math><msup><mi>text</mi><mn>small superscript</mn></msup></math><br />
<math>text&lt;mstyle scriptlevel=+1&gt; small &lt;mstyle scriptlevel=+1&gt; smaller &lt;mstyle scriptlevel=-1&gt; small again &lt;/mstyle&gt;&lt;/mstyle&gt;&lt;/mstyle&gt;</math>
</div>

<p>(<a href="https://codepen.io/anon/pen/BdZJgR">codepen</a>)</p>

<p>So this isn’t as bad. It’s as if <code>scriptlevel</code> is a weird <code>em</code> unit. No biggie, we know how to deal with those already.</p>

<p>Except you also have <code>scriptminsize</code>. This lets you set the minimum font size <em>for changes caused by <code>scriptlevel</code></em>.</p>

<p>This means that <code>scriptminsize</code> will make sure <code>scriptlevel</code> never causes changes that make the font smaller than the min size,
but it will ignore cases where you deliberately specify an <code>em</code> unit or a pixel value.</p>

<p>There’s already a subtle bit of complexity introduced here, <code>scriptlevel</code> now becomes another thing
that tweaks how <code>font-size</code> inherits. Fortunately, in Firefox/Servo internally <code>scriptlevel</code> (as are
<code>scriptminsize</code> and <code>scriptsizemultiplier</code>) is also handled as a CSS property, which means that we
can use the same framework we used for font-family and language here – compute the script
properties before font-size, and if <code>scriptlevel</code> is set, force-recalculate the font size even if
font-size itself was not set.</p>

<h3 id="interlude-early-and-late-computed-properties">Interlude: early and late computed properties</h3>

<p>In Servo the way we handle dependencies in properties is to have a set of “early” properties and a
set of “late” properties (which are allowed to depend on early properties). We iterate the
declarations twice, once looking for early properties, and once for late. However, now we have a
pretty intricate set of dependencies, where font-size must be calculated after language, font-family,
and the script properties, but before everything else that involves lengths. Additionally, font-family
has to be calculated after all the other early properties due to another font complexity I’m not covering here.</p>

<p>The way we handle this is to <a href="https://github.com/servo/servo/blob/53c6f8ea8bf1002d0c99c067601fe070dcd6bcf1/components/style/properties/properties.mako.rs#L3195-L3204">pull font-size and font-family</a> out during the early computation,
but not deal with them until <a href="https://github.com/servo/servo/blob/53c6f8ea8bf1002d0c99c067601fe070dcd6bcf1/components/style/properties/properties.mako.rs#L3211-L3327">after the early computation is done</a>.</p>

<p>At that stage we first <a href="https://github.com/servo/servo/blob/53c6f8ea8bf1002d0c99c067601fe070dcd6bcf1/components/style/properties/properties.mako.rs#L3219-L3233">handle the disabling of text-zoom</a>, and then handle <a href="https://github.com/servo/servo/blob/53c6f8ea8bf1002d0c99c067601fe070dcd6bcf1/components/style/properties/properties.mako.rs#L3235-L3277">the complexities of font-family</a>.</p>

<p>We then <a href="https://github.com/servo/servo/blob/53c6f8ea8bf1002d0c99c067601fe070dcd6bcf1/components/style/properties/properties.mako.rs#L3280-L3303">compute the font family</a>. If a font size was specified, we <a href="https://github.com/servo/servo/blob/53c6f8ea8bf1002d0c99c067601fe070dcd6bcf1/components/style/properties/properties.mako.rs#L3305-L3309">just compute that</a>. If it
was not, but a font family, lang, or scriptlevel was specified, we <a href="https://github.com/servo/servo/blob/53c6f8ea8bf1002d0c99c067601fe070dcd6bcf1/components/style/properties/properties.mako.rs#L3310-L3324">force compute as inherited</a>, which handles all the constraints.</p>

<h3 id="why-scriptminsize-gets-complicated">Why scriptminsize gets complicated</h3>

<p>Unlike with the other “minimum font size”, using an <code>em</code> unit in any property will calculate the
length with the clamped value, not the “if nothing had been clamped” value, when the font size has
been clamped with scriptminsize. So at first glance handling this seems straightforward; only
consider the script min size when deciding to scale because of scriptlevel.</p>

<p>As always, it’s not that simple 😀:</p>

<pre><code class="language-html">&lt;math&gt;
&lt;mstyle scriptminsize="10px" scriptsizemultiplier="0.75" style="font-size:20px"&gt;
    20px
    &lt;mstyle scriptlevel="+1"&gt;
        15px
        &lt;mstyle scriptlevel="+1"&gt;
            11.25px
                &lt;mstyle scriptlevel="+1"&gt;
                    would be 8.4375, but is clamped at 10px
                        &lt;mstyle scriptlevel="+1"&gt;
                            would be 6.328125, but is clamped at 10px
                                &lt;mstyle scriptlevel="-1"&gt;
                                    This is not 10px/0.75=13.3, rather it is still clamped at 10px
                                        &lt;mstyle scriptlevel="-1"&gt;
                                            This is not 10px/0.75=13.3, rather it is still clamped at 10px
                                            &lt;mstyle scriptlevel="-1"&gt;
                                                This is 11.25px again
                                                    &lt;mstyle scriptlevel="-1"&gt;
                                                        This is 15px again
                                                    &lt;/mstyle&gt;
                                            &lt;/mstyle&gt;
                                        &lt;/mstyle&gt;
                                &lt;/mstyle&gt;
                        &lt;/mstyle&gt;
                &lt;/mstyle&gt;
        &lt;/mstyle&gt;
    &lt;/mstyle&gt;
&lt;/mstyle&gt;
&lt;/math&gt;
</code></pre>

<p>(<a href="https://codepen.io/anon/pen/wqepjo">codepen</a>)</p>

<p>Basically, if you increase the level a bunch of times after hitting the min size, decreasing it by one should not immediately
compute <code>min size / multiplier</code>. That would make things asymmetric; something with a net script level of <code>+5</code> should
have the same size as something with a net script level of <code>+6 -1</code>, provided the multiplier hasn’t changed.</p>

<p>So what happens is that the script level is calculated against the font size <em>as if scriptminsize had never applied</em>,
and we only use that size if it is greater than the min size.</p>

<p>It’s not just a matter of keeping track of the script level at which clamping happened – the multiplier could change
in the process and you need to keep track of that too. So this ends up in creating <em>yet another font-size value to inherit</em>.</p>

<p>To recap, we are now at <em>four</em> different notions of font size being inherited:</p>

<ul>
  <li>The main font size used by styling</li>
  <li>The “actual” font size, i.e. the main font size but clamped by the min size</li>
  <li>(In servo only) The “keyword” size; i.e. the size stored as a keyword and ratio, if it was derived from a keyword</li>
  <li>The “script unconstrained” size; the font size as if scriptminsize never existed.</li>
</ul>

<p>Another complexity here is that the following should still work:</p>

<pre><code class="language-html">&lt;math&gt;
&lt;mstyle scriptminsize="10px" scriptsizemultiplier="0.75" style="font-size: 5px"&gt;
    5px
    &lt;mstyle scriptlevel="-1"&gt;
        6.666px
    &lt;/mstyle&gt;
&lt;/mstyle&gt;
&lt;/math&gt;
</code></pre>

<p>(<a href="https://codepen.io/anon/pen/prwpVd">codepen</a>)</p>

<p>Basically, if you were already below the scriptminsize, reducing the script level (to increase the font size) should not get clamped, since then you’d get something too large.</p>

<p>This basically means you only apply scriptminsize if you are applying the script level to a value <em>greater than</em> the script min size.</p>

<p>In Servo, all of the MathML handling culminates in <a href="https://github.com/servo/servo/blob/53c6f8ea8bf1002d0c99c067601fe070dcd6bcf1/components/style/properties/gecko.mako.rs#L2304-L2403">this wonderful function that is more comment than code</a>, and
some code in the functions near it.</p>

<hr />

<p>So there you have it. <code>font-size</code> is actually pretty complicated. A lot of the web platform has hidden complexities like this, and it’s always fun to encounter more of them.</p>

<p>(Perhaps less fun when I have to implement them 😂)</p>

<p><em>Thanks to mystor, mgattozzi, bstrie, and projektir for reviewing drafts of this post</em></p>
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:5" role="doc-endnote">
      <p>Interestingly, in Firefox, this number is 50% for all ruby <em>except</em> for when the language is Taiwanese Mandarin (where it is 30%). This is because Taiwan uses a phonetic script called Bopomofo, and each Han glyph can be represented as a maximum of 3 Bopomofo letters. So it is possible to choose a reasonable minimum size such that the ruby never extends the size of the glyph below it. On the other hand, pinyin can be up to six letters, and Hiragana up to (I think) 5, and the corresponding “no overflow” scaling will be too tiny. So fitting them on top of the glyph is not a consideration and instead we elect to have a larger font size for better readability. Additionally, Bopomofo ruby is often set on the side of the glyph instead of on top, and 30% works better there. (h/t @upsuper for pointing this out) <a href="#fnref:5" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:1" role="doc-endnote">
      <p>Other browser engines have other optimizations, I’m just less familiar with them <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>Some properties are inherited, some are “reset”. For example, <code>font-family</code> is inherited — child elements inherit font family from the parent unless otherwise specified. However <code>transform</code> is not, if you transform an element that does not further transform the children. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>This won’t handle <code>calc</code>s, which is something I need to fix. Fixing this is trivial, you store an absolute offset in addition to the ratio. <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Teaching Programming: Proactive vs Reactive]]></title>
    <link href="http://manishearth.github.io/blog/2017/05/19/teaching-programming-proactive-vs-reactive/"/>
    <updated>2017-05-19T00:00:00+00:00</updated>
    <id>http://manishearth.github.io/blog/2017/05/19/teaching-programming-proactive-vs-reactive</id>
    <content type="html"><![CDATA[<p>I’ve been thinking about this a lot these days. In part because of <a href="https://github.com/Manishearth/rust-clippy/issues/1737">an idea I had</a>
but also due to <a href="https://twitter.com/sehurlburt/status/863829482645340160">this twitter discussion</a>.</p>

<p>When teaching most things, there are two non-mutually-exclusive ways of approaching the problem. One
is “proactive”<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">1</a></sup>, which is where the teacher decides a learning path beforehand, and executes it. The
other is “reactive”, where the teacher reacts to the student trying things out and dynamically
tailors the teaching experience.</p>

<p>Most in-person teaching experiences are a mix of both. Planning beforehand is very important whilst teaching,
but tailoring the experience to the student’s reception of the things being taught is important too.</p>

<p>In person, you <em>can</em> mix these two, and in doing so you get a “best of both worlds” situation. Yay!</p>

<p>But … we don’t really learn much programming in a classroom setup.
Sure, some folks learn the basics in college for a few years, but everything
they learn after that isn’t in a classroom situation where this can work<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote">2</a></sup>.
I’m an autodidact,
and while I have taken a few programming courses for random interesting things, I’ve taught myself most of what I know
using various sources. I care a lot about improving the situation here.</p>

<p>With self-driven learning we have a similar divide. The “proactive” model corresponds to reading books
and docs. Various people have proactively put forward a path for learning in the form of a book
or tutorial. It’s up to you to pick one, and follow it.</p>

<p>The “reactive” model is not so well-developed. In the context of self-driven learning in programming,
it’s basically “do things, make mistakes, hope that Google/Stackoverflow help”. It’s how
a lot of people learn programming; and it’s how I prefer to learn programming.</p>

<p>It’s very nice to be able to “learn along the way”. While this is a long and arduous process,
involving many false starts and a lack of a sense of progress, it can be worth it in terms of
the kind of experience this gets you.</p>

<p>But as I mentioned, this isn’t as well-developed. With the proactive approach, there still
is a teacher – the author of the book! That teacher may not be able to respond in real time,
but they’re able to set forth a path for you to work through.</p>

<p>On the other hand, with the “reactive” approach, there is no teacher. Sure, there are
Random Answers on the Internet, which are great, but they don’t form a coherent story.
Neither can you really be your own teacher for a topic you do not understand.</p>

<p>Yet plenty of folks do this. Plenty of folks approach things like learning a new language by reading
at most two pages of docs and then just diving straight in and trying stuff out. The only language I
have not done this for is the first language I learned<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote">3</a></sup> <sup id="fnref:4" role="doc-noteref"><a href="#fn:4" class="footnote">4</a></sup>.</p>

<p>I think it’s unfortunate that folks who prefer this approach don’t get the benefit of a teacher.
In the reactive approach, teachers can still tell you what you’re doing wrong and steer you away from
tarpits of misunderstanding. They can get you immediate answers and guidance. When we look
for answers on stackoverflow, we get some of this, but it also involves a lot of pattern-matching
on the part of the student, and we end up with a bad facsimile of what a teacher can do for you.</p>

<p>But it’s possible to construct a better teacher for this!</p>

<p>In fact, examples of this exist in the wild already!</p>

<p>The Elm compiler is my favorite example of this. <a href="http://elm-lang.org/blog/compilers-as-assistants">It has amazing error messages</a></p>

<p><img class="center" src="http://manishearth.github.io/images/post/elm-error.png" />
<img class="center" src="http://manishearth.github.io/images/post/elm-error2.png" /></p>

<p>The error messages tell you what you did wrong, sometimes suggest fixes, and help
correct potential misunderstandings.</p>

<p>Rust does this too. Many compilers do. (Elm is exceptionally good at it)</p>

<p><img class="center" src="http://manishearth.github.io/images/post/rust-error.png" width="700" /></p>

<p>One thing I particularly like about Rust is that from that error you can
try <code>rustc --explain E0373</code> and get a terminal-friendly version
of <a href="https://doc.rust-lang.org/nightly/error-index.html#E0373">this help text</a>.</p>

<p>Anyway, diagnostics basically provide a reactive component to learning programming. I’ve cared about
diagnostics in Rust for a long time, and I often remind folks that many things taught through the
docs can/should be taught through diagnostics too. Especially because diagnostics are a kind of soapbox
for compiler writers — you can’t guarantee that your docs will be read, but you can guarantee
that your error messages will. These days, while I don’t have much time to work on stuff myself I’m
very happy to mentor others working on improving diagnostics in Rust.</p>

<p>Only recently did I realize <em>why</em> I care about them so much – they cater exactly to my approach
to learning programming languages! If I’m not going to read the docs when I get started and try the
reactive approach, having help from the compiler is invaluable.</p>

<p>I think this space is relatively unexplored. Elm might have the best diagnostics out there,
and as diagnostics (helping all users of a language – new and experienced), they’re great,
but as a teaching tool for newcomers; they still have a long way to go. Of course, compilers
like Rust are even further behind.</p>

<p>One thing I’d like to experiment with is a first-class tool for reactive teaching. In a sense,
<a href="https://github.com/Manishearth/rust-clippy">clippy</a> is already something like this. Clippy looks out for antipatterns, and tries to help
teach. But it also does many other things, and not all are teaching moments are antipatterns.</p>

<p>For example, in C, this isn’t necessarily an antipattern:</p>

<pre><code class="language-c">struct thingy *result;
if (result = do_the_thing()) {
    frob(*result)
}
</code></pre>

<p>Many C codebases use <code>if (foo = bar())</code>. It is a potential footgun if you confuse it with <code>==</code>,
but there’s no way to be sure. Many compilers now have a warning for this that you can silence by
doubling the parentheses, though.</p>

<p>In Rust, this isn’t an antipattern either:</p>

<pre><code class="language-rust">fn add_one(mut x: u8) {
    x += 1;
}

let num = 0;
add_one(num);
// num is still 0
</code></pre>

<p>For someone new to Rust, they may feel that the way to have a function mutate arguments (like <code>num</code>) passed to it
is to use something like <code>mut x: u8</code>. What this actually does is copies <code>num</code> (because <code>u8</code> is a <code>Copy</code> type),
and allows you to mutate the copy within the scope of the function. The right way to make a function that
mutates arguments passed to it by-reference would be to do something like <code>fn add_one(x: &amp;mut u8)</code>.
If you try the <code>mut x</code> thing for non-Copy values, you’d get a “reading out of moved value” error
when you try to access <code>num</code> after calling <code>add_one</code>. This would help you figure out what you did wrong,
and potentially that error could detect this situation and provide more specific help.</p>

<p>But for <code>Copy</code> types, this will just compile. And it’s not an antipattern – the way this works
makes complete sense in the context of how Rust variables work, and is something that you do need
to use at times.</p>

<p>So we can’t even warn on this. Perhaps in “pedantic clippy” mode, but really, it’s not
a pattern we want to discourage. (At least in the C example that pattern is one
that many people prefer to forbid from their codebase)</p>

<p>But it would be nice if we could tell a learning programmer “hey, btw, this is what this syntax
means, are you sure you want to do this?”. With explanations and the ability to dismiss the error.</p>

<p>In fact, you don’t even need to restrict this to potential footguns!</p>

<p>You can detect various things the learner is trying to do. Are they probably mixing up <code>String</code>
and <code>&amp;str</code>? Help them! Are they writing a trait? Give a little tooltip explaining the feature.</p>

<p>This is beginning to remind me of the original “office assistant” <a href="https://en.wikipedia.org/wiki/Office_Assistant">Clippy</a>, which was super annoying.
But an opt-in tool or IDE feature which gives helpful suggestions could still be nice, especially
if you can strike a balance between being so dense it is annoying and so sparse it is useless.</p>

<p>It also reminds me of well-designed tutorial modes in games. Some games have a tutorial mode that guides you
through a set path of doing things. Other games, however, have a tutorial mode that will give you hints even
if you stray off the beaten path. <a href="https://twitter.com/mgattozzi">Michael</a> tells me that <a href="http://store.steampowered.com/app/480490/Prey/">Prey</a> is
a recent example of such a game.</p>

<p>This really feels like it fits the “reactive” model I prefer. The student gets to mold their own
journey, but gets enough helpful hints and nudges from the “teacher” (the tool) so that they
don’t end up wasting too much time and can make informed decisions on how to proceed learning.</p>

<p>Now, rust-clippy isn’t exactly the place for this kind of tool. This tool needs the ability to globally
“silence” a hint once you’ve learned it. rust-clippy is a linter, and while you can silence lints in
your code, you can’t silence them globally for the current user. Nor does that really make sense.</p>

<p>But rust-clippy does have the infrastructure for writing stuff like this, so it’s an ideal prototyping
point. I’ve filed <a href="https://github.com/Manishearth/rust-clippy/issues/1737">this issue</a> to discuss this topic.</p>

<p>Ultimately, I’d love to see this as an IDE feature.</p>

<p>I’d also like to see more experimentation in the department of “reactive” teaching — not just tools like this.</p>

<p>Thoughts? Ideas? Let me know!</p>

<p><em>thanks to Andre (llogiq) and Michael Gattozzi for reviewing this</em></p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>This is how I’m using these terms. There seems to be precedent in pedagogy for the proactive/reactive classification, but it might not be exactly the same as the way I’m using it. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>This is true for everything, but I’m focusing on programming (in particular programming <em>languages</em>) here. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>And when I learned Rust, it only <em>had</em> two pages of docs, aka “The Tutorial”. Good times. <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:4" role="doc-endnote">
      <p>I do eventually get around to doing a full read of the docs or a book but this is after I’m already able to write nontrivial things in the language, and it takes a lot of time to get there. <a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Mentally Modelling Modules]]></title>
    <link href="http://manishearth.github.io/blog/2017/05/14/mentally-modelling-modules/"/>
    <updated>2017-05-14T00:00:00+00:00</updated>
    <id>http://manishearth.github.io/blog/2017/05/14/mentally-modelling-modules</id>
    <content type="html"><![CDATA[<p>The module and import system in Rust is sadly one of the many confusing things you have to deal with whilst
learning the language. A lot of these confusions stem from a misunderstanding of how it works.
In explaining this I’ve seen that it’s usually a common set of misunderstandings.</p>

<p>In the spirit of <a href="http://manishearth.github.io/blog/2017/04/05/youre-doing-it-wrong/">“You’re doing it wrong”</a>, I want to try and explain one
“right” way of looking at it. You can go pretty far<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">1</a></sup> without knowing this, but it’s useful
and helps avoid confusion.</p>

<hr />

<p><br /></p>

<p>First off, just to get this out of the way, <code>mod foo;</code> is basically a way of saying
“look for <code>foo.rs</code> or <code>foo/mod.rs</code> and make a module named <code>foo</code> with its contents”.
It’s the same as <code>mod foo { ... }</code> except the contents are in a different file. This
itself can be confusing at first, but it’s not what I wish to focus on here. The Rust book explains this more
in <a href="https://doc.rust-lang.org/book/crates-and-modules.html#multiple-file-crates">the chapter on modules</a>.</p>

<p>In the examples here I will just be using <code>mod foo { ... }</code> since multi-file examples are annoying,
but keep in mind that the stuff here applies equally to multi-file crates.</p>

<h3 id="motivating-examples">Motivating examples</h3>

<p>To start off, I’m going to provide some examples of Rust code which compiles. Some of these may be
counterintuitive, based on your existing model.</p>

<pre><code class="language-rust">pub mod foo {
    extern crate regex;
    
    mod bar {
        use foo::regex::Regex;
    }
}
</code></pre>

<p>(<a href="http://play.integer32.com/?gist=7673736a57fe99092446ec73f8b8f555&amp;version=undefined">playpen</a>)</p>

<pre><code class="language-rust">use std::mem;


pub mod foo {
    // not std::mem::transmute!
    use mem::transmute;

    pub mod bar {
        use foo::transmute;
    }
}
</code></pre>

<p>(<a href="http://play.integer32.com/?gist=49415d74214b07b13c236ce88bdf54aa&amp;version=undefined">playpen</a>)</p>

<pre><code class="language-rust">pub mod foo {
    use bar;
    use bar::bar_inner;

    fn foo() {
        // this works!
        bar_inner();
        bar::bar_inner();
        // this doesn't
        // baz::baz_inner();
        
        // but these do!
        ::baz::baz_inner();
        super::baz::baz_inner();
        
        // these do too!
        ::bar::bar_inner();
        super::bar::bar_inner();
        self::bar::bar_inner();
        
    }
}

pub mod bar {
    pub fn bar_inner() {}
}
pub mod baz {
    pub fn baz_inner() {}
}
</code></pre>

<p>(<a href="http://play.integer32.com/?gist=547fea76590b6c5dbbb04ccbc89cf8d2&amp;version=undefined">playpen</a>)</p>

<pre><code class="language-rust">pub mod foo {
    use bar::baz;
    // this won't work
    // use baz::inner();
    
    // this will
    use self::baz::inner;
    // or
    // use bar::baz::inner
    
    pub fn foo() {
        // but this will work!
        baz::inner();
    }
}

pub mod bar {
    pub mod baz {
        pub fn inner() {}
    }
}
</code></pre>

<p>(<a href="http://play.integer32.com/?gist=e553e52d1cbf0d38fd0b42c09ccafe44&amp;version=undefined">playpen</a>)</p>

<p>These examples remind me of the “point at infinity” in elliptic curve crypto or fake particles in
physics or fake lattice elements in various fields of CS<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote">2</a></sup>. Sometimes, for something to make sense,
you add in things that don’t normally exist. Similarly, these examples may contain code which
is not traditional Rust style, but the import system
still makes more sense when you include them.</p>

<h3 id="imports">Imports</h3>

<p>The core confusion behind how imports work can really be resolved by remembering two rules:</p>

<ul>
  <li><code>use foo::bar::baz</code> resolves <code>foo</code> relative to the root module (<code>lib.rs</code> or <code>main.rs</code>)
    <ul>
      <li>You can resolve relative to the current module by explicily trying <code>use self::foo::bar::baz</code></li>
    </ul>
  </li>
  <li><code>foo::bar::baz</code> within your code<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote">3</a></sup> resolves <code>foo</code> relative to the current module
    <ul>
      <li>You can resolve relative to the root by explicitly using <code>::foo::bar::baz</code></li>
    </ul>
  </li>
</ul>

<p>That’s actually … it. There are no further caveats. The rest of this is modelling what
constitutes as “being within a module”.</p>

<p>Let’s take a pretty standard setup, where <code>extern crate</code> declarations are placed in the the root
module:</p>

<pre><code class="language-rust">extern crate regex;

mod foo {
    use regex::Regex;

    fn foo() {
        // won't work
        // let ex = regex::Regex::new("");
        let ex = Regex::new("");
    }
}
</code></pre>

<p>When we say <code>extern crate regex</code>, we pull in the <code>regex</code> crate into the crate root. This behaves
pretty similar to <code>mod regex { /* contents of regex crate */}</code>. Basically, we’ve imported
the crate into the crate root, and since all <code>use</code> paths are relative to the crate root,
<code>use regex::Regex</code> works fine inside the module.</p>

<p>Inline in code, <code>regex::Regex</code> won’t work because as mentioned before inline paths are relative
to the current module. However, you can try <code>::regex::Regex::new("")</code>.</p>

<p>Since we’ve imported <code>regex::Regex</code> in <code>mod foo</code>, that name is now accessible to everything inside
the module directly, so the code can just say <code>Regex::new()</code>.</p>

<p>The way you can view this is that <code>use blah</code> and <code>extern crate blah</code> create an item named
<code>blah</code> “within the module”, which is basically something like a symbolic link, saying
“yes this item named <code>blah</code> is actually elsewhere but we’ll pretend it’s within the module”</p>

<p>The error message from this code may further drive this home:</p>

<pre><code class="language-rust">use foo::replace;

pub mod foo {
    use std::mem::replace;
}
</code></pre>

<p>(<a href="http://play.integer32.com/?gist=07527a61153519fbf218ffb93f13b3cd&amp;version=undefined">playpen</a>)</p>

<p>The error I get is</p>

<pre><code>error: function `replace` is private
 --&gt; src/main.rs:3:5
  |
3 | use foo::replace;
  |     ^^^^^^^^^^^^
</code></pre>

<p>There’s no function named <code>replace</code> in the module <code>foo</code>! But the compiler seems to think there is?</p>

<p>That’s because <code>use std::mem::replace</code> basically is equivalent to there being something like:</p>

<pre><code class="language-rust">pub mod foo {
    fn replace(...) -&gt; ... {
        ...
    }

    // here we can refer to `replace` freely (in inline paths)
    fn whatever() {
        // ...
        let something = replace(blah);
        // ...
    }
}
</code></pre>

<p>except it’s actually like a symlink to the function defined in <code>std::mem</code>. Because inline paths
are relative to the current module, saying <code>use std::mem::replace</code> works as if you had defined
a function <code>replace</code> in the same module, and you can refer to <code>replace()</code> without needing
any extra qualification in inline paths.</p>

<p>This also makes <code>pub use</code> fit perfectly in our model. <code>pub use</code> says “make this symlink, but let
others see it too”:</p>

<pre><code class="language-rust">// works now!
use foo::replace;

pub mod foo {
    pub use std::mem::replace;
}
</code></pre>

<hr />

<p><br /></p>

<p>Folks often get annoyed when this doesn’t work:</p>

<pre><code class="language-rust">mod foo {
    use std::mem;
    // nope
    // use mem::replace;
}
</code></pre>

<p>As mentioned before, <code>use</code> paths are relative to the root module. There is no <code>mem</code>
in the root module, so this won’t work. We can make it work via <code>self</code>, which I mentioned
before:</p>

<pre><code class="language-rust">mod foo {
    use std::mem;
    // yep!
    use self::mem::replace;
}
</code></pre>

<p>Note that this brings overloading of the <code>self</code> keyword up to a grand total of <em>four</em>! Two cases
which occur in the import/path system:</p>

<ul>
  <li><code>use self::foo</code> means “find me <code>foo</code> within the current module”</li>
  <li><code>use foo::bar::{self, baz}</code> is equivalent to <code>use foo::bar; use foo::bar::baz;</code></li>
  <li><code>fn foo(&amp;self)</code> lets you define methods and specify if the receiver is by-move, borrowed, mutably borrowed, or other</li>
  <li><code>Self</code> within implementations lets you refer to the type being implemented on</li>
</ul>

<p>Oh well, at least it’s not <code>static</code>.</p>

<hr />

<p><br /><br /></p>

<p>Going back to one of the examples I gave at the beginning:</p>

<pre><code class="language-rust">use std::mem;


pub mod foo {
    use mem::transmute;

    pub mod bar {
        use foo::transmute;
    }
}
</code></pre>

<p>(<a href="http://play.integer32.com/?gist=49415d74214b07b13c236ce88bdf54aa&amp;version=undefined">playpen</a>)</p>

<p>It should be clearer now why this works. The root module imports <code>mem</code>. Now, from everyone’s point
of view, there’s an item called <code>mem</code> in the root.</p>

<p>Within <code>mod foo</code>, <code>use mem::transmute</code> works because <code>use</code> is relative to the root, and <code>mem</code>
already exists in the root! When you <code>use</code> something, all child modules will see it as if it were
actually belonging to the module. (Non-child modules won’t see it because of privacy, we
saw an example of this already)</p>

<p>This is why <code>use foo::transmute</code> works from <code>mod bar</code>, too. <code>bar</code> can refer to the contents
of <code>foo</code> via <code>use foo::whatever</code>, since <code>foo</code> is a child of the root module, and <code>use</code> is relative
to the root. <code>foo</code> already has an item named <code>transmute</code> inside it because it imported one.
Nothing in the parent module is private from the child, so we can <code>use foo::transmute</code> from
<code>bar</code>.</p>

<p>Generally, the standard way of doing things is to either not use modules (just a single lib.rs),
or, if you do use modules, put nothing other than <code>extern crate</code>s and <code>mod</code>s in the root.
This is why we rarely see shenanigans like the above; there’s nothing in the root crate
to import, aside from other crates specified by <code>extern crate</code>. The trick of
“reimport something from the parent module” is also pretty rare because there’s basically no
point to using that (just import it directly!). So this is not the kind of code
you’ll see in the wild.</p>

<hr />

<p><br /></p>

<p>Basically, the way the import system works can be summed up as:</p>

<ul>
  <li><code>extern crate</code> and <code>use</code> will act as if they were defining the imported item in the current module, like a symbolic link</li>
  <li><code>use foo::bar::baz</code> resolves the path relative to the root module</li>
  <li><code>foo::bar::baz</code> in an inline path (i.e. not in a <code>use</code>) will resolve relative to the current module</li>
  <li><code>::foo::bar::baz</code> will <em>always</em> resolve relative to the root module</li>
  <li><code>self::foo::bar::baz</code> will <em>always</em> resolve relative to the current module</li>
  <li><code>super::foo::bar::baz</code> will <em>always</em> resolve relative to the parent module</li>
</ul>

<p>Alright, on to the other half of this. Privacy.</p>

<h3 id="privacy">Privacy</h3>

<p>So how does privacy work?</p>

<p>Privacy, too, follows some basic rules:</p>

<ul>
  <li>If you can access a module, you can access all of its <code>pub</code> contents</li>
  <li>A module can always access its child modules, but not recursively
    <ul>
      <li>This means that a module cannot access private items in its children, nor can it access private grandchildren modules</li>
    </ul>
  </li>
  <li>A child can always access its parent modules (and their parents), and <em>all</em> their contents</li>
  <li><code>pub(restricted)</code> <a href="https://github.com/rust-lang/rfcs/blob/master/text/1422-pub-restricted.md">is a proposal</a> which extends this a bit, but it’s experimental so we won’t deal with it here</li>
</ul>

<p>Giving some examples,</p>

<pre><code class="language-rust">mod foo {
    mod bar {
        // can access `foo::foofunc`, even though `foofunc` is private

        pub fn barfunc() {}

    }
    // can access `foo::bar::barfunc()`, even though `bar` is private
    fn foofunc() {}
}
</code></pre>

<pre><code class="language-rust">mod foo {
    mod bar {
        // We can access our parent and _all_ its contents,
        // so we have access to `foo::baz`. We can access
        // all pub contents of modules we have access to, so we
        // can access `foo::baz::bazfunc`
        use foo::baz::bazfunc;
    }
    mod baz {
        pub fn bazfunc() {}
    }
}
</code></pre>

<p>It’s important to note that this is all contextual; whether or not a particular
path works is a function of where you are. For example, this works<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" class="footnote">4</a></sup>:</p>

<pre><code class="language-rust">pub mod foo {
    /* not pub */ mod bar {
        pub mod baz {
            pub fn bazfunc() {}
        }
        pub mod quux {
            use foo::bar::baz::bazfunc;
        }
    }
}
</code></pre>

<p>We are able to write the path <code>foo::bar::baz::bazfunc</code> even though <code>bar</code> is private!</p>

<p>This is because we still have <em>access</em> to the module <code>bar</code>, by being a descendent module.</p>

<hr />

<p><br /></p>

<p>Hopefully this is helpful to some of you. I’m not really sure how this can fit into the official
docs, but if you have ideas, feel free to adapt it<sup id="fnref:5" role="doc-noteref"><a href="#fn:5" class="footnote">5</a></sup>!</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>This is because most of these misunderstandings lead to a model where you think fewer things compile, which is fine as long as it isn’t too restrictive. Having a mental model where you feel more things will compile than actually do is what leads to frustration; the opposite can just be restrictive. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>One example closer to home is how Rust does lifetime resolution. Lifetimes form a lattice with <code>'static</code> being the bottom element. There is no top element for lifetimes in Rust syntax, but internally <a href="http://manishearth.github.io/rust-internals-docs/rustc/ty/enum.Region.html#variant.ReEmpty">there is the “empty lifetime”</a> which is used during borrow checking. If something resolves to have an empty lifetime, it can’t exist, so we get a lifetime error. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>When I say “within your code”, I mean “anywhere but a <code>use</code> statement”. I may also term these as “inline paths”. <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:4" role="doc-endnote">
      <p>Example adapted from <a href="https://www.reddit.com/r/rust/comments/5m4w95/the_rust_module_system_is_too_confusing/dc1df2z/">this discussion</a> <a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:5" role="doc-endnote">
      <p>Contact me if you have licensing issues; I still have to figure out the licensing situation for the blog, but am more than happy to grant exceptions for content being uplifted into official or semi-official docs. <a href="#fnref:5" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Two Interpretations Diverged in a Yellow Wood]]></title>
    <link href="http://manishearth.github.io/blog/2017/05/02/two-interpretations-diverged-in-a-yellow-wood/"/>
    <updated>2017-05-02T00:00:00+00:00</updated>
    <id>http://manishearth.github.io/blog/2017/05/02/two-interpretations-diverged-in-a-yellow-wood</id>
    <content type="html"><![CDATA[<p>Whose words are these I think I know<br />
His house is in the village though<br />
He will not see me stopping here<br />
To interpret his work as I go<br /></p>

<p>My little student must think it queer<br />
To read without some context near<br />
Between the words and the intent<br />
He wonders what the poem meant<br /></p>

<p>He gives his head a little shake<br />
To ask if there is some mistake<br />
“That’s not what the author said!”<br />
Providing another view instead<br /></p>

<p>The words are lovely, dark, and deep<br />
But I have literary criticism to preach<br />
And miles to go before I sleep<br />
And miles to go before I sleep<br /></p>

<hr />

<p><br /><br /><br /><br /><br /></p>

<p>Seriously though, try reading <em>The Road Not Taken</em> as metacircular commentary on how the poem
<a href="https://en.wikipedia.org/wiki/The_Road_Not_Taken#Analysis">is very often “mis”interpreted</a>, and the nature of interpretation / <em>Death of the Author</em>. It fits perfectly when
you read “road” as “interpretation”.</p>

<p><small>(Yes, I know, the parody above is not based on <em>The Road Not Taken</em> but instead a different Frost
poem. I was originally going to modify <em>The Road Not Taken</em> but realized all I had to do was change
a few words to get there, which was no fun at all) </small></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Prolonging Temporaries in Rust]]></title>
    <link href="http://manishearth.github.io/blog/2017/04/13/prolonging-temporaries-in-rust/"/>
    <updated>2017-04-13T00:00:00+00:00</updated>
    <id>http://manishearth.github.io/blog/2017/04/13/prolonging-temporaries-in-rust</id>
    <content type="html"><![CDATA[<p>A colleague of mine learning Rust had an interesting type / borrow checker error. The solution needs
a less-used feature of Rust (which basically exists precisely for this kind of thing), so I thought
I’d document it.</p>

<p>The code was like this:</p>

<pre><code class="language-rust">let maybe_foo = if some_condition {
    thing.get_ref() // returns Option&lt;&amp;Foo&gt;, borrowed from `thing`
} else {
    thing.get_owned() // returns Option&lt;Foo&gt;
};

use(maybe_foo);
</code></pre>

<p>If you want to follow along, here is a full program that does this (<a href="https://play.rust-lang.org/?gist=e09a79b511e347fe786e4689d282b806&amp;version=stable&amp;backtrace=0">playpen</a>):</p>

<pre><code class="language-rust">#[derive(Debug)]
struct Foo;

struct Thingy {
    foo: Foo
}

impl Thingy {
    pub fn get_ref(&amp;self) -&gt; Option&lt;&amp;Foo&gt; {
        Some(&amp;self.foo)
    }
    pub fn get_owned(&amp;self) -&gt; Option&lt;Foo&gt; {
        Some(Foo)
    }
    pub fn new() -&gt; Self {
        Thingy {
            foo: Foo
        }
    }
}



pub fn main() {
    let some_condition = true;
    let thing = Thingy::new();

    let maybe_foo = if some_condition {
        thing.get_ref() // returns Option&lt;&amp;Foo&gt;, borrowed from `thing`
    } else {
        thing.get_owned() // returns Option&lt;Foo&gt;
    };
    
    println!("{:?}", maybe_foo);
}
</code></pre>

<p>I’m only going to be changing the contents of <code>main()</code> here.</p>

<p>What’s happening here is that a non-<code>Copy</code> type, <code>Foo</code>, is returned in an <code>Option</code>. In one case,
we have a reference to the <code>Foo</code>, and in another case an owned copy.</p>

<p>We want to set a variable to these, but of course we can’t because they’re different types.</p>

<p>In one case, we have an owned <code>Foo</code>, and we can usually obtain a borrow from an owned type. For
<code>Option</code>, there’s a convenience method <code>.as_ref()</code> that does this<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">1</a></sup>. Let’s try using that (<a href="https://play.rust-lang.org/?gist=41c3f836b9485c216ccb05c257ae5326&amp;version=stable&amp;backtrace=0">playpen</a>):</p>

<pre><code class="language-rust">let maybe_foo = if some_condition {
    thing.get_ref()
} else {
    thing.get_owned().as_ref()
};
</code></pre>

<p>This will give us an error.</p>

<pre><code>error: borrowed value does not live long enough
  --&gt; &lt;anon&gt;:32:5
   |
31 |         thing.get_owned().as_ref()
   |         ----------------- temporary value created here
32 |     };
   |     ^ temporary value dropped here while still borrowed
...
35 | }
   | - temporary value needs to live until here

error: aborting due to previous error
</code></pre>

<p>The problem is, <code>thing.get_owned()</code> returns an owned value. There’s nothing that it gets anchored to
(we don’t set its value to a variable), so it is just a temporary – we can call methods on it, but
once we’re done the value will go out of scope.</p>

<p>What we want is something like</p>

<pre><code class="language-rust">let maybe_foo = if some_condition {
    thing.get_ref()
} else {
    let owned = thing.get_owned();
    owned.as_ref()
};
</code></pre>

<p>but this will still give a borrow error – <code>owned</code> will still go out of scope within the <code>if</code> block,
and we need the reference to it last as long as <code>maybe_foo</code> (outside the block) is supposed to last.</p>

<p>So this is no good.</p>

<p>An alternate solution here <em>can</em> be copying/cloning the <code>Foo</code> in the <em>first</em> case by calling <code>.map(|x|
x.clone())</code> or <code>.cloned()</code> or something. Sometimes you don’t want to clone, so this isn’t great.</p>

<p>Another solution here – the generic advice for dealing with values which may be owned or borrow –
is to use <code>Cow</code>. It does incur a runtime check, though; one which can be optimized out if things are
inlined enough.</p>

<p>What we need to do here is to extend the lifetime of the temporary returned by <code>thing.get_owned()</code>.
We need to extend it <em>past</em> the scope of the <code>if</code>.</p>

<p>One way to do this is to have an <code>Option</code> outside that scope which we mutate (<a href="https://play.rust-lang.org/?gist=7868045f2cebec6d23e7a065f5823767&amp;version=stable&amp;backtrace=0">playpen</a>).</p>

<pre><code class="language-rust">let mut owned = None;
let maybe_foo = if some_condition {
    thing.get_ref()
} else {
    owned = thing.get_owned();
    owned.as_ref()
};
</code></pre>

<p>This works in this case, but in this case we already had an <code>Option</code>. If <code>get_ref()</code> and <code>get_owned()</code>
returned <code>&amp;Foo</code> and <code>Foo</code> respectively, then we’d need to do something like:</p>

<pre><code class="language-rust">let mut owned = None;
let maybe_foo = if some_condition {
    thing.get_ref()
} else {
    owned = Some(thing.get_owned());
    owned.as_ref().unwrap()
};
</code></pre>

<p>which is icky since it introduces an unwrap.</p>

<p>What we really need is a way to signal to the compiler that it needs to hold on to that temporary
for the scope of the enclosing block.</p>

<p>We can do that! (<a href="https://play.rust-lang.org/?gist=1ddf2a428e73b01baa72acdad7cbbf2b&amp;version=stable&amp;backtrace=0">playpen</a>)</p>

<pre><code class="language-rust">let owned; // 😯😯😯😯😯
let maybe_foo = if some_condition {
    thing.get_ref()
} else {
    owned = thing.get_owned();
    owned.as_ref()
};
</code></pre>

<p>We know that Rust doesn’t do “uninitialized” variables. If you want to name a variable, you have to
initialize it. <code>let foo;</code> feels rather like magic in this context, because it looks like we’ve declared
an uninitialized variable.</p>

<p>What’s less well known is that Rust <em>can</em> do “deferred” initialization. Here, you declare a variable
and can initialize it later, but expressions involving the variable can only exist in branches
where the compiler knows it has been initialized.</p>

<p>This is the case here. We declared the <code>owned</code> variable beforehand. It now lives in the outer scope
and won’t be destroyed until the end of the outer scope. However, the variable cannot be used directly
in an expression in the first branch, or after the <code>if</code>. Doing so will give a compile time error
saying <code>use of possibly uninitialized variable: `owned`</code>. We can only use it in the <code>else</code> branch
because the compiler can see that it is unconditionally initialized in that branch.</p>

<p>We can still read the value of <code>owned</code> indirectly through <code>maybe_foo</code> from outside the branch.
This is okay because the storage of <code>owned</code> is guaranteed to live as long as the outer scope,
and <code>maybe_foo</code> borrows from it. The only time <code>maybe_foo</code> is set to a value inside <code>owned</code> is when
<code>owned</code> has been initialized, so it is safe.</p>
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>In my experience <code>.as_ref()</code> is the solution to many, many borrow check issues newcomers come across, especially those involving <code>.map()</code> <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[You're Doing It Wrong]]></title>
    <link href="http://manishearth.github.io/blog/2017/04/05/youre-doing-it-wrong/"/>
    <updated>2017-04-05T00:00:00+00:00</updated>
    <id>http://manishearth.github.io/blog/2017/04/05/youre-doing-it-wrong</id>
    <content type="html"><![CDATA[<p>“You’re doing it wrong”</p>

<p>A common refrain in issue trackers and discussion forums everywhere. In isolation,
it’s a variant of RTFM – give a non-answer when someone wants help, and bounce them
back to a manual or docs which they probably have already read. Not very helpful,
and not useful to anyone. Of course, one can accompany it with a nice explanation
of how to do it right; “You’re doing it wrong” isn’t always a bad thing :)</p>

<p>Especially when it comes to programming languages, but in general in the context of any programming
tool or library, “you’re doing it wrong” is almost always due to a “bad” mental model. The person, whilst
learning, has built a mental model of how the tool works, but this doesn’t accurately reflect
reality. Other times, it does reflect reality, but it does not reflect the mental model of the
maintainers (there can be multiple valid ways of looking at something!),
which leads to an impedance mismatch when reading docs or error messages.</p>

<p>In other cases, “doing it wrong” is a <a href="https://meta.stackexchange.com/q/66377/178438">case of the XY problem</a>, where the user has problem X,
and think they can solve it with solution Y, and end up asking how they can achieve Y. This happens pretty
often — folks may be approaching your technology with prior experience with related things
that work differently, and may think the same idioms apply.</p>

<p>When I was at <a href="https://maintainerati.org/">WONTFIX</a>, someone who had done support work in the past mentioned that one
thing everyone learns in support is <strong>“the user is always wrong …. and it’s not their fault!”</strong>.</p>

<p>This is a pretty good template for an attitude to approach “doing it wrong” questions about your
technology on online forums as well. And this doesn’t just benefit the users who ask questions,
this attitude can benefit your technology!</p>

<p>Back when I used to be more active contributing to the Rust compiler, I also used to hang out in
<code>#rust</code> a lot, and often answer newbie questions (now <code>#rust-beginners</code> exists too, and I hang out
in both, but I don’t really actively participate as much). One thing I learned to do was probe
deeper into why people hit that confusion in the first place. It’s almost always a “bad” mental
model. Rust is rarely the first programming language folks learn, and people approach it with
preconceptions about how programming works. This isn’t unique to Rust, this happens any time someone
learns a language with a different paradigm — learning C or C++ after doing a GCd language,
learning a functional language after an imperative one, statically typed after dynamic, or one of
the many other axes by which programming languages differ.</p>

<p>Other times, it’s just assumptions they made when reading between the lines of whatever resource
they used to learn the language.</p>

<p>So, anyway, folks often have a “bad” mental model. If we are able to identify that model and correct
it, we have saved that person from potentially getting confused at every step in the future. Great!</p>

<p>With a <em>tiny</em> bit more effort, however, we can do one step better. Not for that person, but for
ourselves! We can probe a bit more and try to understand what caused them to obtain that mental
model. And fix the docs so that it never happens again! Of course, not everyone reads the docs, but
that’s what diagnostics are for (in the case of errors). They’re a tool to help us nudge the user
towards the right mental model, whilst helping them fix their immediate problem. Rust has for a long
time had pretty great diagnostics, with improvements happening all the time<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">1</a></sup>. I think this is at
least in part due to the attitude of the folks in <code>#rust</code>; always trying to figure out how to
preempt various confusions they see.</p>

<p>It’s a good attitude to have. I hope more folks, both in and out of the Rust community, approach
“You’re doing it wrong” cases like that.</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>Diagnostics issues are often the easiest way to contribute to the compiler itself, so if you want to contribute, I suggest starting there. Willing to mentor! <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[I Never Hear the Phrase 'INHTPAMA' Anymore]]></title>
    <link href="http://manishearth.github.io/blog/2017/03/18/inhtpinhtpamaa/"/>
    <updated>2017-03-18T00:00:00+00:00</updated>
    <id>http://manishearth.github.io/blog/2017/03/18/inhtpinhtpamaa</id>
    <content type="html"><![CDATA[<p>Imagine never hearing the phrase ‘INHTPAMA’ again.</p>

<p>Oh, that’s already the case? Bummer.</p>

<p>Often, when talking about Rust, folks refer to the core aliasing rule as “that <code>&amp;mut</code> thing”,
“compile-time <code>RWLock</code>” (or “compile-time <code>RefCell</code>”), or something similar. Basically, referring to
the fact that you can’t mutate the data that is currently held via an <code>&amp;</code> reference, and that you
can’t mutate or read the data currently held via an <code>&amp;mut</code> reference except through that reference
itself.</p>

<p>It’s always bugged me that we really don’t have a name for this thing. It’s one of the core
bits of Rust, and crops up often in discussions.</p>

<p>But we did have a name for it! It was “INHTPAMA” (which was later butchered into “INHTWAMA”).</p>

<p>This is a reference to <a href="http://smallcultfollowing.com/babysteps/blog/2012/11/18/imagine-never-hearing-the-phrase-aliasable/">Niko’s 2012 blog post</a>, titled
“Imagine Never Hearing The Phrase ‘aliasable, mutable’ again”. It’s where the aliasing
rules came from. Go read it, it’s great. It talks about this weird language with at symbols
and purity, but I assure you, that language is Baby Rust. Or maybe Teenage Rust. The
<a href="https://www.ars.usda.gov/images/docs/9910_10104/Pg-lifecycle.jpg">lifecycle of rusts is complex and interesting</a> and I don’t know how to categorize it.</p>

<p>The point of this post isn’t really to encourage reviving the use of “INHTWAMA”; it’s
a rather weird acronym that will probably confuse folks. I would like to have a better
way of refering to “that <code>&amp;mut</code> thing”, but I’d prefer if it wasn’t a confusing acronym
that carries no meaning of its own if you don’t know the history of it. That’s a recipe for
making new community members feel like outsiders.</p>

<p>But that post is amazing and I’d hate to see it drop out of the collective
memory of the Rust community.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Use Signal. Use Tor.]]></title>
    <link href="http://manishearth.github.io/blog/2017/03/12/use-signal-use-tor/"/>
    <updated>2017-03-12T00:00:00+00:00</updated>
    <id>http://manishearth.github.io/blog/2017/03/12/use-signal-use-tor</id>
    <content type="html"><![CDATA[<p>I went to send a missive today<br />
As I have done so oft before<br />
But I forgot to employ that scrap of advice<br />
“Use Signal. Use Tor.”</p>

<p>Intercepted of course the missive was<br />
By a ferocious beast of lore<br />
Because I failed to use that bit of advice<br />
“Use Signal. Use Tor.”</p>

<p>The beast was strong; and formidable<br />
He hated the amendments four<br />
I should have remembered that piece of advice<br />
“Use Signal. Use Tor.”</p>

<p>I tried to reason with the beast<br />
but he only wanted war<br />
Do not neglect that important advice<br />
“Use Signal. Use Tor.”</p>

<p>Here I lie in the belly of the beast<br />
I shall discount this advice no more<br />
If I ever manage to leave this place<br />
I’ll use Signal, and Tor.</p>

<p>Heed this advice, children.<br />
It’s not something to ignore<br />
Always, always, always, always<br />
Use Signal. Use Tor.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Why Quantum Computing Is Weird]]></title>
    <link href="http://manishearth.github.io/blog/2017/03/11/why-quantum-computing-is-weird/"/>
    <updated>2017-03-11T00:00:00+00:00</updated>
    <id>http://manishearth.github.io/blog/2017/03/11/why-quantum-computing-is-weird</id>
    <content type="html"><![CDATA[<p><em>I’ve been meaning to write about physics for a while. When I started this blog the intention was to
write about a wide variety of interests, but I ended up focusing on programming, despite the fact
that I was doing more physics than programming for most of the lifetime of this blog. Time to change
that, and hopefully write about other non-programming topics too.</em></p>

<p>Quantum Computing. It’s the new hip thing that’s going to change the world<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">1</a></sup>. Someday.</p>

<p>In it’s essence, where classical computing deals with “bits”, which are on/off states, quantum
computing deals with “qubits”, which are probabalistic quantum states that are often a mixture of on
and off. These have interesting properties which make certain kinds of so-far-hard computation very
easy to perform.</p>

<p>The goal of this post is not to teach quantum computing, rather to garner interest. I come to praise
quantum computing, not bury it<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote">2</a></sup>. As a result, this post doesn’t require a background in physics.
Having worked with very simple logic circuits is probably enough, though you may not even need that.</p>

<p>I’m basically going to sketch out an example of a very simple quantum algorithm. One that’s very
logic-defying. It’s even logic-defying for many who have studied quantum mechanics; it certainly
was for me. When I learned this first I could understand <em>why</em> it worked but there was a lot of
dissonance between that and my intuitive conviction that it was <em>wrong</em>.</p>

<h2 id="the-algorithm">The algorithm</h2>

<p><img class="center" src="http://manishearth.github.io/images/post/deutsch/deutsch-jozsa.png" width="600" /></p>

<p>This is a quantum circuit (specifically, the circuit for the <a href="https://en.wikipedia.org/wiki/Deutsch%E2%80%93Jozsa_algorithm">Deutsch-Jozsa algorithm</a>).
It’s used to find out the nature of a black-box function <code>f(x)</code>, which takes in one qubit and outputs
another<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote">3</a></sup>. For now, you can try to interpret this circuit as if it were a regular logic circuit.
You’ll soon see that this interpretation is wrong, but it’s useful for the purposes of this explanation.</p>

<p>To run this algorithm, you first construct an “oracle” out of the black-box function. The oracle,
given inputs <code>x</code> and <code>y</code>, has outputs <code>x</code> and <code>y ⊕ f(x)</code> (where <code>⊕</code> is the symbol for XOR, the
“exclusive OR”).</p>

<p>As with logic circuits, data flow here goes from left to right. This circuit has two constant
inputs, a zero and a one. This is similar to how we might have constant “true” and “false” inputs
to logic circuits.</p>

<p>They are then passed through “Hadamard gates”. These are <em>like</em> NOT gates, in that applying them
twice is a no-op (they are their own inverse), but they’re not actually NOT gates. I like to
describe them as “sideways NOT gates” since that description somewhat intuitively captures what’s
going on with the qubits. What’s important to note here is that they have one input and one
output, so they’re unaffected by the goings-on in a different wire.</p>

<p>Once these inputs have been Hadamard’ed, they are fed to the oracle we constructed. The top input
goes on to become the top output. It’s also passed through <code>f(x)</code> and XORd with the bottom input to make
the bottom output.</p>

<p>The top output is then Hadamard’ed again, and finally we observe its value.</p>

<p>Here’s where the magic comes in. By observing the top output, <em>we will know the nature of <code>f(x)</code></em><sup id="fnref:4" role="doc-noteref"><a href="#fn:4" class="footnote">4</a></sup>.</p>

<p>Wait, what? The top output doesn’t appear to have any interaction with <code>f(x)</code> at all! How can that work?</p>

<p>In fact, we could try to rewrite this circuit such that the measured output definitely has no interaction with
<code>f(x)</code> whatever, assuming that the Hadamard gate isn’t doing anything funky<sup id="fnref:7" role="doc-noteref"><a href="#fn:7" class="footnote">5</a></sup> (it isn’t):</p>

<p><img class="center" src="http://manishearth.github.io/images/post/deutsch/deutsch-jozsa-wrong.png" width="600" /></p>

<p>How in the world does this work?</p>

<h2 id="why-it-works">Why it works</h2>

<p>Sadly, I can’t give a satisfying explanation to <em>exactly</em> why this works. This requires some quantum mechanics
background<sup id="fnref:5" role="doc-noteref"><a href="#fn:5" class="footnote">6</a></sup> to grasp.</p>

<p>However, I can give a hopefully-satisfying explanation as to why our regular intuition doesn’t work here.</p>

<p>First and foremost: The rewritten circuit I showed above? It’s wrong. If this was a logic circuit, we could always do that,
but in quantum computing, T-junctions like the following can’t exist:</p>

<p><img class="center" src="http://manishearth.github.io/images/post/deutsch/deutsch-jozsa-tjunction.png" width="600" /></p>

<p>This is due to the <a href="https://en.wikipedia.org/wiki/No-cloning_theorem">“No Cloning theorem”</a>. Unlike regular logic circuits, you can’t
just “duplicate” a qubit. In some cases (like this one), you can try to create a similar qubit
via the same process (e.g. here we could take another 0 and pass it through a Hadamard gate), but
it’s not the “same” qubit. Unlike bits, qubits have a stronger notion of unique identity.</p>

<p>And it’s this sense of identity that fuels this algorithm (and most of quantum computing).</p>

<p>You see, while the top output of the oracle was <code>x</code>, it wasn’t exactly the <em>same</em> <code>x</code>. This <code>x</code> had
been mixed with the lower output. This means that the upper and lower outputs are now <em>entangled</em>,
with their state depending on each other. In fact, it’s really misleading to show the output as two
wires in the first place – it’s really a single “entangled” state of two qubits that can’t be
decomposed as a “top half” and a “bottom half”. Of course, this way of representing quantum circuits
is still used because it’s a tidy way of visualizing these circuits, and physicists are aware of the
caveats involved.</p>

<p>So what happens is that when you observe the top output, you are really doing a partial observation
on the combined state of the two outputs, and this includes some information about <code>f(x)</code>, which
leaks out when you perform the observation.</p>

<p>These properties of qubits make quantum circuits work significantly differently from regular logic
ones. On one hand, this severely restricts what you can do with them, but at the same time, new
avenues of erstwhile-impossible operations open up. Most useful quantum algorithms (like Shor’s
factorization algorithm) involve a mixture of a classical algorithm and a quantum circuit due to
this reason. It’s pretty cool!</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>What isn’t? <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>The abstruseness of physics lives after it; the coolness is oft interred with its bones. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>This actually can be generalized to a function with n input and n output qubits, and the circuit stays mostly the same, except the top “x” line becomes n lines all initialized to 0 and passing through n parallel H gates. <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:4" role="doc-endnote">
      <p>Specifically, if the observation is 1, the function is a constant, whereas if the observation is 0, the function is “balanced” (gives a different output for inputs 1 and 0) <a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:7" role="doc-endnote">
      <p>For Hadamard is an honorable gate. So are they all, all honorable gates. <a href="#fnref:7" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:5" role="doc-endnote">
      <p>If you do have this background, it’s relatively straightforward; the Wikipedia page has the equations for it. <a href="#fnref:5" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
  </entry>
  
</feed>
