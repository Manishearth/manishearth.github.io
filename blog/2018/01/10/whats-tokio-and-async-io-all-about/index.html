
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>What Are Tokio and Async IO All About? - In Pursuit of Laziness</title>
  <meta name="author" content="Manish Goregaokar">

  
  <meta name="description" content="The Rust community lately has been focusing a lot on “async I/O” through the tokio
project. This is pretty great! But for many in the community who &hellip;">
  
  <!-- Tweaked https://harimenon.com/blog/2013/02/23/twitter-cards-for-octopress-blogs/ -->
  
      <meta property="twitter:card" content="summary">
      <meta property="twitter:site" content="Manishearth">
      <meta property="twitter:url" content="http://manishearth.github.io">
      <meta property="twitter:title" content="What are Tokio and Async IO all about?">
      <meta property="twitter:description" content="The Rust community lately has been focusing a lot on “async I/O” through the tokio
project. This is pretty great! But for many in the community who haven’t worked with web servers and related things &hellip;">
      <meta name="twitter:image" content="http://manishearth.github.io/images/me.png" />
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://manishearth.github.io/blog/2018/01/10/whats-tokio-and-async-io-all-about/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/stylesheets/data-table.css" media="screen, projection" rel="stylesheet" type="text/css" />
  <link href="/stylesheets/custom.css" media="screen, projection" rel="stylesheet" type="text/css" />
  <link href="/atom.xml" rel="alternate" title="In Pursuit of Laziness" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="/javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <script src="/javascripts/manish.js" type="text/javascript"></script>
  <!--- MathJax Configuration -->
  
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-62537162-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">In Pursuit of Laziness</a></h1>
  
    <h2>Manish Goregaokar's blog</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="sitesearch" value="manishearth.github.io">
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/blog/categories">Categories</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
    
    

    
      <h1 class="entry-title">What Are Tokio and Async IO All About?</h1>
      <em>Posted by Manish Goregaokar on January 10, 2018 in <a class='category' href='/blog/categories/programming/'>programming</a>, <a class='category' href='/blog/categories/rust/'>rust</a></em>
    
    
      <p class="meta">
        





        
      </p>
    
  </header>


<div class="entry-content"><p>The Rust community lately has been focusing a lot on “async I/O” through the <a href="https://github.com/tokio-rs/">tokio</a>
project. This is pretty great!</p>

<p>But for many in the community who haven’t worked with web servers and related things it’s pretty
confusing as to what we’re trying to achieve there. When this stuff was being discussed around 1.0,
I was pretty lost as well, having never worked with this stuff before.</p>

<p>What’s all this Async I/O business about? What are coroutines? Lightweight threads? Futures? How
does this all fit together?</p>

<h2 id="what-problem-are-we-trying-to-solve">What problem are we trying to solve?</h2>

<p>One of Rust’s key features is “fearless concurrency”. But the kind of concurrency required for handling a
large amount of I/O bound tasks – the kind of concurrency found in Go, Elixir, Erlang – is absent
from Rust.</p>

<p>Let’s say you want to build something like a web service. It’s going to be handling thousands of
requests at any point in time (known as the “<a href="https://en.wikipedia.org/wiki/C10k_problem">c10k</a> problem”). In general, the problem we’re
considering is having a huge number of I/O bound (usually network I/O) tasks.</p>

<p>“Handling N things at once” is best done by using threads. But … <em>thousands</em> of threads? That
sounds a bit much. Threads can be pretty expensive: Each thread needs to allocate a large stack,
setting up a thread involves a bunch of syscalls, and context switching is expensive.</p>

<p>Of course, thousands of threads <em>all doing work</em> at once is not going to work anyway. You only
have a fixed number of cores, and at any one time only one thread will be running on a core.</p>

<p>But for cases like web servers, most of these threads won’t be doing work. They’ll be waiting on the
network. Most of these threads will either be listening for a request, or waiting for their response
to get sent.</p>

<p>With regular threads, when you perform a blocking I/O operation, the syscall returns control
to the kernel, which won’t yield control back, because the I/O operation is probably not finished.
Instead, it will use this as an opportunity to swap in a different thread, and will swap the original
thread back when its I/O operation is finished (i.e. it’s “unblocked”). Without Tokio and friends,
this is how you would handle such things in Rust. Spawn a million threads; let the OS deal with
scheduling based on I/O.</p>

<p>But, as we already discovered, threads don’t scale well for things like this<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">1</a></sup>.</p>

<p>We need “lighter” threads.</p>

<h2 id="lightweight-threading">Lightweight threading</h2>

<p>I think the best way to understand lightweight threading is to forget about Rust for a moment
and look at a language that does this well, Go.</p>

<p>Instead of using OS threads, Go has lightweight threads, called “goroutines”. You spawn these with the <code class="language-plaintext highlighter-rouge">go</code>
keyword. A web server might do something like this:</p>

<div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">listener</span><span class="p">,</span> <span class="n">err</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">Listen</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="c">// handle err</span>
<span class="k">for</span> <span class="p">{</span>
    <span class="n">conn</span><span class="p">,</span> <span class="n">err</span> <span class="o">:=</span> <span class="n">listener</span><span class="o">.</span><span class="n">Accept</span><span class="p">()</span>
    <span class="c">// handle err</span>

    <span class="c">// spawn goroutine:</span>
    <span class="k">go</span> <span class="n">handler</span><span class="p">(</span><span class="n">conn</span><span class="p">)</span>
<span class="p">}</span>
</code></pre></div></div>

<p>This is a loop which waits for new TCP connections, and spawns a goroutine with the connection
and the function <code class="language-plaintext highlighter-rouge">handler</code>. Each connection will be a new goroutine, and the goroutine will shut down
when <code class="language-plaintext highlighter-rouge">handler</code> finishes. In the meantime, the main loop continues executing, because it’s running in
a different goroutine.</p>

<p>So if these aren’t “real” (operating system) threads, what’s going on?</p>

<p>A goroutine is an example of a “lightweight” thread. The operating system doesn’t know about these,
it sees N threads owned by the Go runtime, and the Go runtime maps M goroutines onto them<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote">2</a></sup>, swapping
goroutines in and out much like the operating system scheduler. It’s able to do this because
Go code is already interruptible for the GC to be able to run, so the scheduler can always ask goroutines
to stop. The scheduler is also aware of I/O, so when a goroutine is waiting on I/O it yields to the scheduler.</p>

<p>Essentialy, a compiled Go function will have a bunch of points scattered throughout it where it
tells the scheduler and GC “take over if you want” (and also “I’m waiting on stuff, please take
over”).</p>

<p>When a goroutine is swapped on an OS thread, some registers will be saved, and
the program counter will switch to the new goroutine.</p>

<p>But what about its stack? OS threads have a large stack with them, and you kinda need a stack for functions
and stuff to work.</p>

<p>What Go used to do was segmented stacks. The reason a thread needs a large stack is that most
programming languages, including C, expect the stack to be contiguous, and stacks can’t just be
“reallocated” like we do with growable buffers since we expect stack data to stay put so that
pointers to stack data to continue to work. So we reserve all the stack we think we’ll ever need
(~8MB), and hope we don’t need more.</p>

<p>But the expectation of stacks being contiguous isn’t strictly necessary. In Go, stacks are made of tiny
chunks. When a function is called, it checks if there’s enough space on the stack for it to run, and if not,
allocates a new chunk of stack and runs on it. So if you have thousands of threads doing a small amount of work,
they’ll all get thousands of tiny stacks and it will be fine.</p>

<p>These days, Go actually does something different; it <a href="https://blog.cloudflare.com/how-stacks-are-handled-in-go/">copies stacks</a>. I mentioned that stacks can’t
just be “reallocated” we expect stack data to stay put. But that’s not necessarily true —
because Go has a GC it knows what all the pointers are <em>anyway</em>, and it can rewrite pointers to
stack data on demand.</p>

<p>Either way, Go’s rich runtime lets it handle this stuff well. Goroutines are super cheap, and you can spawn
thousands without your computer having problems.</p>

<p>Rust <em>used</em> to support lightweight/”green” threads (I believe it used segmented stacks). However, Rust cares
a lot about not paying for things you don’t use, and this imposes a penalty on all your code even if you
aren’t using green threads, and it was removed pre-1.0.</p>

<h2 id="async-io">Async I/O</h2>

<p>A core building block of this is Async I/O. As mentioned in the previous section,
with regular blocking I/O, the moment you request I/O your thread will not be allowed to run
(“blocked”) until the operation is done. This is perfect when working with OS threads (the OS
scheduler does all the work for you!), but if you have lightweight threads you instead want to
replace the lightweight thread running on the OS thread with a different one.</p>

<p>Instead, you use non-blocking I/O, where the thread queues a request for I/O with the OS and continues
execution. The I/O request is executed at some later point by the kernel. The thread then needs to ask the
OS “Is this I/O request ready yet?” before looking at the result of the I/O.</p>

<p>Of course, repeatedly asking the OS if it’s done can be tedious and consume resources. This is why
there are system calls like <a href="https://en.wikipedia.org/wiki/Epoll"><code class="language-plaintext highlighter-rouge">epoll</code></a>. Here, you can bundle together a bunch of unfinished I/O requests,
and then ask the OS to wake up your thread when <em>any</em> of these completes. So you can have a scheduler
thread (a real thread) that swaps out lightweight threads that are waiting on I/O, and when there’s nothing
else happening it can itself go to sleep with an <code class="language-plaintext highlighter-rouge">epoll</code> call until the OS wakes it up (when one of the I/O
requests completes).</p>

<p>(The exact mechanism involved here is probably more complex)</p>

<p>So, bringing this to Rust, Rust has the <a href="https://github.com/carllerche/mio">mio</a> library, which is a platform-agnostic
wrapper around non-blocking I/O and tools like epoll/kqueue/etc. It’s a building block; and while
those used to directly using <code class="language-plaintext highlighter-rouge">epoll</code> in C may find it helpful, it doesn’t provide a nice programming
model like Go does. But we can get there.</p>

<h2 id="futures">Futures</h2>

<p>These are another building block. A <a href="https://docs.rs/futures/0.1.17/futures/future/trait.Future.html"><code class="language-plaintext highlighter-rouge">Future</code></a> is the promise of eventually having a value
(in fact, in Javascript these are called <code class="language-plaintext highlighter-rouge">Promise</code>s).</p>

<p>So for example, you can ask to listen on a network socket, and get a <code class="language-plaintext highlighter-rouge">Future</code> back  (actually, a
<code class="language-plaintext highlighter-rouge">Stream</code>, which is like a future but for a sequence of values). This <code class="language-plaintext highlighter-rouge">Future</code> won’t contain the
response <em>yet</em>, but will know when it’s ready. You can <code class="language-plaintext highlighter-rouge">wait()</code> on a <code class="language-plaintext highlighter-rouge">Future</code>, which will block
until you have a result, and you can also <code class="language-plaintext highlighter-rouge">poll()</code> it, asking it if it’s done yet (it will give you
the result if it is).</p>

<p>Futures can also be chained, so you can do stuff like <code class="language-plaintext highlighter-rouge">future.then(|result| process(result))</code>.
The closure passed to <code class="language-plaintext highlighter-rouge">then</code> itself can produce another future, so you can chain together
things like I/O operations. With chained futures, <code class="language-plaintext highlighter-rouge">poll()</code> is how you make progress; each time
you call it it will move on to the next future provided the existing one is ready.</p>

<p>This is a pretty good abstraction over things like non-blocking I/O.</p>

<p>Chaining futures works much like chaining iterators. Each <code class="language-plaintext highlighter-rouge">and_then</code> (or whatever combinator)
call returns a struct wrapping around the inner future, which may contain an additional closure.
Closures themselves carry their references and data with them, so this really ends up being
very similar to a tiny stack!</p>

<h2 id="-tokio-">🗼 Tokio 🗼</h2>

<p>Tokio’s essentially a nice wrapper around mio that uses futures. Tokio has a core
event loop, and you feed it closures that return futures. What it will do is
run all the closures you feed it, use mio to efficiently figure out which futures
are ready to make a step<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote">3</a></sup>, and make progress on them (by calling <code class="language-plaintext highlighter-rouge">poll()</code>).</p>

<p>This actually is already pretty similar to what Go was doing, at a conceptual level.
You have to manually set up the Tokio event loop (the “scheduler”), but once you do
you can feed it tasks which intermittently do I/O, and the event loop takes
care of swapping over to a new task when one is blocked on I/O. A crucial difference is
that Tokio is single threaded, whereas the Go scheduler can use multiple OS threads
for execution. However, you can offload CPU-critical tasks onto other OS threads and
use channels to coordinate so this isn’t that big a deal.</p>

<p>While at a conceptual level this is beginning to shape up to be similar to what we had for Go, code-wise this doesn’t look so pretty. For the following Go code:</p>

<div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">// error handling ignored for simplicity</span>

<span class="k">func</span> <span class="n">foo</span><span class="p">(</span><span class="o">...</span><span class="p">)</span> <span class="n">ReturnType</span> <span class="p">{</span>
    <span class="n">data</span> <span class="o">:=</span> <span class="n">doIo</span><span class="p">()</span>
    <span class="n">result</span> <span class="o">:=</span> <span class="n">compute</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">moreData</span> <span class="o">=</span> <span class="n">doMoreIo</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
    <span class="n">moreResult</span> <span class="o">:=</span> <span class="n">moreCompute</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="c">// ...</span>
    <span class="k">return</span> <span class="n">someFinalResult</span>
<span class="p">}</span>
</code></pre></div></div>

<p>The Rust code will look something like</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">// error handling ignored for simplicity</span>

<span class="k">fn</span> <span class="nf">foo</span><span class="p">(</span><span class="o">...</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">Future</span><span class="o">&lt;</span><span class="n">ReturnType</span><span class="p">,</span> <span class="n">ErrorType</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="nf">do_io</span><span class="p">()</span><span class="nf">.and_then</span><span class="p">(|</span><span class="n">data</span><span class="p">|</span> <span class="nf">do_more_io</span><span class="p">(</span><span class="nf">compute</span><span class="p">(</span><span class="n">data</span><span class="p">)))</span>
          <span class="nf">.and_then</span><span class="p">(|</span><span class="n">more_data</span><span class="p">|</span> <span class="nf">do_even_more_io</span><span class="p">(</span><span class="nf">more_compute</span><span class="p">(</span><span class="n">more_data</span><span class="p">)))</span>
    <span class="c">// ......</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Not pretty. <a href="https://docs.rs/futures/0.1.25/futures/future/fn.loop_fn.html#examples">The code gets worse if you introduce branches and loops</a>. The problem is that in Go we
got the interruption points for free, but in Rust we have to encode this by chaining up combinators
into a kind of state machine. Ew.</p>

<h2 id="generators-and-asyncawait">Generators and async/await</h2>

<p>This is where generators (also called coroutines) come in.</p>

<p><a href="https://doc.rust-lang.org/nightly/unstable-book/language-features/generators.html">Generators</a> are an experimental feature in Rust. Here’s an example:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">let</span> <span class="k">mut</span> <span class="n">generator</span> <span class="o">=</span> <span class="p">||</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="k">loop</span> <span class="p">{</span>
        <span class="n">yield</span> <span class="n">i</span><span class="p">;</span>
        <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="p">}</span>
<span class="p">};</span>
<span class="nd">assert_eq!</span><span class="p">(</span><span class="n">generator</span><span class="nf">.resume</span><span class="p">(),</span> <span class="nn">GeneratorState</span><span class="p">::</span><span class="nf">Yielded</span><span class="p">(</span><span class="mi">0</span><span class="p">));</span>
<span class="nd">assert_eq!</span><span class="p">(</span><span class="n">generator</span><span class="nf">.resume</span><span class="p">(),</span> <span class="nn">GeneratorState</span><span class="p">::</span><span class="nf">Yielded</span><span class="p">(</span><span class="mi">1</span><span class="p">));</span>
<span class="nd">assert_eq!</span><span class="p">(</span><span class="n">generator</span><span class="nf">.resume</span><span class="p">(),</span> <span class="nn">GeneratorState</span><span class="p">::</span><span class="nf">Yielded</span><span class="p">(</span><span class="mi">2</span><span class="p">));</span>
</code></pre></div></div>

<p>Functions are things which execute a task and return once. On the other hand, generators
return multiple times; they pause execution to “yield” some data, and can be resumed
at which point they will run until the next yield. While my example doesn’t show this, generators
can also finish executing like regular functions.</p>

<p>Closures in Rust are
<a href="http://huonw.github.io/blog/2015/05/finding-closure-in-rust/">sugar for a struct containing captured data, plus an implementation of one of the <code class="language-plaintext highlighter-rouge">Fn</code> traits to make it callable</a>.</p>

<p>Generators are similar, except they implement the <code class="language-plaintext highlighter-rouge">Generator</code> trait<sup id="fnref:5" role="doc-noteref"><a href="#fn:5" class="footnote">4</a></sup>, and usually store an enum representing various states.</p>

<p>The <a href="https://doc.rust-lang.org/nightly/unstable-book/language-features/generators.html#generators-as-state-machines">unstable book</a> has some examples on what the generator state machine enum will look like.</p>

<p>This is much closer to what we were looking for! Now our code can look like this:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="nf">foo</span><span class="p">(</span><span class="o">...</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">Future</span><span class="o">&lt;</span><span class="n">ReturnType</span><span class="p">,</span> <span class="n">ErrorType</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">generator</span> <span class="o">=</span> <span class="p">||</span> <span class="p">{</span>
        <span class="k">let</span> <span class="k">mut</span> <span class="n">future</span> <span class="o">=</span> <span class="nf">do_io</span><span class="p">();</span>
        <span class="k">let</span> <span class="n">data</span><span class="p">;</span>
        <span class="k">loop</span> <span class="p">{</span>
            <span class="c">// poll the future, yielding each time it fails,</span>
            <span class="c">// but if it succeeds then move on</span>
            <span class="k">match</span> <span class="n">future</span><span class="nf">.poll</span><span class="p">()</span> <span class="p">{</span>
                <span class="nf">Ok</span><span class="p">(</span><span class="nn">Async</span><span class="p">::</span><span class="nf">Ready</span><span class="p">(</span><span class="n">d</span><span class="p">))</span> <span class="k">=&gt;</span> <span class="p">{</span> <span class="n">data</span> <span class="o">=</span> <span class="n">d</span><span class="p">;</span> <span class="k">break</span> <span class="p">},</span>
                <span class="nf">Ok</span><span class="p">(</span><span class="nn">Async</span><span class="p">::</span><span class="nf">NotReady</span><span class="p">(</span><span class="n">d</span><span class="p">))</span> <span class="k">=&gt;</span> <span class="p">(),</span>
                <span class="nf">Err</span><span class="p">(</span><span class="o">..</span><span class="p">)</span> <span class="k">=&gt;</span> <span class="o">...</span>
            <span class="p">};</span>
            <span class="n">yield</span> <span class="n">future</span><span class="nf">.polling_info</span><span class="p">();</span>
        <span class="p">}</span>
        <span class="k">let</span> <span class="n">result</span> <span class="o">=</span> <span class="nf">compute</span><span class="p">(</span><span class="n">data</span><span class="p">);</span>
        <span class="c">// do the same thing for `doMoreIo()`, etc</span>
    <span class="p">}</span>

    <span class="nf">futurify</span><span class="p">(</span><span class="n">generator</span><span class="p">)</span>
<span class="p">}</span>
</code></pre></div></div>

<p>where <code class="language-plaintext highlighter-rouge">futurify</code> is a function that takes a generator and returns a future which on
each <code class="language-plaintext highlighter-rouge">poll</code> call will <code class="language-plaintext highlighter-rouge">resume()</code> the generator, and return <code class="language-plaintext highlighter-rouge">NotReady</code> until the generator
finishes executing.</p>

<p>But wait, this is even <em>more</em> ugly! What was the point of converting our relatively
clean callback-chaining code into this mess?</p>

<p>Well, if you look at it, this code now looks <em>linear</em>. We’ve converted our callback
code to the same linear flow as the Go code, however it has this weird loop-yield boilerplate
and the <code class="language-plaintext highlighter-rouge">futurify</code> function and is overall not very neat.</p>

<p>And that’s where <a href="https://github.com/alexcrichton/futures-await">futures-await</a> comes in. <code class="language-plaintext highlighter-rouge">futures-await</code> is a procedural macro that
does the last-mile work of packaging away this boilerplate. It essentially lets you write
the above function as</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">#[async]</span>
<span class="k">fn</span> <span class="nf">foo</span><span class="p">(</span><span class="o">...</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">Result</span><span class="o">&lt;</span><span class="n">ReturnType</span><span class="p">,</span> <span class="n">ErrorType</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">data</span> <span class="o">=</span> <span class="k">await</span><span class="o">!</span><span class="p">(</span><span class="nf">do_io</span><span class="p">());</span>
    <span class="k">let</span> <span class="n">result</span> <span class="o">=</span> <span class="nf">compute</span><span class="p">(</span><span class="n">data</span><span class="p">);</span>
    <span class="k">let</span> <span class="n">more_data</span> <span class="o">=</span> <span class="k">await</span><span class="o">!</span><span class="p">(</span><span class="nf">do_more_io</span><span class="p">());</span>
    <span class="c">// ....</span>
</code></pre></div></div>

<p>Nice and clean. Almost as clean as the Go code, just that we have explicit <code class="language-plaintext highlighter-rouge">await!()</code> calls. These
await calls are basically providing the same function as the interruption points that Go code
gets implicitly.</p>

<p>And, of course, since it’s using a generator under the hood, you can loop and branch and do whatever
else you want as normal, and the code will still be clean.</p>

<h2 id="tying-it-together">Tying it together</h2>

<p>So, in Rust, futures can be chained together to provide a lightweight stack-like system. With async/await,
you can neatly write these future chains, and <code class="language-plaintext highlighter-rouge">await</code> provides explicit interruption points on each I/O operation.
Tokio provides an event loop “scheduler” abstraction, which you can feed async functions to, and under the hood it
uses mio to abstract over low level non-blocking I/O primitives.</p>

<p>These are components which can be used independently — you can use tokio with futures without
using async/await. You can use async/await without using Tokio. For example, I think this would be
useful for Servo’s networking stack. It doesn’t need to do <em>much</em> parallel I/O (not at the order
of thousands of threads), so it can just use multiplexed OS threads. However, we’d still want
to pool threads and pipeline data well, and async/await would help here.</p>

<p>Put together, all these components get something almost as clean as the Go stuff, with a little more
explicit boilerplate. Because generators (and thus async/await) play nice with the borrow checker
(they’re just enum state machines under the hood), Rust’s safety guarantees are all still in play,
and we get to have “fearless concurrency” for programs having a huge quantity of I/O bound tasks!</p>

<p><em>Thanks to Arshia Mufti, Steve Klabnik, Zaki Manian, and Kyle Huey for reviewing drafts of this post</em></p>
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>Note that this isn’t necessarily true for <em>all</em> network server applications. For example, Apache uses OS threads. OS threads are often the best tool for the job. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>Lightweight threading is also often called M:N threading (also “green threading”) <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>In general future combinators aren’t really aware of tokio or even I/O, so there’s no easy way to ask a combinator “hey, what I/O operation are you waiting for?”. Instead, with Tokio you use special I/O primitives that still provide futures but also register themselves with the scheduler in thread local state. This way when a future is waiting for I/O, Tokio can check what the recentmost I/O operation was, and associate it with that future so that it can wake up that future again when <code class="language-plaintext highlighter-rouge">epoll</code> tells it that that I/O operation is ready. (<em>Edit Dec 2018: This has changed, futures now have a built in <code class="language-plaintext highlighter-rouge">Waker</code> concept that handles passing things up the stack</em>) <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:5" role="doc-endnote">
      <p>The <code class="language-plaintext highlighter-rouge">Generator</code> trait has a <code class="language-plaintext highlighter-rouge">resume()</code> function which you can call multiple times, and each time it will return any yielded data or tell you that the generator has finished running. <a href="#fnref:5" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>
</div>


  <footer>
    <p class="meta">
      
<span class="byline author vcard beforesep">Posted by <span class="fn">Manish Goregaokar</span></span>

      





      


<span class="aftersep beforesep">
    <a class='category' href='/blog/categories/mozilla/'><img width='16px' style='border:none;box-shadow:none;vertical-align:middle;' src='/images/mozilla-dino.png' title='This post will show up on planet.mozilla.org' /></a>
</span>


<span class="categories aftersep">
  
    <a class='category' href='/blog/categories/programming/'>programming</a>, <a class='category' href='/blog/categories/rust/'>rust</a>
  
</span>


    </p>
    
      <div class="sharing">
  
  <a href="//twitter.com/share" class="twitter-share-button" data-url="http://manishearth.github.io/blog/2018/01/10/whats-tokio-and-async-io-all-about/" data-via="Manishearth" data-counturl="http://manishearth.github.io/blog/2018/01/10/whats-tokio-and-async-io-all-about/" >Tweet</a>
  
  
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/2018/01/10/rust-in-2018/" title="Previous Post: Rust in 2018">&laquo; Rust in 2018</a>
      
      
        <a class="basic-alignment right" href="/blog/2018/02/01/a-rough-proposal-for-sum-types-in-go/" title="Next Post: A rough proposal for sum types in Go">A rough proposal for sum types in Go &raquo;</a>
      
    </p>
  </footer>
</article>

</div>

<aside class="sidebar">
  
    <section>
<h1> About Me </h1>
<div id="about">
    I'm a self-taught programmer with interests in programming languages, human languages, Rust, physics, and online communities to name a few. <br><br>

    I'm heavily involved in the <a href="https://www.rust-lang.org">Rust programming language</a>, leading the <a href="https://www.rust-lang.org/governance/teams/dev-tools">Devtools</a> and <a href="https://www.rust-lang.org/governance/teams/dev-tools#clippy">Clippy</a> teams. I also work at Google on <a href="https://github.com/unicode-org/icu4x">ICU4X</a>.
</div>
<div id="doodads">
 <a href="http://twitter.com/Manishearth" style="white-space:normal">   <img style="border:none;box-shadow:none" src="/images/twitter.png" width="30px"></a>
 <a href="http://github.com/Manishearth" style="white-space:normal">   <img style="border:none;box-shadow:none"  src="/images/github.png" width="30px"></a>
</div>
</section>
<section>
<!-- <iframe scrolling="no" style="border: 0; height: 58px; width: 208px; overflow: hidden;" src="https://se-flair.appspot.com/751483b5-3bd0-467a-b3aa-f0bb8ac3887d/"></iframe> -->
</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2021/04/05/a-tour-of-safe-tracing-gc-designs-in-rust/">A Tour of Safe Tracing GC Designs in Rust</a>
      </li>
    
      <li class="post">
        <a href="/blog/2021/03/15/arenas-in-rust/">Arenas in Rust</a>
      </li>
    
      <li class="post">
        <a href="/blog/2021/02/22/integrating-rust-and-c-plus-plus-in-firefox/">Integrating Rust and C++ in Firefox</a>
      </li>
    
      <li class="post">
        <a href="/blog/2019/10/09/on-voting-systems/">On Voting Systems</a>
      </li>
    
      <li class="post">
        <a href="/blog/2019/02/04/rust-governance-scaling-empathy/">Rust Governance: Scaling Empathy</a>
      </li>
    
  </ul>
</section>
<section>
  <h1>Categories</h1>
  <ul id="sidebar_categories">
    <li class='category'><a href='/blog/categories/c-/'>c++ (2)</a></li>
<li class='category'><a href='/blog/categories/cryptography/'>cryptography (5)</a></li>
<li class='category'><a href='/blog/categories/css/'>css (1)</a></li>
<li class='category'><a href='/blog/categories/elections/'>elections (1)</a></li>
<li class='category'><a href='/blog/categories/html/'>html (1)</a></li>
<li class='category'><a href='/blog/categories/js/'>js (1)</a></li>
<li class='category'><a href='/blog/categories/physics/'>physics (1)</a></li>
<li class='category'><a href='/blog/categories/poetry/'>poetry (2)</a></li>
<li class='category'><a href='/blog/categories/politics/'>politics (1)</a></li>
<li class='category'><a href='/blog/categories/programming/'>programming (43)</a></li>
<li class='category'><a href='/blog/categories/rust/'>rust (27)</a></li>
<li class='category'><a href='/blog/categories/systems/'>systems (1)</a></li>
<li class='category'><a href='/blog/categories/tidbits/'>tidbits (5)</a></li>
<li class='category'><a href='/blog/categories/unicode/'>unicode (3)</a></li>
<li class='category'><a href='/blog/categories/web/'>web (2)</a></li>
<li class='category'><a href='/blog/categories/writing/'>writing (1)</a></li>

  </ul>
</section>
  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2021 - Manish Goregaokar - Licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/">CC BY SA 4.0</a> - 
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
