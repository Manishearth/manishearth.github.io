<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Crypto | In Pursuit of Laziness]]></title>
  <link href="http://manishearth.github.io/blog/categories/crypto/atom.xml" rel="self"/>
  <link href="http://manishearth.github.io/"/>
  <updated>2017-04-13T07:54:48-07:00</updated>
  <id>http://manishearth.github.io/</id>
  <author>
    <name><![CDATA[Manish Goregaokar]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Use Signal. Use Tor.]]></title>
    <link href="http://manishearth.github.io/blog/2017/03/12/use-signal-use-tor/"/>
    <updated>2017-03-12T12:36:54-07:00</updated>
    <id>http://manishearth.github.io/blog/2017/03/12/use-signal-use-tor</id>
    <content type="html"><![CDATA[<p>I went to send a missive today<br>
As I have done so oft before<br>
But I forgot to employ that scrap of advice<br>
&ldquo;Use Signal. Use Tor.&rdquo;</p>

<p>Intercepted of course the missive was<br>
By a ferocious beast of lore<br>
Because I failed to use that bit of advice<br>
&ldquo;Use Signal. Use Tor.&rdquo;</p>

<p>The beast was strong; and formidable<br>
He hated the amendments four<br>
I should have remembered that piece of advice<br>
&ldquo;Use Signal. Use Tor.&rdquo;</p>

<p>I tried to reason with the beast<br>
but he only wanted war<br>
Do not neglect that important advice<br>
&ldquo;Use Signal. Use Tor.&rdquo;</p>

<p>Here I lie in the belly of the beast<br>
I shall discount this advice no more<br>
If I ever manage to leave this place<br>
I&rsquo;ll use Signal, and Tor.</p>

<p>Heed this advice, children.<br>
It&rsquo;s not something to ignore<br>
Always, always, always, always<br>
Use Signal. Use Tor.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Clarifying Misconceptions About SHAttered]]></title>
    <link href="http://manishearth.github.io/blog/2017/02/26/clarifying-misconceptions-about-shattered/"/>
    <updated>2017-02-26T00:30:56-08:00</updated>
    <id>http://manishearth.github.io/blog/2017/02/26/clarifying-misconceptions-about-shattered</id>
    <content type="html"><![CDATA[<p>This week Google published a <a href="https://shattered.io/">SHA-1 collision</a>.</p>

<p>There&rsquo;s a lot of confusion about the implications of this. A lot of this is due to differences of
opinion on what exactly constitutes a &ldquo;new&rdquo; collision. I <a href="https://twitter.com/ManishEarth/status/835557328308969472">tweeted about this</a>. The webpage
for the attack itself is misleading, saying that the answer to &ldquo;Who is capable of mounting this attack?&rdquo;
is people with Google-esque resources. This depends on what exactly you mean by &ldquo;this attack&rdquo;.</p>

<p>So I&rsquo;m seeing a lot of &ldquo;oh well just another anti-milestone for SHA, doesn&rsquo;t affect anyone since its
still quite expensive to exploit&rdquo; reactions, as well as the opposite &ldquo;aaaaa everything is on fire&rdquo;
reaction. Both are wrong. It has practical implications for you even if you are certain that you
won&rsquo;t attract the ire of an entity with a lot of computational power. None of these implications,
however, are likely to be disastrous.</p>

<p>TLDR: Now <em>anyone</em>, without needing Google-esque resources,
can generate two colliding PDFs with arbitrary visual content in each.</p>

<p>(In fact, there&rsquo;s already <a href="http://alf.nu/SHA1">a PDF collision-generator</a> up where
you can upload two images and get a PDF with collisions in it)</p>

<h2>Okay, back up a bit. What&rsquo;s a hash? What&rsquo;s SHA-1?</h2>

<p>I explained this a bit in my older post about <a href="http://manishearth.github.io/blog/2016/03/05/exploring-zero-knowledge-proofs/">zero-knowledge-proofs</a>.</p>

<p>In essence, a hash function takes some data (usually of arbitrary size), and produces a value called
a <em>hash</em> (usually of fixed size). The function has some additional properties:</p>

<ul>
<li>In almost all cases, a small perturbation in the input will lead to a large perturbation in the hash</li>
<li>Given an input and its hash, it is computationally hard to find an alternate input producing the same hash</li>
<li>It&rsquo;s also hard to just find two inputs that has to the same value, though this is usually easier than the previous one</li>
</ul>


<p>when two inputs hash to the same value, this is called a collision. As mentioned, is easier to find
<em>a</em> collision, over finding a colliding alternate input for a known input.</p>

<p>SHA-1 is one such hash function. It&rsquo;s been known for a while that it&rsquo;s insecure, and the industry has
largely moved off of it, but it&rsquo;s still used,</p>

<h2>What did the researchers do?</h2>

<p>They found a hash collision for SHA-1. In essence, they found two strings, <code>A</code> and <code>B</code>, where
<code>SHA1(A) == SHA1(B)</code>.</p>

<p><em>However</em>, given the way SHA-1 works, this means that you can generate infinitely many other
such pairs of strings. And given the nature of the exact <code>A</code> and <code>B</code> they created, it is possible
to use this to create arbitrary colliding PDFs.</p>

<p>Basically, SHA-1 (and many other hash functions), operate on &ldquo;blocks&rdquo;. These are fixed-size chunks
of data, where the size is a property of the hash function. For SHA1 this is 512 bits.</p>

<p>The function starts off with an &ldquo;initial&rdquo; built-in hash. It takes the first block of your data and
this hash, and does some computation with the two to produce a new hash, which is its state after
the first block.</p>

<p>It will then take this hash and the second block, and run the same computations to produce
a newer hash, which is its state after the second block. This is repeated till all blocks have
been processed, and the final state is the result of the function.</p>

<p>There&rsquo;s an important thing to notice here. At each block, the only inputs are the block itself and the
hash of the string up to that block.</p>

<p>This means, if <code>A</code> and <code>B</code> are of a size that is a multiple of the block size, and <code>SHA1(A) == SHA1(B)</code>,
then <code>SHA1(A + C) == SHA1(B + C)</code>. This is because, when the hash function reaches <code>C</code>, the state will
be the same due to the hash collision, and after this point the next input blocks are identical in
both cases, so the final hash will be the same.</p>

<p>Now, while you might consider <code>A+C, B+C</code> to be the &ldquo;same collision&rdquo; as <code>A, B</code>, the implications
of this are different than just &ldquo;there is now one known pair of inputs that collide&rdquo;, since everyone
now has the ability to generate new colliding inputs by appending an arbitrary string to <code>A</code> and <code>B</code>.</p>

<p>Of course, these new collisions have the restriction that the strings will always start with <code>A</code> or
<code>B</code> and the suffixes will be identical. If you want to break this restriction, you will
have to devote expensive resources to finding a new collision, like Google did.</p>

<h2>How does this let us generate arbitrary colliding PDFs?</h2>

<p>So this exploit actually uses features of the JPEG format to work. It was done in
a PDF format since JPEGs often get compressed when sent around the Internet. However,
since both A and B start a partial PDF document, they can only be used to generate colliding
PDFs, not JPEGs.</p>

<p>I&rsquo;m going to first sketch out a simplified example of what this is doing, using a hypothetical
pseudocode-y file format. The researchers found a collision between the strings:</p>

<ul>
<li>A: <code>&lt;header data&gt; COMMENT(&lt;nonce for A&gt;) DISPLAY IMAGE 1</code></li>
<li>B: <code>&lt;header data&gt; COMMENT(&lt;nonce for B&gt;) DISPLAY IMAGE 2</code></li>
</ul>


<p>Here, <code>&lt;header data&gt;</code> is whatever is necessary to make the format work, and the &ldquo;nonce&#8221;s are
strings that make <code>A</code> and <code>B</code> have the same hash. Finding these nonces is where
the computational power is required, since you basically have to brute-force a solution.</p>

<p>Now, to both these strings, they append a suffix C: <code>IMAGE 1(&lt;data for image 1&gt;) IMAGE 2(&lt;data for image 2&gt;)</code>.
This creates two complete documents. Both of the documents contain both images, but each one is instructed
to display a different one. Note that since <code>SHA1(A) == SHA1(B)</code>, <code>SHA1(A + C) = SHA1(B + C)</code>, so these
final documents have the same hash.</p>

<p>The contents of <code>C</code> don&rsquo;t affect the collision at all. So, we can insert any two images in <code>C</code>, to create
our own personal pair of colliding PDFs.</p>

<p>The actual technique used is similar to this, and it relies on JPEG comment fields. They have found
a collision between two strings that look like:</p>

<pre><code class="text">pdf header data                       | String A
begin embedded image                  |  
    jpg header data                   |
    declare jpg comment of length N   |
    random nonce of length N          | (comment ends here) 
                                     ---
    image 1, length L                 | String C
    jpg EOF byte (2 bytes)            |
    image 2                           |
end embedded image                    |

and

pdf header data                       | String B
begin embedded image                  |
    jpg header data                   |
    declare jpg comment of length M   |
    random nonce of length M-L-2      |
                                     ---
    image 1, length L                 | String C
    jpg EOF marker (2 bytes)          | (comment ends here)
    image 2                           |
end embedded image                    |
</code></pre>

<p>By playing with the nonces, they managed to generate a collision between <code>A</code> and <code>B</code>. In the first
pdf, the embedded image has a comment containing only the nonce. Once the JPEG reader gets past that
comment, it sees the first image, displays it, and then sees the end-of-file marker and decides to
stop. Since the PDF format doesn&rsquo;t try to interpret the image itself, the PDF format won&rsquo;t be
boggled by the fact that there&rsquo;s some extra garbage data after the JPEG EOF marker. It
simply takes all the data between the &ldquo;begin embedded image&rdquo; and &ldquo;end embedded image&rdquo; blocks,
and passes it to the JPEG decoder. The JPEG decoder itself stops after it sees the end of file
marker, and doesn&rsquo;t get to the extra data for the second image.</p>

<p>In the second pdf, the jpg comment is longer, and subsumes the first image (as well as the EOF marker)
Thus, the JPEG decoder directly gets to the second image, which it displays.</p>

<p>Since the actual images are not part of the original collision (A and B), you can substitute any pair
of jpeg images there, with some length restrictions.</p>

<h2>What are the implications?</h2>

<p>This does mean that you should not trust the integrity of a PDF when all you have
to go on is its SHA-1 hash. Use a better hash. <em>Anyone can generate these colliding PDFs
now.</em></p>

<p>Fortunately, since all such PDFs will have the same prefix A or B, you can detect when
such a deception is being carried out.</p>

<p>Don&rsquo;t check colliding PDFs into SVN. <a href="https://bugs.webkit.org/show_bug.cgi?id=168774#c27">Things break</a>.</p>

<p>In some cases it is possible to use the PDF collision in other formats. For example,
<a href="https://mobile.twitter.com/arw/status/834883944898125824">it can be used to create colliding HTML documents</a>. I think it can be used to colide
ZIP files too.</p>

<p>Outside the world of complex file formats, little has changed. It&rsquo;s still a bad idea to use SHA-1.
It&rsquo;s still possible for people to generate entirely new collisions like Google did, though this
needs a lot of resources. It&rsquo;s possible that someone with resources has already generated such a
&ldquo;universal-key collision&rdquo; for some other file format<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup> and will use it on you, but this was
equally possible before Google published their attack.</p>

<p>This does not make it easier to collide with arbitrary hashes &ndash; if someone else
has uploaded a document with a hash, and you trust them to not be playing any tricks,
an attacker won&rsquo;t be able to generate a colliding document for this without immense
resources. The attack only works when the attacker has control over the initial document;
e.g. in a bait-and-switch-like attack where the attacker uploads document A, you read and verify it
and broadcast your trust in document A with hash <code>SHA(A)</code>, and then the attacker switches it with
document B.</p>
<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>Google&rsquo;s specific collision was designed to be a &ldquo;universal key&rdquo;, since A and B are designed to have the image-switching mechanism built into it. Some other collision may not be like this; it could just be a collision of two images (or whatever) with no such switching mechanism. It takes about the same effort to do either of these, however, so if you have a file format that can be exploited to create a switching mechanism, it would always make more sense to build one into any collision you look for.<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interactive Sudoku Zero-knowledge Proof]]></title>
    <link href="http://manishearth.github.io/blog/2016/08/10/interactive-sudoku-zero-knowledge-proof/"/>
    <updated>2016-08-10T12:21:19-07:00</updated>
    <id>http://manishearth.github.io/blog/2016/08/10/interactive-sudoku-zero-knowledge-proof</id>
    <content type="html"><![CDATA[<p>Back in March I was particularly interested in Zero-Knowledge Proofs. At the time, I wrote
<a href="http://manishearth.github.io/blog/2016/03/05/exploring-zero-knowledge-proofs/">a long blog post</a> introducing them and explaining how the ZKP for generic execution
works.</p>

<p>I was really enjoying learning about them, so I decided to do a presentation on them in my crypto
course. Sadly there wasn&rsquo;t going to be time for explaining the structure of the proof for general
execution, but I could present something more fun: Sudoku.</p>

<p>Sudoku solutions can be proven via ZKP. That is to say, if Peggy has a solution to Victor&rsquo;s Sudoku
problem, she can prove that she has a valid solution without ever revealing any information about
her solution to Victor (aside from the fact that it is valid).</p>

<p>To make the ZKP easier to explain, I wrote an <a href="https://manishearth.github.io/sudoku-zkp/zkp.html">interactive version of it</a>.</p>

<p>I planned to write about it then, but completely forgot till now. Oops.</p>

<p>I&rsquo;m first going to explain how the ZKP is carried out before I explain how the interactive verifier
works. If you aren&rsquo;t familiar with ZKPs, you might want to read
<a href="http://manishearth.github.io/blog/2016/03/05/exploring-zero-knowledge-proofs/">my previous post on the subject</a> up to and including the part about proving graph colorings.</p>

<h2>Proving Sudoku</h2>

<p>This proof is going to be carried out very similarly to the graph coloring proof. Indeed, Sudoku can
be reduced to a graph coloring problem, though that&rsquo;s not how we&rsquo;re going to obtain the ZKP.</p>

<p>Victor has a Sudoku problem:</p>

<p><img src="/images//sudoku-zkp/sudoku-problem.png" width="300"></p>

<p>Peggy has a solution:</p>

<p><img src="/images//sudoku-zkp/sudoku-solution.png" width="300"></p>

<p>In order to not leak information about her solution, Peggy permutes it:</p>

<p><img src="/images//sudoku-zkp/sudoku-solution-permuted.png" width="300"></p>

<p>Basically, there is a 1-1 mapping between the old digits and the new ones. In this specific
permutation, all 3s are replaced by 4s, all 1s by 5s, etc.</p>

<p>She now commits to this permutation by committing to every individual cell. A random nonce is
obtained for each cell, and the contents of that cell are hashed along with the nonce. This
is the same commitment procedure used in the graph coloring ZKP.</p>

<p>These commitments are now sent over to Victor.</p>

<p>Victor ponders for a bit, and demands that Peggy reveal the third row of the sudoku square.</p>

<p><img src="/images//sudoku-zkp/victor-ask.png" width="300"></p>

<p>(Note that this is the non-permuted problem statement)</p>

<p>This row is marked in orange. There are some additional elements marked in green, which I shall
get to shortly.</p>

<p>Peggy reveals the permuted values for this row:</p>

<p><img src="/images//sudoku-zkp/peggy-reveal-orange.png" width="300"></p>

<p>Victor can now verify that all digits 1-9 appear within this permuted row, and that they match the
commitments. This means that they appear in the original solution too (since permutation doesn&rsquo;t
change this fact), and, at least for this row, the solution is correct. If Peggy didn&rsquo;t have a
solution, there was a chance she&rsquo;d be caught in this round if Victor had asked for the right
set of 9 squares to be revealed.</p>

<p>The procedure can be repeated (with a new permutation each time) to minimize this chance, with
Victor asking to reveal a row, column, or 3x3 subsquare each time, until he is certain that Peggy
has a solution.</p>

<p>But wait! This only works towards proving that Peggy has a valid Sudoku solution, not that this
is <em>the</em> solution to Victor&rsquo;s specific problem. Victor only verified that each row/column/subsquare
had no duplicates, a property which is true for all sudoku solutions!</p>

<p>This is where the green squares come in. For any given set of &ldquo;orange squares&rdquo; (a row, column, or
3x3 subsquare), we take the &ldquo;preset&rdquo; digits appearing in the problem statement (In this case: 7, 8,
and 6) in that set of squares. All other instances of those digits preset in the problem statement
form the set of &ldquo;green squares&rdquo;:</p>

<p><img src="/images//sudoku-zkp/victor-ask.png" width="300"></p>

<p>Peggy reveals the permuted values for both the green and orange squares each time:</p>

<p><img src="/images//sudoku-zkp/peggy-reveal-both.png" width="300"></p>

<p>In addition to verifying that there are no duplicates in the orange squares, Victor additionally
verifies that the permutation is consistent. For example, the 7th element in that row is a 6, which
is already preset in the problem statement. There are two other 6s in the problem statement, one in
the 5th row 8th column, and one in the 7th row 1st column. If the permutation is consistent, their
corresponding squares in the revealed portion of the permuted solution should all have the same
digit. In this case, that number is 1. Similarly, the 5th element in that row is a preset 8, and
there&rsquo;s a corresponding green square in the 5th row last column that also has an 8. In the permuted
solution, Victor verifies that they both have the same digit, in this case 7.</p>

<p>This lets Victor ensure that Peggy has a solution to his sudoku problem. The fact that two given
squares must share the same digit is invariant under permutations, so this can be safely verified.
In fact, a sudoku problem is really just a problem saying &ldquo;Fill these 81 squares with 9 symbols such
that there are no duplicates in any row/column/subsquare, and these three squares have the same
symbol in them, and these five squares have the same symbol in them, and &hellip;&rdquo;. So that&rsquo;s all we
verify: There should be no duplicates, and the digits in certain sets of squares should be the same.</p>

<p>Note that revealing the green squares doesn&rsquo;t reveal additional information about Peggy&rsquo;s solution.
Assuming Peggy&rsquo;s solution is correct, from comparing the problem statement with the
revealed/permuted values, Victor already <em>knows</em> that in the permutation, 7 has become 6, 8 has
become 7, and 6 has become 1. So he already knows what the other preset green squares contain, he
is just verifying them.</p>

<p>We cannot reveal anything <em>more</em> than the green squares, since that would reveal additional
information about the permutation and thus the solution.</p>

<p>Edit: This actually <em>still</em> isn&rsquo;t enough, which was pointed out to me by &ldquo;dooglius&rdquo;
<a href="https://github.com/Manishearth/sudoku-zkp/issues/1">here</a>. Basically, if the sudoku problem has two digits which only appear once each,
there is nothing that can stop Peggy from coming up with a solution where these two digits have been
changed to something else (since they&rsquo;ll never be in a green square). Fixing this is easy, we allow
Victor to ask Peggy to reveal just the permuted values of the presets (without simultaneously
revealing a row/column/subsquare). Victor can then verify that the preset-permutation mapping is
consistent (all presets of the same value map to the same permutation) and 1-1.</p>

<p>This check actually obviates the need of the green squares entirely. As long as there is a chance
that Victor will ask for the presets to be revealed instead of a row/column/subsquare, Peggy cannot
try to trick Victor with the solution of a different sudoku problem without the risk of getting
caught when Victor asks for the presets to be revealed. However, the green squares leak no
information, so there&rsquo;s no problem in keeping them as a part of the ZKP as a way to reduce the
chances of Peggy duping Victor.</p>

<h2>The interactive verifier</h2>

<p>Visit the <a href="https://manishearth.github.io/sudoku-zkp/zkp.html">interactive verifier</a>. There&rsquo;s a sudoku square at the top which you can fill
with a problem, and you can fill the solution in on the first square on the Prover side &ndash; fill this
in and click Start. Since I know nobody&rsquo;s going to actually do that, there&rsquo;s a &ldquo;Fill with known
problem/solution&rdquo; that does this for you.</p>

<p>Once you&rsquo;ve initiated the process, the ball is in the Prover&rsquo;s court. The Prover must first permute
the solution by clicking the Permute button. You can edit the permutation if you like (to introduce
a flaw), or manually do this after clicking the button.</p>

<p>Once you&rsquo;ve clicked the button, generate nonces by clicking the next one, &ldquo;Populate Nonces&rdquo;. These,
too can be edited. You can generate hashes (which can also be edited) by clicking the next button,
and after that send the hashes (commitments) over to the Verifier&rsquo;s side.</p>

<p>The ball is now in the Verifier&rsquo;s court. As you can see, there&rsquo;s a set of hashes on the Verifier&rsquo;s
side. The Verifier only knows the problem statement and whatever is visible on their side of the
screen, and nothing more.</p>

<p>You, acting on behalf of the Verifier, can now select a row/column/subsquare/preset using the
dropdown and text box on the Verifier. As you select, the orange/green squares that are going to be
revealed will be shown. When satisfied with your choice, click &ldquo;Reveal&rdquo;, and the Prover will
populate your squares with the permuted values and nonces. &ldquo;Verify&rdquo; will verify that:</p>

<ul>
<li>The appropriate elements and hashes are revealed</li>
<li>The hash is equal to <code>SHA256(nonce + "-" + digit)</code></li>
<li>The orange squares contain distinct digits.</li>
<li>The green squares contain digits that match with the orange squares they correspond to from the problem solution</li>
</ul>


<p>Once you click verify, it will show the probability of correctness (this isn&rsquo;t an exact value, it&rsquo;s
calculated using an approximate formula that doesn&rsquo;t depend on the problem statement), and the ball
moves back into Peggy&rsquo;s court, who can permute her solution again and continue. The probability
slowly increases each round.</p>

<p>Doing this manually till it reaches 99% is boring, so there&rsquo;s a button at the top (&ldquo;Run
automatically&rdquo;) which can be clicked to run it for a given number of rounds, at any stage in the
process once started. If you tamper with one of the values in the permuted solution, and run it
for ~20 runs, it usually gets caught.</p>

<p>Have fun!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Exploring Zero-Knowledge Proofs]]></title>
    <link href="http://manishearth.github.io/blog/2016/03/05/exploring-zero-knowledge-proofs/"/>
    <updated>2016-03-05T01:46:01-08:00</updated>
    <id>http://manishearth.github.io/blog/2016/03/05/exploring-zero-knowledge-proofs</id>
    <content type="html"><![CDATA[<p><em>Follow up article to this one <a href="http://manishearth.github.io/blog/2016/08/10/interactive-sudoku-zero-knowledge-proof/">here</a></em></p>

<p>So recently I read <a href="https://bitcoincore.org/en/2016/02/26/zero-knowledge-contingent-payments-announcement/">this article</a> about how the Bitcoin community had executed
what&rsquo;s known as a &ldquo;Zero-Knowledge Contingent Payment&rdquo;; a pretty neat concept.</p>

<p>What was really interesting for me was the <a href="https://people.xiph.org/~greg/simple_verifyable_execution.txt">(simplified) underlying algorithm</a> for generic
zero knowledge proofs. It took me a while (and some questions asked to helpful folks on the
Internet) to understand it fully, but the concept is quite intriguing and sounds rather magical. I
thought I&rsquo;d explain it here in an accessible way, both so that others can get it and to
improve my own understanding.</p>

<p>I intend this article to be read by people with a programming or mathematical background<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>,
who have some understanding of what logic gates are. Please let me know if you feel that something
is inadequately (or wrongly) explained.</p>

<h2>So what is a zero knowledge proof?</h2>

<p>Let&rsquo;s say Alice has a problem she wants to solve. It could be a mathematical problem, like
factorizing a large number, or coloring a map (or graph!) with only three colors, or solving a
Sudoku puzzle. Anything where you can write a program to verify the solution.</p>

<p>She doesn&rsquo;t have the resources to solve the problem herself, but wants to buy a solution from
someone else. She makes the problem public, and Bob says he has a solution.</p>

<p>However, Alice is skeptical. She&rsquo;s not sure if Bob is telling the truth here, and would like some
evidence that he does indeed have a solution. At the same time, Bob is not willing to share his
solution with Alice without getting paid. They also don&rsquo;t want to involve a third party; let&rsquo;s say
this is a rather Important Sudoku Puzzle that affects National Security ¯\_(ツ)_/¯.</p>

<p>What Alice and Bob need here is a way for Bob to prove to Alice that he has the solution, without
sharing the solution, and without involving a third party<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup>.</p>

<p>It turns out that this is totally possible (magical, right!). There&rsquo;s a quick example
<a href="https://en.wikipedia.org/wiki/Zero-knowledge_proof#Abstract_example">on Wikipedia</a> of a simple proof of a non-mathematical fact &ndash; whether or not someone
has a key to a particular door.</p>

<p>For proving more complicated problems, we have to digress into some basic crypto first</p>

<h2>Interlude: Hashes and commitments</h2>

<p><em>Feel free to skip this if you know what a hash function and a nonce is.</em></p>

<p>In cryptography, there&rsquo;s something called a &ldquo;hash function&rdquo;. In essence it&rsquo;s an &ldquo;irreversible&rdquo;
function whose output is known as a &ldquo;hash&rdquo;, with the following three properties:</p>

<ul>
<li>It&rsquo;s not computationally intensive to calculate the hash of an input</li>
<li>Given a hash, it&rsquo;s a computationally hard problem to calculate an input to the hash function that results in this hash, usually involving brute force</li>
<li>It&rsquo;s also a computationally hard problem, given an input and a hash, to find a different input (<em>especially</em> a different input that is similar to the first one) that produces the same hash.</li>
</ul>


<p>Note that multiple values <em>may</em> result in the same hash.</p>

<p>The result of this is basically that hashes are hard to forge. If Bob shares a hash <code>Y = H(X)</code> with
Alice, where <code>X</code> is some secret data and <code>H</code> is a hash function, if Bob reveals <code>X</code> at some later
point, by checking that <code>Y = H(X)</code>, Alice can be reasonably certain that the value shared by Bob was
indeed the original input to the hash function and not tampered with in a way that the same hash was
produced. Similarly, Bob can be certain that knowing only <code>Y</code>, Alice cannot reverse-engineer <code>X</code>
since the hash function is &ldquo;irreversible&rdquo;.</p>

<p>This brings us to the concept of a commitment. Hashes can be used as described above to &ldquo;commit&rdquo; to
a value. If Bob decides on a number <code>X</code>, and makes its hash <code>Y</code> public, he has committed to this
value without revealing it. When he does decide to reveal it, he is forced to reveal <code>X</code> and not
some modified bogus value, thus making the &ldquo;commitment&rdquo; binding.</p>

<p>Some of you may have noticed a flaw here: It&rsquo;s hard to commit to small numbers, or things that come
from a restricted set. If Bob wishes to commit to the number <code>5</code> (without revealing it), or the
color <code>red</code> (out of a set of three colors), Alice can just try <code>H(0)</code> to <code>H(9)</code> or <code>H(red),
H(green), H(blue)</code> and find out which one matches. After all, hashes aren&rsquo;t supposed to be resilient
to brute force attacks, and brute force attacks become very easy when the set of inputs is tiny.</p>

<p>A solution to this is to use a <em>nonce</em> (also known as a &ldquo;trapdoor&rdquo;). Bob commits to <code>5</code> by hashing
the string <code>5-vektvzkjyfdqtnwry</code>, where <code>vektvzkjyfdqtnwry</code> is a random value he selected, known as
a &ldquo;nonce&rdquo;. When Bob wishes to reveal the value, he just reveals <code>5-vektvzkjyfdqtnwry</code> and Alice is
convinced that the original value committed to was indeed 5. Of course, this requires some agreement
on the format of the nonce; in this case the nonce is just &ldquo;everything after the dash&rdquo;. Note that
the nonce is private, and only revealed when Bob wishes to reveal the committed number.</p>

<p>Note that each new commitment should use a new nonce. Otherwise, information can be leaked; for
example if Bob needs to commit to three numbers (say, 2, 5, 2) in a way that they can be
individually revealed, he shouldn&rsquo;t compute the hashes for
<code>2-vektvzkjyfdqtnwry, 5-vektvzkjyfdqtnwry, 2-vektvzkjyfdqtnwry</code>, since the first
and last hashes will be equal and Alice will know that the committed values behind them are probably
the same too (something which you may not wish to reveal).</p>

<p>Another issue that can turn up is a &ldquo;rainbow table&rdquo;, where one party comes into the game with a
precomputed table of hashes of all strings up till a certain number of characters. One solution for
this is to increase the nonce size, however since Bob decides the nonces it&rsquo;s possible for him to
smartly select them if he&rsquo;s the one with a table. The solution here is to use a &ldquo;salt&rdquo;, which is a
large random string combined with the committed value and hash. Bob and Alice could, for example,
mutually decide on a salt of <code>asdcjyxeafxjvikfzmnyfqsehsxwxsfywbreb</code>, and when Bob wishes to
commit to the number <code>5</code>, he hashes
<code>asdcjyxeafxjvikfzmnyfqsehsxwxsfywbreb-5-vektvzkjyfdqtnwry</code>. Note that salts work similar
to nonces here, however the salt is known publically (you can model it as a last-minute modification
of the agreed-upon hash function <code>H</code>, since <code>H'(X) = H(add_salt(X))</code>). In some cases, you may also
want a per-instance salt, which is mutually decided every time Bob wants to compute a hash.</p>

<p>Hashes are a useful building block for many things; they&rsquo;re a key component in password security, as
well as being part of all kinds of cryptographics protocols. In this post we&rsquo;ll mainly focus on
their ability to be used as a unbreakable commitment.</p>

<p>Back to your regularly scheduled blog post.</p>

<h2>Coloring graphs</h2>

<p>The classic example of zero knowledge proofs is graph coloring.  I&rsquo;ll run through a quick
explanation, though it&rsquo;s explained beautifully <a href="http://blog.cryptographyengineering.com/2014/11/zero-knowledge-proofs-illustrated-primer.html">here</a> too.</p>

<p>Let&rsquo;s say Alice has a graph:</p>

<p><img src="/images/post/alice-graph.png"></p>

<p>No, not that kind, Alice. The <em>other</em> graph.</p>

<p><img src="/images/dotgen/graph-uncolored.dot.png"></p>

<p>She wants it colored such that no two adjacent nodes share a color. This is an NP-complete problem (so
it can take up a lot of computational resources to solve). Of course, <em>this</em> graph is small and easy
to color, but that&rsquo;s just for the sake of this blog post.</p>

<p>Bob, using his trusty Crayola™ 3-crayon set<sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup>, has managed to come up with a valid coloring:</p>

<p><img src="/images/dotgen/graph-colored.dot.png"></p>

<p>He wishes to prove that he has this to Alice, without revealing it or involving a third party.
Probably for National Security Reasons. Something something Nicolas Cage.</p>

<p>Bob and Alice meet, and Alice gives him a large piece of paper with the (uncolored) graph drawn on
it.</p>

<p>Bob goes into a private room, and colors it. He also covers each graph node with a hat. Alice now
enters the room.</p>

<p>Alice chooses an adjacent pair of nodes. Let&rsquo;s say she chooses 1 and 2. Bob removes those two hats
(since Alice is watching him, he has no chance to tamper with the colorings underneath the hats
before revealing them). Now, Alice knows the colors of nodes 1 and 2:</p>

<p><img src="/images/dotgen/graph-12.dot.png"></p>

<p>This lets her verify that nodes 1 and 2 had different colorings in the graph Bob drew.</p>

<p>Note that this doesn&rsquo;t actually <em>tell</em> her anything about Bob&rsquo;s coloring aside from the increased
probability of correctness. The colors can always be permuted, so <em>any</em> valid coloring would give
the same answer here if the colors were permuted so that 1 is red and 2 is blue. This is important;
we don&rsquo;t want to leak information about Bob&rsquo;s solution aside from the fact that it is correct.</p>

<p>Nor is this information enough to verify correctness. Bob could have equally drawn a wrong
coloring.</p>

<p><img src="/images/dotgen/graph-wrong.dot.png"></p>

<p>(clearly someone wasn&rsquo;t paying attention in kindergarten)</p>

<p>Since Alice only looked at nodes 1 and 2, she didn&rsquo;t see anything wrong with the graph. But if she
had by chance picked nodes 3 and 4, Bob&rsquo;s deception would have been revealed.</p>

<p>So she only has 14% (1/7) certainity<sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup> that Bob&rsquo;s graph is correct.</p>

<p>However, we can run this experiment again. Bob can permute the colors, draw on a fresh copy of the
graph, and ask Alice to choose another pair of adjacent nodes. She can check this, and the
probability of correctness will increase to around 27% (1 - (6/7)*(6/7)).</p>

<p>Since Bob has permuted the colors, Alice cannot use the information from the previous round to glean
any information about Bob&rsquo;s solution in this round. Of course, Bob is free to produce a completely
different coloring (one that is not a permutation), with a different flaw this time. Regardless of
where the flaw is, Alice still has a chance of uncovering it each time.</p>

<p>This can continue until Alice is satisfied that there is a very little chance that Bob has cheated.
For example, after 60 rounds, Alice would be 99.99% certain.</p>

<p>Note that this didn&rsquo;t actually involve any cryptography; it was an algorithm based on <em>information
flow</em>. However, if you want this to work securely (in the current solution Alice could push Bob away
and reveal all the nodes herself) and make it work without requiring Alice and Bob to be in the same
location, you need to use hashes.</p>

<p>Remember when Bob colored the graph whilst alone in the secret room? Once Alice had entered the
room, this coloring was <em>committed</em>. There was no way for Bob to tamper with this coloring.</p>

<p>We do the same thing here. After obtaining a valid coloring, Bob <em>commits</em> to this coloring by
calculating some hashes.</p>

<table>
<thead>
<tr><th>Node</th><th>Color(private)</th><th>Nonce(private)</th><th>Hash</th></tr>
</thead>
<tr><td>1</td><td>red</td><td>wmdqatobck</td><td>e1f957bedcceeb217305bfa12cbee4abac36eff1</td></tr>
<tr><td>2</td><td>blue</td><td>fmcbpzkgyp</td><td>87d9d7239909c28ec8d73a3b9a99673cbf870046</td></tr>
<tr><td>3</td><td>green</td><td>dktuqvrsss</td><td>a40bafb81149937c77ae55589aff1b53d9c043d8</td></tr>
<tr><td>4</td><td>blue</td><td>auhbyuzkmz</td><td>b3503962937850f7c1b59cf4b827ca40a62b122a</td></tr>
<tr><td>5</td><td>red</td><td>gfunjcmygk</td><td>d8db52bb36ca595b9231180c1055fe3958c3ea7d</td></tr>
</table>


<p><br></p>

<p>(The hashes here are calculated using SHA-1 for the hashing algorithm. It&rsquo;s not considered very
secure anymore, but the secure ones all output huge hashes which spill over the page)</p>

<p>Bob sends the public part of the table (the node-hash mapping) to Alice. Alice asks for nodes 1 and
2, and Bob reveals the entire table entry for those two nodes (including the nonce).</p>

<p>Note that since Alice now knows the color and nonce for nodes 1 and 2, she can verify that the
colors shown are indeed the ones Bob committed to. <code>echo red-wmdqatobck | sha1sum</code> if you want to
check on a local Unixy shell.</p>

<p>As in the previous case, Alice can repeat this algorithm until she reaches an acceptable level of
certainty (each time with a permutation of colors and a new set of nonces).</p>

<p>A lot of zero knowledge proofs (but not all!) are inherently probabalistic and interactive. They
involve multiple rounds where in each round the prover (Bob) commits to something, the verifier
(Alice) challenges the prover to reveal some information. The process repeats, with the certainity
on the verifier&rsquo;s side approaching 100% as more and more rounds happen.</p>

<h2>Zero Knowledge Proof for General Execution</h2>

<p>It turns out that you can have a ZKP exchange for the execution of any algorithm that can be
transcribed into combinatorical logic. In other words, you should be able to write the program
without loops and recursion, though loops bounded by a constant are allowed<sup id="fnref:5"><a href="#fn:5" rel="footnote">5</a></sup>. This isn&rsquo;t as
restrictive as it seems, usually <em>verification</em> is a straightforward task not involving convoluted
loops. The examples above (graph coloring<sup id="fnref:6"><a href="#fn:6" rel="footnote">6</a></sup>, sudoku, prime factorization<sup id="fnref:7"><a href="#fn:7" rel="footnote">7</a></sup>) can all be verified
without loops.</p>

<p>The algorithm shown here is by Gregory Maxwell, originally published <a href="https://people.xiph.org/~greg/simple_verifyable_execution.txt">here</a>. It&rsquo;s somewhat
inefficient, but it demonstrates the idea behind ZKP for general execution. As mentioned there, it
can be optimized using techniques described in <a href="https://eprint.iacr.org/2013/155.pdf">this paper</a>.</p>

<p>Let&rsquo;s get started. Any combinatorical program can be decomposed into a bunch of AND and NOT
gates, taking in a bunch of input values and giving out one or more output values. For simplicity
let&rsquo;s assume that the problem statement (i.e. the specific sudoku puzzle, etc) that needs verifying
is embedded inside the program, and the final output of the program is just a single boolean
indicating whether or not the input is a solution. This algorithm, however, can work for programs
with arbitrarily large outputs.</p>

<p>Alice and Bob do this decomposition. The also agree on a numbering of the AND gates. Let&rsquo;s say
that there are N AND gates. We&rsquo;re mostly going to ignore the NOT gates for the purpose of this
article &ndash; they&rsquo;re there, but they aren&rsquo;t modified or anything.</p>

<h3>Creating encrypted AND gates</h3>

<p>Now, Bob creates 4*N <em>encrypted AND gates</em>. This is an AND gate, but with the
inputs and outputs all muddled up.</p>

<p>This is a regular AND gate:</p>

<p><img src="/images/post/and-and.png" width="200"></p>

<p>This is an encrypted AND gate:</p>

<p><img src="/images/post/and-and.png" width="200"></p>

<p>(yes, it can be identical to an AND gate)</p>

<p>So is this:</p>

<p><img src="/images/post/and-encr1.png" width="300"></p>

<p>and this:</p>

<p><img src="/images/post/and-encr2.png" width="300"></p>

<p>Basically, each input and the output may or may not be inverted. We can model this in a different
way, there is an <em>encryption key</em> corresponding to each input and output. This key is XORd with the
input/output (so if the key is 1, the wire is inverted, and if the key is 0, the wire is not
inverted).</p>

<p><img src="/images/post/and-encr-xor.png" width="500"></p>

<p>A regular AND gate has a truth table as follows:</p>

<table>
<thead>
<tr>
<th>Input 1 </th>
<th> Input 2 </th>
<th> Output</th>
</tr>
</thead>
<tbody>
<tr>
<td>0 </td>
<td> 0 </td>
<td> 0</td>
</tr>
<tr>
<td>1 </td>
<td> 0 </td>
<td> 0</td>
</tr>
<tr>
<td>0 </td>
<td> 1 </td>
<td> 0</td>
</tr>
<tr>
<td>1 </td>
<td> 1 </td>
<td> 1</td>
</tr>
</tbody>
</table>


<p><br></p>

<p>
This truth table, encrypted (with the input keys &#92;(e_1 = 1, e_2 = 0&#92;) and output key &#92;(e_o = 1&#92;))
is:
</p>

<table>
<thead>
<tr>
<th>Encrypted Input 1 </th>
<th> Encrypted Input 2 </th>
<th> Encrypted Output</th>
</tr>
</thead>
<tbody>
<tr>
<td>1 </td>
<td> 0 </td>
<td> 1</td>
</tr>
<tr>
<td>0 </td>
<td> 0 </td>
<td> 1</td>
</tr>
<tr>
<td>1 </td>
<td> 1 </td>
<td> 1</td>
</tr>
<tr>
<td>0 </td>
<td> 1 </td>
<td> 0</td>
</tr>
</tbody>
</table>


<p><br>
So, if the encrypted gate gets the (encrypted) inputs 1 and 0, its (encrypted) output will be 1.</p>

<p>
Since XOR is its own inverse (&#92;(x \oplus y \oplus y&#92;) is just &#92;(x&#92;)), if we wish to encrypt
an input before piping it through this gate, we just XOR it with the relevant input key. If we wish
to decrypt the output, we again XOR it with the output key. The XOR gates being applied will just
cancel out with the internal encryption gates. In other words, encryption and decryption are done
with the same operation!</p>

<p>To recap, the dotted box below is an encrypted AND gate. An encrypted input enters from the left,
and is decrypted by the internal XOR gate to obtain the actual input, which is piped through the AND
gate. To encrypt an input so that it can be passed into this gate, one uses the same key with an XOR
(not shown in the diagram). Similarly, the actual output of the AND gate exits on the right, and is
encrypted by the XOR gate at the output to get the &ldquo;encrypted output&rdquo; (the wire that extends out of
the box). To decrypt this, one must apply the same XOR operation to the encrypted output to recover
the actual output of the gate.</p>

<p><img src="/images/post/and-encr-xor.png" width="500"></p>

<p></p>

<h3>Creating adaptation keys and commitments</h3>

<p>Now, unlike regular AND gates, these encrypted AND gates cannot be composed. The output of an
encrypted AND gate is encrypted, with a potentially different encryption key as to that of the next
gate&rsquo;s input. So, we insert an &ldquo;adaptation key&rdquo; between the two. For example, if the output of the
first gate is connected to the first input of the second gate, we need to insert this operation
between the two gates:</p>

<p><img src="/images/post/and-encr-adapt.png" width="500"></p>

<p>
We XOR by &#92;(e_o&#92;) of the first gate (to decrypt), and then again XOR by &#92;(e_1&#92;) of the second gate (to
reencrypt). This operation is the same as XORing by &#92;(e_o \oplus e_1&#92;), which is the
&ldquo;adaptation key&rdquo;. Every pair of encrypted gates will have an adaptation key for every configuration
they can be placed in.
</p>

<p>Alright. Bob creates a ton of these &ldquo;encrypted gates&rdquo;, and calculates all the adaptation keys. He
also mixes up the truth tables of each encrypted gate<sup id="fnref:8"><a href="#fn:8" rel="footnote">8</a></sup>.</p>

<p>Now, he commits to these truth tables. A commitment for each entry in each truth table is made, so
he&rsquo;ll end up with something like this:</p>

<table>
<thead>
<tr>
<th>Encrypted Input 1 </th>
<th> Encrypted Input 2 </th>
<th> Encrypted Output </th>
<th> nonce </th>
<th> commitment</th>
</tr>
</thead>
<tbody>
<tr>
<td>0 </td>
<td> 0 </td>
<td> 1 </td>
<td> .. </td>
<td> H(001 + nonce)</td>
</tr>
<tr>
<td>1 </td>
<td> 0 </td>
<td> 1 </td>
<td> .. </td>
<td> H(101 + nonce)</td>
</tr>
<tr>
<td>0 </td>
<td> 1 </td>
<td> 0 </td>
<td> .. </td>
<td> H(010 + nonce)</td>
</tr>
<tr>
<td>1 </td>
<td> 1 </td>
<td> 1 </td>
<td> .. </td>
<td> H(111 + nonce)</td>
</tr>
</tbody>
</table>


<p><br>
He also commits to each of the adaptation keys and each of the encryption keys.</p>

<p>As usual, all the commitments will be sent to Alice. Alice will then have data like: &ldquo;Commitment for
Gate 1 entry 1: .., Commitment for Gate 2 entry 2:.., &hellip; Commitment for Gate 2 entry 1: .., &hellip;.
Commitment for adaptation key between Gate 1&rsquo;s output and Gate 2&rsquo;s first input: .., Commitment for
adaptation key between Gate 1&rsquo;s output and Gate 2&rsquo;s second input: .., Commitment for encryption key
for Gate 1&rsquo;s first input, &hellip;&rdquo;.</p>

<h3>Shuffling and revealing</h3>

<p>These commitments are taken in some predefined order, and the resultant monster string is hashed
(without a nonce). This &ldquo;superhash&rdquo; is used as the seed to a pseudorandom number generator which is
used to shuffle the gates. Both Alice and Bob can calculate this shuffling.</p>

<p>This post-shuffle ordering is used after this point. The hash-shuffle is important here because it
adds a layer of tamper protection. If Bob wishes to tamper with the, say 4th gate post-shuffle, Bob
would have to create a bad gate before making the commitments; this changes the commitments, and
thus the shuffle order, and so the tampered gate will not end up being the 4th gate. Basically, it&rsquo;s
hard to control where the tampered gate will end up.</p>

<p>Now, out of the 4N  gates, Bob takes the last 2N, and reveals everything about them: Their
encryption keys, the nonces for their truth table commitments, and all adaptation keys between
these gates (along with the nonces for the adaptation key commitments).</p>

<p>Alice ensures that everything in this revealed data adds up. All the truth tables, after decryption,
should actually be AND gate truth tables. All adaptation keys must match up with their relevant
encryption keys. All commitments must match up.</p>

<h3>Double trouble!</h3>

<p>Bob duplicates the AND-and-NOT-gate based circuit. He now has two identical circuits which take
the same inputs, and have one output each. In itself this is pretty useless; this circuit is
obviously redundant. However, in the context of encrypted gates, this redundancy becomes useful.</p>

<p>Bob drops in the 2*N encrypted gates into this double-circuit, using the post-shuffle ordering of
encrypted gates and the predecided numbering<sup id="fnref:9"><a href="#fn:9" rel="footnote">9</a></sup> of the AND gates in the circuit. He puts the
necessary adaptation gates (i.e. an XOR operation with the relevant adaptation key) between
encrypted AND gates to make the circuit work. Note that each &ldquo;half&rdquo; of the circuit has a different
set of encrypted gates, and thus a different encryption key for each input. There are NOT gates here
too (from the original circuit, which was made of ANDs and NOTs); they stay in place (the adaptation
gate can go on either side of them) with no modifications or encryption.</p>

<h3>Execution</h3>

<p>Let&rsquo;s recall that Bob is claiming to have the correct input for the original circuit &ndash; the input
that makes that circuit output true.</p>

<p>Since Bob has all the encryption keys, he can encrypt this correct input to get the correct
encrypted input, which should make the new circuit output true (well, encrypted true) as well.</p>

<p>Bob goes ahead and does this. He encrypts the input (since there are different encryption keys for
either side of the circuit, he does this twice), and runs it through the circuit. He notes down the
truth table entry utilized for each gate. He ensures that the output, once decrypted, is true (it
should be, if everything has been done correctly till now).</p>

<h3>Verification</h3>

<p>He now reveals the details of the program execution to Alice. He reveals:</p>

<ul>
<li>All adaptation gates involved (and their nonces, to verify the commitments)</li>
<li>All truth table <em>entries</em> involved in the execution (and their nonces &hellip;).</li>
<li>The output encryption key (and its nonce)</li>
<li>The encrypted inputs</li>
</ul>


<p>Alice goes ahead and verifies that the commitments have not been reneged upon. Note that she also
now has a full execution history. It&rsquo;s an <em>encrypted</em> history &ndash; she can&rsquo;t calculate the original
input from it &ndash; but she can verify that the execution was faithfully carried out. While she doesn&rsquo;t
have the entire truth table for any encrypted gate, she has the entry that was used in the
execution, which is enough. She just has to ensure that the inputs to a gate match the truth table
entry, use the entry to see what the output is, apply the relevant adaptation key to get the input
for the next gate, and repeat.</p>

<p>And there you have it. Alice has verified that Bob faithfully executed her verification circuit, and
thus he must have the correct answer to her problem.</p>

<h3>Tampering?</h3>

<p>Let&rsquo;s see if it&rsquo;s possible for Bob to tamper with any of this. If Bob wishes to tamper with one of
the gates, he has to tamper with the gates before calculating commitments, which means that the
shuffling will get mixed up, which will mean that he can&rsquo;t control where the tampered gate will end
up in the final circuit. This is compounded by the fact that half the gates are revealed (so the
tampered gate may end up in the wrong set), and that there are <em>two</em> copies of the circuit (so you
need to tamper with both sides simultaneously, requiring even more luck on getting the shuffle where
you want it).</p>

<p>The probability of Bob being able to execute a succesful tamper can be adjusted by increasing the
number of revealed gates, and increasing the duplication of the circuit. There is also the
aforementioned fudge factor that can be introduced by having Alice choose where each encrypted gate
should go after Bob has already provided commitments, and finally the procedure can be repeated as
many times as necessary with a fresh set of encrypted gates to increase certainty. Unlike the graph
coloring algorithm (where the uncertainty in a single run was large &ndash; if Bob has a couple of wrong
edges there&rsquo;s relatively small chance he&rsquo;ll get caught); here in a single run it is Bob who has a
massive disadvantage, since he must tamper with <em>exactly</em> the right gates, and there&rsquo;s very little
chance that his tampered gates will fall in the right place based on Alice&rsquo;s chosen ordering.
Additionally, tampering with the gates in the first place is hard, since you need to avoid having
them get revealed. I think that with reasonable (e.g., not asking for something like 1000 duplicated
circuits) choices on the level of duplication and number of revealed gates, it&rsquo;s possible for Alice
to get a very high level of certainty without needing to conduct multiple rounds.</p>

<p>How about the opposite question: Can Alice find out anything about the input, aside from the fact
that it is correct, from the information she has? At first glance it seems like she can, because she
can see the whole path of execution. In case of a program with non-constant loops, this would be
damning, since she can figure out how many executions happened (and thus know the decrypted value
for the number of loop iterations) and backtrack using that in a cleverly-written program. However,
this program has no loops.</p>

<p>Looking at it closely, any encrypted history of execution can be changed to a different encrypted
history of execution for the same nonencrypted execution by adding NOT gates wherever they don&rsquo;t
match, and then absorbing these NOT gates into the input or output keys (by NOTing them) of the
adjacent encrypted AND gates. This means that without knowing the details of the encrypted gates,
all histories of execution are equally possible for a given actual execution<sup id="fnref:10"><a href="#fn:10" rel="footnote">10</a></sup>. Therefore,
knowing only a history of execution does not provide you further information about the actual
execution, since it could equally have been for some other history of execution.</p>

<h2>Bonus: Fixing the escrow and Bitcoin</h2>

<p>(I&rsquo;m going to assume basic knowledge of Bitcoin later on in this section)</p>

<p>After all this, we still only have a way of Bob <em>proving</em> he has a solution. There&rsquo;s no way of
securely exchanging the solution for money (or whatever) without involving a trusted third party to
handle the swap. This is known as <em>escrow</em>, where a third party is given both items for swapping;
and after checking that everything is in order the third party completes the swap.</p>

<p>We can build on this so that the third party is only trusted with the money, and cannot actually
peek at the answer.</p>

<p>It&rsquo;s pretty straightforward: Bob and Alice mutually agree on a shared secret &ldquo;pad&rdquo; P. Bob takes his
answer, bitwise-XORs it with the pad (which is of the same length as the answer) to get padded input
X, and then hashes it to get hash Y.</p>

<p>Now, initially we had a verification program which proves the statement &ldquo;This input is a solution to
Alice&rsquo;s problem&rdquo;. We modify this program so that it proves the following two statements:</p>

<ul>
<li>This input is a solution to Alice&rsquo;s problem</li>
<li>When the input is XORd with P, and subsequently hashed, the hash that comes out is Y</li>
</ul>


<p>Alice and Bob now go through the ZKP algorithm and the above is proven. Of course, they must keep
the exchange between themselves, since the value of the pad (which can be extracted from the
circuit) must remain secret.</p>

<p>Assuming that Bob isn&rsquo;t able to cause any hash collisions, Alice at this point would be happy with a
number that, when hashed, gives Y. This is something that escrow can verify, since neither Y nor X
can be reverse-engineered to get the original answer unless you have P.</p>

<p>Now, Alice puts the money in escrow, and notifies the third party handing escrow of the value of Y
(the hash). Bob puts the padded input X in escrow as well. The third party verifies that Y is the
hash of X, and releases the money to Bob and the padded input to Alice. Since Alice knows pad P, she
can XOR it with X to recover the original real input. Everyone walks away happy!</p>

<p>Well, maybe not. There still is the danger of the third party handling escrow to walk away with the
money. Why trust any one party?</p>

<p>Turns out that Bitcoin proves to be an alternative to this situation. The technique described in
<a href="https://bitcoincore.org/en/2016/02/26/zero-knowledge-contingent-payments-announcement/">Greg Maxwell&rsquo;s article</a> (called Zero-Knowledge Contingent Payment), builds upon
the above protocol using &ldquo;scripts&rdquo; in Bitcoin.</p>

<p>The way a Bitcoin transaction works is that anyone (well, the first person) who can solve the
embedded challenge is allowed to use the money contained in it. Like a piñata. Except with money
instead of candy and public-key cryptography instead of a stick.</p>

<p><em>Most</em> Bitcoin transactions pay directly to a person, and they use a standard kind of challenge (the
actual script is <a href="https://en.bitcoin.it/wiki/Script#Standard_Transaction_to_Bitcoin_address_.28pay-to-pubkey-hash.29">here</a>). If Alice wishes to pay Bob 5 BTC, Alice crafts a
transaction which says &ldquo;anyone with the private key behind Bob&rsquo;s public key (his address) may spend
this money&rdquo;. Of course, in practice this means that only Bob can spend the money. Alice created a
piñata which only Bob can break.</p>

<p>We can build on this to make the Bitcoin network behave as a trustworthy escrow. After having
stepped through the zero-knowledge protocol and being confident that Y is the hash of the padded
input, Alice crafts a transaction which says &ldquo;anyone with a string that results in this hash may
spend this money&rdquo;<sup id="fnref:11"><a href="#fn:11" rel="footnote">11</a></sup>. Bob has this string; it is the padded answer X. He makes a transaction with
X as part of the input script (so that he can claim the money); and the Bitcoin network accepts it.
Assuming Alice and Bob are not able to tamper with each others&#8217; local networks, by the time Alice
sees the transaction containing X, the network should have accepted this transaction already (though
it may not yet be part of the blockchain), and Bob should be getting his money.</p>

<p>(In case the crucial part is trusting that the escrow doesn&rsquo;t run off with the money, and you don&rsquo;t
care if other people can see the answer, you can skip the padding step and directly hash the input.
I believe the proof of concept executed in Greg&rsquo;s post did this, but I&rsquo;m not sure)</p>

<p><em>Thanks to Shantanu Thakoor, eternaleye, and ebfull for feedback on drafts of this post</em></p>
<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>I have some physics friends who would probably enjoy this too.<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
<li id="fn:2">
<p>Actually, you still need a trusted third party to make the money-swap work, but it can be done in a way that the National Secrets Sudoku Solution isn&rsquo;t actually shared with the third party. The Bitcoin article linked above describes a way to do away with a trusted third party, instead replacing it with the implicitly trusted Bitcoin network. We&rsquo;ll discuss this further at the end of the post.<a href="#fnref:2" rev="footnote">&#8617;</a></p></li>
<li id="fn:3">
<p>With free sharpener!<a href="#fnref:3" rev="footnote">&#8617;</a></p></li>
<li id="fn:4">
<p>There are seven edges. This is a conservative estimate, assuming that Bob&rsquo;s graph has one bad edge. More mistakes increase this probability, but it becomes more cumbersome to calculate.<a href="#fnref:4" rev="footnote">&#8617;</a></p></li>
<li id="fn:5">
<p>We basically want to be able to write this as a series of sequentially-arranged logic gates. If a loop is bounded by a constant, it can just be unrolled. <code>break</code> and <code>continue</code> can be handled here, though <code>goto</code> cannot.<a href="#fnref:5" rev="footnote">&#8617;</a></p></li>
<li id="fn:6">
<p>Remember that the number of nodes and edges is already known, so we can just write a program &ldquo;Check edge 1&rdquo;, &ldquo;Check edge 2&rdquo;, &hellip; without needing to explicitly loop over everything<a href="#fnref:6" rev="footnote">&#8617;</a></p></li>
<li id="fn:7">
<p>Again, since the number being factorized is known beforehand, there are bounds on the sizes of its factors, and a multiplication circuit for a number of bounded size can be designed.<a href="#fnref:7" rev="footnote">&#8617;</a></p></li>
<li id="fn:8">
<p>mixing up a truth table doesn&rsquo;t change how it works, but it makes it impossible to figure out the original entry just by knowing that your entry was the &ldquo;third&rdquo; entry or something<a href="#fnref:8" rev="footnote">&#8617;</a></p></li>
<li id="fn:9">
<p>You can actually add another fudge factor here by making Alice decide the gate numbering after having received gate commitments. If N isn&rsquo;t that large, there&rsquo;s still a small chance Bob can fake the output by permuting the original gates (and twiddling the nonces) until the tampered gates fall into the right spot. This removes that possibility to a reasonably high level of certainty, which can be strengthened by going through the whole procedure multiple times.<a href="#fnref:9" rev="footnote">&#8617;</a></p></li>
<li id="fn:10">
<p>We&rsquo;re ignoring the commitments made by Bob here, which let us make the opposite statement &ndash; &ldquo;this encrypted history of execution is the only one that&rsquo;s possible given the commitments&rdquo;. However, the commitments themselves don&rsquo;t carry any new <em>information</em> per se; they instead lock in information which is revealed to you in the future (information which is not revealed at all cannot be reverse-engineered from the commitments, so that&rsquo;s safe too). This means that Alice cannot use them to glean anything about the decrypted input, and we can ignore them for the time being.<a href="#fnref:10" rev="footnote">&#8617;</a></p></li>
<li id="fn:11">
<p>She should probably also add a clause that requires Bob&rsquo;s private key to sign something, so that someone else can&rsquo;t copy the answer from Bob&rsquo;s transaction and steal the money. Additional work can be done to make it so that if the transaction goes unclaimed, Alice can reclaim the money.<a href="#fnref:11" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
  </entry>
  
</feed>
