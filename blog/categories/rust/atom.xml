<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Rust | In Pursuit of Laziness]]></title>
  <link href="http://manishearth.github.io/blog/categories/rust/atom.xml" rel="self"/>
  <link href="http://manishearth.github.io/"/>
  <updated>2021-03-15T06:24:36+00:00</updated>
  <id>http://manishearth.github.io/</id>
  <author>
    <name><![CDATA[Manish Goregaokar]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Integrating Rust and C++ in Firefox]]></title>
    <link href="http://manishearth.github.io/blog/2021/02/22/integrating-rust-and-c-plus-plus-in-firefox/"/>
    <updated>2021-02-22T00:00:00+00:00</updated>
    <id>http://manishearth.github.io/blog/2021/02/22/integrating-rust-and-c-plus-plus-in-firefox</id>
    <content type="html"><![CDATA[<p><em>This post was originally drafted in August 2018, but I never got around to finishing it. As such, parts of its framing (e.g. the focus on bindgen) are outdated, given the relative infancy of the interop space at the time. I was recently told that the post is still useful in this form so I decided to finish and publish it anyway, while attempting to mark outdated things as such when I notice them. Everything after the allocators section was written near the time of publication.</em></p>

<p>In 2017 I worked on the <a href="https://hacks.mozilla.org/2017/08/inside-a-super-fast-css-engine-quantum-css-aka-stylo/">Stylo</a> project, uplifting Servo’s CSS engine (“style system”) into Firefox’s browser engine
(“Gecko”). This involved a <em>lot</em> of gnarly FFI between Servo’s Rust codebase and Firefox’s C++ codebase. There were a
lot of challenges in doing this, and I feel like it’s worth sharing things from our experiences.</p>

<p>If you’re interested in Rust integrations, you may find <a href="https://www.youtube.com/watch?v=x9acx2zgx4Q">this talk by Katharina on Rust - C++ FFI</a>, and <a href="https://hsivonen.fi/modern-cpp-in-rust/">this blog post by Henri on integrating encoding-rs into Firefox</a> useful as well.</p>

<h2 id="who-is-this-post-for">Who is this post for?</h2>

<p>So, first off the bat, I’ll mention that when integrating Rust into a C++ codebase, you
want to <em>avoid</em> having integrations as tight as Stylo. Don’t do what we did; make your Rust
component mostly self-contained so that you just have to maintain something like ten FFI functions
for interacting with it. If this is possible to do, you should do it and your life will be <em>much</em> easier. Pick a clean API boundary, define a straightforward API, use cbindgen or bindgen if necessary without any tricks, and you should be good to go.</p>

<p>That said, sometimes you <em>have</em> to have gnarly integrations, and this blog post is for those use cases.
These techniques mostly use bindgen in their examples, however you can potentially use them with hand-rolled bindings or another tool as well. If you’re at this level of complexity, however, the potential for mistakes in the hand-rolled bindings is probably not worth it.</p>

<p><em>Note from 2021: <a href="https://github.com/dtolnay/cxx">cxx</a> is probably a better tool for many of the use cases here, though many of the techniques still transfer.</em></p>

<h2 id="what-was-involved-in-stylos-ffi">What was involved in Stylo’s FFI?</h2>

<p>So, what made Stylo’s FFI so complicated?</p>

<p>It turns out that browsers are quite monolithic. You can split them into vaguely-defined components, but
these components are still tightly integrated. If you intend to replace a component, you may need to
make a jagged edge of an integration surface.</p>

<p>The style system is more self-contained than other parts, but it’s still quite tightly integrated.</p>

<p>The main job of a “style system” is to take the CSS rules and DOM tree, and run them through “the cascade”<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">1</a></sup>
with an output of “computed styles” tagged on each node in the tree. So, for example, it will take a document like
the following:</p>

<div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;style </span><span class="na">type=</span><span class="s">"text/css"</span><span class="nt">&gt;</span>
    <span class="nt">body</span> <span class="p">{</span>
        <span class="nl">font-size</span><span class="p">:</span> <span class="m">12px</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="nt">div</span> <span class="p">{</span>
        <span class="nl">height</span><span class="p">:</span> <span class="m">2em</span><span class="p">;</span>
    <span class="p">}</span>
<span class="nt">&lt;/style&gt;</span>
<span class="nt">&lt;body&gt;</span>
    <span class="nt">&lt;div</span> <span class="na">id=</span><span class="s">"foo"</span><span class="nt">&gt;&lt;/div&gt;</span>

<span class="nt">&lt;/body&gt;</span>
</code></pre></div></div>

<p>and turn it into something like:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">&lt;body&gt;</code> has a <code class="language-plaintext highlighter-rouge">font-size</code> of <code class="language-plaintext highlighter-rouge">12px</code>, everything else is the default</li>
  <li>the <code class="language-plaintext highlighter-rouge">div</code> <code class="language-plaintext highlighter-rouge">#foo</code> has a computed <code class="language-plaintext highlighter-rouge">height</code> of <code class="language-plaintext highlighter-rouge">24px</code> <sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote">2</a></sup>, everything else is the default. It “inherits” the <code class="language-plaintext highlighter-rouge">font-size</code> from <code class="language-plaintext highlighter-rouge">&lt;body&gt;</code> as <code class="language-plaintext highlighter-rouge">12px</code></li>
</ul>

<p>From a code point of view, this means that Stylo takes in Gecko’s C++ DOM tree. It parses all the CSS,
and then runs the cascade on the tree. It stores computed styles on each element in a way that Gecko can read
very cheaply.</p>

<p>Style computation can involve some complex steps that require calling back into C++ code. Servo’s style system
is multithreaded, but Gecko is mostly designed to work off of a single main thread per process, so we need to
deal with this impedence mismatch.</p>

<p>Since the output of Stylo is C++-readable structs, Stylo needs to be able to read and write nontrivial C++
abstractions. Typical FFI involves passing values over a boundary, never to be seen again, however here we’re
dealing with persistent state that is accessed by both sides.</p>

<p>To sum up, we have:</p>

<ul>
  <li>Lots and lots of back-and-forth FFI</li>
  <li>Thread safety concerns</li>
  <li>Rust code regularly dealing with nontrivial C++ abstractions</li>
  <li>A need for nontrivial abstractions to be passed over FFI</li>
</ul>

<p>All of this conspires to make for some really complicated FFI code.</p>

<h1 id="the-actual-techniques">The actual techniques</h1>

<p>I’ll try to structure this so that the more broadly useful (and/or less gnarly) techniques come earlier in the post.</p>

<h2 id="the-basics-of-bindgen">The basics of bindgen</h2>

<p><a href="https://github.com/rust-lang-nursery/rust-bindgen/">Bindgen</a> is a tool that generates Rust bindings for structs and functions from the provided C or C++ header files. It’s often used for writing Rust bindings to existing C/C++ libraries, however it’s useful for integrations as well.</p>

<p>To use it for an integration, write a header file containing the functions your Rust code needs (referencing structs from other header files if necessary), and <a href="https://rust-lang-nursery.github.io/rust-bindgen/command-line-usage.html">run bindgen on it</a>. For some codebases, doing this once and
checking in the generate file suffices, but if your C++ code is going to change a lot, <a href="https://rust-lang-nursery.github.io/rust-bindgen/tutorial-1.html">run it as a build dependency instead</a>. Beware that this can adversely impact build times, since your Rust build now has a partial
C++ compilation step.</p>

<p>For large C++ codebases, pulling in a single header will likely pull in a <em>lot</em> of stuff. You should <a href="https://rust-lang.github.io/rust-bindgen/allowlisting.html">allowlist</a>, <a href="https://rust-lang.github.io/rust-bindgen/blocklisting.html">blocklist</a>, and/or mark things as <a href="https://rust-lang.github.io/rust-bindgen/opaque.html">opaque</a> to reduce the amount of bindings generated. It’s best to go the allowlisting route — give bindgen an allowlisted list of functions / structs to generate bindings for, and it will transitively generate bindings for any dependencies they may have. Sometimes even this will end up generating a lot, it’s sometimes worth finding structs you’re not using and marking them as opaque so that their bindings aren’t necessary. Marking something as opaque replaces it with an array of the appropriate size and alignment, so from the Rust side it’s just some bits you don’t care about and can’t introspect further.</p>

<p>Bindgen <a href="https://rust-lang-nursery.github.io/rust-bindgen/cpp.html"><em>does</em> support some C++ features</a> (you may need to pass <code class="language-plaintext highlighter-rouge">-x c++</code>). This is pretty good for generating bindings to e.g. templated structs. However, it’s not possible to support <em>all</em> C++ features here, so you may need to blocklist, opaqueify, or use intermediate types if you have some complicated C++ abstractions in the deps. You’ll typically get an error when generating bindings or when compiling the generated bindings, so don’t worry about this unless that happens.</p>

<p>Bindgen is <em>quite</em> configurable. Stylo has a <a href="https://searchfox.org/mozilla-central/rev/819cd31a93fd50b7167979607371878c4d6f18e8/servo/components/style/build_gecko.rs">script</a> that consumes a <a href="https://searchfox.org/mozilla-central/source/layout/style/ServoBindings.toml">large toml file</a> containing all of the configuration.</p>

<h2 id="cbindgen">cbindgen</h2>

<p>We don’t use <a href="https://github.com/eqrion/cbindgen">cbindgen</a> in Stylo, but it’s used for Webrender. It does the inverse of what bindgen does: given a Rust crate, it generates C headers for its public <code class="language-plaintext highlighter-rouge">extern "C"</code> API. It’s also quite configurable.</p>

<h2 id="cxx">cxx</h2>

<p><a href="https://github.com/dtolnay/cxx">cxx</a> is the cool new hotness in 2021, which kind of approaches the problem from both sides, enabling you to write Rust bindings for C++ and C++ bindings for Rust. It’s definitely worth checking out, a lot of the things that are hard to make work with bindgen are trivial in cxx. For example, it automatically figures out what types need to be opaque, it automatically converts between <code class="language-plaintext highlighter-rouge">&amp;T</code> and <code class="language-plaintext highlighter-rouge">T*</code> across FFI, and it is overall more targeted for the use case of an FFI layer where Rust and C++ both call each other.</p>

<h2 id="bindgen-aided-c-calling-rust">Bindgen-aided C++ calling Rust</h2>

<p>So bindgen helps with creating things for Rust to call and manipulate, but not in the opposite direction. cbindgen can help here, but I’m not sure if it’s advisable to have <em>both</em> bindgen and cbindgen operating near each other on the same codebase.</p>

<p>In Stylo we use a bit of a hack for this. Firstly, all FFI functions defined in C++ that Rust calls are declared in <a href="https://searchfox.org/mozilla-central/rev/819cd31a93fd50b7167979607371878c4d6f18e8/layout/style/ServoBindingList.h">one file</a>, and are all named <code class="language-plaintext highlighter-rouge">Gecko_*</code>. Bindgen supports regexes for things like allowlisting, so this naming scheme makes it easy to deal with.</p>

<p>We also declare the FFI functions defined in Rust that C++ calls in <a href="https://searchfox.org/mozilla-central/rev/819cd31a93fd50b7167979607371878c4d6f18e8/layout/style/ServoBindingList.h">another file</a>, named <code class="language-plaintext highlighter-rouge">Servo_*</code>. They’re also all <a href="https://searchfox.org/mozilla-central/rev/819cd31a93fd50b7167979607371878c4d6f18e8/servo/ports/geckolib/glue.rs">defined in one place</a>.</p>

<p>However, there’s nothing ensuring that the signatures match! If we’re not careful, there may be mismatches, causing bad things to happen at link time or runtime. We use a small <a href="https://searchfox.org/mozilla-central/rev/819cd31a93fd50b7167979607371878c4d6f18e8/servo/ports/geckolib/tests/build.rs">autogenerated</a> <a href="https://searchfox.org/mozilla-central/rev/819cd31a93fd50b7167979607371878c4d6f18e8/servo/ports/geckolib/tests/servo_function_signatures.rs">unit test</a> to ensure the validity of the signatures.</p>

<p>This is especially important as we do things like type replacement, and we need tests to ensure that the rug isn’t pulled out from underneath us.</p>

<h2 id="type-replacing-for-fun-and-profit">Type replacing for fun and profit</h2>

<p>Using <a href="https://rust-lang.github.io/rust-bindgen/blocklisting.html">blocklisting</a> in conjunction with the <code class="language-plaintext highlighter-rouge">--raw-line</code>/<code class="language-plaintext highlighter-rouge">raw_line()</code> flag, one can effectively ask bindgen to “replace” types. Blocklisting asks bindgen not to generate bindings for a type, however bindgen will continue to generate bindings <em>referring</em> to that type if necessary. (Unlike opaque types where bindgen generates an opaque binding for the type and uses it everywhere). <code class="language-plaintext highlighter-rouge">--raw-line</code> lets you request bindgen to add a line of raw rust code to the file, and such a line can potentially define or import a new version of the type you blocklisted. Effectively, this lets you replace types.</p>

<p>Bindgen generates unit tests ensuring that the layout of your structs is correct (run them!), so if you accidentally replace a type with something incompatible, you will get warnings at the struct level (functions may not warn).</p>

<p>There are various ways this can be used:</p>

<h3 id="safe-references-across-ffi">Safe references across FFI</h3>

<p><em>Note from 2021: <a href="https://github.com/dtolnay/cxx">cxx</a> does this automatically</em></p>

<p>Calling into C++ (and accepting data from C++) is unsafe. However, there’s no reason we should have to worry about this more than we have to. For example, it would be nice if accessor FFI functions – functions which take a foreign object and return something from inside it –  could use lifetimes. It would be even nicer if nullability were represented on the FFI boundary so that you don’t miss null checks, and can assume non-nullness when the C++ API is okay with it.</p>

<p>In Stylo, we have lots of functions like the following:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">RawGeckoNodeBorrowedOrNull</span> <span class="nf">Gecko_GetLastChild</span><span class="p">(</span><span class="n">RawGeckoNodeBorrowed</span> <span class="n">node</span><span class="p">);</span>
</code></pre></div></div>

<p>which bindgen translates to:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">extern</span> <span class="s">"C"</span> <span class="p">{</span>
    <span class="k">fn</span> <span class="nf">Gecko_GetLastChild</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="o">&amp;</span><span class="n">RawGeckoNode</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">Option</span><span class="o">&lt;&amp;</span><span class="n">RawGeckoNode</span><span class="o">&gt;</span><span class="p">;</span>   
<span class="p">}</span>
</code></pre></div></div>

<p>Using the <a href="https://searchfox.org/mozilla-central/rev/819cd31a93fd50b7167979607371878c4d6f18e8/servo/components/style/build_gecko.rs">bindgen build script</a> on a provided <a href="https://searchfox.org/mozilla-central/rev/819cd31a93fd50b7167979607371878c4d6f18e8/layout/style/ServoBindings.toml#648-671">list of borrow-able types</a>, we’ve told bindgen that:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">FooBorrowedOrNull</code> is actually <code class="language-plaintext highlighter-rouge">Option&lt;&amp;Foo&gt;</code></li>
  <li><code class="language-plaintext highlighter-rouge">FooBorrowed</code> is actually <code class="language-plaintext highlighter-rouge">&amp;Foo</code></li>
</ul>

<p><code class="language-plaintext highlighter-rouge">Option&lt;&amp;Foo&gt;</code> <a href="https://doc.rust-lang.org/nomicon/repr-rust.html">is represented as a single nullable pointer in Rust</a>, so this is a clean translation. 
We’re forced to null-check it, but once we do we can safely assume that the reference is valid. Furthermore, due to lifetime elision the actual signature of the FFI function is <code class="language-plaintext highlighter-rouge">fn Gecko_GetLastChild&lt;'a&gt;(x: &amp;'a RawGeckoNode) -&gt; Option&lt;&amp;'a RawGeckoNode&gt;</code>, which ensures we won’t let the returned reference outlive the passed reference. Lifetime elision means that we can call C++ functions “safely” with the appropriate lifetime requirements, even though C++ has no such concept!</p>

<p>Note that this is shifting some of the safety invariants to the C++ side: We rely on the C++ to give us valid references, and we rely on it to not have nulls when the type is not marked as nullable. Most C++ codebases internally rely on such invariants for safety anyway, so this isn’t much of a stretch.</p>

<p>We do this on both sides, actually: Many of our Rust-defined <code class="language-plaintext highlighter-rouge">extern "C"</code> functions that C++ calls get to be internally-safe because the types let us assume the validity of the pointers obtained from C++.</p>

<h3 id="making-c-abstractions-rust-accessible">Making C++ abstractions Rust-accessible</h3>

<p>A very useful thing to do here is to replace various C++ abstractions with Rust versions of them that share semantics. In Gecko, most strings are stored in <code class="language-plaintext highlighter-rouge">nsString</code>/<code class="language-plaintext highlighter-rouge">nsAString</code>/etc.</p>

<p>We’ve written an <a href="https://searchfox.org/mozilla-central/rev/6ddb5fb144993fb5de044e2e8d900d7643b98a4d/servo/support/gecko/nsstring/src/lib.rs">nsstring</a> crate that represents layout-compatible <code class="language-plaintext highlighter-rouge">nsString</code>s in a more Rusty way, with Rusty APIs. We then ask bindgen to replace Gecko <code class="language-plaintext highlighter-rouge">nsString</code>s with these.</p>

<p>Usually it’s easier to just write an impl for the bindgen-generated abstraction, however sometimes you must replace it:</p>

<ul>
  <li>When the abstraction internally does a lot of template stuff not supported by bindgen</li>
  <li>When you want the code for the abstraction to be in a separate crate</li>
</ul>

<h2 id="potential-pitfall-passing-c-classes-by-value-over-ffi">Potential pitfall: Passing C++ classes by-value over FFI</h2>

<p>It’s quite tempting to do stuff like</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">RefPtr</span><span class="o">&lt;</span><span class="n">Foo</span><span class="o">&gt;</span> <span class="n">Servo_Gimme</span><span class="p">(...);</span>
</code></pre></div></div>

<p>where you pass complicated classes by-value over FFI (<code class="language-plaintext highlighter-rouge">RefPtr</code> is Gecko’s variant of <code class="language-plaintext highlighter-rouge">Rc&lt;T&gt;</code>/<code class="language-plaintext highlighter-rouge">Arc&lt;T&gt;</code>).</p>

<p>This works on some systems, but is broken on MSVC:
<a href="https://github.com/rust-lang/rust/issues/38258">The ABI for passing non-POD types through functions is different</a>. The linker usually notices this and complains, but it’s worth avoiding this entirely.</p>

<p>In Stylo we handle this by using some macro-generated intermediate types which are basically the same thing as the original class but without any constructors/destructors/operators. We convert to/from these types immediately before/after the FFI call, and on the Rust side we do similar conversions to Rust-compatible abstractions.</p>

<h2 id="sharing-abstractions-with-destructors">Sharing abstractions with destructors</h2>

<p>If you’re passing ownership of collections or other templated types across FFI, you probably want Rust code to be able to destroy C++ objects, and vice versa.</p>

<p>One way of doing this is to implement <code class="language-plaintext highlighter-rouge">Drop</code> on the generated struct. If you have <code class="language-plaintext highlighter-rouge">class MyString</code>, you can do:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MyString</span> <span class="p">{</span>
    <span class="c1">// ...</span>
    <span class="o">~</span><span class="n">MyString</span><span class="p">();</span>
<span class="p">}</span>

<span class="kt">void</span> <span class="nf">MyString_Destroy</span><span class="p">(</span><span class="o">*</span><span class="n">MyString</span> <span class="n">x</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">x</span><span class="o">-&gt;~</span><span class="n">MyString</span><span class="p">()</span>
<span class="p">}</span>
</code></pre></div></div>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">impl</span> <span class="n">Drop</span> <span class="k">for</span> <span class="nn">bindings</span><span class="p">::</span><span class="n">MyString</span> <span class="p">{</span>
    <span class="k">fn</span> <span class="k">drop</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">)</span> <span class="p">{</span>
        <span class="c">// (bindgen only)</span>
        <span class="nn">bindings</span><span class="p">::</span><span class="nn">MyString</span><span class="p">::</span><span class="nf">destruct</span><span class="p">(</span><span class="k">self</span><span class="p">)</span>
        <span class="c">// OR</span>
        <span class="nn">bindings</span><span class="p">::</span><span class="nf">MyString_Destroy</span><span class="p">(</span><span class="k">self</span><span class="p">)</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>The <code class="language-plaintext highlighter-rouge">MyString_Destroy</code> isn’t necessary with bindgen – bindgen will generate a <code class="language-plaintext highlighter-rouge">MyString::destruct()</code> function for you – but be careful, this will make your generated bindings very platform-specific, so be sure to only do this if running them at build time. In general, when bindgen generates C++ <em>methods</em>, your bindings become platform specific and are best regenerated at build time<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" class="footnote">3</a></sup>.</p>

<p>In Stylo we went down the route of manually defining <code class="language-plaintext highlighter-rouge">_Destroy()</code> functions since we started off with checked-in platform-agnostic bindings, however we could probably switch to using <code class="language-plaintext highlighter-rouge">destruct()</code> if we want to now.</p>

<p>When it comes to generic types, it’s a bit trickier, since <code class="language-plaintext highlighter-rouge">Drop</code> can’t be implemented piecewise on a generic type (you cannot <code class="language-plaintext highlighter-rouge">impl Drop for MyVector&lt;Foo&gt;</code>). You have to do something like:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">template</span><span class="o">&lt;</span><span class="k">typename</span> <span class="nc">T</span><span class="p">&gt;</span>
<span class="k">class</span> <span class="nc">MyVector</span> <span class="p">{</span>
    <span class="c1">// ...</span>
<span class="p">}</span>

<span class="c1">// Deallocate buffer, but do not call destructors on elements</span>
<span class="kt">void</span> <span class="nf">MyVector_Deallocate_Buffer</span><span class="p">(</span><span class="n">MyVector</span><span class="o">&lt;</span><span class="kt">void</span><span class="o">&gt;*</span> <span class="n">x</span><span class="p">);</span>
</code></pre></div></div>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">// assume we have an implementation of Iterator for MyVector&lt;T&gt; somewhere</span>

<span class="k">impl</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="n">Drop</span> <span class="k">for</span> <span class="nn">bindings</span><span class="p">::</span><span class="n">MyVector</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="k">fn</span> <span class="k">drop</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">for</span> <span class="n">v</span> <span class="n">in</span> <span class="k">self</span><span class="nf">.iter_mut</span><span class="p">()</span> <span class="p">{</span>
            <span class="c">// calls the destructor for `v`, if any</span>
            <span class="nn">std</span><span class="p">::</span><span class="nn">ptr</span><span class="p">::</span><span class="nf">drop_in_place</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
        <span class="p">}</span>
        <span class="nn">bindings</span><span class="p">::</span><span class="nf">MyVector_Deallocate_Buffer</span><span class="p">(</span><span class="k">self</span> <span class="k">as</span> <span class="o">*</span><span class="k">mut</span> <span class="n">MyVector</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="k">as</span> <span class="o">*</span><span class="k">mut</span> <span class="n">MyVector</span><span class="o">&lt;</span><span class="nb">c_void</span><span class="o">&gt;</span><span class="p">)</span>
    <span class="p">}</span>
<span class="p">}</span>

</code></pre></div></div>

<p>Note that if you forget to add a <code class="language-plaintext highlighter-rouge">Drop</code> implementation for <code class="language-plaintext highlighter-rouge">T</code>, this will silently forget to clean up the contents of the vector. See <a href="#mirror-types">the next section</a> for some ways to handle this by creating a “safe” mirror type.</p>

<h2 id="mirror-types">Mirror types</h2>

<p>C++ libraries often have useful templated abstractions, and it’s nice to be able to manipulate them from Rust. Sometimes, it’s possible to just tack on semantics on the Rust side (either by adding an implementation or by doing type replacement), but in some cases this is tricky.</p>

<p>For example, Gecko has <code class="language-plaintext highlighter-rouge">RefPtr&lt;T&gt;</code>, which is similar to <code class="language-plaintext highlighter-rouge">Rc&lt;T&gt;</code>, except the actual refcounting logic is up to <code class="language-plaintext highlighter-rouge">T</code> to implement (it can choose between threadsafe, non-threadsafe, etc), which it does by writing <code class="language-plaintext highlighter-rouge">AddRef()</code> and <code class="language-plaintext highlighter-rouge">Release()</code> methods.</p>

<p>We mirror this in Rust by having a trait:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">/// Trait for all objects that have Addref() and Release</span>
<span class="c">/// methods and can be placed inside RefPtr&lt;T&gt;</span>
<span class="k">pub</span> <span class="k">unsafe</span> <span class="k">trait</span> <span class="n">RefCounted</span> <span class="p">{</span>
    <span class="c">/// Bump the reference count.</span>
    <span class="k">fn</span> <span class="nf">addref</span><span class="p">(</span><span class="o">&amp;</span><span class="k">self</span><span class="p">);</span>
    <span class="c">/// Decrease the reference count.</span>
    <span class="k">unsafe</span> <span class="k">fn</span> <span class="nf">release</span><span class="p">(</span><span class="o">&amp;</span><span class="k">self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c">/// A custom RefPtr implementation to take into account Drop semantics and</span>
<span class="c">/// a bit less-painful memory management.</span>
<span class="k">pub</span> <span class="k">struct</span> <span class="n">RefPtr</span><span class="o">&lt;</span><span class="n">T</span><span class="p">:</span> <span class="n">RefCounted</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="n">ptr</span><span class="p">:</span> <span class="o">*</span><span class="k">mut</span> <span class="n">T</span><span class="p">,</span>
    <span class="mi">_</span><span class="n">marker</span><span class="p">:</span> <span class="n">PhantomData</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div></div>

<p>We implement the <code class="language-plaintext highlighter-rouge">RefCounted</code> trait for C++ types that are wrapped in <code class="language-plaintext highlighter-rouge">RefPtr</code> which we wish to access through Rust. We have <a href="https://searchfox.org/mozilla-central/rev/cfaa5a1d48d6bc6552199e73004ecb05d0a9c921/servo/components/style/gecko_bindings/sugar/refptr.rs#258-315">some</a> <a href="https://searchfox.org/mozilla-central/rev/cfaa5a1d48d6bc6552199e73004ecb05d0a9c921/layout/style/GeckoBindings.h#52-60">macros</a> that make this easier to do. We have to have such a trait, because otherwise Rust code wouldn’t know how to manage various C++ types.</p>

<p>However, <code class="language-plaintext highlighter-rouge">RefPtr&lt;T&gt;</code> here can’t be the type that ends up being used in bindgen. Rust doesnt let us do things like <code class="language-plaintext highlighter-rouge">impl&lt;T: RefCounted&gt; Drop for RefPtr&lt;T&gt;</code> <sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote">4</a></sup>, so we can’t effectively make this work with the bindgen generated type unless we write a <code class="language-plaintext highlighter-rouge">RefCounted</code> implementation for every refcounted type that shows up in the bindgen output at all – which would be a lot of work.</p>

<p>Instead, we let bindgen generate its own <code class="language-plaintext highlighter-rouge">RefPtr&lt;T&gt;</code>, called <code class="language-plaintext highlighter-rouge">structs::RefPtr&lt;T&gt;</code> (all the structs that bindgen generates for Gecko go in a <code class="language-plaintext highlighter-rouge">structs::</code> module). <code class="language-plaintext highlighter-rouge">structs::RefPtr&lt;T&gt;</code> itself doesn’t have enough semantics to be something we can pass around willy-nilly in Rust code without causing leaks. However, it has <a href="https://searchfox.org/mozilla-central/rev/cfaa5a1d48d6bc6552199e73004ecb05d0a9c921/servo/components/style/gecko_bindings/sugar/refptr.rs#150-234">some methods</a> that allow for conversion into the “safe” mirror <code class="language-plaintext highlighter-rouge">RefPtr&lt;T&gt;</code> (but only if <code class="language-plaintext highlighter-rouge">T: RefCounted</code>). So if you need to manipulate a <code class="language-plaintext highlighter-rouge">RefPtr&lt;T&gt;</code> in a C++ struct somewhere, you immediately use one of the conversion methods to get a safe version of it first, and <em>then</em> do things to it. Refcounted types that don’t have the <code class="language-plaintext highlighter-rouge">RefCounted</code> implementation won’t have conversion methods: they may exist in the data you’re manipulating, however you won’t be able to work with them.</p>

<p>In general, whenever attaching extra semantics to generic bindgen types doesn’t work create a mirror type that’s completely safe to use from Rust, with a trait that gates conversion to the mirror type.</p>

<h2 id="potential-pitfall-allocators">Potential pitfall: Allocators</h2>

<p>If you’re passing heap-managed abstractions across FFI, be careful about which code frees which objects. If your Rust
and C++ code don’t share allocators, deallocating memory allocated on the other side can have disastrous consequences.</p>

<p>If you’re building a cdylib or staticlib with Rust (this is likely if you’re linking it with a C++ application), the compiler will by default pick the system allocator (<code class="language-plaintext highlighter-rouge">malloc</code>), so if your C++ application also uses the same you’re all set.</p>

<p>On some platforms when building rlibs and binaries, Rust may choose jemalloc instead. It’s also possible that your C++ code uses a different allocator (lots of applications use allocators like jemalloc or tcmalloc, some have their own custom allocators like <code class="language-plaintext highlighter-rouge">tor_malloc</code> in Tor).</p>

<p>In such cases you have one of three options:</p>

<ul>
  <li>Avoid transferring ownership of heap-allocated items, only share things as borrowed references</li>
  <li>Call destructors over FFI, as detailed in <a href="#sharing-abstractions-with-destructors">the section on destructors above</a></li>
  <li>Set Rust’s allocator to be the same as documented <a href="https://doc.rust-lang.org/nightly/std/alloc/#the-global_allocator-attribute">in the <code class="language-plaintext highlighter-rouge">std::alloc</code> module</a>. Basically, can use the <code class="language-plaintext highlighter-rouge">#[global_allocator]</code> attribute to select which allocator you wish to use, and if necessary you can implement the <code class="language-plaintext highlighter-rouge">GlobalAlloc</code> trait on a custom allocator type that calls into whatever custom allocator C++ is using.</li>
</ul>

<p><em>Note from 2021: Most stdlib collections (<a href="https://doc.rust-lang.org/nightly/std/vec/struct.Vec.html"><code class="language-plaintext highlighter-rouge">Vec</code></a>, for example) now have an optional “custom allocator” parameter that can be used to swap in a different allocator for a specific use site.</em></p>

<h2 id="arcs-over-ffi-triomphe">Arcs over FFI: Triomphe</h2>

<p>This isn’t really a generalizable technique, but it’s pretty cool and generally instructive, so I’m including it here.</p>

<p>Stylo uses a lot of <code class="language-plaintext highlighter-rouge">Arc</code>s. A <em>lot</em> of them. The entire computation of styles makes heavy use of <code class="language-plaintext highlighter-rouge">Arc::make_mut</code>’s copy-on-write semantics so that we can build up the style tree in parallel but not have to make unnecessary copies of duplicated/defaulted styles for each element.</p>

<p>Many of these <code class="language-plaintext highlighter-rouge">Arc</code>s need to be readable from C++. Rust’s <code class="language-plaintext highlighter-rouge">Arc</code>, however, consists of a pointer to an allocation containing a refcount and the data, so if C++ needs to get access to the data it needs to know the layout of the <code class="language-plaintext highlighter-rouge">Arc</code> allocation, which we’d rather not do<sup id="fnref:5" role="doc-noteref"><a href="#fn:5" class="footnote">5</a></sup>.</p>

<p>We picked a different route: We created a crate duplicating <code class="language-plaintext highlighter-rouge">Arc&lt;T&gt;</code> which behaves almost exactly the same as <code class="language-plaintext highlighter-rouge">Arc&lt;T&gt;</code>, but it can be converted to <code class="language-plaintext highlighter-rouge">OffsetArc&lt;T&gt;</code> which has its pointer point to the <em>middle</em> of the allocation, where the <code class="language-plaintext highlighter-rouge">T</code> begins. To C++, this just looks like a <code class="language-plaintext highlighter-rouge">*const T</code>! We were then able to make it work with <code class="language-plaintext highlighter-rouge">RefPtr&lt;T&gt;</code> on the C++ side so that C++ can transparently read from the <code class="language-plaintext highlighter-rouge">OffsetArc&lt;T&gt;</code>, and only needs to call into Rust if it wishes to clone or drop it.</p>

<p>The external version of this crate can be found in <a href="https://docs.rs/triomphe">triomphe</a>. It contains a bunch of other goodies that are additionally useful outside of the FFI world, like <code class="language-plaintext highlighter-rouge">ArcBorrow</code> which is essentially “<code class="language-plaintext highlighter-rouge">&amp;Arc&lt;T&gt;</code> without double indirection”, <code class="language-plaintext highlighter-rouge">UniqueArc&lt;T&gt;</code>, a mutable <code class="language-plaintext highlighter-rouge">Arc&lt;T&gt;</code> known to be uniquely owned, and <code class="language-plaintext highlighter-rouge">ArcUnion&lt;T, U&gt;</code>, which is a space-efficient union of <code class="language-plaintext highlighter-rouge">Arc&lt;T&gt;</code> and <code class="language-plaintext highlighter-rouge">Arc&lt;U&gt;</code>.</p>

<h2 id="other-pitfalls">Other pitfalls</h2>

<h3 id="transparent">Transparent</h3>

<p>It’s <em>very</em> tempting to wrap C++ types in tuple structs and pass them over FFI. For example, one might imagine that the following is okay:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">struct</span> <span class="nf">Wrapper</span><span class="p">(</span><span class="nn">bindings</span><span class="p">::</span><span class="n">SomeCppType</span><span class="p">);</span>

<span class="k">extern</span> <span class="s">"C"</span> <span class="p">{</span>
    <span class="c">// C++ signature: `SomeCppType get_cpp_type();`</span>
    <span class="k">fn</span> <span class="nf">get_cpp_type</span><span class="p">()</span> <span class="k">-&gt;</span> <span class="n">Wrapper</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<p>This kind of thing is quite useful to get around coherence, or for adding additional semantics to a type.</p>

<p>While there’s basically one obvious way <code class="language-plaintext highlighter-rouge">Wrapper</code> can be represented, ABI stuff can be tricky, and Rust’s layout isn’t defined. It is safer to use <code class="language-plaintext highlighter-rouge">#[repr(transparent)]</code>, which guarantees that <code class="language-plaintext highlighter-rouge">Wrapper</code> will have the same representation as the type it contains.</p>

<h3 id="c-enums">C enums</h3>

<p>Rust supports C-like enums, but there’s a crucial difference between them. In C, it is not undefined behavior for an enum to have an unlisted value. In fact, the following pattern is not uncommon:</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">enum</span> <span class="n">Flags</span> <span class="p">{</span>
    <span class="n">Flag1</span> <span class="o">=</span> <span class="mi">0</span><span class="n">b0001</span><span class="p">,</span>
    <span class="n">Flag2</span> <span class="o">=</span> <span class="mi">0</span><span class="n">b0010</span><span class="p">,</span>
    <span class="n">Flag3</span> <span class="o">=</span> <span class="mi">0</span><span class="n">b0100</span><span class="p">,</span>
    <span class="n">Flag4</span> <span class="o">=</span> <span class="mi">0</span><span class="n">b1000</span><span class="p">;</span>
<span class="p">};</span>
</code></pre></div></div>

<p>where the enum is actually used for bitflags, and <code class="language-plaintext highlighter-rouge">Flag1 | Flag2</code> and <code class="language-plaintext highlighter-rouge">0</code> are both valid values for <code class="language-plaintext highlighter-rouge">Flags</code>.</p>

<p>This is not the case in Rust. If you are type-replacing C enums with Rust ones, make sure they are <code class="language-plaintext highlighter-rouge">#[repr(C)]</code>. The Rust compiler uses invalid enum values as space for packing other information while optimizing types, for example Rust is able to represent <code class="language-plaintext highlighter-rouge">Option&lt;Option&lt;... 255 times .. Option&lt;bool&gt;&gt;</code> as a single byte.</p>

<p>If you are working with a C enum that is used for bitflags like above, please use an integer type instead. <code class="language-plaintext highlighter-rouge">#[repr(C)]</code> on enums in Rust guarantees layout, but it is <a href="https://doc.rust-lang.org/stable/nomicon/other-reprs.html">still undefined behavior for any enum to take on invalid values</a>.</p>

<h3 id="abi-concerns">ABI concerns</h3>

<p>ABIs can be tricky. If you <em>just</em> use bindgen with no special flags, you can be pretty much guaranteed to have an okay ABI, but as you start doing type replacements, stuff can get murkier.</p>

<p>Firstly, make sure you’re not passing owned C++ classes with destructors/etc across FFI boundaries. See <a href="#potential-pitfall-passing-c-classes-by-value-over-ffi">above</a> for why. There’s a bunch of subtle stuff here, but you can avoid most of it it if you just don’t pass these things across FFI in an owned way.</p>

<p>Also, try to make sure everything is <code class="language-plaintext highlighter-rouge">#[repr(C)]</code> across the boundary. Rust’s <code class="language-plaintext highlighter-rouge">improper-ctypes</code> lints will help here.</p>

<h2 id="should-c-apis-be-unconditionally-unsafe">Should C++ APIs be unconditionally <code class="language-plaintext highlighter-rouge">unsafe</code>?</h2>

<p>Before I get into this, I want to reiterate that most of the recommendations in this post are for <em>complex</em> C++-Rust integrations, which are likely to only crop up when attempting to rewrite parts of a large C++ codebase in Rust. Such codebases have unique needs and it’s important to calibrate for that when judging what’s right for them.</p>

<p>I recall when <a href="https://www.chromium.org/Home/chromium-security/memory-safety/rust-and-c-interoperability">this Chromium post</a> and <a href="https://steveklabnik.com/writing/the-cxx-debate">Steve’s <code class="language-plaintext highlighter-rouge">cxx</code> post</a> came out, there was a bunch of discussion about C++ functions not being universally marked <code class="language-plaintext highlighter-rouge">unsafe</code>. Essentially, a lot of people are of the opinion that all FFI into C++ (or C) should be unconditionally marked <code class="language-plaintext highlighter-rouge">unsafe</code> (and that tools like <code class="language-plaintext highlighter-rouge">cxx</code> should follow these rules).</p>

<p>Back then I wrote <a href="https://www.reddit.com/r/rust/comments/ielvxu/the_cxx_debate/g2jurb3/?context=3">a Reddit comment</a> about my thoughts on this. It’s a comment that’s the length of a blog post in and of itself so I’m not going to reproduce all of it here, but I’ll try to get the gist. I highly suggest you read it instead of this section.</p>

<p>In short, I would recommend people in large, complex codebases doing heavy C++ interop to generally be okay with marking functions calling into C++ as “safe” provided that function would be considered “safe to call without thinking too much about it” on the C++ side, whatever that means for your codebase.</p>

<p>From <a href="https://manishearth.github.io/blog/2017/12/24/undefined-vs-unsafe-in-rust/">my post on “undefined” vs “unsafe”</a>, for Rust I define “safe” as</p>

<blockquote>
  <p>Basically, in Rust a bit of code is “safe” if it cannot exhibit undefined behavior under all circumstances of that code being used.</p>
</blockquote>

<p>C++ doesn’t have a rigid language-level concept of safety that can be applied the same way. Instead, most C++ code follows a similar heuristic:</p>

<blockquote>
  <p>a bit of code is “safe” if it cannot exhibit undefined behavior under all <strong>expected</strong> circumstances of that code being used.</p>
</blockquote>

<p>This is, perhaps, not as good or useful a heuristic as the one we have for Rust, but it’s still a heuristic that gets used in deciding how careful one needs to be when using various APIs. After all, there are <em>plenty</em> of giant C++ codebases out there, they have got to be able to reason about safety <em>somehow</em>.</p>

<p>When you decide to meld together a C++ and Rust codebase, or start rewriting parts of a C++ codebase in Rust, you have already in essence decided for a large part of the codebase to not exactly follow Rust’s safety rules (but hopefully still be safe). There is little to be gained by making that an explicit part of your FFI boundary. Rather, it is more useful to save <code class="language-plaintext highlighter-rouge">unsafe</code> on the FFI boundary for truly unsafe functions which you actually do need to be careful to call.</p>

<p><code class="language-plaintext highlighter-rouge">unsafe</code> is useful for finding potential sources of badness in your codebase. For a tightly-integrated Rust/C++ codebase it’s already well known that the C++-side is introducing badness, marking every simple C++ getter as <code class="language-plaintext highlighter-rouge">unsafe</code> will lead to alarm fatigue and make it <em>harder</em> to find the real problems.</p>

<p>It’s worth figuring out where this boundary lies for you. Tools like <code class="language-plaintext highlighter-rouge">cxx</code> make it straightforward to call C++ functions through a safe interface, and it’s valuable to make use of that support.</p>

<h2 id="closing-comments">Closing comments</h2>

<p>Again, before going down this route it’s worth wondering if you <em>really</em> need tight Rust-C++ integration. When possible, it’s always better to pick a small, well-defined API boundary, rather than Stylo-esque tight integration with shared objects and a highly criscrossed callgraph.</p>

<p>These days <a href="https://github.com/dtolnay/cxx">cxx</a> is probably the most complete tool for such integrations. <a href="https://github.com/rust-lang-nursery/rust-bindgen/">bindgen</a> and <a href="https://github.com/eqrion/cbindgen">cbindgen</a> are still quite good, but cxx is C++-first, with a lot more magic, and generally seems to Just Work without too much configuration.</p>

<p><a href="https://github.com/google/autocxx">autocxx</a> is a cool concept by Adrian Taylor which melds bindgen and cxx to make something even <em>more</em> magical. It’s currently experimental, but I’m going to be watching it with interest.</p>

<p>Overall the field of Rust and C++ integration is at a stage where it’s mature enough for integrations to be <em>possible</em> without too much effort, but there are still tons of ways things could be improved and I’m super excited to see that happen as more people work on such integrations!</p>

<p><em>Thanks to Adam Perry, Adrian Taylor, katie martin, Nika Layzell, and Tyler Mandry for reviewing drafts of this post</em></p>
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>The <em>cascade</em> in “Cascading Style Sheets” is the process used to take all the potential rules which could apply to an element and find the “most applicable” one that gets actually used. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>The <code class="language-plaintext highlighter-rouge">em</code> unit is font-size-relative, so <code class="language-plaintext highlighter-rouge">2em</code> with a <code class="language-plaintext highlighter-rouge">font-size</code> of <code class="language-plaintext highlighter-rouge">12px</code> is computed to <code class="language-plaintext highlighter-rouge">2 * 12 = 24px</code>. <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:4" role="doc-endnote">
      <p>C++ name mangling <a href="https://en.wikipedia.org/wiki/Name_mangling#How_different_compilers_mangle_the_same_functions">is not standardized</a>, so any function with the C++ ABI will generate a <code class="language-plaintext highlighter-rouge">#[link_name = "_Z1foobarbaz"]</code> attribute on the Rust side, and the exact string used here will differ across compiler implementations and platforms. Since GCC and Clang follow the same scheme, most people will encounter this problem when their code doesn’t work on Windows due to MSVC using a different scheme. <a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p><code class="language-plaintext highlighter-rouge">Drop</code> impls are restricted in a bunch of ways for safety, in particular you cannot write <code class="language-plaintext highlighter-rouge">impl&lt;T: RefCounted&gt; Drop for RefPtr&lt;T&gt;</code> unless <code class="language-plaintext highlighter-rouge">RefPtr</code> is defined as <code class="language-plaintext highlighter-rouge">RefPtr&lt;T: RefCounted&gt;</code>. It’s not possible to have a generic type that has an impl of <code class="language-plaintext highlighter-rouge">Drop</code> for only <em>some</em> possible instantiations of its generics. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:5" role="doc-endnote">
      <p>Rust’s standard library does not typically guarantee anything about the layout of its types, and furthermore, Rust does not make many guarantees about the stability of most types without a <code class="language-plaintext highlighter-rouge">#[repr]</code> attribute. This would <em>work</em>, but it would be brittle and prone to breakage. <a href="#fnref:5" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Rust Governance: Scaling Empathy]]></title>
    <link href="http://manishearth.github.io/blog/2019/02/04/rust-governance-scaling-empathy/"/>
    <updated>2019-02-04T00:00:00+00:00</updated>
    <id>http://manishearth.github.io/blog/2019/02/04/rust-governance-scaling-empathy</id>
    <content type="html"><![CDATA[<p>There’s been a lot of talk about improving Rust’s governance model lately. As we decompress from last year’s hectic edition work, we’re slowly starting to look at all the bits of <a href="https://twitter.com/ManishEarth/status/1073088515041198080">debt</a> we accumulated, and <a href="https://boats.gitlab.io/blog/post/rust-2019/">organizational debt</a> is high on that list.</p>

<p>I’ve been talking in private with people about a bunch of these things for quite a while now, and I felt it worthwhile to write down as much of my thoughts as I can before the Rust All Hands in Berlin this week.</p>

<p>In the interest of brevity<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">1</a></sup> I’m going to assume the reader is roughly familiar with most of the stuff that’s happened with the Rust community in the past few years. I’m probably going to omit concrete examples of incidents, both to avoid mischaracterizing individual actions (as with most such analyses, I wish to talk in more general terms about trends), and also just because it would take me forever to write this if I were to supply all the layers of context. If you feel something is inaccurate, please let me know.</p>

<p>This blog post is probably going to reach the eyes of non-Rust-community members. You’re welcome to read it, but please accept my apologies in advance if it doesn’t make any sense. This is something that I initially planned to circulate as a private post (writing for a general audience is <em>hard</em>), but I felt this would be more widely useful. However due to time constraints I haven’t had time to edit it to make it acceptable to a wider audience.</p>

<h2 id="the-symptoms">The symptoms</h2>

<p>Before I actually get into it, I’d like to carefully delineate <em>what</em> the problem is that I’m talking about. Or more accurately, the <em>symptoms</em> I am talking about — as I’ll explain soon I feel like these are not the actual problem but symptoms of a more general problem.</p>

<p>Basically, as time has gone by our decisionmaking process has become more and more arduous, both for community members and the teams. Folks have to deal with:</p>

<ul>
  <li>The same arguments getting brought up over and over again</li>
  <li>Accusations of bad faith</li>
  <li>Derailing</li>
  <li>Not feeling heard</li>
  <li>Just getting exhausted by all the stuff that’s going on</li>
</ul>

<p>The RFC process is the primary exhibitor of these symptoms, but semi-official consensus-building threads on https://internals.rust-lang.org have similar problems.</p>

<p>Aaron <a href="http://aturon.github.io/2018/05/25/listening-part-1/">has written some extremely empathetic blog posts</a> about a bunch of these problems, starting with concrete examples and ending with a takeaway of a bunch of values for us to apply as well as thoughts on what our next steps can be. I highly recommend you read them if you haven’t already.</p>

<p>Fundamentally I consider our problems to be social problems, not technical ones. In my opinion, technical solutions like changing the discussion forum format may be necessary but are not sufficient for fixing this.</p>

<h2 id="the-scaling-problem">The scaling problem</h2>

<p>I contend that all of these issues are symptoms of an underlying <em>scaling issue</em>, but also a failure of how our moderation works.</p>

<p>The scaling issue is somewhat straightforward. Such forum discussions are inherently N-to-N discussions. When you leave a comment, you’re leaving a comment for <em>everyone</em> to read and interpret, and this is hard to get right. It’s <em>much</em> easier to have one-on-one discussions because it’s easy to build a shared vocabulary and avoid misunderstandings. Any misunderstandings can often be quickly detected and corrected.</p>

<p>I find that most unpleasant technical arguments stem from an unenumerated mismatch of assumptions, or sometimes what I call a mismatch of axioms (i.e. when there is fundamental conflict between core beliefs). A mismatch of assumptions, if identified, can be resolved, leading to an amicable conclusion. Mismatches of axioms are harder to resolve, however recognizing them can take most of the vitriol out of an argument, because both parties will <em>understand</em> each other, even if they don’t <em>agree</em>. In such situations the end result may leave one or both parties <em>unhappy</em>, but rarely <em>angry</em>. (It’s also not necessary that axiom mismatches leave people unhappy, embracing <a href="http://aturon.github.io/2018/06/02/listening-part-2/#pluralism-and-positive-sums">positive sum thinking</a> helps us come to mutually beneficial conclusions)</p>

<p>All of these mismatches are easy to identify in one-on-one discussions, because it’s easy to switch gears to the meta discussion for a bit.</p>

<p>One-on-one discussions are pleasant. They foster empathy.</p>

<p>N-to-N discussions are <em>not</em>. It’s harder to converge on this shared vocabulary amongst N other people. It’s harder to identify these mismatches, partly because it’s hard to switch into the meta-mode of a discussion at all, but also because there’s a lot going on. It’s harder to build empathy.</p>

<p>As we’ve grown, discussion complexity has grown quadratically, and we’re not really attempting to relinearize them.</p>

<h3 id="hanabi-and-parallel-universes">Hanabi and parallel universes</h3>

<p>I quite enjoy the game of <a href="https://en.wikipedia.org/wiki/Hanabi_(card_game)">Hanabi</a>. It’s a game of information and trust, and I find it extremely fun, especially with the right group.</p>

<p>Hanabi is a cooperative game. You can see everyone’s cards (or tiles) but your own, and information-sharing is severely restricted. The goal is to play the right cards in the right order to collectively win. The gimmick is to share additional information through the side-channel of <em>the choice of move you make</em>.</p>

<p>A very common occurrence in this game is that people start making plans in their mind. You typically have a decent understanding of what information everyone has, and you can use this to make predictions as to what everyone’s moves will be. With this in mind, you can attempt to “set up” situations where the game progresses rapidly in a short period of time. This is somewhat necessary for the game to work, but a common pitfall is for these plans to be <em>extremely</em> elaborate, leading to frustration as the game doesn’t actually play out as planned.</p>

<p>The core issue behind this is forgetting that you actually <em>can’t</em> see the entire game state, since your own cards are hidden. It’s not just <em>you</em> who has plans — everyone does! And each of those plans is incomplete since they’re missing a piece of the picture, just as you are.</p>

<p>In Hanabi it’s very easy to forget that you’re missing a piece of the picture — in competitive card games you mostly can’t see the game state since everyone else’s cards are hidden. But in Hanabi you can see <em>most</em> of the cards and it’s easy to forget that your own four cards are hidden from you.</p>

<p>So what ends up happening is that due to incomplete information, everyone is operating in their own little parallel universe, occasionally getting frustrated when it becomes clear that other players are not operating in the same universe. As long as you recognize the existence of these parallel universes beforehand you’re fine, but if you don’t you will be frustrated.</p>

<p>This is largely true of N-to-N discussions as well. Because most of what’s being said makes sense to an individual in a particular way, it’s very easy for them to forget that other people may not share your assumptions and thus may be on a different page. Every time someone leaves a comment, different people may interpret it differently, “forking” the common understanding of the state of the discussion into multiple parallel universes. Eventually there are enough parallel universes that everyone’s talking past each other.</p>

<p>One thing I often prefer doing in such cases is to have a one on one discussion with people who disagree with me — typically the shared understanding that is the end result of such discussions is super useful and can be brought back to the discussion as something that all participants interpret the same way. I’m not consistent in doing this — in the midst of a heated argument it’s easy to get too wrapped up in the argument to think about getting results and I’ve certainly had my time arguing instead of resolving — but overall whenever I’ve chosen to do this it’s been a useful policy.</p>

<p>This is a good example of how relinearization and communication can help move N-to-N discussions along. Operating in different parallel universes is kind of the <em>point</em> of Hanabi, but it’s not the point of having a technical discussion.</p>

<h2 id="the-moderation-problem">The moderation problem</h2>

<p>In a technical discussion, broadly speaking, I find that there are three kinds of comments disagreeing with you:</p>

<ul>
  <li>Constructive: Comments which disagree with you constructively. We’re glad these exist, disagreement can hurt but is necessary for us to collaboratively reach the best outcomes.</li>
  <li>Disruptive: Comments which may be written in good faith but end up being disruptive. For example, this includes people who don’t read enough of the discussion and end up rehashing the same points. It also includes taking discussions off topic. These kinds of things are problematic but not covered by the code of conduct.</li>
  <li>Abrasive: Comments which are rude/abrasive. These are covered by the code of conduct. The mod team tries to handle these.</li>
</ul>

<p>(For a long time I and <a href="http://twitter.com/aaron_turon/">Aaron</a> had a shared vocabulary of “Type A, B, C” for these, mostly because I’m often unimaginative when it comes to such things, thanks to <a href="https://github.com/mark-simulacrum">Mark</a> for coming up with, better, descriptive titles)</p>

<p>Note that while I’m talking about “disruptive” comments it’s not a judgement on the <em>intent</em> of the participants, but rather a judgement on the harm it has caused.</p>

<p>The second category – disruptive comments – are the thing we’re currently unable to handle well. They snowball pretty badly too — as more and more of these collect, more and more people get frustrated and in turn leave comments that cause further disruption. As the discussion progresses into more and more “parallel universes” it also just becomes <em>easier</em> for a comment to be disruptive.</p>

<p>The Rust moderation team operates mostly passively, we simply don’t have the scale<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote">2</a></sup> to watch for and nip these things in the bud. Active moderation requires a degree of involvement we cannot provide. So while the best response would be to work with participants and resolve issues early as we see them crop up, we typically get pulled in at a point where some participants are already causing harm, and our response has to be more severe. It’s a bit of a catch-22: it’s not exactly our job to deal with this stuff<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote">3</a></sup>, but by the time it <em>becomes</em> our job (or even, by the time we <em>notice</em>), most acceptable actions for us to take are extremely suboptimal. The problem with passive moderation is that it’s largely reactive — it’s harder to proactively nudge the discussion in the right direction when you don’t even <em>notice</em> what’s going on until it’s too late. This is largely okay for dealing with bad-faith actors (the main goal of the mod team); it’s hard to <em>prevent</em> someone from deciding to harass someone else. But for dealing with disruptive buildups, we kind of need something different.</p>

<h2 id="participation-guidelines">Participation guidelines</h2>

<p>Part of the solution here is recognizing that spaces for official discussion are <em>different</em> from community hangout spaces. Our code of conduct attempts to handle abrasive behavior, which can disrupt discussions anywhere, but the comments that can disrupt consensusbuilding official discussions aren’t really covered. Nor are the repercussions of code of conduct violations really <em>appropriate</em> for such disruptive comments anyway.</p>

<p>A proposal I’ve circulated in the past is to have a notion of participation guidelines. Discussions in team spaces (RFCs, pre-RFCs, discord/zulip/IRC channels during team meetings) follow a set of rules set forth by the individual teams. It might be worth having a base set of participation guidelines defined by the core team. Something like the following is a very rough strawman:</p>

<ul>
  <li>Don’t have irrelevant discussions during team meetings on Discord/IRC/Zulip</li>
  <li>Don’t take threads off topic</li>
  <li>Don’t rehash discussions</li>
</ul>

<p>We ask people to read these before participating, but also breaking these rules isn’t considered serious, it just triggers a conversation (and maybe the hiding/deletion of a comment). If someone repeatedly breaks these rules they may be asked to not participate in a given thread anymore. The primary goal here is to empower team members to better deal with disruptive comments by giving them a formalized framework. Having codified rules helps team members confidently deal with such situations without having to worry as much about drawing direct ire from affected community members.</p>

<p>A base participation guidelines document can also be a value statement, not just a set of rules but also set of values. These values can be things like:</p>

<ul>
  <li>“We explicitly value high empathy interactions”</li>
  <li>“How everyone is feeling is everyone’s business”</li>
</ul>

<p>(h/t <a href="http://twitter.com/adam_n_p/">Adam</a> for the articulate wording here)</p>

<p>Having such words written somewhere — both the high level values we expect people to hold, and the individual behaviors we expect people to exhibit (or not exhibit) — is really valuable in and of itself, even if not enforced. The value of such documents is not that everyone reads them before participating — most don’t — but they serve as a good starting point for people interested in learning how to best conduct themselves, as well as an easy place to point people to where they’re having trouble doing so.</p>

<p>On its own, I find that this is a powerful framework but may not achieve the goal of improving the situation. I recently realized that this actually couples really well with a <em>different</em> idea I’ve been talking about for quite a while now, the idea of having facilitators:</p>

<h2 id="facilitators">Facilitators</h2>

<p>A common conflict I see occurring is that in many cases it’s a team’s job to think about and opine on a technical decision, but it’s also the team’s job to shepherd the discussion for that decision. This often works out great, but it also leads to people just feeling unheard. It kinda hurts when someone who has just strongly disagreed with you goes on to summarize the state of the discussion in a way that you feel you’ve been unfairly represented. The natural response to that for most people isn’t to work with that person and try to be properly represented, it’s to just get angry, leading to less empathy over time.</p>

<p>By design, Rust team members are <em>partisan</em>. The teams exist to build well-informed, carefully crafted opinions, and present them to the community. They also exist to make final decisions based on the results of a consensusbuilding discussion, which can involve picking sides. This is fine, there is always going to be some degree of partisanship amongst decisionmakers, or decisions would not get made.</p>

<p>Having team members also facilitate discussions is somewhat at odds with all of this. Furthermore, I feel like they don’t have enough bandwidth to do this well anyway. Some teams do have a concept of “sheriffs”, but this is more of an onramp to full team membership and the role of a sheriff is largely the same as the role of a team member, just without a binding vote.</p>

<p>I feel like it would be useful to have a group of (per-team?) <em>facilitators</em> to help with this. Facilitators are people who are interested in seeing progress happening, and largely don’t have <em>much</em> of an opinion on a given discussion, or are able to set aside this opinion in the interest of moving a discussion forward. They operate largely at the meta level of the discussion. Actions they may take are:</p>

<ul>
  <li>Summarizing the discussion every now and then</li>
  <li>Calling out one sided discussions</li>
  <li>Encouraging one-on-one tangents to be discussed elsewhere (perhaps creating a space for them, like an issue)</li>
  <li>Calling out specific people to do a thing that helps move the discussion forward. For example, something like “hey @Manishearth, I noticed you’ve been vocal in <a href="https://github.com/mystor/slag">arguing that Rust should switch to whitespace-sensitive syntax</a>, could you summarize all the arguments made by people on your side?” would help.</li>
  <li>Reinforcing positive behavior</li>
  <li>Occasionally pinging participants privately to help them improve their comments</li>
  <li>Attempting to identify the root cause of a disagreement, or empowering people to work together to identify this. This one is important but tricky. I’ve often enjoyed doing it — noticing the core axiomatic disagreement at play and spelling it out is a great feeling. But I’ve also found that it’s incredibly hard to do when you’re emotionally involved, and I’ve often needed a nudge from someone else to get there.</li>
</ul>

<p>At a high level, the job of the facilitators is to:</p>

<ul>
  <li>help foster empathy between participants</li>
  <li>help linearize complex discussions</li>
  <li>nudge towards cooperative behavior, away from adversarial behavior. Get people playing not to win, but to win-win.</li>
</ul>

<p>It’s important to note that facilitators don’t make decisions — the team does. In fact, they almost completely avoid making technical points, they instead keep their comments largely at the meta level, perhaps occasionally making factual corrections.</p>

<p>The teams <em>could</em> do most of this themselves<sup id="fnref:5" role="doc-noteref"><a href="#fn:5" class="footnote">4</a></sup>, but as I’ve mentioned before it’s harder for others to not perceive all of your actions as partisan when some of them are. Furthermore, it can come off as patronizing at times.</p>

<p>This is also something the moderation team could do, however it’s <em>much</em> harder to scale the moderation team this way. Given that the moderation team deals with harassment and stuff like that, we need to be careful about how we build it up. On the other hand facilitating discussions is largely a public task, and the stakes aren’t as high: screwups can get noticed, and they don’t cause much harm. As a fundamentally <em>proactive</em> moderation effort, most actions taken will be to nudge things in a positive direction; getting this wrong usually just means that the status quo is maintained, not that harm is caused. Also, from talking to people it seems that while very few people want to be involved in moderating Rust, this notion of <em>facilitating</em> sounds much more fun and rewarding (I’d love to hear from people who would like to help).</p>

<p>And to me, this pairs really well with the idea of participation guidelines: teams can write down how they want discussions to take place on their venues, and facilitators can help ensure this works out. It’s good to look at the participation guidelines less as a set of rules and more as an aspiration for how we conduct ourselves, with the facilitators as a means to achieving that goal.</p>

<p>There are a lot of specifics we can twiddle with this proposal. For example, we can have a per-team group of appointed facilitators (with no overlap with the team), and for a given discussion one facilitator is picked (if they don’t have time or feel like they have strong opinions, try someone else). But there’s also no strong need for there to be such a group, facilitators can be picked as a discussion is starting, too. I don’t expect <em>most</em> discussions to need facilitators, so this is mostly reserved for discussions we expect will get heated, or discussions that have started to get heated. I’m not really going to spend time analysing these specifics; I have opinions but I’d rather have us figure out if we want to do something like this and how before getting into the weeds.</p>

<h2 id="prospective-outcomes">Prospective outcomes</h2>

<p>The real goal here is to bootstrap better empathy within the community. In an ideal world we don’t need facilitators, instead everyone is able to facilitate well. The explicitly non-partisan nature of facilitators is <em>useful</em>, but if everyone was able to operate in this manner it would largely be unnecessary. But as with any organization, being able to horizontally scale specific skills is really tricky without specialization.</p>

<p>I suspect that in the process of building up such a team of facilitators, we will also end up building a set of resources that can help others learn to act the same way, and eventually overall improve how empathetic our community is.</p>

<p>The concept of facilitators directly addresses the moderation problem, but it also handles the scaling problem pretty well! Facilitators are key in re-linearizing the n-to-n discussions, bringing the “parallel universes” together again. This should overall help people (especially team members) who are feeling overwhelmed by all the things that are going on.</p>

<p>This also helps with concerns people have that they’re not getting heard, as facilitators are basically posed as allies on all sides of the argument; people whose primary goal is to <em>help communication happen</em>.</p>

<hr />

<p>Overall what I’ve proposed here isn’t a fully-formed idea; but it’s the seed of one. There are a lot of interesting bits to discuss and build upon. I’m hoping through this post we might push forward some of the discussions about governance — both by providing a strawman idea, as well as by providing a perspective on the problem that I hope is useful.</p>

<p>I’m really interested to hear what people think!</p>

<p><em>Thanks to <a href="http://twitter.com/aaron_turon/">Aaron</a>, <a href="https://twitter.com/ag_dubs">Ashley</a>, <a href="http://twitter.com/adam_n_p/">Adam</a>, <a href="https://twitter.com/cmrx64/">Corey</a>, <a href="http://twitter.com/arshia__">Arshia</a>, <a href="https://twitter.com/mgattozzi">Michael</a>, <a href="https://twitter.com/sunjay03">Sunjay</a>, <a href="http://twitter.com/fitzgen/">Nick</a> and other people I’ve probably forgotten for having been part of these discussions with me over the last few years, helping me refine my thoughts</em></p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>I am way too verbose for “brief” to be an accurate description of anything I write, but might as well <em>try</em>. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>Scaling the moderation team properly is another piece of this puzzle that I’m working on; we’ve made some progress recently. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>I helped draft <a href="https://www.rust-lang.org/policies/code-of-conduct#moderation">our moderation policy</a>, so this is a somewhat a lack of foresight on my part, but as I’ll explain later it’s suboptimal for the mod team to be dealing with this anyway. <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:5" role="doc-endnote">
      <p>In particular, I feel like Aaron has done an <em>excellent</em> and consistent job of facilitating discussions this way in many cases. <a href="#fnref:5" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Down a Rusty Rabbit Hole]]></title>
    <link href="http://manishearth.github.io/blog/2018/04/12/down-a-rusty-rabbit-hole/"/>
    <updated>2018-04-12T00:00:00+00:00</updated>
    <id>http://manishearth.github.io/blog/2018/04/12/down-a-rusty-rabbit-hole</id>
    <content type="html"><![CDATA[<p>Last week I fell down a rather interesting rabbit hole in Rust, which was basically
me discovering a series of quirks of the Rust compiler/language, each one leading to the
next when I asked “why?”.</p>

<p>It started when someone asked why autogenerated <code class="language-plaintext highlighter-rouge">Debug</code> impls use argument names like <code class="language-plaintext highlighter-rouge">__arg_0</code>
which start with a double underscore.</p>

<p>This happened to be <a href="https://github.com/rust-lang/rust/pull/32294">my fault</a>. The reason <a href="https://github.com/rust-lang/rust/pull/32251#issuecomment-197481726">we used a double underscore</a> was that
while a single underscore tells rustc not to warn about a possibly-unused variable, there’s an off-
by-default clippy lint that warns about variables that start with a single underscore that are used,
which can be silenced with a double underscore. Now, the correct fix here is to make the lint ignore
derive/macros (which I believe we did as well), but at the time we needed to add an underscore
anyway so a double underscore didn’t seem worse.</p>

<p>Except of course, this double underscore appears in the docs. Oops.</p>

<p>Ideally the rustc derive infrastructure would have a way of specifying the argument name to use so
that we can at least have descriptive things here, but that’s a bit more work (I’m willing to mentor
this work though!). So I thought I’d fix this by at least removing the double underscore, and making
the unused lint ignore <code class="language-plaintext highlighter-rouge">#[derive()]</code> output.</p>

<p>While going through the code to look for underscores I also discovered a hygiene issue. The following code
throws a bunch of very weird type errors:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">pub</span> <span class="k">const</span> <span class="mi">__</span><span class="n">cmp</span><span class="p">:</span> <span class="nb">u8</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="nd">#[derive(PartialOrd,</span> <span class="nd">PartialEq)]</span>
<span class="k">pub</span> <span class="k">enum</span> <span class="n">Foo</span> <span class="p">{</span>
    <span class="nf">A</span><span class="p">(</span><span class="nb">u8</span><span class="p">),</span> <span class="nf">B</span><span class="p">(</span><span class="nb">u8</span><span class="p">)</span>
<span class="p">}</span>
</code></pre></div></div>

<p>(<a href="https://play.rust-lang.org/?gist=2352b6a2192f38caba70bc2b1fa889e7&amp;version=stable">playpen</a>)</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>error[E0308]: mismatched types
 --&gt; src/main.rs:6:7
  |
6 |     A(u8), B(u8)
  |       ^^^ expected enum `std::option::Option`, found u8
  |
  = note: expected type `std::option::Option&lt;std::cmp::Ordering&gt;`
             found type `u8`
.....
</code></pre></div></div>

<p>This is because the generated code for PartialOrd contains the following:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">match</span> <span class="n">foo</span><span class="nf">.cmp</span><span class="p">(</span><span class="n">bar</span><span class="p">)</span> <span class="p">{</span>
    <span class="nf">Some</span><span class="p">(</span><span class="nn">Ordering</span><span class="p">::</span><span class="n">Equal</span><span class="p">)</span> <span class="k">=&gt;</span> <span class="o">.....</span><span class="p">,</span>
    <span class="mi">__</span><span class="n">cmp</span> <span class="k">=&gt;</span> <span class="mi">__</span><span class="n">cmp</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">__cmp</code> can both be a binding to a wildcard pattern match as well as a match against a constant
named <code class="language-plaintext highlighter-rouge">__cmp</code>, and in the presence of such a constant it resolves to the constant, causing
type errors.</p>

<p>One way to fix this is to bind <code class="language-plaintext highlighter-rouge">foo.cmp(bar)</code> to some temporary variable <code class="language-plaintext highlighter-rouge">x</code> and use that directly in
a <code class="language-plaintext highlighter-rouge">_ =&gt; x</code> branch.</p>

<p>I thought I could be clever and try <code class="language-plaintext highlighter-rouge">cmp @ _ =&gt; cmp</code> instead. <code class="language-plaintext highlighter-rouge">match</code> supports syntax where you can
do <code class="language-plaintext highlighter-rouge">foo @ &lt;pattern&gt;</code>, where <code class="language-plaintext highlighter-rouge">foo</code> is bound to the entire matched variable. The <code class="language-plaintext highlighter-rouge">cmp</code> here is unambiguously
a binding; it cannot be a pattern. So no conflicting with the <code class="language-plaintext highlighter-rouge">const</code>, problem solved!</p>

<p>So I made <a href="https://github.com/rust-lang/rust/pull/49676">a PR for both removing the underscores and also fixing this</a>. The change for <code class="language-plaintext highlighter-rouge">__cmp</code>
is no longer in that PR, but you can find it <a href="https://github.com/Manishearth/rust/commit/partial-cmp-hygiene">here</a>.</p>

<p>Except I hit a problem. With that PR, the following still breaks:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">pub</span> <span class="k">const</span> <span class="n">cmp</span><span class="p">:</span> <span class="nb">u8</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="nd">#[derive(PartialOrd,</span> <span class="nd">PartialEq)]</span>
<span class="k">pub</span> <span class="k">enum</span> <span class="n">Foo</span> <span class="p">{</span>
    <span class="nf">A</span><span class="p">(</span><span class="nb">u8</span><span class="p">),</span> <span class="nf">B</span><span class="p">(</span><span class="nb">u8</span><span class="p">)</span>
<span class="p">}</span>
</code></pre></div></div>

<p>throwing a slightly cryptic error:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>error[E0530]: match bindings cannot shadow constants
 --&gt; test.rs:9:7
  |
4 | pub const cmp: u8 = 1;
  | ---------------------- a constant `cmp` is defined here
...
9 |     B(u8)
  |       ^^^ cannot be named the same as a constant
</code></pre></div></div>

<p>You can see a reduced version of this error in the following code:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">pub</span> <span class="k">const</span> <span class="n">cmp</span> <span class="p">:</span> <span class="nb">u8</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="k">fn</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
    <span class="k">match</span> <span class="mi">1</span> <span class="p">{</span>
        <span class="n">cmp</span> <span class="o">@</span> <span class="mi">_</span> <span class="k">=&gt;</span> <span class="p">()</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>(<a href="https://play.rust-lang.org/?gist=feebbc048b47c286d5720b9926c6925e&amp;version=stable">playpen</a>)</p>

<p>Huh. Wat. Why? <code class="language-plaintext highlighter-rouge">cmp @ _</code> seems to be pretty unambiguous, what’s wrong with it shadowing a constant?</p>

<p>Turns out bindings cannot shadow constants at all, for a <a href="https://github.com/rust-lang/rust/issues/33118#issuecomment-233962221">rather subtle reason</a>:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">const</span> <span class="n">A</span><span class="p">:</span> <span class="nb">u8</span> <span class="o">=</span> <span class="o">...</span><span class="p">;</span> <span class="c">// A_const</span>
<span class="k">let</span> <span class="n">A</span> <span class="o">@</span> <span class="mi">_</span> <span class="o">=</span> <span class="o">...</span><span class="p">;</span> <span class="c">// A_let</span>
<span class="k">match</span> <span class="o">..</span> <span class="p">{</span>
    <span class="n">A</span> <span class="k">=&gt;</span> <span class="o">...</span><span class="p">;</span> <span class="c">// A_match</span>
<span class="p">}</span>
</code></pre></div></div>

<p>What happens here is that constants and variables occupy the same namespace. So <code class="language-plaintext highlighter-rouge">A_let</code> shadows
<code class="language-plaintext highlighter-rouge">A_const</code> here, and when we attempt to <code class="language-plaintext highlighter-rouge">match</code>, <code class="language-plaintext highlighter-rouge">A_match</code> is resolved to <code class="language-plaintext highlighter-rouge">A_let</code> and rejected (since
you can’t match against a variable), and <code class="language-plaintext highlighter-rouge">A_match</code> falls back to resolving as a fresh binding
pattern, instead of resolving to a pattern that matches against <code class="language-plaintext highlighter-rouge">A_const</code>.</p>

<p>This is kinda weird, so we disallow shadowing constants with variables. This is rarely a problem
because variables are lowercase and constants are uppercase. We could <em>technically</em> allow this
language-wise, but it’s hard on the implementation (and irrelevant in practice) so we don’t.</p>

<hr />

<p>So I dropped that fix. The temporary local variable approach is broken as well since
you can also name a constant the same as the local variable and have a clash (so again, you
need the underscores to avoid surprises).</p>

<p>But then I realized that we had an issue with removing the underscores from <code class="language-plaintext highlighter-rouge">__arg_0</code> as well.</p>

<p>The following code is also broken:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">pub</span> <span class="k">const</span> <span class="mi">__</span><span class="n">arg_0</span><span class="p">:</span> <span class="nb">u8</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="nd">#[derive(Debug)]</span>
<span class="k">struct</span> <span class="nf">Foo</span><span class="p">(</span><span class="nb">u8</span><span class="p">);</span>
</code></pre></div></div>

<p>(<a href="https://play.rust-lang.org/?gist=6e10fd8de1123c6f6f695c891e879f70&amp;version=stable">playpen</a>)</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>error[E0308]: mismatched types
 --&gt; src/main.rs:3:10
  |
3 | #[derive(Debug)]
  |          ^^^^^ expected mutable reference, found u8
  |
  = note: expected type `&amp;mut std::fmt::Formatter&lt;'_&gt;`
             found type `u8`
</code></pre></div></div>

<p>You can see a reduced version of this error in the following code:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">pub</span> <span class="k">const</span> <span class="mi">__</span><span class="n">arg_0</span><span class="p">:</span> <span class="nb">u8</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="k">fn</span> <span class="nf">foo</span><span class="p">(</span><span class="mi">__</span><span class="n">arg_0</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="p">{}</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>error[E0308]: mismatched types
 --&gt; src/main.rs:3:8
  |
3 | fn foo(__arg_0: bool) {}
  |        ^^^^^^^ expected bool, found u8
</code></pre></div></div>

<p>(<a href="https://play.rust-lang.org/?gist=2cf2c8b3520d5b343de1b76f80ea3fe7&amp;version=stable">playpen</a>)</p>

<p>This breakage is not an issue with the current code because of the double underscores – there’s a
very low chance someone will create a constant that is both lowercase and starts with a double
underscore. But it’s a problem when I remove the underscores since that chance shoots up.</p>

<p>Anyway, this failure is even weirder. Why are we attempting to match against the constant in the
first place? <code class="language-plaintext highlighter-rouge">fn</code> argument patterns<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">1</a></sup> are irrefutable, i.e. all possible values of the type should match
the argument. For example, <code class="language-plaintext highlighter-rouge">fn foo(Some(foo): Option&lt;u8&gt;) {}</code> will fail to compile with
“refutable pattern in function argument: <code class="language-plaintext highlighter-rouge">None</code> not covered”.</p>

<p>There’s no point trying to match against constants here; because even if we find a constant it will be rejected
later. Instead, we can unambiguously resolve identifiers as new bindings, yes?</p>

<p>Right?</p>

<p>Firm in my belief, <a href="https://github.com/rust-lang/rust/issues/49680">I filed an issue</a>.</p>

<p>I was wrong, it’s <a href="https://github.com/rust-lang/rust/issues/49680#issuecomment-379029404">not going to always be rejected later</a>. With zero-sized types this
can totally still work:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">struct</span> <span class="n">S</span><span class="p">;</span>

<span class="k">const</span> <span class="n">C</span><span class="p">:</span> <span class="n">S</span> <span class="o">=</span> <span class="n">S</span><span class="p">;</span>

<span class="k">fn</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">C</span> <span class="o">=</span> <span class="n">S</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Here because <code class="language-plaintext highlighter-rouge">S</code> has only one state, matching against a constant of the type is still irrefutable.</p>

<p>I argued that this doesn’t matter – since the type has a single value, it doesn’t matter whether we resolved to
a new binding or the constant; the value and semantics are the same.</p>

<p>This is true.</p>

<p>Except.</p>

<p><a href="https://github.com/rust-lang/rust/issues/49680#issuecomment-379032842">Except for when destructors come in</a>.</p>

<p>It was at this point that my table found itself in the perplexing state of being upside-down.</p>

<p>This is still really fine, zero-sized-constants-with-destructors is a pretty rare thing in Rust
and I don’t really see folks <em>relying</em> on this behavior.</p>

<p>However I later realized that this entire detour was pointless because even if we fix this, we end up
with a way for bindings to shadow constants. Which … which we already realized isn’t allowed by the
compiler till we fix some bugs.</p>

<p>Damn.</p>

<hr />

<p>The <em>actual</em> fix to the macro stuff is to use hygenic generated variable names, which the current
infrastructure supports. I plan to make a PR for this eventually.</p>

<p>But it was a very interesting dive into the nuances of pattern matching in Rust.</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>Yes, function arguments in Rust are patterns. You can totally do things like <code class="language-plaintext highlighter-rouge">(a, b): (u8, u8)</code> in function arguments (like you can do in <code class="language-plaintext highlighter-rouge">let</code>) <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A Rough Proposal for Sum Types in Go]]></title>
    <link href="http://manishearth.github.io/blog/2018/02/01/a-rough-proposal-for-sum-types-in-go/"/>
    <updated>2018-02-01T00:00:00+00:00</updated>
    <id>http://manishearth.github.io/blog/2018/02/01/a-rough-proposal-for-sum-types-in-go</id>
    <content type="html"><![CDATA[<p>Sum types are pretty cool. Just like how a struct is basically “This contains one of these <em>and</em> one of these”,
a sum type is “This contains one of these <em>or</em> one of these”.</p>

<p>So for example, the following sum type in Rust:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">enum</span> <span class="n">Foo</span> <span class="p">{</span>
    <span class="nf">Stringy</span><span class="p">(</span><span class="nb">String</span><span class="p">),</span>
    <span class="nf">Numerical</span><span class="p">(</span><span class="nb">u32</span><span class="p">)</span>
<span class="p">}</span>
</code></pre></div></div>

<p>or Swift:</p>

<div class="language-swift highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">enum</span> <span class="kt">Foo</span> <span class="p">{</span>
    <span class="k">case</span> <span class="nf">stringy</span><span class="p">(</span><span class="kt">String</span><span class="p">),</span>
    <span class="k">case</span> <span class="nf">numerical</span><span class="p">(</span><span class="kt">Int</span><span class="p">)</span>
<span class="p">}</span>
</code></pre></div></div>

<p>would be one where it’s either <code class="language-plaintext highlighter-rouge">Foo::Stringy</code> (<code class="language-plaintext highlighter-rouge">Foo::stringy</code> for swift), containing a <code class="language-plaintext highlighter-rouge">String</code>,
<em>or</em> <code class="language-plaintext highlighter-rouge">Foo::Numerical</code>, containing an integer.</p>

<p>This can be pretty useful. For example, messages between threads are often of a “this or that or that or that”
form.</p>

<p>The nice thing is, matching (switching) on these enums is usually <em>exhaustive</em> – you must list all
the cases (or include a default arm) for your code to compile. This leads to a useful component
of type safety – if you add a message to your message passing system, you’ll know where to update it.</p>

<p>Go doesn’t have these. Go <em>does</em> have interfaces, which are dynamically dispatched. The drawback here
is that you do not get the exhaustiveness condition, and consumers of your library can even add further
cases. (And, of course, dynamic dispatch can be slow). You <em>can</em> get exhaustiveness in Go with <a href="https://github.com/haya14busa/gosum">external tools</a>,
but it’s preferable to have such things in the language IMO.</p>

<p>Many years ago when I was learning Go I wrote a <a href="http://inpursuitoflaziness.blogspot.in/2015/02/thoughts-of-rustacean-learning-go.html">blog post</a> about what I liked and disliked
as a Rustacean learning Go. Since then, I’ve spent a lot more time with Go, and I’ve learned to like each Go design decision that I initially
disliked, <em>except</em> for the lack of sum types. Most of my issues arose from “trying to program Rust in Go”,
i.e. using idioms that are natural to Rust (or other languages I’d used previously). Once I got used to the
programming style, I realized that aside from the lack of sum types I really didn’t find much missing
from the language. Perhaps improvements to error handling.</p>

<p>Now, my intention here isn’t really to sell sum types. They’re somewhat controversial for Go, and
there are good arguments on both sides. You can see one discussion on this topic <a href="https://github.com/golang/go/issues/19412">here</a>.
If I were to make a more concrete proposal I’d probably try to motivate this in much more depth. But even
I’m not very <em>strongly</em> of the opinion that Go needs sum types; I have a slight preference for it.</p>

<p>Instead, I’m going to try and sketch this proposal for sum types that has been floating around my
mind for a while. I end up mentioning it often and it’s nice to have something to link to. Overall,
I think this “fits well” with the existing Go language design.</p>

<h2 id="the-proposal">The proposal</h2>

<p>The essence is pretty straightforward: Extend interfaces to allow for “closed interfaces”. These are
interfaces that are only implemented for a small list of types.</p>

<p>Writing the <code class="language-plaintext highlighter-rouge">Foo</code> sum type above would be:</p>

<div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">type</span> <span class="n">Foo</span> <span class="k">interface</span> <span class="p">{</span>
    <span class="n">SomeFunction</span><span class="p">()</span>
    <span class="n">OtherFunction</span><span class="p">()</span>
    <span class="k">for</span> <span class="kt">string</span><span class="p">,</span> <span class="kt">int</span>
<span class="p">}</span>
</code></pre></div></div>

<p>It doesn’t even need to have functions defined on it.</p>

<p>The interface functions can only be called if you have an interface object; they are not directly available
on variant types without explicitly casting (<code class="language-plaintext highlighter-rouge">Foo("...").SomeFunction()</code>).</p>

<p>(I’m not strongly for the <code class="language-plaintext highlighter-rouge">for</code> keyword syntax, it’s just a suggestion. The core idea is that
you define an interface and you define the types it closes over. Somehow.)</p>

<p>A better example would be an interface for a message-passing system for Raft:</p>

<div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">type</span> <span class="n">VoteRequest</span> <span class="k">struct</span> <span class="p">{</span>
    <span class="n">CandidateId</span> <span class="kt">uint</span>
    <span class="n">Term</span> <span class="kt">uint</span>
    <span class="c">// ...</span>
<span class="p">}</span>

<span class="k">type</span> <span class="n">VoteResponse</span> <span class="k">struct</span> <span class="p">{</span>
    <span class="n">Term</span> <span class="kt">uint</span>
    <span class="n">VoteGranted</span> <span class="kt">bool</span>
    <span class="n">VoterId</span> <span class="kt">uint</span>
<span class="p">}</span>

<span class="k">type</span> <span class="n">AppendRequest</span> <span class="k">struct</span> <span class="p">{</span>
    <span class="c">//...</span>
<span class="p">}</span>

<span class="k">type</span> <span class="n">AppendResponse</span> <span class="k">struct</span> <span class="p">{</span>
    <span class="c">//...</span>
<span class="p">}</span>
<span class="c">// ...</span>
<span class="k">type</span> <span class="n">RaftMessage</span> <span class="k">interface</span> <span class="p">{</span>
    <span class="k">for</span> <span class="n">VoteRequest</span><span class="p">,</span> <span class="n">VoteResponse</span><span class="p">,</span> <span class="n">AppendRequest</span><span class="p">,</span> <span class="n">AppendResponse</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Now, you use type switches for dealing with these:</p>

<div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">switch</span> <span class="n">value</span> <span class="o">:=</span> <span class="n">msg</span><span class="o">.</span><span class="p">(</span><span class="k">type</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">case</span> <span class="n">VoteRequest</span><span class="o">:</span>
        <span class="k">if</span> <span class="n">value</span><span class="o">.</span><span class="n">Term</span> <span class="o">&lt;=</span> <span class="n">me</span><span class="o">.</span><span class="n">Term</span> <span class="p">{</span>
            <span class="n">me</span><span class="o">.</span><span class="n">reject_vote</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">CandidateId</span><span class="p">)</span>
        <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
            <span class="n">me</span><span class="o">.</span><span class="n">accept_vote</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">CandidateId</span><span class="p">,</span> <span class="n">value</span><span class="o">.</span><span class="n">Term</span><span class="p">)</span>
        <span class="p">}</span>
    <span class="k">case</span> <span class="n">VoteResponse</span><span class="o">:</span> <span class="c">// ...</span>
    <span class="k">case</span> <span class="n">AppendRequest</span><span class="o">:</span> <span class="c">// ...</span>
    <span class="k">case</span> <span class="n">AppendResponse</span><span class="o">:</span> <span class="c">// ...</span>
<span class="p">}</span>
</code></pre></div></div>

<p>There is no need for the default case, unless you wish to leave one or more of the cases out.</p>

<p>Ideally, these could be implemented as inline structs instead of using dynamic dispatch. I’m not sure
what this entails for the GC design, but I’d love to hear thoughts on this.</p>

<p>We also make it possible to add methods to closed interfaces. This is in the spirit of
<a href="https://github.com/golang/go/issues/16254">this proposal</a>, where you allow</p>

<div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">func</span> <span class="p">(</span><span class="n">message</span> <span class="n">RaftMessage</span><span class="p">)</span> <span class="n">Process</span><span class="p">(</span><span class="n">me</span> <span class="n">Me</span><span class="p">)</span> <span class="kt">error</span> <span class="p">{</span>
    <span class="c">// message handling logic</span>
<span class="p">}</span>
</code></pre></div></div>

<p>for closed interfaces.</p>

<p>This aligns more with how sum types are written and used in other languages; instead of assuming
that each method will be a <code class="language-plaintext highlighter-rouge">switch</code> on the variant, you can write arbitrary code that <em>may</em> <code class="language-plaintext highlighter-rouge">switch</code>
on the type but it can also just call other methods. This is really nice because you can write
methods in <em>both</em> ways – if it’s a “responsibility of the inner type” kind of method, require it in
the interface and delegate it to the individual types. If it’s a “responsibility of the interface”
method, write it as a method on the interface as a whole. I kind of wish Rust had this, because in Rust
you sometimes end up writing things like:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">match</span> <span class="n">foo</span> <span class="p">{</span>
    <span class="nn">Foo</span><span class="p">::</span><span class="nf">Stringy</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="k">=&gt;</span> <span class="n">s</span><span class="nf">.process</span><span class="p">(),</span>
    <span class="nn">Foo</span><span class="p">::</span><span class="nf">Numerical</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="k">=&gt;</span> <span class="n">n</span><span class="nf">.process</span><span class="p">(),</span>
    <span class="c">// ...</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Yes, this would work better as a trait, but then you lose some niceties of Rust enums. With this
proposal Go can have it both ways.</p>

<hr />

<p>Anyway, thoughts? This is a really rough proposal, and I’m not sure how receptive other Gophers will be
to this, nor how complex its implementation would be. I don’t really intend to submit this as a formal proposal,
but if someone else wants to they are more than welcome to build on this idea.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[What Are Tokio and Async IO All About?]]></title>
    <link href="http://manishearth.github.io/blog/2018/01/10/whats-tokio-and-async-io-all-about/"/>
    <updated>2018-01-10T00:00:00+00:00</updated>
    <id>http://manishearth.github.io/blog/2018/01/10/whats-tokio-and-async-io-all-about</id>
    <content type="html"><![CDATA[<p>The Rust community lately has been focusing a lot on “async I/O” through the <a href="https://github.com/tokio-rs/">tokio</a>
project. This is pretty great!</p>

<p>But for many in the community who haven’t worked with web servers and related things it’s pretty
confusing as to what we’re trying to achieve there. When this stuff was being discussed around 1.0,
I was pretty lost as well, having never worked with this stuff before.</p>

<p>What’s all this Async I/O business about? What are coroutines? Lightweight threads? Futures? How
does this all fit together?</p>

<h2 id="what-problem-are-we-trying-to-solve">What problem are we trying to solve?</h2>

<p>One of Rust’s key features is “fearless concurrency”. But the kind of concurrency required for handling a
large amount of I/O bound tasks – the kind of concurrency found in Go, Elixir, Erlang – is absent
from Rust.</p>

<p>Let’s say you want to build something like a web service. It’s going to be handling thousands of
requests at any point in time (known as the “<a href="https://en.wikipedia.org/wiki/C10k_problem">c10k</a> problem”). In general, the problem we’re
considering is having a huge number of I/O bound (usually network I/O) tasks.</p>

<p>“Handling N things at once” is best done by using threads. But … <em>thousands</em> of threads? That
sounds a bit much. Threads can be pretty expensive: Each thread needs to allocate a large stack,
setting up a thread involves a bunch of syscalls, and context switching is expensive.</p>

<p>Of course, thousands of threads <em>all doing work</em> at once is not going to work anyway. You only
have a fixed number of cores, and at any one time only one thread will be running on a core.</p>

<p>But for cases like web servers, most of these threads won’t be doing work. They’ll be waiting on the
network. Most of these threads will either be listening for a request, or waiting for their response
to get sent.</p>

<p>With regular threads, when you perform a blocking I/O operation, the syscall returns control
to the kernel, which won’t yield control back, because the I/O operation is probably not finished.
Instead, it will use this as an opportunity to swap in a different thread, and will swap the original
thread back when its I/O operation is finished (i.e. it’s “unblocked”). Without Tokio and friends,
this is how you would handle such things in Rust. Spawn a million threads; let the OS deal with
scheduling based on I/O.</p>

<p>But, as we already discovered, threads don’t scale well for things like this<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">1</a></sup>.</p>

<p>We need “lighter” threads.</p>

<h2 id="lightweight-threading">Lightweight threading</h2>

<p>I think the best way to understand lightweight threading is to forget about Rust for a moment
and look at a language that does this well, Go.</p>

<p>Instead of using OS threads, Go has lightweight threads, called “goroutines”. You spawn these with the <code class="language-plaintext highlighter-rouge">go</code>
keyword. A web server might do something like this:</p>

<div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">listener</span><span class="p">,</span> <span class="n">err</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">Listen</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="c">// handle err</span>
<span class="k">for</span> <span class="p">{</span>
    <span class="n">conn</span><span class="p">,</span> <span class="n">err</span> <span class="o">:=</span> <span class="n">listener</span><span class="o">.</span><span class="n">Accept</span><span class="p">()</span>
    <span class="c">// handle err</span>

    <span class="c">// spawn goroutine:</span>
    <span class="k">go</span> <span class="n">handler</span><span class="p">(</span><span class="n">conn</span><span class="p">)</span>
<span class="p">}</span>
</code></pre></div></div>

<p>This is a loop which waits for new TCP connections, and spawns a goroutine with the connection
and the function <code class="language-plaintext highlighter-rouge">handler</code>. Each connection will be a new goroutine, and the goroutine will shut down
when <code class="language-plaintext highlighter-rouge">handler</code> finishes. In the meantime, the main loop continues executing, because it’s running in
a different goroutine.</p>

<p>So if these aren’t “real” (operating system) threads, what’s going on?</p>

<p>A goroutine is an example of a “lightweight” thread. The operating system doesn’t know about these,
it sees N threads owned by the Go runtime, and the Go runtime maps M goroutines onto them<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote">2</a></sup>, swapping
goroutines in and out much like the operating system scheduler. It’s able to do this because
Go code is already interruptible for the GC to be able to run, so the scheduler can always ask goroutines
to stop. The scheduler is also aware of I/O, so when a goroutine is waiting on I/O it yields to the scheduler.</p>

<p>Essentialy, a compiled Go function will have a bunch of points scattered throughout it where it
tells the scheduler and GC “take over if you want” (and also “I’m waiting on stuff, please take
over”).</p>

<p>When a goroutine is swapped on an OS thread, some registers will be saved, and
the program counter will switch to the new goroutine.</p>

<p>But what about its stack? OS threads have a large stack with them, and you kinda need a stack for functions
and stuff to work.</p>

<p>What Go used to do was segmented stacks. The reason a thread needs a large stack is that most
programming languages, including C, expect the stack to be contiguous, and stacks can’t just be
“reallocated” like we do with growable buffers since we expect stack data to stay put so that
pointers to stack data to continue to work. So we reserve all the stack we think we’ll ever need
(~8MB), and hope we don’t need more.</p>

<p>But the expectation of stacks being contiguous isn’t strictly necessary. In Go, stacks are made of tiny
chunks. When a function is called, it checks if there’s enough space on the stack for it to run, and if not,
allocates a new chunk of stack and runs on it. So if you have thousands of threads doing a small amount of work,
they’ll all get thousands of tiny stacks and it will be fine.</p>

<p>These days, Go actually does something different; it <a href="https://blog.cloudflare.com/how-stacks-are-handled-in-go/">copies stacks</a>. I mentioned that stacks can’t
just be “reallocated” we expect stack data to stay put. But that’s not necessarily true —
because Go has a GC it knows what all the pointers are <em>anyway</em>, and it can rewrite pointers to
stack data on demand.</p>

<p>Either way, Go’s rich runtime lets it handle this stuff well. Goroutines are super cheap, and you can spawn
thousands without your computer having problems.</p>

<p>Rust <em>used</em> to support lightweight/”green” threads (I believe it used segmented stacks). However, Rust cares
a lot about not paying for things you don’t use, and this imposes a penalty on all your code even if you
aren’t using green threads, and it was removed pre-1.0.</p>

<h2 id="async-io">Async I/O</h2>

<p>A core building block of this is Async I/O. As mentioned in the previous section,
with regular blocking I/O, the moment you request I/O your thread will not be allowed to run
(“blocked”) until the operation is done. This is perfect when working with OS threads (the OS
scheduler does all the work for you!), but if you have lightweight threads you instead want to
replace the lightweight thread running on the OS thread with a different one.</p>

<p>Instead, you use non-blocking I/O, where the thread queues a request for I/O with the OS and continues
execution. The I/O request is executed at some later point by the kernel. The thread then needs to ask the
OS “Is this I/O request ready yet?” before looking at the result of the I/O.</p>

<p>Of course, repeatedly asking the OS if it’s done can be tedious and consume resources. This is why
there are system calls like <a href="https://en.wikipedia.org/wiki/Epoll"><code class="language-plaintext highlighter-rouge">epoll</code></a>. Here, you can bundle together a bunch of unfinished I/O requests,
and then ask the OS to wake up your thread when <em>any</em> of these completes. So you can have a scheduler
thread (a real thread) that swaps out lightweight threads that are waiting on I/O, and when there’s nothing
else happening it can itself go to sleep with an <code class="language-plaintext highlighter-rouge">epoll</code> call until the OS wakes it up (when one of the I/O
requests completes).</p>

<p>(The exact mechanism involved here is probably more complex)</p>

<p>So, bringing this to Rust, Rust has the <a href="https://github.com/carllerche/mio">mio</a> library, which is a platform-agnostic
wrapper around non-blocking I/O and tools like epoll/kqueue/etc. It’s a building block; and while
those used to directly using <code class="language-plaintext highlighter-rouge">epoll</code> in C may find it helpful, it doesn’t provide a nice programming
model like Go does. But we can get there.</p>

<h2 id="futures">Futures</h2>

<p>These are another building block. A <a href="https://docs.rs/futures/0.1.17/futures/future/trait.Future.html"><code class="language-plaintext highlighter-rouge">Future</code></a> is the promise of eventually having a value
(in fact, in Javascript these are called <code class="language-plaintext highlighter-rouge">Promise</code>s).</p>

<p>So for example, you can ask to listen on a network socket, and get a <code class="language-plaintext highlighter-rouge">Future</code> back  (actually, a
<code class="language-plaintext highlighter-rouge">Stream</code>, which is like a future but for a sequence of values). This <code class="language-plaintext highlighter-rouge">Future</code> won’t contain the
response <em>yet</em>, but will know when it’s ready. You can <code class="language-plaintext highlighter-rouge">wait()</code> on a <code class="language-plaintext highlighter-rouge">Future</code>, which will block
until you have a result, and you can also <code class="language-plaintext highlighter-rouge">poll()</code> it, asking it if it’s done yet (it will give you
the result if it is).</p>

<p>Futures can also be chained, so you can do stuff like <code class="language-plaintext highlighter-rouge">future.then(|result| process(result))</code>.
The closure passed to <code class="language-plaintext highlighter-rouge">then</code> itself can produce another future, so you can chain together
things like I/O operations. With chained futures, <code class="language-plaintext highlighter-rouge">poll()</code> is how you make progress; each time
you call it it will move on to the next future provided the existing one is ready.</p>

<p>This is a pretty good abstraction over things like non-blocking I/O.</p>

<p>Chaining futures works much like chaining iterators. Each <code class="language-plaintext highlighter-rouge">and_then</code> (or whatever combinator)
call returns a struct wrapping around the inner future, which may contain an additional closure.
Closures themselves carry their references and data with them, so this really ends up being
very similar to a tiny stack!</p>

<h2 id="-tokio-">🗼 Tokio 🗼</h2>

<p>Tokio’s essentially a nice wrapper around mio that uses futures. Tokio has a core
event loop, and you feed it closures that return futures. What it will do is
run all the closures you feed it, use mio to efficiently figure out which futures
are ready to make a step<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote">3</a></sup>, and make progress on them (by calling <code class="language-plaintext highlighter-rouge">poll()</code>).</p>

<p>This actually is already pretty similar to what Go was doing, at a conceptual level.
You have to manually set up the Tokio event loop (the “scheduler”), but once you do
you can feed it tasks which intermittently do I/O, and the event loop takes
care of swapping over to a new task when one is blocked on I/O. A crucial difference is
that Tokio is single threaded, whereas the Go scheduler can use multiple OS threads
for execution. However, you can offload CPU-critical tasks onto other OS threads and
use channels to coordinate so this isn’t that big a deal.</p>

<p>While at a conceptual level this is beginning to shape up to be similar to what we had for Go, code-wise this doesn’t look so pretty. For the following Go code:</p>

<div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">// error handling ignored for simplicity</span>

<span class="k">func</span> <span class="n">foo</span><span class="p">(</span><span class="o">...</span><span class="p">)</span> <span class="n">ReturnType</span> <span class="p">{</span>
    <span class="n">data</span> <span class="o">:=</span> <span class="n">doIo</span><span class="p">()</span>
    <span class="n">result</span> <span class="o">:=</span> <span class="n">compute</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">moreData</span> <span class="o">=</span> <span class="n">doMoreIo</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
    <span class="n">moreResult</span> <span class="o">:=</span> <span class="n">moreCompute</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="c">// ...</span>
    <span class="k">return</span> <span class="n">someFinalResult</span>
<span class="p">}</span>
</code></pre></div></div>

<p>The Rust code will look something like</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">// error handling ignored for simplicity</span>

<span class="k">fn</span> <span class="nf">foo</span><span class="p">(</span><span class="o">...</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">Future</span><span class="o">&lt;</span><span class="n">ReturnType</span><span class="p">,</span> <span class="n">ErrorType</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="nf">do_io</span><span class="p">()</span><span class="nf">.and_then</span><span class="p">(|</span><span class="n">data</span><span class="p">|</span> <span class="nf">do_more_io</span><span class="p">(</span><span class="nf">compute</span><span class="p">(</span><span class="n">data</span><span class="p">)))</span>
          <span class="nf">.and_then</span><span class="p">(|</span><span class="n">more_data</span><span class="p">|</span> <span class="nf">do_even_more_io</span><span class="p">(</span><span class="nf">more_compute</span><span class="p">(</span><span class="n">more_data</span><span class="p">)))</span>
    <span class="c">// ......</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Not pretty. <a href="https://docs.rs/futures/0.1.25/futures/future/fn.loop_fn.html#examples">The code gets worse if you introduce branches and loops</a>. The problem is that in Go we
got the interruption points for free, but in Rust we have to encode this by chaining up combinators
into a kind of state machine. Ew.</p>

<h2 id="generators-and-asyncawait">Generators and async/await</h2>

<p>This is where generators (also called coroutines) come in.</p>

<p><a href="https://doc.rust-lang.org/nightly/unstable-book/language-features/generators.html">Generators</a> are an experimental feature in Rust. Here’s an example:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">let</span> <span class="k">mut</span> <span class="n">generator</span> <span class="o">=</span> <span class="p">||</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="k">loop</span> <span class="p">{</span>
        <span class="n">yield</span> <span class="n">i</span><span class="p">;</span>
        <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="p">}</span>
<span class="p">};</span>
<span class="nd">assert_eq!</span><span class="p">(</span><span class="n">generator</span><span class="nf">.resume</span><span class="p">(),</span> <span class="nn">GeneratorState</span><span class="p">::</span><span class="nf">Yielded</span><span class="p">(</span><span class="mi">0</span><span class="p">));</span>
<span class="nd">assert_eq!</span><span class="p">(</span><span class="n">generator</span><span class="nf">.resume</span><span class="p">(),</span> <span class="nn">GeneratorState</span><span class="p">::</span><span class="nf">Yielded</span><span class="p">(</span><span class="mi">1</span><span class="p">));</span>
<span class="nd">assert_eq!</span><span class="p">(</span><span class="n">generator</span><span class="nf">.resume</span><span class="p">(),</span> <span class="nn">GeneratorState</span><span class="p">::</span><span class="nf">Yielded</span><span class="p">(</span><span class="mi">2</span><span class="p">));</span>
</code></pre></div></div>

<p>Functions are things which execute a task and return once. On the other hand, generators
return multiple times; they pause execution to “yield” some data, and can be resumed
at which point they will run until the next yield. While my example doesn’t show this, generators
can also finish executing like regular functions.</p>

<p>Closures in Rust are
<a href="http://huonw.github.io/blog/2015/05/finding-closure-in-rust/">sugar for a struct containing captured data, plus an implementation of one of the <code class="language-plaintext highlighter-rouge">Fn</code> traits to make it callable</a>.</p>

<p>Generators are similar, except they implement the <code class="language-plaintext highlighter-rouge">Generator</code> trait<sup id="fnref:5" role="doc-noteref"><a href="#fn:5" class="footnote">4</a></sup>, and usually store an enum representing various states.</p>

<p>The <a href="https://doc.rust-lang.org/nightly/unstable-book/language-features/generators.html#generators-as-state-machines">unstable book</a> has some examples on what the generator state machine enum will look like.</p>

<p>This is much closer to what we were looking for! Now our code can look like this:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="nf">foo</span><span class="p">(</span><span class="o">...</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">Future</span><span class="o">&lt;</span><span class="n">ReturnType</span><span class="p">,</span> <span class="n">ErrorType</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">generator</span> <span class="o">=</span> <span class="p">||</span> <span class="p">{</span>
        <span class="k">let</span> <span class="k">mut</span> <span class="n">future</span> <span class="o">=</span> <span class="nf">do_io</span><span class="p">();</span>
        <span class="k">let</span> <span class="n">data</span><span class="p">;</span>
        <span class="k">loop</span> <span class="p">{</span>
            <span class="c">// poll the future, yielding each time it fails,</span>
            <span class="c">// but if it succeeds then move on</span>
            <span class="k">match</span> <span class="n">future</span><span class="nf">.poll</span><span class="p">()</span> <span class="p">{</span>
                <span class="nf">Ok</span><span class="p">(</span><span class="nn">Async</span><span class="p">::</span><span class="nf">Ready</span><span class="p">(</span><span class="n">d</span><span class="p">))</span> <span class="k">=&gt;</span> <span class="p">{</span> <span class="n">data</span> <span class="o">=</span> <span class="n">d</span><span class="p">;</span> <span class="k">break</span> <span class="p">},</span>
                <span class="nf">Ok</span><span class="p">(</span><span class="nn">Async</span><span class="p">::</span><span class="nf">NotReady</span><span class="p">(</span><span class="n">d</span><span class="p">))</span> <span class="k">=&gt;</span> <span class="p">(),</span>
                <span class="nf">Err</span><span class="p">(</span><span class="o">..</span><span class="p">)</span> <span class="k">=&gt;</span> <span class="o">...</span>
            <span class="p">};</span>
            <span class="n">yield</span> <span class="n">future</span><span class="nf">.polling_info</span><span class="p">();</span>
        <span class="p">}</span>
        <span class="k">let</span> <span class="n">result</span> <span class="o">=</span> <span class="nf">compute</span><span class="p">(</span><span class="n">data</span><span class="p">);</span>
        <span class="c">// do the same thing for `doMoreIo()`, etc</span>
    <span class="p">}</span>

    <span class="nf">futurify</span><span class="p">(</span><span class="n">generator</span><span class="p">)</span>
<span class="p">}</span>
</code></pre></div></div>

<p>where <code class="language-plaintext highlighter-rouge">futurify</code> is a function that takes a generator and returns a future which on
each <code class="language-plaintext highlighter-rouge">poll</code> call will <code class="language-plaintext highlighter-rouge">resume()</code> the generator, and return <code class="language-plaintext highlighter-rouge">NotReady</code> until the generator
finishes executing.</p>

<p>But wait, this is even <em>more</em> ugly! What was the point of converting our relatively
clean callback-chaining code into this mess?</p>

<p>Well, if you look at it, this code now looks <em>linear</em>. We’ve converted our callback
code to the same linear flow as the Go code, however it has this weird loop-yield boilerplate
and the <code class="language-plaintext highlighter-rouge">futurify</code> function and is overall not very neat.</p>

<p>And that’s where <a href="https://github.com/alexcrichton/futures-await">futures-await</a> comes in. <code class="language-plaintext highlighter-rouge">futures-await</code> is a procedural macro that
does the last-mile work of packaging away this boilerplate. It essentially lets you write
the above function as</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">#[async]</span>
<span class="k">fn</span> <span class="nf">foo</span><span class="p">(</span><span class="o">...</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">Result</span><span class="o">&lt;</span><span class="n">ReturnType</span><span class="p">,</span> <span class="n">ErrorType</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">data</span> <span class="o">=</span> <span class="k">await</span><span class="o">!</span><span class="p">(</span><span class="nf">do_io</span><span class="p">());</span>
    <span class="k">let</span> <span class="n">result</span> <span class="o">=</span> <span class="nf">compute</span><span class="p">(</span><span class="n">data</span><span class="p">);</span>
    <span class="k">let</span> <span class="n">more_data</span> <span class="o">=</span> <span class="k">await</span><span class="o">!</span><span class="p">(</span><span class="nf">do_more_io</span><span class="p">());</span>
    <span class="c">// ....</span>
</code></pre></div></div>

<p>Nice and clean. Almost as clean as the Go code, just that we have explicit <code class="language-plaintext highlighter-rouge">await!()</code> calls. These
await calls are basically providing the same function as the interruption points that Go code
gets implicitly.</p>

<p>And, of course, since it’s using a generator under the hood, you can loop and branch and do whatever
else you want as normal, and the code will still be clean.</p>

<h2 id="tying-it-together">Tying it together</h2>

<p>So, in Rust, futures can be chained together to provide a lightweight stack-like system. With async/await,
you can neatly write these future chains, and <code class="language-plaintext highlighter-rouge">await</code> provides explicit interruption points on each I/O operation.
Tokio provides an event loop “scheduler” abstraction, which you can feed async functions to, and under the hood it
uses mio to abstract over low level non-blocking I/O primitives.</p>

<p>These are components which can be used independently — you can use tokio with futures without
using async/await. You can use async/await without using Tokio. For example, I think this would be
useful for Servo’s networking stack. It doesn’t need to do <em>much</em> parallel I/O (not at the order
of thousands of threads), so it can just use multiplexed OS threads. However, we’d still want
to pool threads and pipeline data well, and async/await would help here.</p>

<p>Put together, all these components get something almost as clean as the Go stuff, with a little more
explicit boilerplate. Because generators (and thus async/await) play nice with the borrow checker
(they’re just enum state machines under the hood), Rust’s safety guarantees are all still in play,
and we get to have “fearless concurrency” for programs having a huge quantity of I/O bound tasks!</p>

<p><em>Thanks to Arshia Mufti, Steve Klabnik, Zaki Manian, and Kyle Huey for reviewing drafts of this post</em></p>
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>Note that this isn’t necessarily true for <em>all</em> network server applications. For example, Apache uses OS threads. OS threads are often the best tool for the job. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>Lightweight threading is also often called M:N threading (also “green threading”) <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>In general future combinators aren’t really aware of tokio or even I/O, so there’s no easy way to ask a combinator “hey, what I/O operation are you waiting for?”. Instead, with Tokio you use special I/O primitives that still provide futures but also register themselves with the scheduler in thread local state. This way when a future is waiting for I/O, Tokio can check what the recentmost I/O operation was, and associate it with that future so that it can wake up that future again when <code class="language-plaintext highlighter-rouge">epoll</code> tells it that that I/O operation is ready. (<em>Edit Dec 2018: This has changed, futures now have a built in <code class="language-plaintext highlighter-rouge">Waker</code> concept that handles passing things up the stack</em>) <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:5" role="doc-endnote">
      <p>The <code class="language-plaintext highlighter-rouge">Generator</code> trait has a <code class="language-plaintext highlighter-rouge">resume()</code> function which you can call multiple times, and each time it will return any yielded data or tell you that the generator has finished running. <a href="#fnref:5" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
  </entry>
  
</feed>
